<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小旋锋</title>
  
  <subtitle>更努力，只为了我们想要的明天</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://laijianfeng.org/"/>
  <updated>2018-09-19T17:14:18.546Z</updated>
  <id>http://laijianfeng.org/</id>
  
  <author>
    <name>小旋锋</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>设计模式 | 适配器模式及典型应用</title>
    <link href="http://laijianfeng.org/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
    <id>http://laijianfeng.org/2018/09/设计模式-适配器模式及典型应用/</id>
    <published>2018-09-19T17:00:54.000Z</published>
    <updated>2018-09-19T17:14:18.546Z</updated>
    
    <content type="html"><![CDATA[<h2 id="适配器模式"><a href="#适配器模式" class="headerlink" title="适配器模式"></a>适配器模式</h2><p><strong>适配器模式(Adapter Pattern)</strong>：将一个接口转换成客户希望的另一个接口，使接口不兼容的那些类可以一起工作，其别名为包装器(Wrapper)。适配器模式既可以作为类结构型模式，也可以作为对象结构型模式。</p><p>在适配器模式中，我们通过增加一个新的适配器类来解决接口不兼容的问题，使得原本没有任何关系的类可以协同工作。</p><p>根据适配器类与适配者类的关系不同，适配器模式可分为对象适配器和类适配器两种，在<strong>对象适配器模式</strong>中，适配器与适配者之间是<strong>关联</strong>关系；在<strong>类适配器模式</strong>中，适配器与适配者之间是<strong>继承</strong>（或实现）关系。</p><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><p><strong>Target（目标抽象类）</strong>：目标抽象类定义客户所需接口，可以是一个抽象类或接口，也可以是具体类。</p><p><strong>Adapter（适配器类）</strong>：适配器可以调用另一个接口，作为一个转换器，对Adaptee和Target进行适配，适配器类是适配器模式的核心，在对象适配器中，它通过继承Target并关联一个Adaptee对象使二者产生联系。</p><p><strong>Adaptee（适配者类）</strong>：适配者即被适配的角色，它定义了一个已经存在的接口，这个接口需要适配，适配者类一般是一个具体类，包含了客户希望使用的业务方法，在某些情况下可能没有适配者类的源代码。</p><blockquote><p>缺省适配器模式(Default Adapter Pattern)：当不需要实现一个接口所提供的所有方法时，可先设计一个抽象类实现该接口，并为接口中每个方法提供一个默认实现（空方法），那么该抽象类的子类可以选择性地覆盖父类的某些方法来实现需求，它适用于不想使用一个接口中的所有方法的情况，又称为单接口适配器模式。缺省适配器模式是适配器模式的一种变体，其应用也较为广泛。在JDK类库的事件处理包java.awt.event中广泛使用了缺省适配器模式，如WindowAdapter、KeyAdapter、MouseAdapter等。</p></blockquote><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><h3 id="类适配器"><a href="#类适配器" class="headerlink" title="类适配器"></a>类适配器</h3><p>首先有一个已存在的将被适配的类</p><pre><code>public class Adaptee {    public void adapteeRequest() {        System.out.println(&quot;被适配者的方法&quot;);    }}</code></pre><p>定义一个目标接口</p><pre><code>public interface Target {    void request();}</code></pre><p>怎么才可以在目标接口中的 <code>request()</code> 调用 <code>Adaptee</code> 的 <code>adapteeRequest()</code> 方法呢？</p><p>如果直接实现 <code>Target</code> 是不行的</p><pre><code>public class ConcreteTarget implements Target {    @Override    public void request() {        System.out.println(&quot;concreteTarget目标方法&quot;);    }}</code></pre><p>如果通过一个适配器类，实现 <code>Target</code> 接口，同时继承了 <code>Adaptee</code> 类，然后在实现的 <code>request()</code> 方法中调用父类的 <code>adapteeRequest()</code> 即可实现</p><pre><code>public class Adapter extends Adaptee implements Target{    @Override    public void request() {        //...一些操作...        super.adapteeRequest();        //...一些操作...    }}</code></pre><p>我们来测试一下</p><pre><code>public class Test {    public static void main(String[] args) {        Target target = new ConcreteTarget();        target.request();        Target adapterTarget = new Adapter();        adapterTarget.request();    }}</code></pre><p>输出</p><pre><code>concreteTarget目标方法被适配者的方法</code></pre><p><img src="http://image.laijianfeng.org/Package%20classadapter.png" alt="类适配器模式类图"></p><p>这样我们即可在新接口 <code>Target</code> 中适配旧的接口或类</p><h3 id="对象适配器"><a href="#对象适配器" class="headerlink" title="对象适配器"></a>对象适配器</h3><p>对象适配器与类适配器不同之处在于，类适配器通过继承来完成适配，对象适配器则是通过关联来完成，这里稍微修改一下 <code>Adapter</code> 类即可将转变为对象适配器</p><pre><code>public class Adapter implements Target{    // 适配者是对象适配器的一个属性    private Adaptee adaptee = new Adaptee();    @Override    public void request() {        //...        adaptee.adapteeRequest();        //...    }}</code></pre><p><img src="http://image.laijianfeng.org/20180919Package_objectadapter.png" alt="对象适配器模式类图"></p><p>注意这里的 <code>Adapter</code> 是将 <code>Adaptee</code> 作为一个成员属性，而不是继承它</p><h3 id="电压适配器"><a href="#电压适配器" class="headerlink" title="电压适配器"></a>电压适配器</h3><p>再来一个好理解的例子，我们国家的民用电都是 220V，日本是 110V，而我们的手机充电一般需要 5V，这时候要充电，就需要一个电压适配器，将 220V 或者 100V 的输入电压变换为 5V 输出</p><p>定义输出交流电接口，输出220V交流电类和输出110V交流电类</p><pre><code>public interface AC {    int outputAC();}public class AC110 implements AC {    public final int output = 110;    @Override    public int outputAC() {        return output;    }}public class AC220 implements AC {    public final int output = 220;    @Override    public int outputAC() {        return output;    }}</code></pre><p>适配器接口，其中 <code>support()</code> 方法用于检查输入的电压是否与适配器匹配，<code>outputDC5V()</code> 方法则用于将输入的电压变换为 5V 后输出 </p><pre><code>public interface DC5Adapter {    boolean support(AC ac);    int outputDC5V(AC ac);}</code></pre><p>实现中国变压适配器和日本变压适配器</p><pre><code>public class ChinaPowerAdapter implements DC5Adapter {    public static final int voltage = 220;    @Override    public boolean support(AC ac) {        return (voltage == ac.outputAC());    }    @Override    public int outputDC5V(AC ac) {        int adapterInput = ac.outputAC();        //变压器...        int adapterOutput = adapterInput / 44;        System.out.println(&quot;使用ChinaPowerAdapter变压适配器，输入AC:&quot; + adapterInput + &quot;V&quot; + &quot;，输出DC:&quot; + adapterOutput + &quot;V&quot;);        return adapterOutput;    }}public class JapanPowerAdapter implements DC5Adapter {    public static final int voltage = 110;    @Override    public boolean support(AC ac) {        return (voltage == ac.outputAC());    }    @Override    public int outputDC5V(AC ac) {        int adapterInput = ac.outputAC();        //变压器...        int adapterOutput = adapterInput / 22;        System.out.println(&quot;使用JapanPowerAdapter变压适配器，输入AC:&quot; + adapterInput + &quot;V&quot; + &quot;，输出DC:&quot; + adapterOutput + &quot;V&quot;);        return adapterOutput;    }}</code></pre><p>测试，准备中国变压适配器和日本变压适配器各一个，定义一个方法可以根据电压找到合适的变压器，然后进行测试</p><pre><code>public class Test {    private List&lt;DC5Adapter&gt; adapters = new LinkedList&lt;DC5Adapter&gt;();    public Test() {        this.adapters.add(new ChinaPowerAdapter());        this.adapters.add(new JapanPowerAdapter());    }    // 根据电压找合适的变压器    public DC5Adapter getPowerAdapter(AC ac) {        DC5Adapter adapter = null;        for (DC5Adapter ad : this.adapters) {            if (ad.support(ac)) {                adapter = ad;                break;            }        }        if (adapter == null){            throw new  IllegalArgumentException(&quot;没有找到合适的变压适配器&quot;);        }        return adapter;    }    public static void main(String[] args) {        Test test = new Test();        AC chinaAC = new AC220();        DC5Adapter adapter = test.getPowerAdapter(chinaAC);        adapter.outputDC5V(chinaAC);        // 去日本旅游，电压是 110V        AC japanAC = new AC110();        adapter = test.getPowerAdapter(japanAC);        adapter.outputDC5V(japanAC);    }}</code></pre><p>输出</p><pre><code>使用ChinaPowerAdapter变压适配器，输入AC:220V，输出DC:5V使用JapanPowerAdapter变压适配器，输入AC:110V，输出DC:5V</code></pre><h2 id="适配器模式总结"><a href="#适配器模式总结" class="headerlink" title="适配器模式总结"></a>适配器模式总结</h2><p><strong>主要优点</strong>：</p><ol><li>将目标类和适配者类解耦，通过引入一个适配器类来重用现有的适配者类，无须修改原有结构。</li><li>增加了类的透明性和复用性，将具体的业务实现过程封装在适配者类中，对于客户端类而言是透明的，而且提高了适配者的复用性，同一个适配者类可以在多个不同的系统中复用。</li><li>灵活性和扩展性都非常好，通过使用配置文件，可以很方便地更换适配器，也可以在不修改原有代码的基础上增加新的适配器类，完全符合“开闭原则”。</li></ol><p>具体来说，类适配器模式还有如下优点：</p><ul><li>由于适配器类是适配者类的子类，因此可以在适配器类中置换一些适配者的方法，使得适配器的灵活性更强。</li></ul><p>对象适配器模式还有如下优点：</p><ul><li>一个对象适配器可以把多个不同的适配者适配到同一个目标；</li><li>可以适配一个适配者的子类，由于适配器和适配者之间是关联关系，根据“里氏代换原则”，适配者的子类也可通过该适配器进行适配。</li></ul><p>类适配器模式的缺点如下：</p><ol><li>对于Java、C#等不支持多重类继承的语言，一次最多只能适配一个适配者类，不能同时适配多个适配者；</li><li>适配者类不能为最终类，如在Java中不能为final类，C#中不能为sealed类；</li><li>在Java、C#等语言中，类适配器模式中的目标抽象类只能为接口，不能为类，其使用有一定的局限性。</li></ol><p>对象适配器模式的缺点如下：</p><p>与类适配器模式相比，要在适配器中置换适配者类的某些方法比较麻烦。如果一定要置换掉适配者类的一个或多个方法，可以先做一个适配者类的子类，将适配者类的方法置换掉，然后再把适配者类的子类当做真正的适配者进行适配，实现过程较为复杂。</p><p><strong>适用场景</strong>：</p><ul><li>系统需要使用一些现有的类，而这些类的接口（如方法名）不符合系统的需要，甚至没有这些类的源代码。</li><li>想创建一个可以重复使用的类，用于与一些彼此之间没有太大关联的一些类，包括一些可能在将来引进的类一起工作。</li></ul><h2 id="源码分析适配器模式的典型应用"><a href="#源码分析适配器模式的典型应用" class="headerlink" title="源码分析适配器模式的典型应用"></a>源码分析适配器模式的典型应用</h2><h3 id="spring-AOP中的适配器模式"><a href="#spring-AOP中的适配器模式" class="headerlink" title="spring AOP中的适配器模式"></a>spring AOP中的适配器模式</h3><p>在Spring的Aop中，使用的 <code>Advice（通知）</code> 来增强被代理类的功能。<code>Advice</code>的类型有：<code>MethodBeforeAdvice</code>、<code>AfterReturningAdvice</code>、<code>ThrowsAdvice</code> ，在每个类型 <code>Advice</code> 都有对应的拦截器，<code>MethodBeforeAdviceInterceptor</code>、<code>AfterReturningAdviceInterceptor</code>、<code>ThrowsAdviceInterceptor</code>。Spring需要将每个 <code>Advice</code> <strong>都封装成对应的拦截器类型</strong>，返回给容器，所以需要使用适配器模式对 <code>Advice</code> 进行转换。</p><p>三个适配者类 Adaptee 如下：</p><pre><code>public interface MethodBeforeAdvice extends BeforeAdvice {    void before(Method var1, Object[] var2, @Nullable Object var3) throws Throwable;}public interface AfterReturningAdvice extends AfterAdvice {    void afterReturning(@Nullable Object var1, Method var2, Object[] var3, @Nullable Object var4) throws Throwable;}public interface ThrowsAdvice extends AfterAdvice {}</code></pre><p>目标接口 Target，有两个方法，一个判断 <code>Advice</code> 类型是否匹配，一个是工厂方法，创建对应类型的 <code>Advice</code> 对应的拦截器</p><pre><code>public interface AdvisorAdapter {    boolean supportsAdvice(Advice var1);    MethodInterceptor getInterceptor(Advisor var1);}</code></pre><p>三个适配器类 Adapter 分别如下，注意其中的 Advice、Adapter、Interceptor之间的对应关系</p><pre><code>class MethodBeforeAdviceAdapter implements AdvisorAdapter, Serializable {    @Override    public boolean supportsAdvice(Advice advice) {        return (advice instanceof MethodBeforeAdvice);    }    @Override    public MethodInterceptor getInterceptor(Advisor advisor) {        MethodBeforeAdvice advice = (MethodBeforeAdvice) advisor.getAdvice();        return new MethodBeforeAdviceInterceptor(advice);    }}@SuppressWarnings(&quot;serial&quot;)class AfterReturningAdviceAdapter implements AdvisorAdapter, Serializable {    @Override    public boolean supportsAdvice(Advice advice) {        return (advice instanceof AfterReturningAdvice);    }    @Override    public MethodInterceptor getInterceptor(Advisor advisor) {        AfterReturningAdvice advice = (AfterReturningAdvice) advisor.getAdvice();        return new AfterReturningAdviceInterceptor(advice);    }}class ThrowsAdviceAdapter implements AdvisorAdapter, Serializable {    @Override    public boolean supportsAdvice(Advice advice) {        return (advice instanceof ThrowsAdvice);    }    @Override    public MethodInterceptor getInterceptor(Advisor advisor) {        return new ThrowsAdviceInterceptor(advisor.getAdvice());    }}</code></pre><p>客户端 DefaultAdvisorAdapterRegistry</p><pre><code>public class DefaultAdvisorAdapterRegistry implements AdvisorAdapterRegistry, Serializable {    private final List&lt;AdvisorAdapter&gt; adapters = new ArrayList(3);    public DefaultAdvisorAdapterRegistry() {        // 这里注册了适配器        this.registerAdvisorAdapter(new MethodBeforeAdviceAdapter());        this.registerAdvisorAdapter(new AfterReturningAdviceAdapter());        this.registerAdvisorAdapter(new ThrowsAdviceAdapter());    }    public MethodInterceptor[] getInterceptors(Advisor advisor) throws UnknownAdviceTypeException {        List&lt;MethodInterceptor&gt; interceptors = new ArrayList(3);        Advice advice = advisor.getAdvice();        if (advice instanceof MethodInterceptor) {            interceptors.add((MethodInterceptor)advice);        }        Iterator var4 = this.adapters.iterator();        while(var4.hasNext()) {            AdvisorAdapter adapter = (AdvisorAdapter)var4.next();            if (adapter.supportsAdvice(advice)) {   // 这里调用适配器方法                interceptors.add(adapter.getInterceptor(advisor));  // 这里调用适配器方法            }        }        if (interceptors.isEmpty()) {            throw new UnknownAdviceTypeException(advisor.getAdvice());        } else {            return (MethodInterceptor[])interceptors.toArray(new MethodInterceptor[0]);        }    }    // ...省略...}    </code></pre><p>这里看 while 循环里，逐个取出注册的适配器，调用 <code>supportsAdvice()</code> 方法来判断 <code>Advice</code> 对应的类型，然后调用 <code>getInterceptor()</code> 创建对应类型的拦截器</p><p><img src="http://image.laijianfeng.org/20180919_2217.jpg" alt="spring aop 适配器模式"></p><p>这里应该属于对象适配器模式，关键字 <code>instanceof</code> 可看成是 <code>Advice</code> 的方法，不过这里的 <code>Advice</code> 对象是从外部传进来，而不是成员属性</p><h3 id="spring-JPA中的适配器模式"><a href="#spring-JPA中的适配器模式" class="headerlink" title="spring JPA中的适配器模式"></a>spring JPA中的适配器模式</h3><p>在Spring的ORM包中，对于JPA的支持也是采用了适配器模式，首先定义了一个接口的 <code>JpaVendorAdapter</code>，然后不同的持久层框架都实现此接口。</p><p>jpaVendorAdapter：用于设置实现厂商JPA实现的特定属性，如设置Hibernate的是否自动生成DDL的属性generateDdl；这些属性是厂商特定的，因此最好在这里设置；目前Spring提供 <code>HibernateJpaVendorAdapter</code>、<code>OpenJpaVendorAdapter</code>、<code>EclipseLinkJpaVendorAdapter</code>、<code>TopLinkJpaVendorAdapter</code> 四个实现。其中最重要的属性是 database，用来指定使用的数据库类型，从而能<strong>根据数据库类型来决定比如如何将数据库特定异常转换为Spring的一致性异常</strong>，目前支持如下数据库（DB2、DERBY、H2、HSQL、INFORMIX、MYSQL、ORACLE、POSTGRESQL、SQL_SERVER、SYBASE）</p><pre><code>public interface JpaVendorAdapter{  // 返回一个具体的持久层提供者  public abstract PersistenceProvider getPersistenceProvider();  // 返回持久层提供者的包名  public abstract String getPersistenceProviderRootPackage();  // 返回持久层提供者的属性  public abstract Map&lt;String, ?&gt; getJpaPropertyMap();  // 返回JpaDialect  public abstract JpaDialect getJpaDialect();  // 返回持久层管理器工厂  public abstract Class&lt;? extends EntityManagerFactory&gt; getEntityManagerFactoryInterface();  // 返回持久层管理器  public abstract Class&lt;? extends EntityManager&gt; getEntityManagerInterface();  // 自定义回调方法  public abstract void postProcessEntityManagerFactory(EntityManagerFactory paramEntityManagerFactory);}</code></pre><p>我们来看其中一个适配器实现类 HibernateJpaVendorAdapter</p><pre><code>public class HibernateJpaVendorAdapter extends AbstractJpaVendorAdapter {    //设定持久层提供者    private final PersistenceProvider persistenceProvider;    //设定持久层方言    private final JpaDialect jpaDialect;    public HibernateJpaVendorAdapter() {        this.persistenceProvider = new HibernatePersistence();        this.jpaDialect = new HibernateJpaDialect();    }    //返回持久层方言    public PersistenceProvider getPersistenceProvider() {        return this.persistenceProvider;    }    //返回持久层提供者    public String getPersistenceProviderRootPackage() {        return &quot;org.hibernate&quot;;    }    //返回JPA的属性    public Map&lt;String, Object&gt; getJpaPropertyMap() {        Map jpaProperties = new HashMap();        if (getDatabasePlatform() != null) {            jpaProperties.put(&quot;hibernate.dialect&quot;, getDatabasePlatform());        } else if (getDatabase() != null) {            Class databaseDialectClass = determineDatabaseDialectClass(getDatabase());            if (databaseDialectClass != null) {                jpaProperties.put(&quot;hibernate.dialect&quot;,                        databaseDialectClass.getName());            }        }        if (isGenerateDdl()) {            jpaProperties.put(&quot;hibernate.hbm2ddl.auto&quot;, &quot;update&quot;);        }        if (isShowSql()) {            jpaProperties.put(&quot;hibernate.show_sql&quot;, &quot;true&quot;);        }        return jpaProperties;    }    //设定数据库    protected Class determineDatabaseDialectClass(Database database)         {                                                                                               switch (1.$SwitchMap$org$springframework$orm$jpa$vendor$Database[database.ordinal()])         {                                                                                             case 1:                                                                                       return DB2Dialect.class;                                                                    case 2:                                                                                         return DerbyDialect.class;                                                                  case 3:                                                                                         return H2Dialect.class;                                                                     case 4:                                                                                         return HSQLDialect.class;                                                                   case 5:                                                                                         return InformixDialect.class;                                                               case 6:                                                                                         return MySQLDialect.class;                                                                  case 7:                                                                                         return Oracle9iDialect.class;                                                               case 8:                                                                                         return PostgreSQLDialect.class;                                                             case 9:                                                                                         return SQLServerDialect.class;                                                              case 10:                                                                                        return SybaseDialect.class; }                                                               return null;                  }    //返回JPA方言    public JpaDialect getJpaDialect() {        return this.jpaDialect;    }    //返回JPA实体管理器工厂    public Class&lt;? extends EntityManagerFactory&gt; getEntityManagerFactoryInterface() {        return HibernateEntityManagerFactory.class;    }    //返回JPA实体管理器    public Class&lt;? extends EntityManager&gt; getEntityManagerInterface() {        return HibernateEntityManager.class;    }}</code></pre><p>配置文件中可以这样指定</p><pre><code>&lt;bean id=&quot;jpaVendorAdapter&quot; class=&quot;org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter&quot;&gt;    &lt;property name=&quot;generateDdl&quot; value=&quot;false&quot; /&gt;     &lt;property name=&quot;database&quot; value=&quot;HSQL&quot;/&gt;  &lt;/bean&gt;  &lt;bean id=&quot;jpaDialect&quot; class=&quot;org.springframework.orm.jpa.vendor.HibernateJpaDialect&quot;/&gt;  </code></pre><h3 id="spring-MVC中的适配器模式"><a href="#spring-MVC中的适配器模式" class="headerlink" title="spring MVC中的适配器模式"></a>spring MVC中的适配器模式</h3><p>Spring MVC中的适配器模式主要用于执行目标 <code>Controller</code> 中的请求处理方法。</p><p>在Spring MVC中，<code>DispatcherServlet</code> 作为用户，<code>HandlerAdapter</code> 作为期望接口，具体的适配器实现类用于对目标类进行适配，<code>Controller</code> 作为需要适配的类。</p><p>为什么要在 Spring MVC 中使用适配器模式？Spring MVC 中的 <code>Controller</code> 种类众多，不同类型的 <code>Controller</code> 通过不同的方法来对请求进行处理。如果不利用适配器模式的话，<code>DispatcherServlet</code> 直接获取对应类型的 <code>Controller</code>，需要的自行来判断，像下面这段代码一样：</p><pre><code>if(mappedHandler.getHandler() instanceof MultiActionController){     ((MultiActionController)mappedHandler.getHandler()).xxx  }else if(mappedHandler.getHandler() instanceof XXX){      ...  }else if(...){     ...  }  </code></pre><p>这样假设如果我们增加一个 <code>HardController</code>,就要在代码中加入一行 <code>if(mappedHandler.getHandler() instanceof HardController)</code>，这种形式就使得程序难以维护，也违反了设计模式中的开闭原则 – 对扩展开放，对修改关闭。</p><p>我们来看看源码，首先是适配器接口 <code>HandlerAdapter</code></p><pre><code>public interface HandlerAdapter {    boolean supports(Object var1);    ModelAndView handle(HttpServletRequest var1, HttpServletResponse var2, Object var3) throws Exception;    long getLastModified(HttpServletRequest var1, Object var2);}</code></pre><p>现该接口的适配器每一个 <code>Controller</code> 都有一个适配器与之对应，这样的话，每自定义一个 <code>Controller</code> 需要定义一个实现 <code>HandlerAdapter</code> 的适配器。</p><p>springmvc 中提供的 <code>Controller</code> 实现类有如下</p><p><img src="http://image.laijianfeng.org/20180919_233327.png" alt="spring mvc Controller 提供的实现类"></p><p>springmvc 中提供的 <code>HandlerAdapter</code> 实现类如下</p><p><img src="http://image.laijianfeng.org/20180919_234325.png" alt="spring mvc HandlerAdapter 提供的实现类"></p><p><code>HttpRequestHandlerAdapter</code> 这个适配器代码如下</p><pre><code>public class HttpRequestHandlerAdapter implements HandlerAdapter {    public HttpRequestHandlerAdapter() {    }    public boolean supports(Object handler) {        return handler instanceof HttpRequestHandler;    }    public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {        ((HttpRequestHandler)handler).handleRequest(request, response);        return null;    }    public long getLastModified(HttpServletRequest request, Object handler) {        return handler instanceof LastModified ? ((LastModified)handler).getLastModified(request) : -1L;    }}</code></pre><p>当Spring容器启动后，会将所有定义好的适配器对象存放在一个List集合中，当一个请求来临时，<code>DispatcherServlet</code> 会通过 <code>handler</code> 的类型找到对应适配器，并将该适配器对象返回给用户，然后就可以统一通过适配器的 <code>hanle()</code> 方法来调用 <code>Controller</code> 中的用于处理请求的方法。</p><pre><code>public class DispatcherServlet extends FrameworkServlet {    private List&lt;HandlerAdapter&gt; handlerAdapters;    //初始化handlerAdapters    private void initHandlerAdapters(ApplicationContext context) {        //..省略...    }    // 遍历所有的 HandlerAdapters，通过 supports 判断找到匹配的适配器    protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException {        for (HandlerAdapter ha : this.handlerAdapters) {            if (logger.isTraceEnabled()) {                logger.trace(&quot;Testing handler adapter [&quot; + ha + &quot;]&quot;);            }            if (ha.supports(handler)) {                return ha;            }        }    }    // 分发请求，请求需要找到匹配的适配器来处理    protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception {        HttpServletRequest processedRequest = request;        HandlerExecutionChain mappedHandler = null;        // Determine handler for the current request.        mappedHandler = getHandler(processedRequest);        // 确定当前请求的匹配的适配器.        HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler());        ha.getLastModified(request, mappedHandler.getHandler());        mv = ha.handle(processedRequest, response, mappedHandler.getHandler());    }    // ...省略...}    </code></pre><p>通过适配器模式我们将所有的 <code>controller</code> 统一交给 <code>HandlerAdapter</code> 处理，免去了写大量的 <code>if-else</code> 语句对 <code>Controller</code> 进行判断，也更利于扩展新的 <code>Controller</code> 类型。</p><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析<br>孤落:<a href="https://blog.csdn.net/lu__peng/article/details/79117894" target="_blank" rel="noopener">Spring MVC中的适配器模式</a><br>ToughMind_：<a href="https://blog.csdn.net/liuquan0071/article/details/50506121" target="_blank" rel="noopener">深入浅出设计模式（五）：7.适配器模式</a>   </p></blockquote><h3 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h3><p><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483700&amp;idx=1&amp;sn=dd4d23f9400c8be248f5d125465ba941&amp;chksm=e9c2ed39deb5642fb809eca1351f00995f06c9a4875f09986cc5005059eff74d6c20fc1118a3&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 简单工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483704&amp;idx=1&amp;sn=fa3ae947cebf22da35e6ac0a37f566f8&amp;chksm=e9c2ed35deb564230a69e43d93a3b74618287c6ddd402a6f1dc6a5b14a896e99584985e7cf92&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 工厂方法模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483708&amp;idx=1&amp;sn=9b8c155b86511ea6ec323dc6a72c52df&amp;chksm=e9c2ed31deb56427b2a6bbcbad5bdd3a4ef68b52eb88cc47b5bcfc76773d3d983d8aaf57761c&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 抽象工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483712&amp;idx=1&amp;sn=1ffd9837eb9413dde74ff509bf69ecc5&amp;chksm=e9c2ed4ddeb5645b8cbf64c83d103a859ae49921c60e17fe8bebe63c26b04966be101d598848&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 建造者模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483716&amp;idx=1&amp;sn=df00c297c8f32e10e277db8941839c14&amp;chksm=e9c2ed49deb5645fa2586da358a8f0a00dd926f883637adebc59435f846c67c040ef759ba034&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 原型模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483721&amp;idx=1&amp;sn=721d0bce3bd516c10d4b6addbf3eced6&amp;chksm=e9c2ed44deb56452395c94a0b150994b94aa26cae71149e6c030d0ac32f9c3c37e2bfe9685b6&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 外观模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483726&amp;idx=1&amp;sn=df583e5b297ddaff5e1ab822df762274&amp;chksm=e9c2ed43deb56455d2a099f3c3e8622031027d6da00202e6a7d731eac691e4d87d673ca103b5&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 装饰者模式及典型应用</a>  </p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;适配器模式&quot;&gt;&lt;a href=&quot;#适配器模式&quot; class=&quot;headerlink&quot; title=&quot;适配器模式&quot;&gt;&lt;/a&gt;适配器模式&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;适配器模式(Adapter Pattern)&lt;/strong&gt;：将一个接口转换成客户希望的另一个接口
      
    
    </summary>
    
      <category term="后端" scheme="http://laijianfeng.org/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
      <category term="设计模式" scheme="http://laijianfeng.org/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>设计模式 | 装饰者模式及典型应用</title>
    <link href="http://laijianfeng.org/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
    <id>http://laijianfeng.org/2018/09/设计模式-装饰者模式及典型应用/</id>
    <published>2018-09-18T12:44:31.000Z</published>
    <updated>2018-09-18T13:31:51.211Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文的主要内容：</p><ul><li>介绍装饰者模式</li><li>示例</li><li>源码分析装饰者模式的典型应用<ul><li>Java I/O 中的装饰者模式</li><li>spring session 中的装饰者模式</li><li>Mybatis 缓存中的装饰者模式</li></ul></li><li>总结</li></ul><h2 id="装饰者模式"><a href="#装饰者模式" class="headerlink" title="装饰者模式"></a>装饰者模式</h2><p><strong>装饰者模式(Decorator Pattern)</strong>：动态地给一个对象增加一些额外的职责，增加对象功能来说，装饰模式比生成子类实现更为灵活。装饰模式是一种对象结构型模式。</p><p>在装饰者模式中，为了让系统具有更好的灵活性和可扩展性，我们通常会定义一个抽象装饰类，而将具体的装饰类作为它的子类</p><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><p><strong>Component（抽象构件）</strong>：它是具体构件和抽象装饰类的共同父类，声明了在具体构件中实现的业务方法，它的引入可以使客户端以一致的方式处理未被装饰的对象以及装饰之后的对象，实现客户端的透明操作。</p><p><strong>ConcreteComponent（具体构件）</strong>：它是抽象构件类的子类，用于定义具体的构件对象，实现了在抽象构件中声明的方法，装饰器可以给它增加额外的职责（方法）。</p><p><strong>Decorator（抽象装饰类）</strong>：它也是抽象构件类的子类，用于给具体构件增加职责，但是具体职责在其子类中实现。它维护一个指向抽象构件对象的引用，通过该引用可以调用装饰之前构件对象的方法，并通过其子类扩展该方法，以达到装饰的目的。</p><p><strong>ConcreteDecorator（具体装饰类）</strong>：它是抽象装饰类的子类，负责向构件添加新的职责。每一个具体装饰类都定义了一些新的行为，它可以调用在抽象装饰类中定义的方法，并可以增加新的方法用以扩充对象的行为。</p><p>由于具体构件类和装饰类都实现了相同的抽象构件接口，因此装饰模式以对客户透明的方式动态地给一个对象附加上更多的责任，换言之，客户端并不会觉得对象在装饰前和装饰后有什么不同。装饰模式可以在不需要创造更多子类的情况下，将对象的功能加以扩展。</p><p>装饰模式的<strong>核心在于抽象装饰类的设计</strong>。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>煎饼抽象类</p><pre><code>public abstract class ABattercake {    protected abstract String getDesc();    protected abstract int cost();}</code></pre><p>煎饼类，继承了煎饼抽象类，一个煎饼 8 块钱</p><pre><code>public class Battercake extends ABattercake {    @Override    protected String getDesc() {        return &quot;煎饼&quot;;    }    @Override    protected int cost() {        return 8;    }}</code></pre><p>抽象装饰类，需要注意的是，<strong>抽象装饰类通过成员属性的方式将 煎饼抽象类组合进来，同时也继承了煎饼抽象类</strong>，且这里定义了新的业务方法 <code>doSomething()</code></p><pre><code>public abstract class AbstractDecorator extends ABattercake {    private ABattercake aBattercake;    public AbstractDecorator(ABattercake aBattercake) {        this.aBattercake = aBattercake;    }    protected abstract void doSomething();    @Override    protected String getDesc() {        return this.aBattercake.getDesc();    }    @Override    protected int cost() {        return this.aBattercake.cost();    }}</code></pre><p>鸡蛋装饰器，继承了抽象装饰类，鸡蛋装饰器在父类的基础上增加了一个鸡蛋，同时价格加上 1 块钱</p><pre><code>public class EggDecorator extends AbstractDecorator {    public EggDecorator(ABattercake aBattercake) {        super(aBattercake);    }    @Override    protected void doSomething() {    }    @Override    protected String getDesc() {        return super.getDesc() + &quot; 加一个鸡蛋&quot;;    }    @Override    protected int cost() {        return super.cost() + 1;    }    public void egg() {        System.out.println(&quot;增加了一个鸡蛋&quot;);    }}</code></pre><p>香肠装饰器，与鸡蛋装饰器类似，继承了抽象装饰类，给在父类的基础上加上一根香肠，同时价格增加 2 块钱</p><pre><code>public class SausageDecorator extends AbstractDecorator{    public SausageDecorator(ABattercake aBattercake) {        super(aBattercake);    }    @Override    protected void doSomething() {    }    @Override    protected String getDesc() {        return super.getDesc() + &quot; 加一根香肠&quot;;    }    @Override    protected int cost() {        return super.cost() + 2;    }}</code></pre><h3 id="测试，购买煎饼"><a href="#测试，购买煎饼" class="headerlink" title="测试，购买煎饼"></a>测试，购买煎饼</h3><p><strong>1、购买一个煎饼</strong></p><pre><code>public class Test {    public static void main(String[] args) {        ABattercake aBattercake = new Battercake();        System.out.println(aBattercake.getDesc() + &quot;, 销售价格: &quot; + aBattercake.cost());    }}</code></pre><p>输出</p><pre><code>煎饼, 销售价格: 8</code></pre><p><strong>2、购买一个加鸡蛋的煎饼</strong></p><pre><code>public class Test {    public static void main(String[] args) {        ABattercake aBattercake = new Battercake();        aBattercake = new EggDecorator(aBattercake);        System.out.println(aBattercake.getDesc() + &quot;, 销售价格: &quot; + aBattercake.cost());    }}</code></pre><p>输出</p><pre><code>煎饼 加一个鸡蛋, 销售价格: 9</code></pre><p><strong>3、购买一个加两个鸡蛋的煎饼</strong></p><pre><code>public class Test {    public static void main(String[] args) {        ABattercake aBattercake = new Battercake();        aBattercake = new EggDecorator(aBattercake);        aBattercake = new EggDecorator(aBattercake);        System.out.println(aBattercake.getDesc() + &quot;, 销售价格: &quot; + aBattercake.cost());    }}</code></pre><p>输出</p><pre><code>煎饼 加一个鸡蛋 加一个鸡蛋, 销售价格: 10</code></pre><p><strong>4、购买一个加两个鸡蛋和一根香肠的煎饼</strong></p><pre><code>public class Test {    public static void main(String[] args) {        ABattercake aBattercake = new Battercake();        aBattercake = new EggDecorator(aBattercake);        aBattercake = new EggDecorator(aBattercake);        aBattercake = new SausageDecorator(aBattercake);        System.out.println(aBattercake.getDesc() + &quot;, 销售价格: &quot; + aBattercake.cost());    }}</code></pre><p>输出</p><pre><code>煎饼 加一个鸡蛋 加一个鸡蛋 加一根香肠, 销售价格: 12</code></pre><p>画出UML类图如下所示</p><p><img src="http://image.laijianfeng.org/20180917_225232.png" alt="装饰者模式类图"></p><h3 id="小结一下"><a href="#小结一下" class="headerlink" title="小结一下"></a>小结一下</h3><p>由于具体构件类和装饰类都实现了相同的抽象构件接口，因此装饰模式以对客户透明的方式动态地给一个对象附加上更多的责任，换言之，客户端并不会觉得对象在装饰前和装饰后有什么不同。</p><p>譬如我们给煎饼加上一个鸡蛋可以这么写 <code>aBattercake = new EggDecorator(aBattercake);</code>，客户端仍然可以把 <code>aBattercake</code> 当成原来的 <code>aBattercake</code>一样，不过现在的 <code>aBattercake</code>已经被装饰加上了鸡蛋</p><p>装饰模式可以在不需要创造更多子类的情况下，将对象的功能加以扩展。</p><h3 id="透明装饰模式与半透明装饰模式"><a href="#透明装饰模式与半透明装饰模式" class="headerlink" title="透明装饰模式与半透明装饰模式"></a>透明装饰模式与半透明装饰模式</h3><p>在上面的示例中，装饰后的对象是通过抽象构建类类型 <code>ABattercake</code> 的变量来引用的，在鸡蛋装饰器这个类中我们新增了 <code>egg()</code> 方法，如果此时我们想要<strong>单独调用该方法</strong>是调用不到的</p><p>除非引用变量的类型改为 <code>EggDecorator</code>，这样就可以调用了</p><pre><code>EggDecorator eggBattercake = new EggDecorator(aBattercake); eggBattercake.egg();</code></pre><p>在实际使用过程中，由于新增行为可能需要单独调用，因此这种形式的装饰模式也经常出现，这种装饰模式被称为<strong>半透明(Semi-transparent)装饰模式</strong>，而标准的装饰模式是<strong>透明(Transparent)装饰模式</strong>。</p><p><strong>(1) 透明装饰模式</strong></p><p>在透明装饰模式中，要求客户端完全针对抽象编程，装饰模式的透明性要求客户端程序不应该将对象声明为具体构件类型或具体装饰类型，而应该全部声明为抽象构件类型。</p><p><strong>(2) 半透明装饰模式</strong></p><p>透明装饰模式的设计难度较大，而且有时我们需要单独调用新增的业务方法。为了能够调用到新增方法，我们不得不用具体装饰类型来定义装饰之后的对象，而具体构件类型还是可以使用抽象构件类型来定义，这种装饰模式即为半透明装饰模式。</p><p>半透明装饰模式可以给系统带来更多的灵活性，设计相对简单，使用起来也非常方便；但是其最大的缺点在于<strong>不能实现对同一个对象的多次装饰</strong>，而且客户端需要有区别地对待装饰之前的对象和装饰之后的对象。</p><h3 id="装饰模式注意事项"><a href="#装饰模式注意事项" class="headerlink" title="装饰模式注意事项"></a>装饰模式注意事项</h3><p>(1) 尽量保持装饰类的接口与被装饰类的接口相同，这样，对于客户端而言，无论是装饰之前的对象还是装饰之后的对象都可以一致对待。这也就是说，在可能的情况下，我们应该尽量使用透明装饰模式。</p><p>(2) 尽量保持具体构件类是一个“轻”类，也就是说不要把太多的行为放在具体构件类中，我们可以通过装饰类对其进行扩展。</p><p>(3) 如果只有一个具体构件类，那么抽象装饰类可以作为该具体构件类的直接子类。</p><h2 id="源码分析装饰者模式的典型应用"><a href="#源码分析装饰者模式的典型应用" class="headerlink" title="源码分析装饰者模式的典型应用"></a>源码分析装饰者模式的典型应用</h2><h3 id="Java-I-O中的装饰者模式"><a href="#Java-I-O中的装饰者模式" class="headerlink" title="Java I/O中的装饰者模式"></a>Java I/O中的装饰者模式</h3><p>使用 Java I/O 的时候总是有各种输入流、输出流、字符流、字节流、过滤流、缓冲流等等各种各样的流，不熟悉里边的设计模式的话总会看得云里雾里的，现在通过设计模式的角度来看 Java I/O，会好理解很多。</p><p>先用一幅图来看看Java I/O到底是什么，下面的这幅图生动的刻画了Java I/O的作用。</p><p><img src="http://image.laijianfeng.org/java-io-flow.png" alt="Java I/O的作用图"></p><p>由上图可知在Java中应用程序通过输入流（InputStream）的Read方法从源地址处读取字节，然后通过输出流（OutputStream）的Write方法将流写入到目的地址。</p><p>流的来源主要有三种：本地的文件（File）、控制台、通过socket实现的网络通信 </p><p>下面的图可以看出Java中的装饰者类和被装饰者类以及它们之间的关系，这里只列出了InputStream中的关系：</p><p><img src="http://image.laijianfeng.org/20180918InputStream.png" alt="InputStream部分类关系"></p><p>由上图可以看出只要继承了FilterInputStream的类就是装饰者类，可以用于包装其他的流，装饰者类还可以对装饰者和类进行再包装。</p><p><strong>这里总结几种常用流的应用场景</strong>：</p><table><thead><tr><th>流名称</th><th>应用场景</th></tr></thead><tbody><tr><td>ByteArrayInputStream</td><td>访问数组，把内存中的一个缓冲区作为 InputStream 使用，CPU从缓存区读取数据比从存储介质的速率快10倍以上</td></tr><tr><td>StringBufferInputStream</td><td>把一个 String 对象作为。InputStream。不建议使用，在转换字符的问题上有缺陷</td></tr><tr><td>FileInputStream</td><td>访问文件，把一个文件作为 InputStream ，实现对文件的读取操作</td></tr><tr><td>PipedInputStream</td><td>访问管道，主要在线程中使用，一个线程通过管道输出流发送数据，而另一个线程通过管道输入流读取数据，这样可实现两个线程间的通讯</td></tr><tr><td>SequenceInputStream</td><td>把多个 InputStream 合并为一个 InputStream . “序列输入流”类允许应用程序把几个输入流连续地合并起来</td></tr><tr><td>DataInputStream</td><td>特殊流，读各种基本类型数据,如byte、int、String的功能</td></tr><tr><td>ObjectInputStream</td><td>对象流，读对象的功能</td></tr><tr><td>PushBackInputStream</td><td>推回输入流，可以把读取进来的某些数据重新回退到输入流的缓冲区之中</td></tr><tr><td>BufferedInputStream</td><td>缓冲流，增加了缓冲功能</td></tr></tbody></table><p><strong>下面看一下Java中包装流的实例</strong>：</p><pre><code>import java.io.BufferedInputStream;import java.io.DataInputStream;import java.io.FileInputStream;import java.io.IOException;public class StreamDemo {    public static void main(String[] args) throws IOException{        DataInputStream in=new DataInputStream(new BufferedInputStream(new  FileInputStream(&quot;D:\\hello.txt&quot;)));        while(in.available()!=0) {            System.out.print((char)in.readByte());        }        in.close();    }}</code></pre><p>输出结果</p><pre><code>hello world!hello Java I/O!</code></pre><p>上面程序中对流进行了两次包装，先用 BufferedInputStream将FileInputStream包装成缓冲流也就是给FileInputStream增加缓冲功能，再DataInputStream进一步包装方便数据处理。</p><p>如果要<strong>实现一个自己的包装流</strong>，根据上面的类图，需要继承抽象装饰类 FilterInputStream</p><p>譬如来实现这样一个操作的装饰者类：将输入流中的所有小写字母变成大写字母</p><pre><code>import java.io.FileInputStream;import java.io.FilterInputStream;import java.io.IOException;import java.io.InputStream;public class UpperCaseInputStream extends FilterInputStream {    protected UpperCaseInputStream(InputStream in) {        super(in);    }    @Override    public int read() throws IOException {        int c = super.read();        return (c == -1 ? c : Character.toUpperCase(c));    }    @Override    public int read(byte[] b, int off, int len) throws IOException {        int result = super.read(b, off, len);        for (int i = off; i &lt; off + result; i++) {            b[i] = (byte) Character.toUpperCase((char) b[i]);        }        return result;    }    public static void main(String[] args) throws IOException {        int c;        InputStream in = new UpperCaseInputStream(new FileInputStream(&quot;D:\\hello.txt&quot;));        try {            while ((c = in.read()) &gt;= 0) {                System.out.print((char) c);            }        } finally {            in.close();        }    }}</code></pre><p>输出</p><pre><code>HELLO WORLD!HELLO JAVA I/O!</code></pre><p>整个Java IO体系都是基于字符流(InputStream/OutputStream) 和 字节流(Reader/Writer)作为基类，下面画出OutputStream、Reader、Writer的部分类图，更多细节请查看其它资料</p><p><img src="http://image.laijianfeng.org/20180918OutputStream.png" alt="OutputStream类图"></p><p><img src="http://image.laijianfeng.org/20180918Reader.png" alt="Reader类图"></p><p><img src="http://image.laijianfeng.org/20180918Writer.png" alt="Writer类图"></p><h3 id="spring-cache-中的装饰者模式"><a href="#spring-cache-中的装饰者模式" class="headerlink" title="spring cache 中的装饰者模式"></a>spring cache 中的装饰者模式</h3><p>看 <code>org.springframework.cache.transaction</code> 包下的 <code>TransactionAwareCacheDecorator</code> 这个类</p><pre><code>public class TransactionAwareCacheDecorator implements Cache {    private final Cache targetCache;    public TransactionAwareCacheDecorator(Cache targetCache) {        Assert.notNull(targetCache, &quot;Target Cache must not be null&quot;);        this.targetCache = targetCache;    }    public &lt;T&gt; T get(Object key, Class&lt;T&gt; type) {        return this.targetCache.get(key, type);    }    public void put(final Object key, final Object value) {        // 判断是否开启了事务        if (TransactionSynchronizationManager.isSynchronizationActive()) {            // 将操作注册到 afterCommit 阶段            TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter() {                public void afterCommit() {                    TransactionAwareCacheDecorator.this.targetCache.put(key, value);                }            });        } else {            this.targetCache.put(key, value);        }    }    // ...省略...}</code></pre><p>该类实现了 <code>Cache</code> 接口，同时将 <code>Cache</code> 组合到类中成为了成员属性 <code>targetCache</code>，所以可以大胆猜测 <code>TransactionAwareCacheDecorator</code> 是一个装饰类，不过这里并没有抽象装饰类，且 <code>TransactionAwareCacheDecorator</code> 没有子类，这里的装饰类关系并没有Java I/O 中的装饰关系那么复杂</p><p><img src="http://image.laijianfeng.org/20180918Cache.png" alt="spring cache中类图关系"></p><p>该类的主要功能：通过 Spring 的 <code>TransactionSynchronizationManager</code> 将其 <code>put/evict/clear</code> 操作与 Spring 管理的事务同步，仅在成功的事务的 <code>after-commit</code> 阶段执行实际的缓存 <code>put/evict/clear</code> 操作。如果没有事务是 <code>active</code> 的，将立即执行 <code>put/evict/clear</code> 操作</p><h3 id="spring-session-中的装饰者模式"><a href="#spring-session-中的装饰者模式" class="headerlink" title="spring session 中的装饰者模式"></a>spring session 中的装饰者模式</h3><blockquote><p>注意：适配器模式的结尾也可能是 Wrapper</p></blockquote><p>类 <code>ServletRequestWrapper</code> 的代码如下：</p><pre><code>public class ServletRequestWrapper implements ServletRequest {    private ServletRequest request;    public ServletRequestWrapper(ServletRequest request) {        if (request == null) {            throw new IllegalArgumentException(&quot;Request cannot be null&quot;);        }        this.request = request;    }    @Override    public Object getAttribute(String name) {        return this.request.getAttribute(name);    }    //...省略...}    </code></pre><p>可以看到该类对 <code>ServletRequest</code> 进行了包装，这里是一个装饰者模式，再看下图，spring session 中 <code>SessionRepositoryFilter</code> 的一个内部类 <code>SessionRepositoryRequestWrapper</code> 与 <code>ServletRequestWrapper</code> 的关系</p><p><img src="http://image.laijianfeng.org/20180918HttpServletRequestWrapper.png" alt="ServletRequest类图"></p><p>可见 <code>ServletRequestWrapper</code> 是第一层包装，<code>HttpServletRequestWrapper</code> 通过继承进行包装，增加了 HTTP 相关的功能，<code>SessionRepositoryRequestWrapper</code> 又通过继承进行包装，增加了 Session 相关的功能</p><h3 id="Mybatis-缓存中的装饰者模式"><a href="#Mybatis-缓存中的装饰者模式" class="headerlink" title="Mybatis 缓存中的装饰者模式"></a>Mybatis 缓存中的装饰者模式</h3><p><code>org.apache.ibatis.cache</code> 包的文件结构如下所示</p><p><img src="http://image.laijianfeng.org/20180918_202157.png" alt="Mybatis cache 中的装饰者模式"></p><p>我们通过类所在的包名即可判断出该类的角色，<code>Cache</code> 为抽象构件类，<code>PerpetualCache</code> 为具体构件类，<code>decorators</code> 包下的类为装饰类，没有抽象装饰类</p><p>通过名称也可以判断出装饰类所要装饰的功能</p><h2 id="装饰者模式总结"><a href="#装饰者模式总结" class="headerlink" title="装饰者模式总结"></a>装饰者模式总结</h2><p>装饰模式的<strong>主要优点</strong>如下：</p><ol><li>对于扩展一个对象的功能，装饰模式比继承更加灵活性，不会导致类的个数急剧增加。</li><li>可以通过一种动态的方式来扩展一个对象的功能，通过配置文件可以在运行时选择不同的具体装饰类，从而实现不同的行为。</li><li>可以对一个对象进行多次装饰，通过使用不同的具体装饰类以及这些装饰类的排列组合，可以创造出很多不同行为的组合，得到功能更为强大的对象。</li><li>具体构件类与具体装饰类可以独立变化，用户可以根据需要增加新的具体构件类和具体装饰类，原有类库代码无须改变，符合 “开闭原则”。</li></ol><p>装饰模式的<strong>主要缺点</strong>如下：</p><ol><li>使用装饰模式进行系统设计时将产生很多小对象，这些对象的区别在于它们之间相互连接的方式有所不同，而不是它们的类或者属性值有所不同，大量小对象的产生势必会占用更多的系统资源，在一定程序上影响程序的性能。</li><li>装饰模式提供了一种比继承更加灵活机动的解决方案，但同时也意味着比继承更加易于出错，排错也很困难，对于多次装饰的对象，调试时寻找错误可能需要逐级排查，较为繁琐。</li></ol><p><strong>适用场景</strong>：</p><ol><li>在不影响其他对象的情况下，以动态、透明的方式给单个对象添加职责。</li><li>当不能采用继承的方式对系统进行扩展或者采用继承不利于系统扩展和维护时可以使用装饰模式。不能采用继承的情况主要有两类：第一类是系统中存在大量独立的扩展，为支持每一种扩展或者扩展之间的组合将产生大量的子类，使得子类数目呈爆炸性增长；第二类是因为类已定义为不能被继承（如Java语言中的final类）。</li></ol><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析<br><a href="https://blog.csdn.net/u013309870/article/details/75735676" target="_blank" rel="noopener">HankingHu：由装饰者模式来深入理解Java I/O整体框架</a><br><a href="https://blog.csdn.net/qq_33394088/article/details/78512407" target="_blank" rel="noopener">HryReal：Java的io类的使用场景</a></p></blockquote><h3 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h3><p><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483700&amp;idx=1&amp;sn=dd4d23f9400c8be248f5d125465ba941&amp;chksm=e9c2ed39deb5642fb809eca1351f00995f06c9a4875f09986cc5005059eff74d6c20fc1118a3&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 简单工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483704&amp;idx=1&amp;sn=fa3ae947cebf22da35e6ac0a37f566f8&amp;chksm=e9c2ed35deb564230a69e43d93a3b74618287c6ddd402a6f1dc6a5b14a896e99584985e7cf92&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 工厂方法模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483708&amp;idx=1&amp;sn=9b8c155b86511ea6ec323dc6a72c52df&amp;chksm=e9c2ed31deb56427b2a6bbcbad5bdd3a4ef68b52eb88cc47b5bcfc76773d3d983d8aaf57761c&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 抽象工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483712&amp;idx=1&amp;sn=1ffd9837eb9413dde74ff509bf69ecc5&amp;chksm=e9c2ed4ddeb5645b8cbf64c83d103a859ae49921c60e17fe8bebe63c26b04966be101d598848&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 建造者模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483716&amp;idx=1&amp;sn=df00c297c8f32e10e277db8941839c14&amp;chksm=e9c2ed49deb5645fa2586da358a8f0a00dd926f883637adebc59435f846c67c040ef759ba034&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 原型模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483721&amp;idx=1&amp;sn=721d0bce3bd516c10d4b6addbf3eced6&amp;chksm=e9c2ed44deb56452395c94a0b150994b94aa26cae71149e6c030d0ac32f9c3c37e2bfe9685b6&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 外观模式及典型应用</a></p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;本文的主要内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;介绍装饰者模式&lt;/li&gt;
&lt;li&gt;示例&lt;/li&gt;
&lt;li&gt;源码分析装饰者模式的典型应用&lt;ul&gt;

      
    
    </summary>
    
      <category term="后端" scheme="http://laijianfeng.org/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
      <category term="设计模式" scheme="http://laijianfeng.org/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>设计模式 | 外观模式及典型应用</title>
    <link href="http://laijianfeng.org/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
    <id>http://laijianfeng.org/2018/09/设计模式-外观模式及典型应用/</id>
    <published>2018-09-16T12:29:56.000Z</published>
    <updated>2018-09-16T12:34:52.883Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本文的主要内容：</p><ul><li>介绍外观模式</li><li>示例<ul><li>自己泡茶</li><li>到茶馆喝茶</li></ul></li><li>外观模式总结</li><li>外观模式的典型应用<ul><li>spring JDBC 中的外观模式</li><li>Mybatis中的外观模式</li><li>Tomcat 中的外观模式</li><li>SLF4J 中的外观模式</li></ul></li></ul><h3 id="外观模式"><a href="#外观模式" class="headerlink" title="外观模式"></a>外观模式</h3><p>外观模式是一种使用频率非常高的结构型设计模式，它通过引入一个外观角色来简化客户端与子系统之间的交互，为复杂的子系统调用提供一个统一的入口，降低子系统与客户端的耦合度，且客户端调用非常方便。</p><p>外观模式又称为门面模式，它是一种对象结构型模式。外观模式是迪米特法则的一种具体实现，通过引入一个新的外观角色可以降低原有系统的复杂度，同时降低客户类与子系统的耦合度。</p><p>外观模式包含如下两个角色：</p><p><strong>Facade（外观角色）</strong>：在客户端可以调用它的方法，在外观角色中可以知道相关的（一个或者多个）子系统的功能和责任；在正常情况下，它将所有从客户端发来的请求委派到相应的子系统去，传递给相应的子系统对象处理。</p><p><strong>SubSystem（子系统角色）</strong>：在软件系统中可以有一个或者多个子系统角色，每一个子系统可以不是一个单独的类，而是一个类的集合，它实现子系统的功能；每一个子系统都可以被客户端直接调用，或者被外观角色调用，它处理由外观类传过来的请求；子系统并不知道外观的存在，对于子系统而言，外观角色仅仅是另外一个客户端而已。</p><p>外观模式的目的不是给予子系统添加新的功能接口，而是为了让外部减少与子系统内多个模块的交互，松散耦合，从而让外部能够更简单地使用子系统。</p><p>外观模式的本质是：<strong>封装交互，简化调用</strong>。</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>泡茶需要水 <code>Water</code></p><pre><code>public class Water {    private int temperature;    // 温度    private int capacity;       // 容量    public Water() {        this.temperature = 0;        this.capacity = 10;    }    // 省略...}    </code></pre><p>泡茶需要茶叶 <code>TeaLeaf</code></p><pre><code>public class TeaLeaf {    private String teaName;    // 省略...}    </code></pre><p>烧水需要用水壶烧，将水加热</p><pre><code>public class KettleService {    public void waterBurning(String who, Water water, int burnTime) {        // 烧水，计算最终温度        int finalTermperature = Math.min(100, water.getTemperature() + burnTime * 20);        water.setTemperature(finalTermperature);        System.out.println(who + &quot; 使用水壶烧水，最终水温为 &quot; + finalTermperature);    }}</code></pre><p>泡茶，将烧好的水与茶叶进行冲泡，最终得到一杯茶水</p><pre><code>public class TeasetService {    public Teawater makeTeaWater(String who, Water water, TeaLeaf teaLeaf) {        String teawater = &quot;一杯容量为 &quot; + water.getCapacity() + &quot;, 温度为 &quot; + water.getTemperature() + &quot; 的&quot; + teaLeaf.getTeaName() + &quot;茶水&quot;;        System.out.println(who + &quot; 泡了&quot; + teawater);        return new Teawater(teawater);    }}</code></pre><p>人喝茶水</p><pre><code>public class Man {    private String name;    public Man(String name) {        this.name = name;    }    public void drink(Teawater teawater) {        System.out.println(name + &quot; 喝了&quot; + teawater.getTeaWater());    }}</code></pre><h4 id="自己泡茶喝"><a href="#自己泡茶喝" class="headerlink" title="自己泡茶喝"></a>自己泡茶喝</h4><p>张三、李四各自泡茶喝，各自都需要准备茶具、茶叶、水，各自还要完成烧水、泡茶等操作</p><pre><code>public class Main {    public static void main(String[] args) {        Man zhangsan = new Man(&quot;张三&quot;);        KettleService kettleService1 = new KettleService();        TeasetService teasetService1 = new TeasetService();        Water water1 = new Water();        TeaLeaf teaLeaf1 = new TeaLeaf(&quot;西湖龙井&quot;);        kettleService1.waterBurning(zhangsan.getName(), water1, 4);        Teawater teawater1 = teasetService1.makeTeaWater(zhangsan.getName(), water1, teaLeaf1);        zhangsan.drink(teawater1);        System.out.println();        Man lisi = new Man(&quot;李四&quot;);        KettleService kettleService2 = new KettleService();        TeasetService teasetService2 = new TeasetService();        Water water2 = new Water(10, 15);        TeaLeaf teaLeaf2 = new TeaLeaf(&quot;碧螺春&quot;);        kettleService2.waterBurning(lisi.getName(), water2, 4);        Teawater teawater2 = teasetService2.makeTeaWater(lisi.getName(), water2, teaLeaf2);        lisi.drink(teawater2);    }}</code></pre><p>输出为</p><pre><code>张三 使用水壶烧水，最终水温为 80张三 泡了一杯容量为 10, 温度为 80 的西湖龙井茶水张三 喝了一杯容量为 10, 温度为 80 的西湖龙井茶水李四 使用水壶烧水，最终水温为 90李四 泡了一杯容量为 15, 温度为 90 的碧螺春茶水李四 喝了一杯容量为 15, 温度为 90 的碧螺春茶水</code></pre><p>自己泡茶喝模式图</p><p><img src="http://image.laijianfeng.org/2018-09-16_174501.jpg" alt="自己泡茶喝模式图"></p><h4 id="到茶馆喝茶"><a href="#到茶馆喝茶" class="headerlink" title="到茶馆喝茶"></a>到茶馆喝茶</h4><p>茶馆，茶馆有不同的套餐</p><pre><code>public class TeaHouseFacade {    private String name;    private TeasetService teasetService;    private KettleService kettleService;    public TeaHouseFacade(String name) {        this.name = name;        this.teasetService = new TeasetService();        this.kettleService = new KettleService();    }    public Teawater makeTea(int teaNumber) {        switch (teaNumber) {            case 1:                Water water1 = new Water();                TeaLeaf teaLeaf1 = new TeaLeaf(&quot;西湖龙井&quot;);                kettleService.waterBurning(this.name, water1, 4);                Teawater teawater1 = teasetService.makeTeaWater(this.name, water1, teaLeaf1);                return teawater1;            case 2:                Water water2 = new Water(10, 15);                TeaLeaf teaLeaf2 = new TeaLeaf(&quot;碧螺春&quot;);                kettleService.waterBurning(this.name, water2, 4);                Teawater teawater2 = teasetService.makeTeaWater(this.name, water2, teaLeaf2);                return teawater2;            default:                Water water3 = new Water();                TeaLeaf teaLeaf3 = new TeaLeaf(&quot;招牌乌龙&quot;);                kettleService.waterBurning(this.name, water3, 5);                Teawater teawater3 = teasetService.makeTeaWater(this.name, water3, teaLeaf3);                return teawater3;        }    }}</code></pre><p>张三和李四点茶，只需要告诉茶馆套餐编号即可，水、茶叶由茶馆准备，烧水泡茶的操作由茶馆统一完成</p><pre><code>public class Test {    public static void main(String[] args) {        TeaHouseFacade teaHouseFacade = new TeaHouseFacade(&quot;老舍茶馆&quot;);        Man zhangsan = new Man(&quot;张三&quot;);        Teawater teawater = teaHouseFacade.makeTea(1);        zhangsan.drink(teawater);        System.out.println();        Man lisi = new Man(&quot;李四&quot;);        Teawater teawater1 = teaHouseFacade.makeTea(2);        lisi.drink(teawater1);    }}</code></pre><p>输出为</p><pre><code>老舍茶馆 使用水壶烧水，最终水温为 80老舍茶馆 泡了一杯容量为 10, 温度为 80 的西湖龙井茶水张三 喝了一杯容量为 10, 温度为 80 的西湖龙井茶水老舍茶馆 使用水壶烧水，最终水温为 90老舍茶馆 泡了一杯容量为 15, 温度为 90 的碧螺春茶水李四 喝了一杯容量为 15, 温度为 90 的碧螺春茶水</code></pre><p>到茶馆喝茶模式图</p><p><img src="http://image.laijianfeng.org/2018-09-16_174502.jpg" alt="到茶馆喝茶模式图"></p><h3 id="外观模式总结"><a href="#外观模式总结" class="headerlink" title="外观模式总结"></a>外观模式总结</h3><p>外观模式的<strong>主要优点</strong>如下：</p><ul><li>它对客户端屏蔽了子系统组件，减少了客户端所需处理的对象数目，并使得子系统使用起来更加容易。通过引入外观模式，客户端代码将变得很简单，与之关联的对象也很少。</li><li>它实现了子系统与客户端之间的松耦合关系，这使得子系统的变化不会影响到调用它的客户端，只需要调整外观类即可。</li><li>一个子系统的修改对其他子系统没有任何影响，而且子系统内部变化也不会影响到外观对象。</li></ul><p>外观模式的<strong>主要缺点</strong>如下：</p><ul><li>不能很好地限制客户端直接使用子系统类，如果对客户端访问子系统类做太多的限制则减少了可变性和灵活性。</li><li>如果设计不当，增加新的子系统可能需要修改外观类的源代码，违背了开闭原则。</li></ul><p><strong>适用场景：</strong></p><ul><li>当要为访问一系列复杂的子系统提供一个简单入口时可以使用外观模式。</li><li>客户端程序与多个子系统之间存在很大的依赖性。引入外观类可以将子系统与客户端解耦，从而提高子系统的独立性和可移植性。</li><li>在层次化结构中，可以使用外观模式定义系统中每一层的入口，层与层之间不直接产生联系，而通过外观类建立联系，降低层之间的耦合度。</li></ul><h3 id="源码分析外观模式的典型应用"><a href="#源码分析外观模式的典型应用" class="headerlink" title="源码分析外观模式的典型应用"></a>源码分析外观模式的典型应用</h3><h4 id="spring-jdbc中的外观模式"><a href="#spring-jdbc中的外观模式" class="headerlink" title="spring jdbc中的外观模式"></a>spring jdbc中的外观模式</h4><p>查看 <code>org.springframework.jdbc.support.JdbcUtils</code></p><pre><code>public abstract class JdbcUtils {    public static void closeConnection(Connection con) {        if (con != null) {            try {                con.close();            }            catch (SQLException ex) {                logger.debug(&quot;Could not close JDBC Connection&quot;, ex);            }            catch (Throwable ex) {                // We don&#39;t trust the JDBC driver: It might throw RuntimeException or Error.                logger.debug(&quot;Unexpected exception on closing JDBC Connection&quot;, ex);            }        }    }    public static Object getResultSetValue(ResultSet rs, int index, Class&lt;?&gt; requiredType) throws SQLException {        if (requiredType == null) {            return getResultSetValue(rs, index);        }        Object value = null;        boolean wasNullCheck = false;        // Explicitly extract typed value, as far as possible.        if (String.class.equals(requiredType)) {            value = rs.getString(index);        }        else if (boolean.class.equals(requiredType) || Boolean.class.equals(requiredType)) {            value = rs.getBoolean(index);            wasNullCheck = true;        }        else if (byte.class.equals(requiredType) || Byte.class.equals(requiredType)) {            value = rs.getByte(index);            wasNullCheck = true;        }        else if (short.class.equals(requiredType) || Short.class.equals(requiredType)) {            value = rs.getShort(index);            wasNullCheck = true;        }        else if (int.class.equals(requiredType) || Integer.class.equals(requiredType)) {            value = rs.getInt(index);            wasNullCheck = true;        }        else if (long.class.equals(requiredType) || Long.class.equals(requiredType)) {            value = rs.getLong(index);            wasNullCheck = true;        }        else if (float.class.equals(requiredType) || Float.class.equals(requiredType)) {            value = rs.getFloat(index);            wasNullCheck = true;        }        else if (double.class.equals(requiredType) || Double.class.equals(requiredType) ||                Number.class.equals(requiredType)) {            value = rs.getDouble(index);            wasNullCheck = true;        }        else if (byte[].class.equals(requiredType)) {            value = rs.getBytes(index);        }        else if (java.sql.Date.class.equals(requiredType)) {            value = rs.getDate(index);        }        else if (java.sql.Time.class.equals(requiredType)) {            value = rs.getTime(index);        }        else if (java.sql.Timestamp.class.equals(requiredType) || java.util.Date.class.equals(requiredType)) {            value = rs.getTimestamp(index);        }        else if (BigDecimal.class.equals(requiredType)) {            value = rs.getBigDecimal(index);        }        else if (Blob.class.equals(requiredType)) {            value = rs.getBlob(index);        }        else if (Clob.class.equals(requiredType)) {            value = rs.getClob(index);        }        else {            // Some unknown type desired -&gt; rely on getObject.            value = getResultSetValue(rs, index);        }        if (wasNullCheck &amp;&amp; value != null &amp;&amp; rs.wasNull()) {            value = null;        }        return value;    }    // ...省略...}    </code></pre><p>该工具类主要是对原生的 jdbc 进行了封装</p><h4 id="Mybatis中的外观模式"><a href="#Mybatis中的外观模式" class="headerlink" title="Mybatis中的外观模式"></a>Mybatis中的外观模式</h4><p>查看 <code>org.apache.ibatis.session.Configuration</code> 类中以 <code>new</code> 开头的方法</p><pre><code>public class Configuration {    public Executor newExecutor(Transaction transaction, ExecutorType executorType) {        executorType = executorType == null ? defaultExecutorType : executorType;        executorType = executorType == null ? ExecutorType.SIMPLE : executorType;        Executor executor;        if (ExecutorType.BATCH == executorType) {          executor = new BatchExecutor(this, transaction);        } else if (ExecutorType.REUSE == executorType) {          executor = new ReuseExecutor(this, transaction);        } else {          executor = new SimpleExecutor(this, transaction);        }        if (cacheEnabled) {          executor = new CachingExecutor(executor);        }        executor = (Executor) interceptorChain.pluginAll(executor);        return executor;    }    public ResultSetHandler newResultSetHandler(Executor executor, MappedStatement mappedStatement, RowBounds rowBounds, ParameterHandler parameterHandler,          ResultHandler resultHandler, BoundSql boundSql) {        ResultSetHandler resultSetHandler = new DefaultResultSetHandler(executor, mappedStatement, parameterHandler, resultHandler, boundSql, rowBounds);        resultSetHandler = (ResultSetHandler) interceptorChain.pluginAll(resultSetHandler);        return resultSetHandler;    }    // ...省略...}</code></pre><p>该类主要对一些创建对象的操作进行封装</p><h4 id="Tomcat-中的外观模式"><a href="#Tomcat-中的外观模式" class="headerlink" title="Tomcat 中的外观模式"></a>Tomcat 中的外观模式</h4><p>Tomcat 源码中大量使用了很多外观模式</p><p><img src="http://image.laijianfeng.org/20180916_193616.png" alt="Tomcat中的外观模式"></p><p><code>org.apache.catalina.connector.Request</code> 和 <code>org.apache.catalina.connector.RequestFacade</code> 这两个类都实现了 <code>HttpServletRequest</code> 接口</p><p>在 <code>Request</code> 中调用 <code>getRequest()</code> 实际获取的是 <code>RequestFacade</code> 的对象 </p><pre><code>protected RequestFacade facade = null;public HttpServletRequest getRequest() {    if (facade == null) {        facade = new RequestFacade(this);    }    return facade;}</code></pre><p>在 <code>RequestFacade</code> 中再对认为是子系统的操作进行封装</p><pre><code>public class RequestFacade implements HttpServletRequest {    /**     * The wrapped request.     */    protected Request request = null;    @Override    public Object getAttribute(String name) {        if (request == null) {            throw new IllegalStateException(sm.getString(&quot;requestFacade.nullRequest&quot;));        }        return request.getAttribute(name);    }    // ...省略...}    </code></pre><h4 id="SLF4J-中的外观模式"><a href="#SLF4J-中的外观模式" class="headerlink" title="SLF4J 中的外观模式"></a>SLF4J 中的外观模式</h4><p><code>SLF4J</code> 是简单的日志外观模式框架，抽象了各种日志框架例如 <code>Logback</code>、<code>Log4j</code>、<code>Commons-logging</code> 和 <code>JDK</code> 自带的 <code>logging</code> 实现接口。它使得用户可以在部署时使用自己想要的日志框架。</p><p><code>SLF4J</code> <strong>没有替代任何日志框架，它仅仅是标准日志框架的外观模式</strong>。如果在类路径下除了 <code>SLF4J</code> 再没有任何日志框架，那么默认状态是在控制台输出日志。</p><blockquote><p>日志处理框架 Logback 是 Log4j 的改进版本，原生支持SLF4J（因为是同一作者开发的），因此 Logback＋SLF4J 的组合是日志框架的最佳选择，比 SLF4J+其它日志框架 的组合要快一些。而且Logback的配置可以是XML或Groovy代码。</p></blockquote><p>SLF4J 的 helloworld 如下：</p><pre><code>import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class HelloWorld {  public static void main(String[] args) {    Logger logger = LoggerFactory.getLogger(HelloWorld.class);    logger.info(&quot;Hello World&quot;);  }}</code></pre><p>下图为 SLF4J 与日志处理框架的绑定调用关系</p><p><img src="https://www.slf4j.org/images/concrete-bindings.png" alt="SLF4J与日志处理框架的绑定调用关系"></p><p>应用层调用 <code>slf4j-api.jar</code>，<code>slf4j-api.jar</code> 再根据所绑定的日志处理框架调用不同的 jar 包进行处理</p><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析<br><a href="https://www.cnblogs.com/xrq730/p/8619156.html" target="_blank" rel="noopener">Java日志框架：slf4j作用及其实现原理</a></p></blockquote><h4 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h4><p><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483700&amp;idx=1&amp;sn=dd4d23f9400c8be248f5d125465ba941&amp;chksm=e9c2ed39deb5642fb809eca1351f00995f06c9a4875f09986cc5005059eff74d6c20fc1118a3&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 简单工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483704&amp;idx=1&amp;sn=fa3ae947cebf22da35e6ac0a37f566f8&amp;chksm=e9c2ed35deb564230a69e43d93a3b74618287c6ddd402a6f1dc6a5b14a896e99584985e7cf92&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 工厂方法模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483708&amp;idx=1&amp;sn=9b8c155b86511ea6ec323dc6a72c52df&amp;chksm=e9c2ed31deb56427b2a6bbcbad5bdd3a4ef68b52eb88cc47b5bcfc76773d3d983d8aaf57761c&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 抽象工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483712&amp;idx=1&amp;sn=1ffd9837eb9413dde74ff509bf69ecc5&amp;chksm=e9c2ed4ddeb5645b8cbf64c83d103a859ae49921c60e17fe8bebe63c26b04966be101d598848&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 建造者模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483716&amp;idx=1&amp;sn=df00c297c8f32e10e277db8941839c14&amp;chksm=e9c2ed49deb5645fa2586da358a8f0a00dd926f883637adebc59435f846c67c040ef759ba034&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 原型模式及典型应用</a></p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;本文的主要内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;介绍外观模式&lt;/li&gt;
&lt;li&gt;示例&lt;ul&gt;
&lt;li&gt;自己泡茶&lt;/li&gt;
&lt;li&gt;到茶馆喝茶&lt;/
      
    
    </summary>
    
      <category term="后端" scheme="http://laijianfeng.org/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
      <category term="设计模式" scheme="http://laijianfeng.org/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>设计模式 | 原型模式及典型应用</title>
    <link href="http://laijianfeng.org/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
    <id>http://laijianfeng.org/2018/09/设计模式-原型模式及典型应用/</id>
    <published>2018-09-14T16:08:13.000Z</published>
    <updated>2018-09-14T16:09:23.726Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本文的主要内容如下：</p><ul><li>介绍原型模式</li><li>示例<ul><li>Java语言的clone</li><li>浅克隆与深克隆</li><li>实现深克隆</li></ul></li><li>原型模式的典型应用</li></ul><h3 id="原型模式"><a href="#原型模式" class="headerlink" title="原型模式"></a>原型模式</h3><p><strong>原型模式(Prototype Pattern)</strong>：使用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。原型模式是一种对象创建型模式。</p><p>原型模式的工作原理很简单：将一个原型对象传给那个要发动创建的对象，这个要发动创建的对象通过请求原型对象拷贝自己来实现创建过程。</p><p>原型模式是一种“另类”的创建型模式，创建克隆对象的工厂就是原型类自身，工厂方法由克隆方法来实现。</p><p>需要注意的是通过克隆方法所创建的对象是全新的对象，它们在内存中拥有新的地址，通常对克隆所产生的对象进行修改对原型对象不会造成任何影响，每一个克隆对象都是相互独立的。通过不同的方式修改可以得到一系列相似但不完全相同的对象。</p><h4 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h4><ul><li><strong>Prototype（抽象原型类）</strong>：它是声明克隆方法的接口，是所有具体原型类的公共父类，可以是抽象类也可以是接口，甚至还可以是具体实现类。</li><li><strong>ConcretePrototype（具体原型类）</strong>：它实现在抽象原型类中声明的克隆方法，在克隆方法中返回自己的一个克隆对象。</li><li><strong>Client（客户类）</strong>：让一个原型对象克隆自身从而创建一个新的对象，在客户类中只需要直接实例化或通过工厂方法等方式创建一个原型对象，再通过调用该对象的克隆方法即可得到多个相同的对象。由于客户类针对抽象原型类Prototype编程，因此用户可以根据需要选择具体原型类，系统具有较好的可扩展性，增加或更换具体原型类都很方便。</li></ul><p>原型模式的<strong>核心在于如何实现克隆方法</strong>。</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><h4 id="Java语言提供的clone-方法"><a href="#Java语言提供的clone-方法" class="headerlink" title="Java语言提供的clone()方法"></a>Java语言提供的clone()方法</h4><p>学过Java语言的人都知道，所有的Java类都继承自 <code>java.lang.Object</code>。事实上，<code>Object</code> 类提供一个 <code>clone()</code> 方法，可以将一个Java对象复制一份。因此在Java中可以直接使用 <code>Object</code> 提供的 <code>clone()</code> 方法来实现对象的克隆，Java语言中的原型模式实现很简单。</p><p>需要注意的是能够实现克隆的Java类必须实现一个 <code>标识接口 Cloneable</code>，表示这个Java类支持被复制。如果一个类没有实现这个接口但是调用了clone()方法，Java编译器将抛出一个 <code>CloneNotSupportedException</code> 异常。</p><pre><code>public class Mail implements Cloneable{    private String name;    private String emailAddress;    private String content;    public Mail(){        System.out.println(&quot;Mail Class Constructor&quot;);    }    // ...省略 getter、setter    @Override    protected Object clone() throws CloneNotSupportedException {        System.out.println(&quot;clone mail object&quot;);        return super.clone();    }}</code></pre><p>在客户端创建原型对象和克隆对象也很简单，如下代码所示：</p><pre><code>public class Test {    public static void main(String[] args) throws CloneNotSupportedException {        Mail mail = new Mail();        mail.setContent(&quot;初始化模板&quot;);        System.out.println(&quot;初始化mail:&quot;+mail);        for(int i = 0;i &lt; 3;i++){            System.out.println();            Mail mailTemp = (Mail) mail.clone();            mailTemp.setName(&quot;姓名&quot;+i);            mailTemp.setEmailAddress(&quot;姓名&quot;+i+&quot;@test.com&quot;);            mailTemp.setContent(&quot;恭喜您，此次抽奖活动中奖了&quot;);            MailUtil.sendMail(mailTemp);            System.out.println(&quot;克隆的mailTemp:&quot;+mailTemp);        }        MailUtil.saveOriginMailRecord(mail);    }}</code></pre><p>其中的 <code>MailUtil</code> 工具类为</p><pre><code>public class MailUtil {    public static void sendMail(Mail mail) {        String outputContent = &quot;向{0}同学,邮件地址:{1},邮件内容:{2}发送邮件成功&quot;;        System.out.println(MessageFormat.format(outputContent, mail.getName(), mail.getEmailAddress(), mail.getContent()));    }    public static void saveOriginMailRecord(Mail mail) {        System.out.println(&quot;存储originMail记录,originMail:&quot; + mail.getContent());    }}</code></pre><p>输出如下：</p><pre><code>Mail Class Constructor初始化mail:Mail{name=&#39;null&#39;, emailAddress=&#39;null&#39;, content=&#39;初始化模板&#39;}com.designpattern.prototype.Mail@12edcd21clone mail object向姓名0同学,邮件地址:姓名0@test.com,邮件内容:恭喜您，此次抽奖活动中奖了发送邮件成功克隆的mailTemp:Mail{name=&#39;姓名0&#39;, emailAddress=&#39;姓名0@test.com&#39;, content=&#39;恭喜您，此次抽奖活动中奖了&#39;}com.designpattern.prototype.Mail@34c45dcaclone mail object向姓名1同学,邮件地址:姓名1@test.com,邮件内容:恭喜您，此次抽奖活动中奖了发送邮件成功克隆的mailTemp:Mail{name=&#39;姓名1&#39;, emailAddress=&#39;姓名1@test.com&#39;, content=&#39;恭喜您，此次抽奖活动中奖了&#39;}com.designpattern.prototype.Mail@52cc8049clone mail object向姓名2同学,邮件地址:姓名2@test.com,邮件内容:恭喜您，此次抽奖活动中奖了发送邮件成功克隆的mailTemp:Mail{name=&#39;姓名2&#39;, emailAddress=&#39;姓名2@test.com&#39;, content=&#39;恭喜您，此次抽奖活动中奖了&#39;}com.designpattern.prototype.Mail@5b6f7412存储originMail记录,originMail:初始化模板</code></pre><p>从输出结果中我们可以观察到：</p><ul><li>for循环中的 mailTemp 从 mail 对象中克隆得到，它们的内存地址均不同，说明不是同一个对象，克隆成功，克隆仅仅通过调用 <code>super.clone()</code> 即可。</li><li>最后调用的 <code>MailUtil.saveOriginMailRecord(mail);</code> 中的 <code>mail</code> 对象的内容仍为 for 循环之前设置的内容，并没有因为克隆而改变。</li><li>克隆的时候调用了 <code>clone</code> 方法，并没有调用 <code>Mail</code> 类的构造器，只在最前面 <code>new</code> 的时候才调用了一次</li></ul><p>关于输出的内存地址是怎么输出的，我们还需要看一下 <code>Object#toString</code> 方法</p><pre><code>public class Object {    public String toString() {        return getClass().getName() + &quot;@&quot; + Integer.toHexString(hashCode());    }    //...省略...}</code></pre><p>所以所谓的内存地址即为 <code>hashCode()</code> 的十六进制表示，这里简单的认为 内存地址相同则为同一个对象，不同则为不同对象</p><p>再来看一眼 <code>Object#clone</code> 方法</p><pre><code>protected native Object clone() throws CloneNotSupportedException;</code></pre><p>这是一个 <code>native</code> 关键字修饰的方法</p><p>一般而言，Java语言中的clone()方法满足：</p><ul><li>对任何对象x，都有 <code>x.clone() != x</code>，即克隆对象与原型对象不是同一个对象；</li><li>对任何对象x，都有 <code>x.clone().getClass() == x.getClass()</code>，即克隆对象与原型对象的类型一样；</li><li>如果对象x的 <code>equals()</code> 方法定义恰当，那么 <code>x.clone().equals(x)</code> 应该成立。</li></ul><p>为了获取对象的一份拷贝，我们可以直接利用Object类的clone()方法，具体步骤如下：</p><ol><li>在派生类中覆盖基类的 <code>clone()</code> 方法，并声明为public；</li><li>在派生类的 <code>clone()</code> 方法中，调用 <code>super.clone()</code>；</li><li>派生类需实现Cloneable接口。</li></ol><p>此时，Object类相当于<strong>抽象原型类</strong>，所有实现了Cloneable接口的类相当于<strong>具体原型类</strong>。</p><h4 id="浅克隆与深克隆"><a href="#浅克隆与深克隆" class="headerlink" title="浅克隆与深克隆"></a>浅克隆与深克隆</h4><p>看下面的示例</p><pre><code>public class Pig implements Cloneable{    private String name;    private Date birthday;    // ...getter, setter, construct    @Override    protected Object clone() throws CloneNotSupportedException {        Pig pig = (Pig)super.clone();        return pig;    }    @Override    public String toString() {        return &quot;Pig{&quot; +                &quot;name=&#39;&quot; + name + &#39;\&#39;&#39; +                &quot;, birthday=&quot; + birthday +                &#39;}&#39;+super.toString();    }}</code></pre><p>测试</p><pre><code>public class Test {    public static void main(String[] args) throws CloneNotSupportedException, NoSuchMethodException, InvocationTargetException, IllegalAccessException {        Date birthday = new Date(0L);        Pig pig1 = new Pig(&quot;佩奇&quot;,birthday);        Pig pig2 = (Pig) pig1.clone();        System.out.println(pig1);        System.out.println(pig2);        pig1.getBirthday().setTime(666666666666L);        System.out.println(pig1);        System.out.println(pig2);    }}</code></pre><p>输出如下</p><pre><code>Pig{name=&#39;佩奇&#39;, birthday=Thu Jan 01 08:00:00 CST 1970}com.designpattern.clone.Pig@27973e9bPig{name=&#39;佩奇&#39;, birthday=Thu Jan 01 08:00:00 CST 1970}com.designpattern.clone.Pig@312b1daePig{name=&#39;佩奇&#39;, birthday=Sat Feb 16 09:11:06 CST 1991}com.designpattern.clone.Pig@27973e9bPig{name=&#39;佩奇&#39;, birthday=Sat Feb 16 09:11:06 CST 1991}com.designpattern.clone.Pig@312b1dae</code></pre><p>我们照着上一小节说的实现 <code>Cloneable</code>，调用 <code>super.clone();</code> 进行克隆，中间我们对 <code>pig1</code> 对象设置了一个时间戳，从输出中我们可以发现什么问题呢？</p><p>我们可以发现：</p><ul><li><code>pig1</code> 与 <code>pig2</code> 的内存地址不同</li><li>对 <code>pig1</code> 设置了时间，同事 <code>pig2</code> 的时间也改变了</li></ul><p>我们通过 debug 来看一下</p><p><img src="http://image.laijianfeng.org/20180914_224723.png" alt="debug查看对象地址"></p><p>发现如下：</p><ul><li>pig1 与 pig2 地址不一样</li><li>pig1 的 birthday 与 pig2 的 birthday <strong>一样</strong></li></ul><p>这里引出浅拷贝与深拷贝。</p><p>在Java语言中，数据类型分为值类型（基本数据类型）和引用类型，<strong>值类型</strong>包括int、double、byte、boolean、char等简单数据类型，<strong>引用类型</strong>包括类、接口、数组等复杂类型。</p><p>浅克隆和深克隆的主要区别在于<strong>是否支持引用类型的成员变量的复制</strong>，下面将对两者进行详细介绍。</p><p><strong>浅克隆：</strong></p><ul><li><p>在浅克隆中，如果原型对象的成员变量是值类型，将复制一份给克隆对象；如果原型对象的成员变量是引用类型，则将引用对象的地址复制一份给克隆对象，也就是说原型对象和克隆对象的成员变量指向相同的内存地址。</p></li><li><p>简单来说，在浅克隆中，当对象被复制时<strong>只复制它本身和其中包含的值类型的成员变量</strong>，而<strong>引用类型的成员对象并没有复制</strong>。</p></li><li><p>在Java语言中，通过覆盖Object类的clone()方法可以实现浅克隆。</p></li></ul><p><strong>深克隆：</strong></p><ul><li><p>在深克隆中，<strong>无论原型对象的成员变量是值类型还是引用类型，都将复制一份给克隆对象</strong>，深克隆将原型对象的所有引用对象也复制一份给克隆对象。</p></li><li><p>简单来说，在深克隆中，除了对象本身被复制外，对象所包含的所有成员变量也将复制。</p></li><li><p>在Java语言中，如果需要实现深克隆，可以通过序列化(Serialization)等方式来实现。需要注意的是能够实现序列化的对象其类必须实现Serializable接口，否则无法实现序列化操作。</p></li></ul><h4 id="实现深克隆"><a href="#实现深克隆" class="headerlink" title="实现深克隆"></a>实现深克隆</h4><p>方式一，手动对引用对象进行克隆：</p><pre><code>    @Override    protected Object clone() throws CloneNotSupportedException {        Pig pig = (Pig)super.clone();        //深克隆        pig.birthday = (Date) pig.birthday.clone();        return pig;    }</code></pre><p>方式二，通过序列化的方式：</p><pre><code>public class Pig implements Serializable {    private String name;    private Date birthday;    // ...省略 getter, setter等    protected Object deepClone() throws CloneNotSupportedException, IOException, ClassNotFoundException {        //将对象写入流中        ByteArrayOutputStream bao = new ByteArrayOutputStream();        ObjectOutputStream oos = new ObjectOutputStream(bao);        oos.writeObject(this);        //将对象从流中取出        ByteArrayInputStream bis = new ByteArrayInputStream(bao.toByteArray());        ObjectInputStream ois = new ObjectInputStream(bis);        return (ois.readObject());    }}</code></pre><p><img src="http://image.laijianfeng.org/20180914_230920.png" alt="序列化方式的深克隆结果"></p><h3 id="破坏单例模式"><a href="#破坏单例模式" class="headerlink" title="破坏单例模式"></a>破坏单例模式</h3><p>饿汉式单例模式如下：</p><pre><code>public class HungrySingleton implements Serializable, Cloneable {    private final static HungrySingleton hungrySingleton;    static {        hungrySingleton = new HungrySingleton();    }    private HungrySingleton() {        if (hungrySingleton != null) {            throw new RuntimeException(&quot;单例构造器禁止反射调用&quot;);        }    }    public static HungrySingleton getInstance() {        return hungrySingleton;    }    private Object readResolve() {        return hungrySingleton;    }    @Override    protected Object clone() throws CloneNotSupportedException {        return super.clone();    }}</code></pre><p>使用反射获取对象，测试如下</p><pre><code>public class Test {    public static void main(String[] args) throws CloneNotSupportedException, NoSuchMethodException, InvocationTargetException, IllegalAccessException {        HungrySingleton hungrySingleton = HungrySingleton.getInstance();        Method method = hungrySingleton.getClass().getDeclaredMethod(&quot;clone&quot;);        method.setAccessible(true);        HungrySingleton cloneHungrySingleton = (HungrySingleton) method.invoke(hungrySingleton);        System.out.println(hungrySingleton);        System.out.println(cloneHungrySingleton);    }}</code></pre><p>输出</p><pre><code>com.designpattern.HungrySingleton@34c45dcacom.designpattern.HungrySingleton@52cc8049</code></pre><p>可以看到，通过原型模式，我们把单例模式给破坏了，现在有两个对象了</p><p>为了防止单例模式被破坏，我们可以：不实现 <code>Cloneable</code> 接口；或者把 <code>clone</code> 方法改为如下</p><pre><code>    @Override    protected Object clone() throws CloneNotSupportedException {        return getInstance();    }</code></pre><h3 id="原型模式的典型应用"><a href="#原型模式的典型应用" class="headerlink" title="原型模式的典型应用"></a>原型模式的典型应用</h3><ol><li><code>Object</code> 类中的 <code>clone</code> 接口</li><li><code>Cloneable</code> 接口的实现类，可以看到至少一千多个，找几个例子譬如：</li></ol><p><img src="http://image.laijianfeng.org/20180914_233315.png" alt="Cloneable接口的实现类"></p><p><code>ArrayList</code> 对 <code>clone</code> 的重写如下：</p><pre><code>public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;        implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable {    public Object clone() {        try {            ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone();            v.elementData = Arrays.copyOf(elementData, size);            v.modCount = 0;            return v;        } catch (CloneNotSupportedException e) {            // this shouldn&#39;t happen, since we are Cloneable            throw new InternalError(e);        }    }    //...省略}</code></pre><p>调用 <code>super.clone();</code> 之后把 <code>elementData</code> 数据 copy 了一份</p><p>同理，我们看看 <code>HashMap</code> 对 <code>clone</code> 方法的重写：</p><pre><code>public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable {    @Override    public Object clone() {        HashMap&lt;K,V&gt; result;        try {            result = (HashMap&lt;K,V&gt;)super.clone();        } catch (CloneNotSupportedException e) {            // this shouldn&#39;t happen, since we are Cloneable            throw new InternalError(e);        }        result.reinitialize();        result.putMapEntries(this, false);        return result;    }    // ...省略...}</code></pre><p>mybatis 中的 <code>org.apache.ibatis.cache.CacheKey</code> 对 <code>clone</code> 方法的重写：</p><pre><code>public class CacheKey implements Cloneable, Serializable {    private List&lt;Object&gt; updateList;    public CacheKey clone() throws CloneNotSupportedException {        CacheKey clonedCacheKey = (CacheKey)super.clone();        clonedCacheKey.updateList = new ArrayList(this.updateList);        return clonedCacheKey;    }    // ... 省略...}</code></pre><p>这里又要注意，<code>updateList</code> 是 <code>List&lt;Object&gt;</code> 类型，所以可能是值类型的List，也可能是引用类型的List，克隆的结果需要注意是否为深克隆或者浅克隆</p><p><strong>使用原始模式的时候一定要注意为深克隆还是浅克隆。</strong></p><h3 id="原型模式总结"><a href="#原型模式总结" class="headerlink" title="原型模式总结"></a>原型模式总结</h3><p>原型模式的<strong>主要优点</strong>如下：</p><ul><li>当创建新的对象实例较为复杂时，使用原型模式可以简化对象的创建过程，通过复制一个已有实例可以提高新实例的创建效率。</li><li>扩展性较好，由于在原型模式中提供了抽象原型类，在客户端可以针对抽象原型类进行编程，而将具体原型类写在配置文件中，增加或减少产品类对原有系统都没有任何影响。</li><li>原型模式提供了简化的创建结构，工厂方法模式常常需要有一个与产品类等级结构相同的工厂等级结构，而原型模式就不需要这样，原型模式中产品的复制是通过封装在原型类中的克隆方法实现的，无须专门的工厂类来创建产品。</li><li>可以使用深克隆的方式保存对象的状态，使用原型模式将对象复制一份并将其状态保存起来，以便在需要的时候使用（如恢复到某一历史状态），可辅助实现撤销操作。</li></ul><p>原型模式的<strong>主要缺点</strong>如下：</p><ul><li>需要为每一个类配备一个克隆方法，而且该克隆方法位于一个类的内部，当对已有的类进行改造时，需要修改源代码，违背了“开闭原则”。</li><li>在实现深克隆时需要编写较为复杂的代码，而且当对象之间存在多重的嵌套引用时，为了实现深克隆，每一层对象对应的类都必须支持深克隆，实现起来可能会比较麻烦。</li></ul><p><strong>适用场景：</strong></p><ul><li>创建新对象成本较大（如初始化需要占用较长的时间，占用太多的CPU资源或网络资源），新的对象可以通过原型模式对已有对象进行复制来获得，如果是相似对象，则可以对其成员变量稍作修改。</li><li>如果系统要保存对象的状态，而对象的状态变化很小，或者对象本身占用内存较少时，可以使用原型模式配合备忘录模式来实现。</li><li>需要避免使用分层次的工厂类来创建分层次的对象，并且类的实例对象只有一个或很少的几个组合状态，通过复制原型对象得到新实例可能比使用构造函数创建一个新实例更加方便。</li></ul><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析</p></blockquote><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;本文的主要内容如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;介绍原型模式&lt;/li&gt;
&lt;li&gt;示例&lt;ul&gt;
&lt;li&gt;Java语言的clone&lt;/li&gt;
&lt;
      
    
    </summary>
    
      <category term="后端" scheme="http://laijianfeng.org/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
      <category term="设计模式" scheme="http://laijianfeng.org/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>设计模式 | 建造者模式及典型应用</title>
    <link href="http://laijianfeng.org/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
    <id>http://laijianfeng.org/2018/09/设计模式-建造者模式及典型应用/</id>
    <published>2018-09-11T16:39:42.000Z</published>
    <updated>2018-09-11T16:40:51.023Z</updated>
    
    <content type="html"><![CDATA[<h3 id="建造者模式"><a href="#建造者模式" class="headerlink" title="建造者模式"></a>建造者模式</h3><p>建造者模式(Builder Pattern)：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。建造者模式是一种对象创建型模式。</p><p>建造者模式一步一步创建一个复杂的对象，它允许用户只通过指定复杂对象的类型和内容就可以构建它们，用户不需要知道内部的具体构建细节。</p><h4 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h4><p><strong>Builder（抽象建造者）</strong>：它为创建一个产品Product对象的各个部件指定抽象接口，在该接口中一般声明两类方法，一类方法是buildPartX()，它们用于创建复杂对象的各个部件；另一类方法是getResult()，它们用于返回复杂对象。Builder既可以是抽象类，也可以是接口。</p><p><strong>ConcreteBuilder（具体建造者）</strong>：它实现了Builder接口，实现各个部件的具体构造和装配方法，定义并明确它所创建的复杂对象，也可以提供一个方法返回创建好的复杂产品对象。</p><p><strong>Product（产品角色）</strong>：它是被构建的复杂对象，包含多个组成部件，具体建造者创建该产品的内部表示并定义它的装配过程。</p><p><strong>Director（指挥者）</strong>：指挥者又称为导演类，它负责安排复杂对象的建造次序，指挥者与抽象建造者之间存在关联关系，可以在其construct()建造方法中调用建造者对象的部件构造与装配方法，完成复杂对象的建造。客户端一般只需要与指挥者进行交互，在客户端确定具体建造者的类型，并实例化具体建造者对象（也可以通过配置文件和反射机制），然后通过指挥者类的构造函数或者Setter方法将该对象传入指挥者类中。</p><p>在建造者模式的定义中提到了复杂对象，那么什么是复杂对象？简单来说，<strong>复杂对象</strong>是指那些包含多个成员属性的对象，这些成员属性也称为部件或零件，如汽车包括方向盘、发动机、轮胎等部件，电子邮件包括发件人、收件人、主题、内容、附件等部件</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>产品角色 <code>Computer</code></p><pre><code>public class Computer {    private String brand;    private String cpu;    private String mainBoard;    private String hardDisk;    private String displayCard;    private String power;    private String memory;    // 省略 getter, setter, toString}</code></pre><p>抽象建造者 <code>builder</code></p><pre><code>public abstract class Builder {    protected Computer computer = new Computer();    public abstract void buildBrand();    public abstract void buildCPU();    public abstract void buildMainBoard();    public abstract void buildHardDisk();    public abstract void buildDisplayCard();    public abstract void buildPower();    public abstract void buildMemory();    public Computer createComputer() {        return computer;    }}</code></pre><p>具体建造者 <code>DellComputerBuilder</code>，<code>ASUSComputerBuilder</code>，分别建造戴尔电脑和华硕电脑</p><pre><code>public class DellComputerBuilder extends Builder {    @Override    public void buildBrand() {        computer.setBrand(&quot;戴尔电脑&quot;);    }    @Override    public void buildCPU() {        computer.setCpu(&quot;i5-8300H 四核&quot;);    }    @Override    public void buildMainBoard() {        computer.setMainBoard(&quot;戴尔主板&quot;);    }    @Override    public void buildHardDisk() {        computer.setHardDisk(&quot;1T + 128GB SSD&quot;);    }    @Override    public void buildDisplayCard() {        computer.setDisplayCard(&quot;GTX1060 独立6GB&quot;);    }    @Override    public void buildPower() {        computer.setPower(&quot;4芯 锂离子电池 180W AC适配器&quot;);    }    @Override    public void buildMemory() {        computer.setMemory(&quot;4G + 4G&quot;);    }}public class ASUSComputerBuilder extends Builder{    @Override    public void buildBrand() {        computer.setBrand(&quot;华硕电脑&quot;);    }    @Override    public void buildCPU() {        computer.setCpu(&quot;Intel 第8代 酷睿&quot;);    }    @Override    public void buildMainBoard() {        computer.setMainBoard(&quot;华硕主板&quot;);    }    @Override    public void buildHardDisk() {        computer.setHardDisk(&quot;256GB SSD&quot;);    }    @Override    public void buildDisplayCard() {        computer.setDisplayCard(&quot;MX150 独立2GB&quot;);    }    @Override    public void buildPower() {        computer.setPower(&quot;3芯 锂离子电池 65W AC适配器&quot;);    }    @Override    public void buildMemory() {        computer.setMemory(&quot;1 x SO-DIMM  8GB&quot;);    }}</code></pre><p>指挥者 <code>ComputerDirector</code>，指挥构建过程</p><pre><code>public class ComputerDirector {    public Computer construct(Builder builder) {        // 逐步构建复杂产品对象        Computer computer;        builder.buildBrand();        builder.buildCPU();        builder.buildDisplayCard();        builder.buildHardDisk();        builder.buildMainBoard();        builder.buildMemory();        builder.buildPower();        computer = builder.createComputer();        return computer;    }}</code></pre><p>客户端测试</p><pre><code>public class Test {    public static void main(String[] args) {        ComputerDirector director = new ComputerDirector();        Builder asusBuilder = new ASUSComputerBuilder();        Computer asusComputer = director.construct(asusBuilder);        System.out.println(asusComputer.toString());        Builder dellBuilder = new DellComputerBuilder();        Computer dellComputer = director.construct(dellBuilder);        System.out.println(dellComputer.toString());    }}</code></pre><p>输出</p><pre><code>Computer{brand=&#39;华硕电脑&#39;, cpu=&#39;Intel 第8代 酷睿&#39;, mainBoard=&#39;华硕主板&#39;, hardDisk=&#39;256GB SSD&#39;, displayCard=&#39;MX150 独立2GB&#39;, power=&#39;3芯 锂离子电池 65W AC适配器&#39;, memory=&#39;1 x SO-DIMM  8GB&#39;}Computer{brand=&#39;戴尔电脑&#39;, cpu=&#39;i5-8300H 四核&#39;, mainBoard=&#39;戴尔主板&#39;, hardDisk=&#39;1T + 128GB SSD&#39;, displayCard=&#39;GTX1060 独立6GB&#39;, power=&#39;4芯 锂离子电池 180W AC适配器&#39;, memory=&#39;4G + 4G&#39;}</code></pre><p>可以通过反射机制和配置文件配合，创建具体建造者对象</p><pre><code>public class Test {    public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException {        ComputerDirector director = new ComputerDirector();        // 从数据库或者配置文件中读取具体建造者类名        Class c = Class.forName(&quot;com.designpattern.ASUSComputerBuilder&quot;);        Builder asusBuilder = (Builder) c.newInstance();        Computer asusComputer = director.construct(asusBuilder);        System.out.println(asusComputer.toString());    }}</code></pre><p><img src="http://image.laijianfeng.org/20180911_164411.png" alt="image"></p><h3 id="建造者模式总结"><a href="#建造者模式总结" class="headerlink" title="建造者模式总结"></a>建造者模式总结</h3><p>建造者模式的<strong>主要优点</strong>如下：</p><ul><li>在建造者模式中，客户端不必知道产品内部组成的细节，将产品本身与产品的创建过程解耦，使得相同的创建过程可以创建不同的产品对象。</li><li>每一个具体建造者都相对独立，而与其他的具体建造者无关，因此可以很方便地替换具体建造者或增加新的具体建造者，用户使用不同的具体建造者即可得到不同的产品对象。由于指挥者类针对抽象建造者编程，增加新的具体建造者无须修改原有类库的代码，系统扩展方便，符合 “开闭原则”。</li><li>可以更加精细地控制产品的创建过程。将复杂产品的创建步骤分解在不同的方法中，使得创建过程更加清晰，也更方便使用程序来控制创建过程。</li></ul><p>建造者模式的<strong>主要缺点</strong>如下：</p><ul><li>建造者模式所创建的产品一般具有较多的共同点，其组成部分相似，如果产品之间的差异性很大，例如很多组成部分都不相同，不适合使用建造者模式，因此其使用范围受到一定的限制。</li><li>如果产品的内部变化复杂，可能会导致需要定义很多具体建造者类来实现这种变化，导致系统变得很庞大，增加系统的理解难度和运行成本。</li></ul><p><strong>适用场景</strong>：</p><ul><li>需要生成的产品对象有复杂的内部结构，这些产品对象通常包含多个成员属性。</li><li>需要生成的产品对象的属性相互依赖，需要指定其生成顺序。</li><li>对象的创建过程独立于创建该对象的类。在建造者模式中通过引入了指挥者类，将创建过程封装在指挥者类中，而不在建造者类和客户类中。</li><li>隔离复杂对象的创建和使用，并使得相同的创建过程可以创建不同的产品。</li></ul><h3 id="建造者模式的典型应用和源码分析"><a href="#建造者模式的典型应用和源码分析" class="headerlink" title="建造者模式的典型应用和源码分析"></a>建造者模式的典型应用和源码分析</h3><h4 id="java-lang-StringBuilder-中的建造者模式"><a href="#java-lang-StringBuilder-中的建造者模式" class="headerlink" title="java.lang.StringBuilder 中的建造者模式"></a>java.lang.StringBuilder 中的建造者模式</h4><p><code>StringBuilder</code> 的继承实现关系如下所示</p><p><img src="http://image.laijianfeng.org/20180911_172041.png" alt="StringBuilder的类图"></p><p><code>Appendable</code> 接口如下</p><pre><code>public interface Appendable {    Appendable append(CharSequence csq) throws IOException;    Appendable append(CharSequence csq, int start, int end) throws IOException;    Appendable append(char c) throws IOException;}</code></pre><p><code>StringBuilder</code> 中的 <code>append</code> 方法使用了建造者模式，不过装配方法只有一个，并不算复杂，<code>append</code> 方法返回的是 <code>StringBuilder</code> 自身</p><pre><code>public final class StringBuilder extends AbstractStringBuilder implements java.io.Serializable, CharSequence {    @Override    public StringBuilder append(String str) {        super.append(str);        return this;    }    // ...省略...}</code></pre><p><code>StringBuilder</code> 的父类 <code>AbstractStringBuilder</code> 实现了 <code>Appendable</code> 接口</p><pre><code>abstract class AbstractStringBuilder implements Appendable, CharSequence {    char[] value;    int count;    public AbstractStringBuilder append(String str) {        if (str == null)            return appendNull();        int len = str.length();        ensureCapacityInternal(count + len);        str.getChars(0, len, value, count);        count += len;        return this;    }    private void ensureCapacityInternal(int minimumCapacity) {        // overflow-conscious code        if (minimumCapacity - value.length &gt; 0) {            value = Arrays.copyOf(value,                    newCapacity(minimumCapacity));        }    }    // ...省略...}</code></pre><p>我们可以看出，<code>Appendable</code> 为抽象建造者，定义了建造方法，<code>StringBuilder</code> 既充当指挥者角色，又充当产品角色，又充当具体建造者，建造方法的实现由 <code>AbstractStringBuilder</code> 完成，而 <code>StringBuilder</code> 继承了 <code>AbstractStringBuilder</code> </p><h4 id="java-lang-StringBuffer-中的建造者方法"><a href="#java-lang-StringBuffer-中的建造者方法" class="headerlink" title="java.lang.StringBuffer 中的建造者方法"></a>java.lang.StringBuffer 中的建造者方法</h4><p>StringBuffer 继承与实现关系如下</p><p><img src="http://image.laijianfeng.org/20180911_173716.png" alt="StringBuffer的类图"></p><p>这分明就与 <code>StringBuilder</code> 一样嘛！</p><p>那它们有什么不同呢？</p><pre><code>public final class StringBuffer extends AbstractStringBuilder implements java.io.Serializable, CharSequence {    @Override    public synchronized StringBuffer append(String str) {        toStringCache = null;        super.append(str);        return this;    }    //...省略...}</code></pre><p>看 <code>StringBuffer</code> 的源码如上，它们的区别就是： <code>StringBuffer</code> 中的 <code>append</code> 加了 <code>synchronized</code> 关键字，所以<code>StringBuffer</code> 是线程安全的，而 <code>StringBuilder</code> 是非线程安全的</p><p><code>StringBuffer</code> 中的建造者模式与 <code>StringBuilder</code> 是一致的</p><h4 id="Google-Guava-中的建造者模式"><a href="#Google-Guava-中的建造者模式" class="headerlink" title="Google Guava 中的建造者模式"></a>Google Guava 中的建造者模式</h4><p><code>ImmutableSet</code> 不可变Set的主要方法如下</p><p><img src="http://image.laijianfeng.org/20180911_234124.png" alt="ImmutableSet方法列表"></p><p><code>ImmutableSet</code> 类中 <code>of</code>, <code>copyOf</code> 等方法返回的是一个 <code>ImmutableSet</code> 对象，这里是一个建造者模式，所构建的复杂产品对象为 <code>ImmutableSet</code></p><p><code>ImmutableSet</code> 的内部类 <code>ImmutableSet.Builder</code> 如下所示</p><pre><code>public static class Builder&lt;E&gt; extends ArrayBasedBuilder&lt;E&gt; {    @CanIgnoreReturnValue    public ImmutableSet.Builder&lt;E&gt; add(E... elements) {        super.add(elements);        return this;    }    @CanIgnoreReturnValue    public ImmutableSet.Builder&lt;E&gt; addAll(Iterator&lt;? extends E&gt; elements) {        super.addAll(elements);        return this;    }    public ImmutableSet&lt;E&gt; build() {        ImmutableSet&lt;E&gt; result = ImmutableSet.construct(this.size, this.contents);        this.size = result.size();        return result;    }    //...省略...}</code></pre><p>其中的 <code>add</code>、<code>addAll</code>等方法返回的是 <code>ImmutableSet.Builder</code> 对象本身，而 <code>build</code> 则返回 <code>ImmutableSet</code> 对象，所以 <code>ImmutableSet.Builder</code> 是具体建造者，<code>add</code>、<code>addAll</code>等方法则相当于<code>buildPartX()</code>，是装配过程中的一部分，<code>build</code> 方法则是 <code>getResult()</code>，返回最终创建好的复杂产品对象</p><p>ImmutableSet 使用示例如下:</p><pre><code>public class Test2 {    public static void main(String[] args) {        Set&lt;String&gt; set = ImmutableSet.&lt;String&gt;builder().add(&quot;a&quot;).add(&quot;a&quot;).add(&quot;b&quot;).build();        System.out.println(set);        // [a, b]    }}</code></pre><p>再来看一个，一般创建一个 <code>guava缓存</code> 的写法如下所示</p><pre><code>final static Cache&lt;Integer, String&gt; cache = CacheBuilder.newBuilder()        //设置cache的初始大小为10，要合理设置该值          .initialCapacity(10)        //设置并发数为5，即同一时间最多只能有5个线程往cache执行写入操作          .concurrencyLevel(5)        //设置cache中的数据在写入之后的存活时间为10秒          .expireAfterWrite(10, TimeUnit.SECONDS)        //构建cache实例          .build();</code></pre><p>这里很明显，我们不用看源码就可以知道这里是一个典型的建造者模式，<code>CacheBuilder.newBuilder()</code> 创建了一个具体建造者，<code>.initialCapacity(10)</code>、<code>.concurrencyLevel(5)</code>、<code>.expireAfterWrite(10, TimeUnit.SECONDS)</code> 则是构建过程，最终的 <code>.build()</code> 返回创建完成的复杂产品对象</p><p>看看源码是不是符合我们的猜测</p><pre><code>public final class CacheBuilder&lt;K, V&gt; {    // 创建一个具体建造者    public static CacheBuilder&lt;Object, Object&gt; newBuilder() {        return new CacheBuilder();    }    // 建造过程之一    public CacheBuilder&lt;K, V&gt; initialCapacity(int initialCapacity) {        Preconditions.checkState(this.initialCapacity == -1, &quot;initial capacity was already set to %s&quot;, this.initialCapacity);        Preconditions.checkArgument(initialCapacity &gt;= 0);        this.initialCapacity = initialCapacity;        return this;    }    // 建造过程之一    public CacheBuilder&lt;K, V&gt; concurrencyLevel(int concurrencyLevel) {        Preconditions.checkState(this.concurrencyLevel == -1, &quot;concurrency level was already set to %s&quot;, this.concurrencyLevel);        Preconditions.checkArgument(concurrencyLevel &gt; 0);        this.concurrencyLevel = concurrencyLevel;        return this;    }    // 建造过程之一    public CacheBuilder&lt;K, V&gt; expireAfterWrite(long duration, TimeUnit unit) {        Preconditions.checkState(this.expireAfterWriteNanos == -1L, &quot;expireAfterWrite was already set to %s ns&quot;, this.expireAfterWriteNanos);        Preconditions.checkArgument(duration &gt;= 0L, &quot;duration cannot be negative: %s %s&quot;, duration, unit);        this.expireAfterWriteNanos = unit.toNanos(duration);        return this;    }    // 建造完成，返回创建完的复杂产品对象    public &lt;K1 extends K, V1 extends V&gt; Cache&lt;K1, V1&gt; build() {        this.checkWeightWithWeigher();        this.checkNonLoadingCache();        return new LocalManualCache(this);    }    // ...省略...}</code></pre><p>很明显符合我们的猜测，<code>initialCapacity()</code>、<code>concurrencyLevel()</code>、<code>expireAfterWrite()</code> 等方法对传进来的参数进行处理和设置，返回 <code>CacheBuilder</code> 对象本身，<code>build</code> 则把 <code>CacheBuilder</code> 对象 作为参数，new 了一个 <code>LocalManualCache</code> 对象返回</p><h4 id="mybatis-中的建造者模式"><a href="#mybatis-中的建造者模式" class="headerlink" title="mybatis 中的建造者模式"></a>mybatis 中的建造者模式</h4><p>我们来看 <code>org.apache.ibatis.session</code> 包下的 <code>SqlSessionFactoryBuilder</code> 类</p><p><img src="http://image.laijianfeng.org/20180912_002707.png" alt="SqlSessionFactoryBuilder的方法"></p><p>里边很多重载的 <code>build</code> 方法，返回值都是 <code>SqlSessionFactory</code>，除了最后两个所有的 <code>build</code> 最后都调用下面这个 <code>build</code> 方法</p><pre><code>    public SqlSessionFactory build(Reader reader, String environment, Properties properties) {        SqlSessionFactory var5;        try {            XMLConfigBuilder parser = new XMLConfigBuilder(reader, environment, properties);            var5 = this.build(parser.parse());        } catch (Exception var14) {            throw ExceptionFactory.wrapException(&quot;Error building SqlSession.&quot;, var14);        } finally {            ErrorContext.instance().reset();            try {                reader.close();            } catch (IOException var13) {                ;            }        }        return var5;    }</code></pre><p>其中最重要的是 <code>XMLConfigBuilder</code> 的 <code>parse</code> 方法，代码如下</p><pre><code>public class XMLConfigBuilder extends BaseBuilder {    public Configuration parse() {        if (this.parsed) {            throw new BuilderException(&quot;Each XMLConfigBuilder can only be used once.&quot;);        } else {            this.parsed = true;            this.parseConfiguration(this.parser.evalNode(&quot;/configuration&quot;));            return this.configuration;        }    }    private void parseConfiguration(XNode root) {        try {            Properties settings = this.settingsAsPropertiess(root.evalNode(&quot;settings&quot;));            this.propertiesElement(root.evalNode(&quot;properties&quot;));            this.loadCustomVfs(settings);            this.typeAliasesElement(root.evalNode(&quot;typeAliases&quot;));            this.pluginElement(root.evalNode(&quot;plugins&quot;));            this.objectFactoryElement(root.evalNode(&quot;objectFactory&quot;));            this.objectWrapperFactoryElement(root.evalNode(&quot;objectWrapperFactory&quot;));            this.reflectorFactoryElement(root.evalNode(&quot;reflectorFactory&quot;));            this.settingsElement(settings);            this.environmentsElement(root.evalNode(&quot;environments&quot;));            this.databaseIdProviderElement(root.evalNode(&quot;databaseIdProvider&quot;));            this.typeHandlerElement(root.evalNode(&quot;typeHandlers&quot;));            this.mapperElement(root.evalNode(&quot;mappers&quot;));        } catch (Exception var3) {            throw new BuilderException(&quot;Error parsing SQL Mapper Configuration. Cause: &quot; + var3, var3);        }    }    // ...省略...}</code></pre><p><code>parse</code> 方法最终要返回一个 <code>Configuration</code> 对象，构建 <code>Configuration</code> 对象的建造过程都在 <code>parseConfiguration</code> 方法中，这也就是 <code>Mybatis</code> 解析 <code>XML配置文件</code> 来构建 <code>Configuration</code> 对象的主要过程</p><p>所以 <code>XMLConfigBuilder</code> 是建造者 <code>SqlSessionFactoryBuilder</code> 中的建造者，复杂产品对象分别是 <code>SqlSessionFactory</code> 和 <code>Configuration</code></p><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;建造者模式&quot;&gt;&lt;a href=&quot;#建造者模式&quot; class=&quot;headerlink&quot; title=&quot;建造者模式&quot;&gt;&lt;/a&gt;建造者模式&lt;/h3&gt;&lt;p&gt;建造者模式(Builder Pattern)：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表
      
    
    </summary>
    
      <category term="后端" scheme="http://laijianfeng.org/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
      <category term="设计模式" scheme="http://laijianfeng.org/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>设计模式 | 抽象工厂模式及典型应用</title>
    <link href="http://laijianfeng.org/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
    <id>http://laijianfeng.org/2018/09/设计模式之抽象工厂模式及典型应用/</id>
    <published>2018-09-10T15:51:05.000Z</published>
    <updated>2018-09-11T07:10:25.650Z</updated>
    
    <content type="html"><![CDATA[<h3 id="抽象工厂模式"><a href="#抽象工厂模式" class="headerlink" title="抽象工厂模式"></a>抽象工厂模式</h3><p>抽象工厂模式(Abstract Factory Pattern)：提供一个创建一系列相关或相互依赖对象的接口，而无须指定它们具体的类。抽象工厂模式又称为Kit模式，它是一种对象创建型模式。</p><p>在抽象工厂模式中，每一个具体工厂都提供了多个工厂方法用于产生多种不同类型的产品。</p><h4 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h4><p>在抽象工厂模式包含如下几个角色：</p><ul><li><strong>AbstractFactory（抽象工厂）</strong>：它声明了一组用于创建一族产品的方法，每一个方法对应一种产品。</li><li><strong>ConcreteFactory（具体工厂）</strong>：它实现了在抽象工厂中声明的创建产品的方法，生成一组具体产品，这些产品构成了一个产品族，每一个产品都位于某个产品等级结构中。</li><li><strong>AbstractProduct（抽象产品）</strong>：它为每种产品声明接口，在抽象产品中声明了产品所具有的业务方法</li><li><strong>ConcreteProduct（具体产品）</strong>：它定义具体工厂生产的具体产品对象，实现抽象产品接口中声明的业务方法。</li></ul><p>在抽象工厂中声明了多个工厂方法，用于创建不同类型的产品，抽象工厂可以是接口，也可以是抽象类或者具体类</p><p>具体工厂实现了抽象工厂，每一个具体的工厂方法可以返回一个特定的产品对象，而同一个具体工厂所创建的产品对象构成了一个产品族</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>首先定义我们的抽象产品 <code>Article</code> 和 <code>Video</code>，他们是产品族的抽象类，有一个 <code>Article</code> 就有一个 <code>Video</code></p><pre><code>public abstract class Article {    public abstract void produce();}public abstract class Video {    public abstract void produce();}</code></pre><p>具体产品 <code>JavaArticle</code>、<code>PythonArticle</code>、<code>PythonVideo</code>、<code>JavaVideo</code></p><pre><code>public class JavaArticle extends Article {    @Override    public void produce() {        System.out.println(&quot;编写Java课程笔记记&quot;);    }}public class PythonArticle extends Article {    @Override    public void produce() {        System.out.println(&quot;编写Python课程笔记&quot;);    }}public class JavaVideo extends Video {    @Override    public void produce() {        System.out.println(&quot;录制Java课程视频&quot;);    }}public class PythonVideo extends Video {    @Override    public void produce() {        System.out.println(&quot;录制Python课程视频&quot;);    }}</code></pre><p>定义我们的抽象工厂 <code>CourseFactory</code>，与工厂方法模式不同，工厂方法模式中一个工厂只生产一个产品，而抽象工厂模式中一个工厂生产一族产品，有多个工厂方法</p><pre><code>public interface CourseFactory {    Video getVideo();    Article getArticle();}</code></pre><p>具体工厂 <code>JavaCourseFactory</code> 和 <code>PythonCourseFactory</code>，它们都继承抽象工厂接口 <code>CourseFactory</code></p><pre><code>public class JavaCourseFactory implements CourseFactory {    @Override    public Video getVideo() {        return new JavaVideo();    }    @Override    public Article getArticle() {        return new JavaArticle();    }}public class PythonCourseFactory implements CourseFactory {    @Override    public Video getVideo() {        return new PythonVideo();    }    @Override    public Article getArticle() {        return new PythonArticle();    }}</code></pre><p>客户端只需要指定具体工厂，就可以获取该工厂生产的一族产品</p><pre><code>public class Test {    public static void main(String[] args) {        CourseFactory courseFactory = new JavaCourseFactory();        Video video = courseFactory.getVideo();        Article article = courseFactory.getArticle();        video.produce();        article.produce();    }}</code></pre><p>输出</p><pre><code>录制Java课程视频编写Java课程笔记</code></pre><p>也可以利用反射机制和配置文件，当需要修改具体工厂的时候就不需要修改客户端代码，只改配置文件即可</p><pre><code>public class Test {    public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException {        // 从配置文件或数据库等外部渠道获取具体工厂类名        String factoryName = &quot;com.designpattern.JavaCourseFactory&quot;;        // 通过反射机制获取工厂类        Class c = Class.forName(factoryName);        CourseFactory courseFactory = (CourseFactory) c.newInstance();        Video video = courseFactory.getVideo();        Article article = courseFactory.getArticle();        video.produce();        article.produce();    }}</code></pre><p>最终的类图如下所示</p><p><img src="http://image.laijianfeng.org/20180910_231358.png" alt="示例.抽象工厂类图"></p><h3 id="抽象工厂模式总结"><a href="#抽象工厂模式总结" class="headerlink" title="抽象工厂模式总结"></a>抽象工厂模式总结</h3><p>抽象工厂模式的<strong>主要优点</strong>如下：</p><ul><li>抽象工厂模式隔离了具体类的生成，使得客户并不需要知道什么被创建。由于这种隔离，更换一个具体工厂就变得相对容易，所有的具体工厂都实现了抽象工厂中定义的那些公共接口，因此只需改变具体工厂的实例，就可以在某种程度上改变整个软件系统的行为。</li><li>当一个产品族中的多个对象被设计成一起工作时，它能够保证客户端始终只使用同一个产品族中的对象。</li><li>增加新的产品族很方便，无须修改已有系统，符合”开闭原则”。</li></ul><p>抽象工厂模式的<strong>主要缺点</strong>如下：</p><ul><li>增加新的产品等级结构麻烦，需要对原有系统进行较大的修改，甚至需要修改抽象层代码，这显然会带来较大的不便，违背了\”开闭原则”。</li></ul><p><strong>适用场景</strong>：</p><ul><li>一个系统不应当依赖于产品类实例如何被创建、组合和表达的细节，这对于所有类型的工厂模式都是很重要的，用户无须关心对象的创建过程，将对象的创建和使用解耦。</li><li>系统中有多于一个的产品族，而每次只使用其中某一产品族。可以通过配置文件等方式来使得用户可以动态改变产品族，也可以很方便地增加新的产品族。</li><li>属于同一个产品族的产品将在一起使用，这一约束必须在系统的设计中体现出来。同一个产品族中的产品可以是没有任何关系的对象，但是它们都具有一些共同的约束，如同一操作系统下的按钮和文本框，按钮与文本框之间没有直接关系，但它们都是属于某一操作系统的，此时具有一个共同的约束条件：操作系统的类型。</li><li>产品等级结构稳定，设计完成之后，不会向系统中增加新的产品等级结构或者删除已有的产品等级结构。</li></ul><h3 id="抽象工厂模式的典型应用及源码分析"><a href="#抽象工厂模式的典型应用及源码分析" class="headerlink" title="抽象工厂模式的典型应用及源码分析"></a>抽象工厂模式的典型应用及源码分析</h3><p>我们来看 <code>java.sql</code> 包下的 <code>Connection</code> 接口，该接口定义了与特定数据库的连接 <code>Connection</code>，执行 <code>SQL statements</code> 并返回 <code>results</code></p><pre><code>public interface Connection  extends Wrapper, AutoCloseable {    Statement createStatement() throws SQLException;    PreparedStatement prepareStatement(String sql) throws SQLException;    CallableStatement prepareCall(String sql) throws SQLException;    DatabaseMetaData getMetaData() throws SQLException;    Savepoint setSavepoint() throws SQLException;    Clob createClob() throws SQLException;    Blob createBlob() throws SQLException;    SQLXML createSQLXML() throws SQLException;    // ...省略...}</code></pre><p>其中 <code>Statement</code>、<code>PreparedStatement</code>、<code>CallableStatement</code>、<code>DatabaseMetaData</code>、<code>Savepoint</code>、<code>Clob</code>、<code>Blob</code>、<code>SQLXML</code> 等均为接口</p><p>我们来看 <code>Statement</code> 接口</p><pre><code>public interface Statement extends Wrapper, AutoCloseable {    ResultSet executeQuery(String sql) throws SQLException;    int executeUpdate(String sql) throws SQLException;    void close() throws SQLException;    int getMaxFieldSize() throws SQLException;    boolean execute(String sql) throws SQLException;    // ...省略...}</code></pre><p>其中的 <code>ResultSet</code> 又是一个接口</p><pre><code>public interface ResultSet extends Wrapper, AutoCloseable {    boolean next() throws SQLException;    void close() throws SQLException;    boolean wasNull() throws SQLException;    String getString(int columnIndex) throws SQLException;    //...省略...}</code></pre><p>我们可以看一下他们的实现类</p><p><img src="http://image.laijianfeng.org/20180910_234012.png" alt="Connection的实现类"></p><p><img src="http://image.laijianfeng.org/20180910_234051.png" alt="Statement的实现类"></p><p><img src="http://image.laijianfeng.org/20180910_234121.png" alt="ResultSet的实现类"></p><p>可以看出这里边的抽象工厂模式，<code>Connection</code> 为抽象工厂，工厂方法很多，其中一个抽象产品为 <code>Statement</code>，同时 <code>Statement</code> 也是一个抽象工厂，工厂方法也很多，其中一个抽象产品为 <code>ResultSet</code>，具体工厂和具体产品则为他们的实现类</p><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析</p></blockquote><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;抽象工厂模式&quot;&gt;&lt;a href=&quot;#抽象工厂模式&quot; class=&quot;headerlink&quot; title=&quot;抽象工厂模式&quot;&gt;&lt;/a&gt;抽象工厂模式&lt;/h3&gt;&lt;p&gt;抽象工厂模式(Abstract Factory Pattern)：提供一个创建一系列相关或相互依赖对象的接口
      
    
    </summary>
    
      <category term="后端" scheme="http://laijianfeng.org/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
      <category term="设计模式" scheme="http://laijianfeng.org/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>设计模式 | 工厂方法模式及典型应用</title>
    <link href="http://laijianfeng.org/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
    <id>http://laijianfeng.org/2018/09/设计模式之工厂方法模式及典型应用/</id>
    <published>2018-09-09T09:20:14.000Z</published>
    <updated>2018-09-09T09:24:06.085Z</updated>
    
    <content type="html"><![CDATA[<h3 id="工厂方法模式"><a href="#工厂方法模式" class="headerlink" title="工厂方法模式"></a>工厂方法模式</h3><p>工厂方法模式(Factory Method Pattern)：定义一个用于创建对象的接口，让子类决定将哪一个类实例化。工厂方法模式让一个类的实例化延迟到其子类。</p><p>工厂方法模式又简称为工厂模式(Factory Pattern)，又可称作虚拟构造器模式(Virtual Constructor Pattern)或多态工厂模式(Polymorphic Factory Pattern)。</p><p>工厂方法模式是一种类创建型模式。</p><h4 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h4><p>在工厂方法模式结构图中包含如下几个角色：</p><p><strong>Product（抽象产品）</strong>：它是定义产品的接口，是工厂方法模式所创建对象的超类型，也就是产品对象的公共父类</p><p><strong>ConcreteProduct（具体产品）</strong>：它实现了抽象产品接口，某种类型的具体产品由专门的具体工厂创建，具体工厂和具体产品之间一一对应。</p><p><strong>Factory（抽象工厂）</strong>：在抽象工厂类中，声明了工厂方法(Factory Method)，用于返回一个产品。抽象工厂是工厂方法模式的核心，所有创建对象的工厂类都必须实现该接口。</p><p><strong>ConcreteFactory（具体工厂）</strong>：它是抽象工厂类的子类，实现了抽象工厂中定义的工厂方法，并可由客户端调用，返回一个具体产品类的实例。</p><p>与简单工厂模式相比，工厂方法模式最重要的区别是引入了抽象工厂角色，抽象工厂可以是接口，也可以是抽象类或者具体类</p><h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><p>抽象产品类 Video</p><pre><code>public abstract class Video {    public abstract void produce();}</code></pre><p>具体产品类 JavaVideo 和 PythonVideo，需要继承抽象产品类 Video</p><pre><code>public class JavaVideo extends Video {    @Override    public void produce() {        System.out.println(&quot;录制Java课程视频&quot;);    }}public class PythonVideo extends Video {    @Override    public void produce() {        System.out.println(&quot;录制Python课程视频&quot;);    }}</code></pre><p>抽象工厂类 VideoFactory</p><pre><code>public abstract class VideoFactory {    public abstract Video getVideo();}</code></pre><p>具体工厂类 JavaVideoFactory 和 PythonVideoFactory，需要继承抽象工厂类 VideoFactory</p><pre><code>public class JavaVideoFactory extends VideoFactory {    @Override    public Video getVideo() {        return new JavaVideo();    }}public class PythonVideoFactory extends VideoFactory {    @Override    public Video getVideo() {        return new PythonVideo();    }}</code></pre><p>客户端类，需要什么产品则通过该产品对应的工厂类来获取，不需要知道具体的创建过程</p><pre><code>public class Test {    public static void main(String[] args) {        VideoFactory pythonVideoFactory = new PythonVideoFactory();        VideoFactory javaVideoFactory = new JavaVideoFactory();        Video pythonVideo = pythonVideoFactory.getVideo();        pythonVideo.produce();        Video javaVideo = javaVideoFactory.getVideo();        javaVideo.produce();    }}</code></pre><p>输出</p><pre><code>录制Python课程视频录制Java课程视频</code></pre><p>当需要增加一个产品 FEVideo 时，只需要增加 FEVideo 具体产品类和 FEVideoFactory 具体工厂类即可，不需要修改原有的产品类和工厂类</p><pre><code>public class FEVideo extends Video{    @Override    public void produce() {        System.out.println(&quot;录制FE课程视频&quot;);    }}public class FEVideoFactory extends VideoFactory{    @Override    public Video getVideo() {        return new FEVideo();    }}</code></pre><p>修改客户端代码</p><pre><code>public class Test {    public static void main(String[] args) {        VideoFactory feVideoFactory = new FEVideoFactory();        Video feVideo = feVideoFactory.getVideo();        feVideo.produce();    }}</code></pre><p>还可以通过反射机制和配置文件配合，连客户端代码都不需要修改</p><pre><code>public class Test {    public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException {        // 从文件或数据库等外部渠道获取 工厂类名        String factoryName = &quot;com.designpattern.factorymethod.JavaVideoFactory&quot;;        // 通过反射机制获取工厂类        Class c = Class.forName(factoryName);        VideoFactory factory = (VideoFactory)c.newInstance();        // 生产产品        Video video = factory.getVideo();        video.produce();    }}</code></pre><p>最终的类图如下所示</p><p><img src="http://image.laijianfeng.org/20180908_223324.png" alt="示例.工厂方法结构图"></p><h3 id="工厂方法模式总结"><a href="#工厂方法模式总结" class="headerlink" title="工厂方法模式总结"></a>工厂方法模式总结</h3><p>工厂方法模式是简单工厂模式的延伸，它继承了简单工厂模式的优点，同时还弥补了简单工厂模式的不足。工厂方法模式是使用频率最高的设计模式之一，是很多开源框架和API类库的核心模式。</p><h4 id="工厂方法模式的主要优点"><a href="#工厂方法模式的主要优点" class="headerlink" title="工厂方法模式的主要优点"></a>工厂方法模式的主要优点</h4><ul><li>在工厂方法模式中，工厂方法用来创建客户所需要的产品，同时还向客户隐藏了哪种具体产品类将被实例化这一细节，用户只需要关心所需产品对应的工厂，无须关心创建细节，甚至无须知道具体产品类的类名。</li><li>基于工厂角色和产品角色的多态性设计是工厂方法模式的关键。它能够让工厂可以自主确定创建何种产品对象，而如何创建这个对象的细节则完全封装在具体工厂内部。工厂方法模式之所以又被称为多态工厂模式，就正是因为所有的具体工厂类都具有同一抽象父类。</li><li>使用工厂方法模式的另一个优点是在系统中加入新产品时，无须修改抽象工厂和抽象产品提供的接口，无须修改客户端，也无须修改其他的具体工厂和具体产品，而只要添加一个具体工厂和具体产品就可以了，这样，系统的可扩展性也就变得非常好，完全符合”开闭原则”。</li></ul><h4 id="工厂方法模式的主要缺点"><a href="#工厂方法模式的主要缺点" class="headerlink" title="工厂方法模式的主要缺点"></a>工厂方法模式的主要缺点</h4><ul><li>在添加新产品时，需要编写新的具体产品类，而且还要提供与之对应的具体工厂类，系统中类的个数将成对增加，在一定程度上增加了系统的复杂度，有更多的类需要编译和运行，会给系统带来一些额外的开销。</li><li>由于考虑到系统的可扩展性，需要引入抽象层，在客户端代码中均使用抽象层进行定义，增加了系统的抽象性和理解难度，且在实现时可能需要用到DOM、反射等技术，增加了系统的实现难度。</li></ul><h4 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h4><ul><li>客户端不知道它所需要的对象的类。在工厂方法模式中，客户端不需要知道具体产品类的类名，只需要知道所对应的工厂即可，具体的产品对象由具体工厂类创建，可将具体工厂类的类名存储在配置文件或数据库中。</li><li>抽象工厂类通过其子类来指定创建哪个对象。在工厂方法模式中，对于抽象工厂类只需要提供一个创建产品的接口，而由其子类来确定具体要创建的对象，利用面向对象的多态性和里氏代换原则，在程序运行时，子类对象将覆盖父类对象，从而使得系统更容易扩展。</li></ul><h3 id="工厂方法模式的典型应用及源码分析"><a href="#工厂方法模式的典型应用及源码分析" class="headerlink" title="工厂方法模式的典型应用及源码分析"></a>工厂方法模式的典型应用及源码分析</h3><h4 id="Java集合接口-Collection-中的工厂方法模式"><a href="#Java集合接口-Collection-中的工厂方法模式" class="headerlink" title="Java集合接口 Collection 中的工厂方法模式"></a>Java集合接口 Collection 中的工厂方法模式</h4><p>Collection 中的 iterator 方法如下：</p><pre><code>public interface Collection&lt;E&gt; extends Iterable&lt;E&gt; {    Iterator&lt;E&gt; iterator();    // ...省略}</code></pre><blockquote><p>关于 iterator 方法的介绍：<br>Java的迭代器只在Collection中有，而Map没有迭代器，它有不同的迭代方法；<br> <strong>迭代器的终极目标</strong>：就是用统一的方法来迭代不同类型的集合！可能由于不同集合的内部数据结构不尽相同，如果要自己纯手工迭代的话相互之间会有很大的差别，而迭代器的作用就是统一的方法对不同的集合进行迭代，而在迭代器底层隐藏不同集合之间的差异，从而为迭代提供最大的方便<br><strong>使用用迭代器迭代的步骤</strong>： i. 第一步肯定是先获取集合的迭代器：调用集合的iterator方法就能获得，Iterator<e> Collection.iterator(); ii. 使用迭代器的hasNext、next往下迭代<br><strong>Iterator的常用方法</strong>：boolean hasNext()：是否还有下一个元素； Object next()：取出下一个元素并返回； void remove(); ：从容器中删除当前元素，直接会改变容器中的数据</e></p></blockquote><p>查看该接口的实现类，可以看到是非常的多</p><p><img src="http://image.laijianfeng.org/20180908_230822.png" alt="Collection接口的实现类(部分)"></p><p>我们仅看其中一个实现类 <code>java.util.ArrayList</code>，看其对 <code>iterator</code> 方法的实现</p><pre><code>public Iterator&lt;E&gt; iterator() {    return new Itr();}/** * An optimized version of AbstractList.Itr */private class Itr implements Iterator&lt;E&gt; {    int cursor;       // index of next element to return    int lastRet = -1; // index of last element returned; -1 if no such    int expectedModCount = modCount;    Itr() {}    public boolean hasNext() {        return cursor != size;    }    @SuppressWarnings(&quot;unchecked&quot;)    public E next() {        // ...省略...    }    public void remove() {        // ...省略...    }    @Override    @SuppressWarnings(&quot;unchecked&quot;)    public void forEachRemaining(Consumer&lt;? super E&gt; consumer) {        // ...省略...    }    final void checkForComodification() {        // ...省略...    }}</code></pre><p><code>Itr</code> 类实现了 <code>iterator</code> 接口，<code>iterator</code> 接口正是 <code>Collection</code> 接口中 <code>iterator</code> 方法的返回类型，其代码如下：</p><pre><code>public interface Iterator&lt;E&gt; {    boolean hasNext();    E next();    default void remove() {        throw new UnsupportedOperationException(&quot;remove&quot;);    }    default void forEachRemaining(Consumer&lt;? super E&gt; action) {        Objects.requireNonNull(action);        while (hasNext())            action.accept(next());    }}</code></pre><p><strong>由此可见</strong>，<code>Collection</code> 接口扮演了抽象工厂角色，工厂方法为 <code>iterator()</code>，<code>Collection</code> 的实现类譬如 <code>ArrayList</code> 扮演了具体工厂角色，而抽象产品为 <code>Iterator</code> 接口，具体产品为 <code>Itr</code> 类</p><h4 id="java-net-网络包中的工厂方法模式"><a href="#java-net-网络包中的工厂方法模式" class="headerlink" title="java.net 网络包中的工厂方法模式"></a>java.net 网络包中的工厂方法模式</h4><p>URLStreamHandlerFactory 接口为 URL 流协议处理程序定义一个工厂。URL 类使用它可为特定的协议创建 URLStreamHandler</p><pre><code>public interface URLStreamHandlerFactory {    /**     * Creates a new {@code URLStreamHandler} instance with the specified protocol.     *     * @param   protocol   the protocol (&quot;{@code ftp}&quot;, &quot;{@code http}&quot;, &quot;{@code nntp}&quot;, etc.).     * @return  a {@code URLStreamHandler} for the specific protocol.     * @see     java.net.URLStreamHandler     */    URLStreamHandler createURLStreamHandler(String protocol);}</code></pre><p>该接口的实现类为 <code>sun.misc.Launcher</code> 中的内部类 <code>Factory</code></p><pre><code>private static class Factory implements URLStreamHandlerFactory {    private static String PREFIX = &quot;sun.net.www.protocol&quot;;    private Factory() {    }    public URLStreamHandler createURLStreamHandler(String var1) {        String var2 = PREFIX + &quot;.&quot; + var1 + &quot;.Handler&quot;;        try {            Class var3 = Class.forName(var2);            return (URLStreamHandler)var3.newInstance();        } catch (ReflectiveOperationException var4) {            throw new InternalError(&quot;could not load &quot; + var1 + &quot;system protocol handler&quot;, var4);        }    }}</code></pre><p>可以看到 <code>createURLStreamHandler</code> 方法的实现为：传入参数，拼接前缀和后缀，之后通过反射机制获取创建一个 <code>URLStreamHandler</code> 对象</p><p><code>URLStreamHandler</code> 是一个抽象类，其中的方法如下图，只有 <code>openConnection</code> 为抽象方法，其他方法均有具体实现</p><p><img src="http://image.laijianfeng.org/20180908_235350.png" alt="URLStreamHandler抽象类中的方法"></p><blockquote><p>关于URLStreamHandler:<br>抽象类URLStreamHandler是所有流协议处理程序的通用超类。 流协议处理程序知道如何为特定协议类型建立连接，例如http或https</p></blockquote><p>其子类有如下(19个)：</p><p><img src="http://image.laijianfeng.org/20180908_234100.png" alt="URLStreamHandler的子类"></p><p>查看其中一个子类譬如 <code>sun.net.www.protocol.http.Handler</code></p><pre><code>public class Handler extends URLStreamHandler {    protected String proxy;    protected int proxyPort;    protected int getDefaultPort() {        return 80;    }    public Handler() {        this.proxy = null;        this.proxyPort = -1;    }    public Handler(String var1, int var2) {        this.proxy = var1;        this.proxyPort = var2;    }    protected URLConnection openConnection(URL var1) throws IOException {        return this.openConnection(var1, (Proxy)null);    }    protected URLConnection openConnection(URL var1, Proxy var2) throws IOException {        return new HttpURLConnection(var1, var2, this);    }}</code></pre><p>该类实现的 <code>openConnection</code> 方法的返回值类型为 <code>URLConnection</code>，最终返回了一个 <code>HttpURLConnection</code> 对象</p><p>我们又继续看 <code>java.net.URLConnection</code>，这也是一个抽象类</p><p><img src="http://image.laijianfeng.org/20180909_001513.png" alt="image"></p><blockquote><p><strong>URLConnection介绍</strong>：   </p><ul><li>URLConnection是一个功能强大的抽象类，它表示指向URL指定资源的活动连接。<br>与URL类相比，它与服务器的交互提供了更多的控制机制。尤其服务器是HTTP服务器，可以使用URLConnection对HTTP首部的访问，可以配置发送给服务器的请求参数。当然也可以通过它读取服务器的数据以及向服务器写入数据.   </li><li>URLConnection是Java的协议处理器机制的一部分。协议处理器机制是将处理协议的细节与特定数据类型分开。如果要实现一个特定的协议，则实现URLConnection的子类即可。程序运行时可以将该子类作为一个具体的协议处理器来使用。   </li><li><strong>使用URLConnection类的步骤</strong>：1.  构造一个URL对象；2. 调用该URL的openConnection()获取一个URLConnection；3. 配置这个URLConnection；4. 读取首部字段；5. 获得输入流并读取数据；6. 获得输出流并写入数据；7. 关闭连接</li></ul></blockquote><p>其子类有23个</p><p><img src="http://image.laijianfeng.org/20180909_001308.png" alt="image"></p><p>我们可以画出他们的关系图如下所示</p><p><img src="http://image.laijianfeng.org/20180909_164345.png" alt="URLConnection关系图"></p><p><strong>由此可知</strong>：抽象工厂角色为 <code>URLStreamHandlerFactory</code>，工厂方法为 <code>createURLStreamHandler</code>，抽象产品角色为 <code>URLStreamHandler</code>，具体产品角色为 <code>URLStreamHandler</code> 的子类譬如 <code>sun.net.www.protocol.http.Handler</code>、<code>sun.net.www.protocol.ftp.Handler</code> 等</p><p><strong>同时</strong>，<code>URLStreamHandler</code> 也扮演了抽象工厂角色，工厂方法为 <code>openConnection</code>，<code>URLStreamHandler</code> 的子类譬如 <code>sun.net.www.protocol.http.Handler</code> 也扮演了具体工厂角色，抽象产品为 <code>URLConnection</code>，具体产品角色为  <code>URLConnection</code> 的子类如 <code>sun.net.www.protocol.http.HttpURLConnection</code> 等</p><h4 id="Logback-中的工厂方法模式"><a href="#Logback-中的工厂方法模式" class="headerlink" title="Logback 中的工厂方法模式"></a>Logback 中的工厂方法模式</h4><p>在上一篇文章《<a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483700&amp;idx=1&amp;sn=dd4d23f9400c8be248f5d125465ba941&amp;chksm=e9c2ed39deb5642fb809eca1351f00995f06c9a4875f09986cc5005059eff74d6c20fc1118a3&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 简单工厂模式及典型应用</a>》 介绍的 Logback 里有简单工厂模式，其实也有工厂方法模式，画图如下</p><p><img src="http://image.laijianfeng.org/20180909_170301.png" alt="iLoggerFactory类关系"></p><p><strong>可以看出</strong>，抽象工厂角色为 <code>ILoggerFactory</code> 接口，工厂方法为 <code>getLogger</code>，具体工厂角色为 <code>LoggerContext</code>、<code>NOPLoggerFactory</code>、<code>SubstituteLoggerFactory</code> 等，抽象产品角色为 <code>Logger</code>，具体产品角色为 <code>Logger</code> 的实现类如下</p><p><img src="http://image.laijianfeng.org/20180909_171112.png" alt="Logger 的实现类"></p><p>而简单工厂模式应用在 <code>LoggerContext</code> 的  <code>getLogger</code> 方法中，根据参数返回相应的 <code>Logger</code> 对象</p><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析</p></blockquote><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;工厂方法模式&quot;&gt;&lt;a href=&quot;#工厂方法模式&quot; class=&quot;headerlink&quot; title=&quot;工厂方法模式&quot;&gt;&lt;/a&gt;工厂方法模式&lt;/h3&gt;&lt;p&gt;工厂方法模式(Factory Method Pattern)：定义一个用于创建对象的接口，让子类决定将哪一个
      
    
    </summary>
    
      <category term="后端" scheme="http://laijianfeng.org/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
      <category term="设计模式" scheme="http://laijianfeng.org/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>设计模式 | 简单工厂模式及典型应用</title>
    <link href="http://laijianfeng.org/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
    <id>http://laijianfeng.org/2018/09/设计模式-简单工厂模式及典型应用/</id>
    <published>2018-09-07T15:13:45.000Z</published>
    <updated>2018-09-07T15:14:50.320Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>设计模式(Design Pattern)是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结，使用设计模式是为了可重用代码、让代码更容易被他人<br>理解并且保证代码可靠性。</p><p>本文主要介绍简单工厂模式及典型应用，内容如下：</p><ul><li>简单工厂模式的介绍</li><li>简单工厂模式的典型应用及源码分析<ul><li>Calendar 类获取日历类对象</li><li>JDBC 获取数据库连接</li><li>LoggerFactory 获取 Logger 对象</li></ul></li></ul><h3 id="简单工厂模式"><a href="#简单工厂模式" class="headerlink" title="简单工厂模式"></a>简单工厂模式</h3><p>工厂模式是最常用的一类创建型设计模式，包括 抽象工厂模式，工厂方法模式和简单工厂模式 这三种，简单工厂模式是其中最简单的一种</p><p>简单工厂模式(Simple Factory Pattern)：定义一个工厂类，它可以<strong>根据参数的不同</strong>返回不同类的实例，被创建的实例通常都具有共同的父类。</p><p>因为在简单工厂模式中用于创建实例的方法是静态(static)方法，因此简单工厂模式又被称为静态工厂方法(Static Factory Method)模式，它属于类创建型模式，但不属于GOF23种设计模式</p><h4 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h4><p><strong>Factory（工厂角色）</strong>：工厂角色即工厂类，它是<strong>简单工厂模式的核心</strong>，负责实现创建所有产品实例的内部逻辑；工厂类可以被外界直接调用，创建所需的产品对象；在工厂类中提供了静态的工厂方法factoryMethod()，它的返回类型为抽象产品类型Product</p><p><strong>Product（抽象产品角色）</strong>：它是工厂类所创建的所有对象的父类，封装了各种产品对象的公有方法，它的引入将提高系统的灵活性，使得在工厂类中只需定义一个通用的工厂方法，因为所有创建的具体产品对象都是其子类对象。</p><p><strong>ConcreteProduct（具体产品角色）</strong>：它是简单工厂模式的创建目标，所有被创建的对象都充当这个角色的某个具体类的实例。每一个具体产品角色都继承了抽象产品角色，需要实现在抽象产品中声明的抽象方法</p><p>在简单工厂模式中，客户端通过工厂类来创建一个产品类的实例，而无须直接使用new关键字来创建对象，它是工厂模式家族中最简单的一员</p><h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><p>抽象产品类 Video，定义了抽象方法 produce()</p><pre><code>public abstract class Video {    public abstract void produce();}</code></pre><p>具体产品类 JavaVideo 和 PythonVideo，都继承了抽象产品类 Video</p><pre><code>public class JavaVideo extends Video {    @Override    public void produce() {        System.out.println(&quot;录制Java课程视频&quot;);    }}public class PythonVideo extends Video {    @Override    public void produce() {        System.out.println(&quot;录制Python课程视频&quot;);    }}</code></pre><p>工厂类实现的两种方法：使用<code>if-else</code>判断和使用反射来创建对象</p><pre><code>public class VideoFactory {    /**     * 使用if else 判断类型，type 为 Java 则返回 JavaVideo， type为Python则返回 PythonVideo     */    public Video getVideo(String type) {        if (&quot;java&quot;.equalsIgnoreCase(type)) {            return new JavaVideo();        } else if (&quot;python&quot;.equalsIgnoreCase(type)) {            return new PythonVideo();        }        return null;    }    /**     * 使用反射来创建对象     */    public Video getVideo(Class c) {        Video video = null;        try {            video = (Video) Class.forName(c.getName()).newInstance();        } catch (InstantiationException e) {            e.printStackTrace();        } catch (IllegalAccessException e) {            e.printStackTrace();        } catch (ClassNotFoundException e) {            e.printStackTrace();        }        return video;    }}</code></pre><p>使用一个客户端来调用工厂类</p><pre><code>public class Test {    public static void main(String[] args) {        VideoFactory videoFactory = new VideoFactory();        Video video1 = videoFactory.getVideo(&quot;python&quot;);        if (video1 == null) {            return;        }        video1.produce();        Video video2 = videoFactory.getVideo(JavaVideo.class);        if (video2 == null) {            return;        }        video2.produce();    }}</code></pre><p>输出</p><pre><code>录制Python课程视频录制Java课程视频</code></pre><p><img src="http://image.laijianfeng.org/20180907_211234.png" alt="示例.简单工厂模式类图"></p><p>Test 类通过传递参数给 <code>VideoFactory.getVideo()</code> 来获取对象，创建对象的逻辑交给了工厂类 <code>VideoFactory</code> 来完成</p><h4 id="简单工厂模式总结"><a href="#简单工厂模式总结" class="headerlink" title="简单工厂模式总结"></a>简单工厂模式总结</h4><p>简单工厂模式的<strong>主要优点</strong>如下：</p><ul><li>工厂类包含必要的判断逻辑，可以决定在什么时候创建哪一个产品类的实例，客户端可以免除直接创建产品对象的职责，而仅仅“消费”产品，简单工厂模式实现了对象创建和使用的分离。</li><li>客户端无须知道所创建的具体产品类的类名，只需要知道具体产品类所对应的参数即可，对于一些复杂的类名，通过简单工厂模式可以在一定程度减少使用者的记忆量。</li><li>通过引入配置文件，可以在不修改任何客户端代码的情况下更换和增加新的具体产品类，在一定程度上提高了系统的灵活性。</li></ul><p>简单工厂模式的<strong>主要缺点</strong>如下：</p><ul><li>由于工厂类集中了所有产品的创建逻辑，职责过重，一旦不能正常工作，整个系统都要受到影响。</li><li>使用简单工厂模式势必会增加系统中类的个数（引入了新的工厂类），增加了系统的复杂度和理解难度。</li><li>系统扩展困难，一旦添加新产品就不得不修改工厂逻辑，在产品类型较多时，有可能造成工厂逻辑过于复杂，不利于系统的扩展和维护，且违背开闭原则。</li><li>简单工厂模式由于使用了静态工厂方法，造成工厂角色无法形成基于继承的等级结构。</li></ul><p><strong>适用场景</strong>：</p><ul><li>工厂类负责创建的对象比较少，由于创建的对象较少，不会造成工厂方法中的业务逻辑太过复杂。</li><li>客户端只知道传入工厂类的参数，对于如何创建对象并不关心。</li></ul><h3 id="简单工厂模式的典型应用及源码分析"><a href="#简单工厂模式的典型应用及源码分析" class="headerlink" title="简单工厂模式的典型应用及源码分析"></a>简单工厂模式的典型应用及源码分析</h3><h4 id="Calendar-类获取日历类对象"><a href="#Calendar-类获取日历类对象" class="headerlink" title="Calendar 类获取日历类对象"></a>Calendar 类获取日历类对象</h4><p><code>Calendar</code> 抽象类，该类的子类有 <code>BuddhistCalendar</code>、<code>JapaneseImperialCalendar</code>、<code>GregorianCalendar</code>、<code>RollingCalendar</code>等</p><p><code>getInstance</code>方法，根据参数获取一个<code>Calendar</code>子类对象，该方法实际将参数传给 <code>createCalendar</code> 方法，<code>createCalendar</code> 在根据参数通过 <code>provider</code> 或 <code>switch</code> 或者 <code>if-else</code> 创建相应的子类对象</p><p>以下为 Java8 中的 <code>Calendar</code> 类代码，Java7 中的实现为 <code>if-else</code> 方式</p><pre><code>public static Calendar getInstance(TimeZone zone, Locale aLocale) {    return createCalendar(zone, aLocale);}private static Calendar createCalendar(TimeZone zone, Locale aLocale) {    CalendarProvider provider = LocaleProviderAdapter.getAdapter(CalendarProvider.class, aLocale).getCalendarProvider();    if (provider != null) {        try {            return provider.getInstance(zone, aLocale);        } catch (IllegalArgumentException iae) {        }    }    Calendar cal = null;    if (aLocale.hasExtensions()) {        String caltype = aLocale.getUnicodeLocaleType(&quot;ca&quot;);        if (caltype != null) {            switch (caltype) {                case &quot;buddhist&quot;:                    cal = new BuddhistCalendar(zone, aLocale); break;                case &quot;japanese&quot;:                    cal = new JapaneseImperialCalendar(zone, aLocale); break;                case &quot;gregory&quot;:                    cal = new GregorianCalendar(zone, aLocale); break;            }        }    }    if (cal == null) {        if (aLocale.getLanguage() == &quot;th&quot; &amp;&amp; aLocale.getCountry() == &quot;TH&quot;) {            cal = new BuddhistCalendar(zone, aLocale);        } else if (aLocale.getVariant() == &quot;JP&quot; &amp;&amp; aLocale.getLanguage() == &quot;ja&quot; &amp;&amp; aLocale.getCountry() == &quot;JP&quot;) {            cal = new JapaneseImperialCalendar(zone, aLocale);        } else {            cal = new GregorianCalendar(zone, aLocale);        }    }    return cal;}</code></pre><p><img src="http://image.laijianfeng.org/20180907_213426.png" alt="Calendar的继承关系"></p><p>可以看到<code>抽象产品角色</code>和<code>工厂角色</code>都由  <code>Calendar</code> 担任，<code>具体产品角色</code>由 <code>Calendar</code> 的子类担任</p><h4 id="JDBC-获取数据库连接"><a href="#JDBC-获取数据库连接" class="headerlink" title="JDBC 获取数据库连接"></a>JDBC 获取数据库连接</h4><p>一般JDBC获取MySQL连接的写法如下：</p><pre><code>//加载MySql驱动Class.forName(&quot;com.mysql.jdbc.Driver&quot;);DriverManager.getConnection(&quot;jdbc:mysql://127.0.0.1:3306/test&quot;, &quot;root&quot;, &quot;123456&quot;);</code></pre><p>首先通过反射加载驱动类 <code>com.mysql.jdbc.Driver</code> 类，然后再通过 <code>DriverManager</code> 获取连接</p><p>看看 <code>com.mysql.jdbc.Driver</code> 的代码，该类主要的内容是静态代码块，其会随着类的加载一块执行</p><pre><code>public class Driver extends NonRegisteringDriver implements java.sql.Driver {    public Driver() throws SQLException {    }    static {        try {            DriverManager.registerDriver(new Driver());        } catch (SQLException var1) {            throw new RuntimeException(&quot;Can&#39;t register driver!&quot;);        }    }}</code></pre><p>静态代码块：new 一个 <code>Driver</code> 类并注册到 <code>DriverManager</code> 驱动管理类中</p><pre><code>public static synchronized void registerDriver(java.sql.Driver driver, DriverAction da) throws SQLException {    /* Register the driver if it has not already been added to our list */    if(driver != null) {        registeredDrivers.addIfAbsent(new DriverInfo(driver, da));    } else {        throw new NullPointerException();    }    println(&quot;registerDriver: &quot; + driver);}</code></pre><p>其中的 <code>registeredDrivers</code> 是一个 <code>CopyOnWriteArrayList</code> 对象</p><pre><code>private final static CopyOnWriteArrayList&lt;DriverInfo&gt; registeredDrivers = new CopyOnWriteArrayList&lt;&gt;();</code></pre><blockquote><p>CopyOnWriteArrayList是Java并发包中提供的一个并发容器，它是个线程安全且读操作无锁的ArrayList，写操作则通过创建底层数组的新副本来实现，是一种读写分离的并发策略，我们也可以称这种容器为”写时复制器”，Java并发包中类似的容器还有CopyOnWriteSet<br>一篇CopyOnWriteArrayList的文章：<a href="https://www.cnblogs.com/chengxiao/p/6881974.html" target="_blank" rel="noopener">https://www.cnblogs.com/chengxiao/p/6881974.html</a></p></blockquote><p>再通过 <code>DriverManager.getConnection</code> 获取连接对象的主要代码如下：通过for循环从已注册的驱动中(registeredDrivers)获取驱动，尝试连接，成功则返回连接</p><pre><code>private static Connection getConnection(String url, java.util.Properties info, Class&lt;?&gt; caller) throws SQLException {    // ...省略...    println(&quot;DriverManager.getConnection(\&quot;&quot; + url + &quot;\&quot;)&quot;);    for(DriverInfo aDriver : registeredDrivers) {        // If the caller does not have permission to load the driver then skip it.        if(isDriverAllowed(aDriver.driver, callerCL)) {            try {                println(&quot;    trying &quot; + aDriver.driver.getClass().getName());                Connection con = aDriver.driver.connect(url, info);                if (con != null) {                    // Success!                    println(&quot;getConnection returning &quot; + aDriver.driver.getClass().getName());                    return (con);                }            } catch (SQLException ex) {                if (reason == null) {                    reason = ex;                }            }        } else {            println(&quot;    skipping: &quot; + aDriver.getClass().getName());        }    }    // ...省略...}</code></pre><p><img src="http://image.laijianfeng.org/20180907_225826.png" alt="Connection 接口及子类实现关系"></p><p>工厂角色为 <code>DriverManager</code> 类，抽象产品角色为 <code>Connection</code>，具体产品角色则很多</p><h4 id="Logback-中的-LoggerFactory-获取-Logger-对象"><a href="#Logback-中的-LoggerFactory-获取-Logger-对象" class="headerlink" title="Logback 中的 LoggerFactory 获取 Logger 对象"></a>Logback 中的 LoggerFactory 获取 Logger 对象</h4><p>查看 <code>LoggerFactory</code> 类的 <code>getLogger</code> 方法，可看到调用了 <code>iLoggerFactory.getLogger()</code>，其中 <code>iLoggerFactory</code> 是一个接口</p><pre><code>public static Logger getLogger(String name) {    ILoggerFactory iLoggerFactory = getILoggerFactory();    return iLoggerFactory.getLogger(name);}public static Logger getLogger(Class clazz) {    return getLogger(clazz.getName());}</code></pre><p><code>iLoggerFactory</code> 接口只有一个 <code>getLogger</code> 方法</p><pre><code>public interface ILoggerFactory {    Logger getLogger(String var1);}</code></pre><p>查看其子类依赖关系</p><p><img src="http://image.laijianfeng.org/20180907_223038.png" alt="iLoggerFactory接口子类的依赖关系"></p><p>再看一个子类 <code>LoggerContext</code> 对 ILoggerFactory 的实现</p><p><img src="http://image.laijianfeng.org/20180907_222610.png" alt="image"></p><p>可看到这是通过 <code>if-else</code> 方式的简单工厂模式</p><p><img src="http://image.laijianfeng.org/20180907_230131.png" alt="Logger 接口及子类实现关系"></p><p>工厂角色为 <code>iLoggerFactory</code> 接口的子类如 <code>LoggerContext</code>，抽象产品角色为 <code>Logger</code>，具体产品角色为 <code>Logger</code> 的子类，主要是 <code>NOPLogger</code> 和 <code>Logger</code> 类</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>下一篇介绍工厂方法及典型应用</p><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析</p></blockquote><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;设计模式(Design Pattern)是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结，使用设计模式是为了可重用代码、让
      
    
    </summary>
    
      <category term="后端" scheme="http://laijianfeng.org/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
      <category term="设计模式" scheme="http://laijianfeng.org/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch 6.3.2 启动过程</title>
    <link href="http://laijianfeng.org/2018/09/Elasticsearch-6-3-2-%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/"/>
    <id>http://laijianfeng.org/2018/09/Elasticsearch-6-3-2-启动过程/</id>
    <published>2018-09-01T12:25:45.000Z</published>
    <updated>2018-09-01T12:29:11.559Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本文探究Elasticsearch 6.3.2的启动流程</p><h4 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h4><p>使用工具：IDEA，XMind</p><p>关于ES调试环境的搭建，可以参考前面的文章 《<a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483676&amp;idx=1&amp;sn=1d88a883ce21d7dcacd073a8fa85dbfc&amp;chksm=e9c2ed11deb56407879ba0b22a4ef96916f8a9e7931e1efb99df57991966a3dc475eb3e23101&amp;mpshare=1&amp;scene=1&amp;srcid=0901DM6ZqcQqSqyujfIApsDj#rd" target="_blank" rel="noopener">教你编译调试Elasticsearch 6.3.2源码</a>》</p><p>然后通过设置断点，从 <code>org.elasticsearch.bootstrap.ElasticSearch</code> 的入口函数开始，一步一步调试</p><p><img src="http://image.laijianfeng.org/20180901_131938.png" alt="IDEA 2018.2 调试按钮"></p><p>上图为使用 IDEA 2018.2 进行调试的一个截图，左上角84行出红点为一个断点，1、2、3编号的3个按钮是较为常用的按钮，作用如下：</p><ul><li>按钮1：step over，执行到下一行，遇到方法<strong>不进入</strong>方法内部</li><li>按钮2：step into，执行到下一句代码，遇到方法则<strong>进入</strong>方法内部</li><li>按钮3：Run to cursor，执行到下一个断点处，后面没有断点则执行到结束</li></ul><h4 id="通过XMind记录ES启动流程的整个过程"><a href="#通过XMind记录ES启动流程的整个过程" class="headerlink" title="通过XMind记录ES启动流程的整个过程"></a>通过XMind记录ES启动流程的整个过程</h4><p><img src="http://image.laijianfeng.org/ES_startup_process.jpg" alt="ES 6.3.2 启动流程"></p><p>根据上图，作者大概地把ES启动流程分为四个阶段：</p><ul><li>Elasticsearch 解析 Command，加载配置</li><li>Bootstrap 初始化，资源检查</li><li>Node 创建节点</li><li>Bootstrap 启动节点和保活线程</li></ul><h3 id="Elasticsearch-解析-Command，加载配置"><a href="#Elasticsearch-解析-Command，加载配置" class="headerlink" title="Elasticsearch 解析 Command，加载配置"></a>Elasticsearch 解析 Command，加载配置</h3><p>首先可以看一下入口方法 <code>Elasticsearch.main</code>：</p><pre><code>    public static void main(final String[] args) throws Exception {        System.setSecurityManager(new SecurityManager() {            @Override            public void checkPermission(Permission perm) {                // grant all permissions so that we can later set the security manager to the one that we want            }        });        LogConfigurator.registerErrorListener();        final Elasticsearch elasticsearch = new Elasticsearch();        int status = main(args, elasticsearch, Terminal.DEFAULT);        if (status != ExitCodes.OK) {            exit(status);        }    }</code></pre><p>1.1, 创建 SecurityManager 安全管理器</p><blockquote><p>关于 SecurityManager:<br>安全管理器在Java语言中的作用就是<strong>检查操作是否有权限执行</strong>，通过则顺序进行，否则抛出一个异常<br>网上一篇文章：<a href="https://blog.csdn.net/wwwdc1012/article/details/82287474" target="_blank" rel="noopener">Java安全——安全管理器、访问控制器和类装载器</a></p></blockquote><p>1.2, LogConfigurator.registerErrorListener() 注册侦听器</p><p>1.3, 创建Elasticsearch对象</p><p>Elasticsearch 入口类的继承关系如下：</p><p><img src="http://image.laijianfeng.org/20180901_143515.png" alt="Elasticsearch 入口类的继承关系"></p><p>可以看到Elasticsearch继承了EnvironmentAwareCommand，Command，这几个类的功能简要介绍如下：</p><ul><li>Elasticsearch: This class starts elasticsearch.</li><li>EnvironmentAwareCommand: A cli command which requires an <code>org.elasticsearch.env.Environment</code> to use current paths and settings</li><li>Command: An action to execute within a cli.</li></ul><p>可以看出Elasticsearch的一个重要作用是解析命令参数</p><p>执行带 <code>-h</code> 参数的Elasticsearch启动命令</p><p><img src="http://image.laijianfeng.org/20180901_144410.png" alt="带参数的Elasticsearch启动命令"></p><p>可以发现这几个参数与 Cammand 类 和 Elasticsearch 的几个私有变量是对应的</p><p>Elasticsearch的构造函数如下：</p><pre><code>Elasticsearch() {    super(&quot;starts elasticsearch&quot;, () -&gt; {}); // we configure logging later so we override the base class from configuring logging    versionOption = parser.acceptsAll(Arrays.asList(&quot;V&quot;, &quot;version&quot;), &quot;Prints elasticsearch version information and exits&quot;);    daemonizeOption = parser.acceptsAll(Arrays.asList(&quot;d&quot;, &quot;daemonize&quot;), &quot;Starts Elasticsearch in the background&quot;)        .availableUnless(versionOption);    pidfileOption = parser.acceptsAll(Arrays.asList(&quot;p&quot;, &quot;pidfile&quot;), &quot;Creates a pid file in the specified path on start&quot;)        .availableUnless(versionOption).withRequiredArg().withValuesConvertedBy(new PathConverter());    quietOption = parser.acceptsAll(Arrays.asList(&quot;q&quot;, &quot;quiet&quot;), &quot;Turns off standard output/error streams logging in console&quot;)        .availableUnless(versionOption).availableUnless(daemonizeOption);}</code></pre><p>1.4, 接着进入 <code>Command.main</code> 方法</p><p>该方法给当前Runtime类添加一个hook线程，该线程作用是：当Runtime异常关闭时打印异常信息</p><p>1.5, <code>Command.mainWithoutErrorHandling</code> 方法，根据命令行参数，打印或者设置参数，然后执行命令，有异常则抛出所有异常</p><p>1.6, <code>EnvironmentAwareCommand.execute</code>，确保 <code>es.path.data</code>, <code>es.path.home</code>, <code>es.path.logs</code> 等参数已设置，否则从 <code>System.properties</code> 中读取</p><pre><code>putSystemPropertyIfSettingIsMissing(settings, &quot;path.data&quot;, &quot;es.path.data&quot;);putSystemPropertyIfSettingIsMissing(settings, &quot;path.home&quot;, &quot;es.path.home&quot;);putSystemPropertyIfSettingIsMissing(settings, &quot;path.logs&quot;, &quot;es.path.logs&quot;);execute(terminal, options, createEnv(terminal, settings));</code></pre><p>1.7, <code>EnvironmentAwareCommand.createEnv</code>，读取config下的配置文件<code>elasticsearch.yml</code>内容，收集plugins，bin，lib，modules等目录下的文件信息</p><p>createEnv最后返回一个 Environment 对象，执行结果如下</p><p><img src="http://image.laijianfeng.org/20180901_160825.png" alt="EnvironmentAwareCommand.createEnv"></p><p>1.8, <code>Elasticsearch.execute</code> ，读取daemonize， pidFile，quiet 的值，并 确保配置的临时目录(temp)是有效目录</p><p>进入Bootstrap初始化阶段</p><pre><code>Bootstrap.init(!daemonize, pidFile, quiet, initialEnv);</code></pre><h3 id="Bootstrap初始化阶段"><a href="#Bootstrap初始化阶段" class="headerlink" title="Bootstrap初始化阶段"></a>Bootstrap初始化阶段</h3><h4 id="Bootstrap-init"><a href="#Bootstrap-init" class="headerlink" title="Bootstrap.init"></a>Bootstrap.init</h4><p>2.1, 进入 <code>Bootstrap.init</code>, This method is invoked by <code>Elasticsearch#main(String[])</code> to startup elasticsearch.</p><p><code>INSTANCE = new Bootstrap();</code>, 创建一个Bootstrap对象作为类对象，该类构造函数会创建一个用户线程，添加到Runtime Hook中，进行 countDown 操作</p><pre><code> private final CountDownLatch keepAliveLatch = new CountDownLatch(1); /** creates a new instance */    Bootstrap() {        keepAliveThread = new Thread(new Runnable() {            @Override            public void run() {                try {                    keepAliveLatch.await();                } catch (InterruptedException e) {                }            }        }, &quot;elasticsearch[keepAlive/&quot; + Version.CURRENT + &quot;]&quot;);        keepAliveThread.setDaemon(false);        // keep this thread alive (non daemon thread) until we shutdown        Runtime.getRuntime().addShutdownHook(new Thread() {            @Override            public void run() {                keepAliveLatch.countDown();            }        });    }</code></pre><blockquote><p>CountDownLatch是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程执行完后再执行。例如，应用程序的主线程希望在负责启动框架服务的线程已经启动所有框架服务之后执行。<br>CountDownLatch是通过一个计数器来实现的，计数器的初始化值为线程的数量。每当一个线程完成了自己的任务后，计数器的值就相应得减1。当计数器到达0时，表示所有的线程都已完成任务，然后在闭锁上等待的线程就可以恢复执行任务。<br>更多介绍请看文章：<a href="https://blog.csdn.net/wwwdc1012/article/details/82288473" target="_blank" rel="noopener">并发工具类 CountDownLatch</a></p></blockquote><p>2.2, 加载 keystore 安全配置，keystore文件不存在则创建，保存；存在则解密，更新keystore</p><p>2.3, 根据已有的配置信息，创建一个Environment对象</p><p>2.4, LogConfigurator log4j日志配置</p><p>2.5, 检查pid文件是否存在，不存在则创建</p><blockquote><p>关于 pid 文件：<br>(1) <strong>pid文件的内容</strong>：pid文件为文本文件，内容只有一行，记录了该进程的ID，用cat命令可以看到。<br>(2) <strong>pid文件的作用</strong>：防止进程启动多个副本。只有获得pid文件(固定路径固定文件名)写入权限(F_WRLCK)的进程才能正常启动并把自身的PID写入该文件中，其它同一个程序的多余进程则自动退出。</p></blockquote><p>2.6, 检查Lucene版本与实际的Lucene Jar文件的版本是否一致，不一致则抛异常</p><p>2.7, 设置未捕获异常的处理 Thread.setDefaultUncaughtExceptionHandler</p><p>在Thread ApI中提供了UncaughtExceptionHandle，它能检测出某个由于未捕获的异常而终结的情况</p><blockquote><p>朱小厮 <a href="https://blog.csdn.net/u013256816/article/details/50417822" target="_blank" rel="noopener">JAVA多线程之UncaughtExceptionHandler——处理非正常的线程中止</a></p></blockquote><h4 id="INSTANCE-setup-true-environment"><a href="#INSTANCE-setup-true-environment" class="headerlink" title="INSTANCE.setup(true, environment);"></a>INSTANCE.setup(true, environment);</h4><p>3.1，<code>spawner.spawnNativeControllers(environment);</code></p><p>遍历每个模块，生成本机控制类（native Controller）：读取modules文件夹下所有的文件夹中的模块信息，保存为一个 PluginInfo  对象，为合适的模块生成控制类，通过 <code>Files.isRegularFile(spawnPath)</code> 来判断</p><p>尝试为给定模块生成控制器(native Controller)守护程序。    生成的进程将通过其stdin，stdout和stderr流保持与此JVM的连接，但对此包之外的代码不能使用对这些流的引用。</p><p>3.2， <code>initializeNatives(Path tmpFile, boolean mlockAll, boolean systemCallFilter, boolean ctrlHandler)</code>初始化本地资源</p><p>检查用户是否为root用户，是则抛异常;<br>尝试启用 系统调用过滤器 system call filter;<br>如果设置了则进行 mlockall<br>Windows关闭事件监听器<br>init lucene random seed.   </p><p>这个过程中使用到了 Natives 类:<br>Natives类是一个包装类，用于检查调用本机方法所需的类是否在启动时可用。如果它们不可用，则此类将避免调用加载这些类的代码</p><p>3.3, 添加一个Hook： Runtime.getRuntime().addShutdownHook，当ES退出时用于关闭必要的IO流，日志器上下文和配置器等</p><p>3.4, 使用 JarHell 检查重复的 jar 文件</p><p>3.5, 初始化 SecurityManager</p><pre><code>// install SM after natives, shutdown hooks, etc.Security.configure(environment, BootstrapSettings.SECURITY_FILTER_BAD_DEFAULTS_SETTING.get(settings));</code></pre><h3 id="创建-node-节点"><a href="#创建-node-节点" class="headerlink" title="创建 node 节点"></a>创建 node 节点</h3><pre><code>node = new Node(environment) {    @Override    protected void validateNodeBeforeAcceptingRequests(        final BootstrapContext context,        final BoundTransportAddress boundTransportAddress, List&lt;BootstrapCheck&gt; checks) throws NodeValidationException {        BootstrapChecks.check(context, boundTransportAddress, checks);    }};</code></pre><p>4.1, 这里直接贴一下代码（前半部分）</p><pre><code>    protected Node(final Environment environment, Collection&lt;Class&lt;? extends Plugin&gt;&gt; classpathPlugins) {        final List&lt;Closeable&gt; resourcesToClose = new ArrayList&lt;&gt;(); // register everything we need to release in the case of an error        boolean success = false;        {            // use temp logger just to say we are starting. we can&#39;t use it later on because the node name might not be set            Logger logger = Loggers.getLogger(Node.class, NODE_NAME_SETTING.get(environment.settings()));            logger.info(&quot;initializing ...&quot;);        }        try {            originalSettings = environment.settings();            Settings tmpSettings = Settings.builder().put(environment.settings())                .put(Client.CLIENT_TYPE_SETTING_S.getKey(), CLIENT_TYPE).build();            // create the node environment as soon as possible, to recover the node id and enable logging            try {                nodeEnvironment = new NodeEnvironment(tmpSettings, environment);                resourcesToClose.add(nodeEnvironment);            } catch (IOException ex) {                throw new IllegalStateException(&quot;Failed to create node environment&quot;, ex);            }            final boolean hadPredefinedNodeName = NODE_NAME_SETTING.exists(tmpSettings);            final String nodeId = nodeEnvironment.nodeId();            tmpSettings = addNodeNameIfNeeded(tmpSettings, nodeId);            final Logger logger = Loggers.getLogger(Node.class, tmpSettings);            // this must be captured after the node name is possibly added to the settings            final String nodeName = NODE_NAME_SETTING.get(tmpSettings);            if (hadPredefinedNodeName == false) {                logger.info(&quot;node name derived from node ID [{}]; set [{}] to override&quot;, nodeId, NODE_NAME_SETTING.getKey());            } else {                logger.info(&quot;node name [{}], node ID [{}]&quot;, nodeName, nodeId);            }            final JvmInfo jvmInfo = JvmInfo.jvmInfo();            logger.info(                &quot;version[{}], pid[{}], build[{}/{}/{}/{}], OS[{}/{}/{}], JVM[{}/{}/{}/{}]&quot;,                Version.displayVersion(Version.CURRENT, Build.CURRENT.isSnapshot()),                jvmInfo.pid(),                Build.CURRENT.flavor().displayName(),                Build.CURRENT.type().displayName(),                Build.CURRENT.shortHash(),                Build.CURRENT.date(),                Constants.OS_NAME,                Constants.OS_VERSION,                Constants.OS_ARCH,                Constants.JVM_VENDOR,                Constants.JVM_NAME,                Constants.JAVA_VERSION,                Constants.JVM_VERSION);            logger.info(&quot;JVM arguments {}&quot;, Arrays.toString(jvmInfo.getInputArguments()));            warnIfPreRelease(Version.CURRENT, Build.CURRENT.isSnapshot(), logger);            if (logger.isDebugEnabled()) {                logger.debug(&quot;using config [{}], data [{}], logs [{}], plugins [{}]&quot;,                    environment.configFile(), Arrays.toString(environment.dataFiles()), environment.logsFile(), environment.pluginsFile());            }            this.pluginsService = new PluginsService(tmpSettings, environment.configFile(), environment.modulesFile(), environment.pluginsFile(), classpathPlugins);            this.settings = pluginsService.updatedSettings();            localNodeFactory = new LocalNodeFactory(settings, nodeEnvironment.nodeId());            // create the environment based on the finalized (processed) view of the settings            // this is just to makes sure that people get the same settings, no matter where they ask them from            this.environment = new Environment(this.settings, environment.configFile());            Environment.assertEquivalent(environment, this.environment);            final List&lt;ExecutorBuilder&lt;?&gt;&gt; executorBuilders = pluginsService.getExecutorBuilders(settings);            final ThreadPool threadPool = new ThreadPool(settings, executorBuilders.toArray(new ExecutorBuilder[0]));            resourcesToClose.add(() -&gt; ThreadPool.terminate(threadPool, 10, TimeUnit.SECONDS));            // adds the context to the DeprecationLogger so that it does not need to be injected everywhere            DeprecationLogger.setThreadContext(threadPool.getThreadContext());            resourcesToClose.add(() -&gt; DeprecationLogger.removeThreadContext(threadPool.getThreadContext()));            final List&lt;Setting&lt;?&gt;&gt; additionalSettings = new ArrayList&lt;&gt;(pluginsService.getPluginSettings());            final List&lt;String&gt; additionalSettingsFilter = new ArrayList&lt;&gt;(pluginsService.getPluginSettingsFilter());            for (final ExecutorBuilder&lt;?&gt; builder : threadPool.builders()) {                additionalSettings.addAll(builder.getRegisteredSettings());            }            client = new NodeClient(settings, threadPool);    ...</code></pre><p>这里进行的主要操作有:</p><ol><li>生命周期Lifecycle设置为 初始化状态 INITIALIZED</li><li>创建一个 NodeEnvironment 对象保存节点环境信息，如各种数据文件的路径</li><li>读取JVM信息</li><li>创建 PluginsService 对象，创建过程中会读取并加载所有的模块和插件</li><li>创建一个最终的 Environment 对象</li><li>创建线程池 ThreadPool 后面各类对象基本都是通过线程来提供服务，这个线程池可以管理各类线程</li><li>创建 节点客户端 NodeClient</li></ol><p><strong>这里重点介绍 PluginsService 和 ThreadPool 这两个类</strong></p><h4 id="PluginsService"><a href="#PluginsService" class="headerlink" title="PluginsService"></a>PluginsService</h4><p>在构造该类对象是传入的参数如下：</p><p><img src="http://image.laijianfeng.org/20180901_175542.png" alt="PluginsService 构造方法的参数"></p><p>在构造方法中加载所有的模块</p><pre><code>Set&lt;Bundle&gt; seenBundles = new LinkedHashSet&lt;&gt;();List&lt;PluginInfo&gt; modulesList = new ArrayList&lt;&gt;();Set&lt;Bundle&gt; modules = getModuleBundles(modulesDirectory); for (Bundle bundle : modules) {   modulesList.add(bundle.plugin);}seenBundles.addAll(modules);/** Get bundles for plugins installed in the given modules directory. */static Set&lt;Bundle&gt; getModuleBundles(Path modulesDirectory) throws IOException {    return findBundles(modulesDirectory, &quot;module&quot;).stream().flatMap(b -&gt; b.bundles().stream()).collect(Collectors.toSet());}</code></pre><p>其中的 Bundle是一个内部类（a “bundle” is a group of plugins in a single classloader）<br>而 PluginInfo 则是 An in-memory representation of the plugin descriptor. 存在内存中的用来描述一个 plugin 的类</p><p>插件加载的实际代码如下：</p><pre><code>    /**     * Reads the plugin descriptor file.     *     * @param path           the path to the root directory for the plugin     * @return the plugin info     * @throws IOException if an I/O exception occurred reading the plugin descriptor     */    public static PluginInfo readFromProperties(final Path path) throws IOException {        final Path descriptor = path.resolve(ES_PLUGIN_PROPERTIES);        final Map&lt;String, String&gt; propsMap;        {            final Properties props = new Properties();            try (InputStream stream = Files.newInputStream(descriptor)) {                props.load(stream);            }            propsMap = props.stringPropertyNames().stream().collect(Collectors.toMap(Function.identity(), props::getProperty));        }        final String name = propsMap.remove(&quot;name&quot;);        if (name == null || name.isEmpty()) {            throw new IllegalArgumentException(                    &quot;property [name] is missing in [&quot; + descriptor + &quot;]&quot;);        }        final String description = propsMap.remove(&quot;description&quot;);        if (description == null) {            throw new IllegalArgumentException(                    &quot;property [description] is missing for plugin [&quot; + name + &quot;]&quot;);        }        final String version = propsMap.remove(&quot;version&quot;);        if (version == null) {            throw new IllegalArgumentException(                    &quot;property [version] is missing for plugin [&quot; + name + &quot;]&quot;);        }        final String esVersionString = propsMap.remove(&quot;elasticsearch.version&quot;);        if (esVersionString == null) {            throw new IllegalArgumentException(                    &quot;property [elasticsearch.version] is missing for plugin [&quot; + name + &quot;]&quot;);        }        final Version esVersion = Version.fromString(esVersionString);        final String javaVersionString = propsMap.remove(&quot;java.version&quot;);        if (javaVersionString == null) {            throw new IllegalArgumentException(                    &quot;property [java.version] is missing for plugin [&quot; + name + &quot;]&quot;);        }        JarHell.checkVersionFormat(javaVersionString);        final String classname = propsMap.remove(&quot;classname&quot;);        if (classname == null) {            throw new IllegalArgumentException(                    &quot;property [classname] is missing for plugin [&quot; + name + &quot;]&quot;);        }        final String extendedString = propsMap.remove(&quot;extended.plugins&quot;);        final List&lt;String&gt; extendedPlugins;        if (extendedString == null) {            extendedPlugins = Collections.emptyList();        } else {            extendedPlugins = Arrays.asList(Strings.delimitedListToStringArray(extendedString, &quot;,&quot;));        }        final String hasNativeControllerValue = propsMap.remove(&quot;has.native.controller&quot;);        final boolean hasNativeController;        if (hasNativeControllerValue == null) {            hasNativeController = false;        } else {            switch (hasNativeControllerValue) {                case &quot;true&quot;:                    hasNativeController = true;                    break;                case &quot;false&quot;:                    hasNativeController = false;                    break;                default:                    final String message = String.format(                            Locale.ROOT,                            &quot;property [%s] must be [%s], [%s], or unspecified but was [%s]&quot;,                            &quot;has_native_controller&quot;,                            &quot;true&quot;,                            &quot;false&quot;,                            hasNativeControllerValue);                    throw new IllegalArgumentException(message);            }        }        if (esVersion.before(Version.V_6_3_0) &amp;&amp; esVersion.onOrAfter(Version.V_6_0_0_beta2)) {            propsMap.remove(&quot;requires.keystore&quot;);        }        if (propsMap.isEmpty() == false) {            throw new IllegalArgumentException(&quot;Unknown properties in plugin descriptor: &quot; + propsMap.keySet());        }        return new PluginInfo(name, description, version, esVersion, javaVersionString,                              classname, extendedPlugins, hasNativeController);    }</code></pre><p>其中的两个常量的值</p><pre><code>    public static final String ES_PLUGIN_PROPERTIES = &quot;plugin-descriptor.properties&quot;;    public static final String ES_PLUGIN_POLICY = &quot;plugin-security.policy&quot;;</code></pre><p>从以上代码可以看出<strong>模块的加载过程</strong>：</p><ol><li>读取模块的配置文件 <code>plugin-descriptor.properties</code>，解析出内容并存储到 Map 中</li><li>分别校验 <code>name</code>, <code>description</code>, <code>version</code>, <code>elasticsearch.version</code>, <code>java.version</code>, <code>classname</code>, <code>extended.plugins</code>, <code>has.native.controller</code>, <code>requires.keystore</code> 这些配置项，缺失或者不按要求则抛出异常</li><li>根据配置项构造一个 PluginInfo 对象返回</li></ol><p>举例：读取出的 aggs-matrix-stats 模块的配置项信息如下</p><p><img src="http://image.laijianfeng.org/20180901_181500.png" alt="读取插件配置文件并解析文件内容"></p><p>加载插件与加载模块调用的是相同的方法</p><h3 id="ThreadPool-线程池"><a href="#ThreadPool-线程池" class="headerlink" title="ThreadPool 线程池"></a>ThreadPool 线程池</h3><p>线程池的构造方法如下：</p><pre><code>    public ThreadPool(final Settings settings, final ExecutorBuilder&lt;?&gt;... customBuilders) {        super(settings);        assert Node.NODE_NAME_SETTING.exists(settings);        final Map&lt;String, ExecutorBuilder&gt; builders = new HashMap&lt;&gt;();        final int availableProcessors = EsExecutors.numberOfProcessors(settings);        final int halfProcMaxAt5 = halfNumberOfProcessorsMaxFive(availableProcessors);        final int halfProcMaxAt10 = halfNumberOfProcessorsMaxTen(availableProcessors);        final int genericThreadPoolMax = boundedBy(4 * availableProcessors, 128, 512);        builders.put(Names.GENERIC, new ScalingExecutorBuilder(Names.GENERIC, 4, genericThreadPoolMax, TimeValue.timeValueSeconds(30)));        builders.put(Names.INDEX, new FixedExecutorBuilder(settings, Names.INDEX, availableProcessors, 200, true));        builders.put(Names.WRITE, new FixedExecutorBuilder(settings, Names.WRITE, &quot;bulk&quot;, availableProcessors, 200));        builders.put(Names.GET, new FixedExecutorBuilder(settings, Names.GET, availableProcessors, 1000));        builders.put(Names.ANALYZE, new FixedExecutorBuilder(settings, Names.ANALYZE, 1, 16));        builders.put(Names.SEARCH, new AutoQueueAdjustingExecutorBuilder(settings,                        Names.SEARCH, searchThreadPoolSize(availableProcessors), 1000, 1000, 1000, 2000));        builders.put(Names.MANAGEMENT, new ScalingExecutorBuilder(Names.MANAGEMENT, 1, 5, TimeValue.timeValueMinutes(5)));        // no queue as this means clients will need to handle rejections on listener queue even if the operation succeeded        // the assumption here is that the listeners should be very lightweight on the listeners side        builders.put(Names.LISTENER, new FixedExecutorBuilder(settings, Names.LISTENER, halfProcMaxAt10, -1));        builders.put(Names.FLUSH, new ScalingExecutorBuilder(Names.FLUSH, 1, halfProcMaxAt5, TimeValue.timeValueMinutes(5)));        builders.put(Names.REFRESH, new ScalingExecutorBuilder(Names.REFRESH, 1, halfProcMaxAt10, TimeValue.timeValueMinutes(5)));        builders.put(Names.WARMER, new ScalingExecutorBuilder(Names.WARMER, 1, halfProcMaxAt5, TimeValue.timeValueMinutes(5)));        builders.put(Names.SNAPSHOT, new ScalingExecutorBuilder(Names.SNAPSHOT, 1, halfProcMaxAt5, TimeValue.timeValueMinutes(5)));        builders.put(Names.FETCH_SHARD_STARTED, new ScalingExecutorBuilder(Names.FETCH_SHARD_STARTED, 1, 2 * availableProcessors, TimeValue.timeValueMinutes(5)));        builders.put(Names.FORCE_MERGE, new FixedExecutorBuilder(settings, Names.FORCE_MERGE, 1, -1));        builders.put(Names.FETCH_SHARD_STORE, new ScalingExecutorBuilder(Names.FETCH_SHARD_STORE, 1, 2 * availableProcessors, TimeValue.timeValueMinutes(5)));        for (final ExecutorBuilder&lt;?&gt; builder : customBuilders) {            if (builders.containsKey(builder.name())) {                throw new IllegalArgumentException(&quot;builder with name [&quot; + builder.name() + &quot;] already exists&quot;);            }            builders.put(builder.name(), builder);        }        this.builders = Collections.unmodifiableMap(builders);        threadContext = new ThreadContext(settings);        final Map&lt;String, ExecutorHolder&gt; executors = new HashMap&lt;&gt;();        for (@SuppressWarnings(&quot;unchecked&quot;) final Map.Entry&lt;String, ExecutorBuilder&gt; entry : builders.entrySet()) {            final ExecutorBuilder.ExecutorSettings executorSettings = entry.getValue().getSettings(settings);            final ExecutorHolder executorHolder = entry.getValue().build(executorSettings, threadContext);            if (executors.containsKey(executorHolder.info.getName())) {                throw new IllegalStateException(&quot;duplicate executors with name [&quot; + executorHolder.info.getName() + &quot;] registered&quot;);            }            logger.debug(&quot;created thread pool: {}&quot;, entry.getValue().formatInfo(executorHolder.info));            executors.put(entry.getKey(), executorHolder);        }        executors.put(Names.SAME, new ExecutorHolder(DIRECT_EXECUTOR, new Info(Names.SAME, ThreadPoolType.DIRECT)));        this.executors = unmodifiableMap(executors);        this.scheduler = Scheduler.initScheduler(settings);        TimeValue estimatedTimeInterval = ESTIMATED_TIME_INTERVAL_SETTING.get(settings);        this.cachedTimeThread = new CachedTimeThread(EsExecutors.threadName(settings, &quot;[timer]&quot;), estimatedTimeInterval.millis());        this.cachedTimeThread.start();    }</code></pre><p>参考着文档来理解这里的代码：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-threadpool.html" target="_blank" rel="noopener">Elasticsearch Reference [6.4] » Modules » Thread Pool</a> 和 <a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=9405389" target="_blank" rel="noopener">apachecn 线程池</a></p><h4 id="线程池类型-ThreadPoolType"><a href="#线程池类型-ThreadPoolType" class="headerlink" title="线程池类型 ThreadPoolType"></a>线程池类型 ThreadPoolType</h4><p><strong>fixed</strong>（固定）：fixed线程池拥有固定数量的线程来处理请求，在没有空闲线程时请求将被挂在队列中。queue_size参数可以控制在没有空闲线程时，能排队挂起的请求数</p><p><strong>fixed_auto_queue_size</strong>：此类型为实验性的，将被更改或删除，不关注</p><p><strong>scaling</strong>（弹性）：scaling线程池拥有的线程数量是动态的，这个数字介于core和max参数的配置之间变化。keep_alive参数用来控制线程在线程池中空闲的最长时间</p><p><strong>direct</strong>：此类线程是一种不支持关闭的线程,就意味着一旦使用,则会一直存活下去.</p><h4 id="一些重要的线程池"><a href="#一些重要的线程池" class="headerlink" title="一些重要的线程池"></a>一些重要的线程池</h4><p><strong>generic</strong>：用于通用的请求（例如：后台节点发现），线程池类型为 scaling。</p><p><strong>index</strong>：用于index/delete请求，线程池类型为 fixed， 大小的为处理器数量，队列大小为200，最大线程数为 1 + 处理器数量。</p><p><strong>search</strong>：用于count/search/suggest请求。线程池类型为 fixed， 大小的为 int((处理器数量 3) / 2) +1，队列大小为1000。*</p><p><strong>get</strong>：用于get请求。线程池类型为 fixed，大小的为处理器数量，队列大小为1000。</p><p><strong>analyze</strong>：用于analyze请求。线程池类型为 fixed，大小的1，队列大小为16</p><p><strong>write</strong>：用于单个文档的 index/delete/update 请求以及 <strong>bulk 请求</strong>，线程池类型为 fixed，大小的为处理器数量，队列大小为200，最大线程数为 1 + 处理器数量。</p><p><strong>snapshot</strong>：用于snaphost/restore请求。线程池类型为 scaling，线程保持存活时间为5分钟，最大线程数为min(5, (处理器数量)/2)。</p><p><strong>warmer</strong>：用于segment warm-up请求。线程池类型为 scaling，线程保持存活时间为5分钟，最大线程数为min(5, (处理器数量)/2)。</p><p><strong>refresh</strong>：用于refresh请求。线程池类型为 scaling，线程空闲保持存活时间为5分钟，最大线程数为min(10, (处理器数量)/2)。</p><p><strong>listener</strong>：主要用于Java客户端线程监听器被设置为true时执行动作。线程池类型为 scaling，最大线程数为min(10, (处理器数量)/2)。</p><p>ThreadPool 类中除了以上线程队列，还可以看到有 CachedTimeThread（缓存系统时间）、ExecutorService（在当前线程上执行提交的任务）、ThreadContext（线程上下文）、ScheduledThreadPoolExecutor（Java任务调度）等</p><blockquote><p>参考文章：<a href="https://my.oschina.net/u/3145136/blog/848079" target="_blank" rel="noopener">Java并发编程14-ScheduledThreadPoolExecutor详解</a><br><a href="https://www.jianshu.com/p/4b8a257f1b90" target="_blank" rel="noopener">Java线程池原理分析ScheduledThreadPoolExecutor篇</a><br>关于 ScheduledThreadPoolExecutor 更多的细节应该看书或者官方文档</p></blockquote><h4 id="关于线程"><a href="#关于线程" class="headerlink" title="关于线程"></a>关于线程</h4><p>了解了线程池，继续深究ES线程是什么样子的</p><p>在 <code>ScalingExecutorBuilder.build</code> 中可以发现 <code>ExecutorService</code> 对象是由 <code>EsExecutors.newScaling</code> 创建的</p><pre><code>public static EsThreadPoolExecutor newScaling(String name, int min, int max, long keepAliveTime, TimeUnit unit, ThreadFactory threadFactory, ThreadContext contextHolder) {    ExecutorScalingQueue&lt;Runnable&gt; queue = new ExecutorScalingQueue&lt;&gt;();    EsThreadPoolExecutor executor = new EsThreadPoolExecutor(name, min, max, keepAliveTime, unit, queue, threadFactory, new ForceQueuePolicy(), contextHolder);    queue.executor = executor;    return executor;}</code></pre><p>再看看 <code>EsThreadPoolExecutor</code> 这个类的继承关系，其是扩展自Java的线程池 <code>ThreadPoolExecutor</code></p><p><img src="http://image.laijianfeng.org/20180901_192545.png" alt="EsThreadPoolExecutor的继承链"></p><pre><code>    EsThreadPoolExecutor(String name, int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit,            BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, XRejectedExecutionHandler handler,            ThreadContext contextHolder) {        super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, handler);        this.name = name;        this.contextHolder = contextHolder;    }</code></pre><h3 id="回到-Node-节点的创建"><a href="#回到-Node-节点的创建" class="headerlink" title="回到 Node 节点的创建"></a>回到 Node 节点的创建</h3><p>4.2, 创建各种服务类对象 ResourceWatcherService、NetworkService、ClusterService、IngestService、ClusterInfoService、UsageService、MonitorService、CircuitBreakerService、MetaStateService、IndicesService、MetaDataIndexUpgradeService、TemplateUpgradeService、TransportService、ResponseCollectorService、SearchTransportService、NodeService、SearchService、PersistentTasksClusterService</p><p>这些服务类是的功能可以根据名称做一个大概的判断，具体还需要看文档和源码，限于篇幅，在此不做探究</p><p>4.3, ModulesBuilder类加入各种模块 ScriptModule、AnalysisModule、SettingsModule、pluginModule、ClusterModule、IndicesModule、SearchModule、GatewayModule、RepositoriesModule、ActionModule、NetworkModule、DiscoveryModule</p><p>4.4, guice 绑定依赖以及依赖注入</p><blockquote><p>关于 guice 可以参考之前的文章:<br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483683&amp;idx=1&amp;sn=0d77085a0234b2c5b7c679e62200e6f5&amp;chksm=e9c2ed2edeb56438010b5f5d487bcb7f0529c85d50ac7c858e1a8e3a9279c15007341170c5ac&amp;mpshare=1&amp;scene=1&amp;srcid=0901SWQiIdjHZ3endUHZqjkP#rd" target="_blank" rel="noopener">Google Guice 快速入门</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483691&amp;idx=1&amp;sn=3c7175d318bce6728c2105d27ae6bafe&amp;chksm=e9c2ed26deb56430289edabd15cef1a0cf777c5dfe4f4ad5013655e9d3607958e0fe16ac5436&amp;mpshare=1&amp;scene=1&amp;srcid=0901u1aslOFhg6UmeBkLw8BY#rd" target="_blank" rel="noopener">Elasticsearch 中的 Guice</a></p></blockquote><p>elasticsearch里面的组件基本都进行进行了模块化管理，elasticsearch对guice进行了封装，通过ModulesBuilder类构建es的模块（一般包括的模块在 4.3 中列举了）</p><pre><code>// 依赖绑定modules.add(b -&gt; {        b.bind(Node.class).toInstance(this);        b.bind(NodeService.class).toInstance(nodeService);        b.bind(NamedXContentRegistry.class).toInstance(xContentRegistry);        b.bind(PluginsService.class).toInstance(pluginsService);        b.bind(Client.class).toInstance(client);        b.bind(NodeClient.class).toInstance(client);        b.bind(Environment.class).toInstance(this.environment);        b.bind(ThreadPool.class).toInstance(threadPool);        b.bind(NodeEnvironment.class).toInstance(nodeEnvironment);        b.bind(ResourceWatcherService.class).toInstance(resourceWatcherService);        b.bind(CircuitBreakerService.class).toInstance(circuitBreakerService);        b.bind(BigArrays.class).toInstance(bigArrays);        b.bind(ScriptService.class).toInstance(scriptModule.getScriptService());        b.bind(AnalysisRegistry.class).toInstance(analysisModule.getAnalysisRegistry());        b.bind(IngestService.class).toInstance(ingestService);        b.bind(UsageService.class).toInstance(usageService);        b.bind(NamedWriteableRegistry.class).toInstance(namedWriteableRegistry);        b.bind(MetaDataUpgrader.class).toInstance(metaDataUpgrader);        b.bind(MetaStateService.class).toInstance(metaStateService);        b.bind(IndicesService.class).toInstance(indicesService);        b.bind(SearchService.class).toInstance(searchService);        b.bind(SearchTransportService.class).toInstance(searchTransportService);        b.bind(SearchPhaseController.class).toInstance(new SearchPhaseController(settings,            searchService::createReduceContext));        b.bind(Transport.class).toInstance(transport);        b.bind(TransportService.class).toInstance(transportService);        b.bind(NetworkService.class).toInstance(networkService);        b.bind(UpdateHelper.class).toInstance(new UpdateHelper(settings, scriptModule.getScriptService()));        b.bind(MetaDataIndexUpgradeService.class).toInstance(metaDataIndexUpgradeService);        b.bind(ClusterInfoService.class).toInstance(clusterInfoService);        b.bind(GatewayMetaState.class).toInstance(gatewayMetaState);        b.bind(Discovery.class).toInstance(discoveryModule.getDiscovery());        {            RecoverySettings recoverySettings = new RecoverySettings(settings, settingsModule.getClusterSettings());            processRecoverySettings(settingsModule.getClusterSettings(), recoverySettings);            b.bind(PeerRecoverySourceService.class).toInstance(new PeerRecoverySourceService(settings, transportService,                    indicesService, recoverySettings));            b.bind(PeerRecoveryTargetService.class).toInstance(new PeerRecoveryTargetService(settings, threadPool,                    transportService, recoverySettings, clusterService));        }        httpBind.accept(b);        pluginComponents.stream().forEach(p -&gt; b.bind((Class) p.getClass()).toInstance(p));        b.bind(PersistentTasksService.class).toInstance(persistentTasksService);        b.bind(PersistentTasksClusterService.class).toInstance(persistentTasksClusterService);        b.bind(PersistentTasksExecutorRegistry.class).toInstance(registry);    });injector = modules.createInjector();</code></pre><h3 id="Bootstrap-启动"><a href="#Bootstrap-启动" class="headerlink" title="Bootstrap 启动"></a>Bootstrap 启动</h3><p>5.1， 通过 <code>injector</code> 获取各个类的对象，调用 <code>start()</code> 方法启动（实际进入各个类的中 <code>doStart</code> 方法）: LifecycleComponent、IndicesService、IndicesClusterStateService、SnapshotsService、SnapshotShardsService、RoutingService、SearchService、MonitorService、NodeConnectionsService、ResourceWatcherService、GatewayService、Discovery、TransportService</p><p>这里简要介绍一下各个服务类的职能：</p><p>IndicesService：索引管理<br>IndicesClusterStateService：跨集群同步<br>SnapshotsService：负责创建快照<br>SnapshotShardsService：此服务在数据和主节点上运行，并控制这些节点上当前快照的分片。 它负责启动和停止分片级别快照<br>RoutingService：侦听集群状态，当它收到ClusterChangedEvent（集群改变事件）将验证集群状态，路由表可能会更新<br>SearchService：搜索服务<br>MonitorService：监控<br>NodeConnectionsService：此组件负责在节点添加到群集状态后连接到节点，并在删除它们时断开连接。 此外，它会定期检查所有连接是否仍处于打开状态，并在需要时还原它们。 请注意，如果节点断开/不响应ping，则此组件不负责从群集中删除节点。 这是由NodesFaultDetection完成的。 主故障检测由链接MasterFaultDetection完成。<br>ResourceWatcherService：通用资源观察器服务<br>GatewayService：网关</p><p>如果该节点是主节点或数据节点，还需要进行相关的职能操作</p><p>5.2, 集群发现与监控等，启动 HttpServerTransport， 绑定服务端口</p><pre><code>validateNodeBeforeAcceptingRequests(new BootstrapContext(settings, onDiskMetadata), transportService.boundAddress(), pluginsService    .filterPlugins(Plugin    .class)    .stream()    .flatMap(p -&gt; p.getBootstrapChecks().stream()).collect(Collectors.toList()));clusterService.addStateApplier(transportService.getTaskManager());// start after transport service so the local disco is knowndiscovery.start(); // start before cluster service so that it can set initial state on ClusterApplierServiceclusterService.start();assert clusterService.localNode().equals(localNodeFactory.getNode())    : &quot;clusterService has a different local node than the factory provided&quot;;transportService.acceptIncomingRequests();discovery.startInitialJoin();// tribe nodes don&#39;t have a master so we shouldn&#39;t register an observer         sfinal TimeValue initialStateTimeout = DiscoverySettings.INITIAL_STATE_TIMEOUT_SETTING.get(settings);if (initialStateTimeout.millis() &gt; 0) {    final ThreadPool thread = injector.getInstance(ThreadPool.class);    ClusterState clusterState = clusterService.state();    ClusterStateObserver observer = new ClusterStateObserver(clusterState, clusterService, null, logger, thread.getThreadContext());    if (clusterState.nodes().getMasterNodeId() == null) {        logger.debug(&quot;waiting to join the cluster. timeout [{}]&quot;, initialStateTimeout);        final CountDownLatch latch = new CountDownLatch(1);        observer.waitForNextChange(new ClusterStateObserver.Listener() {            @Override            public void onNewClusterState(ClusterState state) { latch.countDown(); }            @Override            public void onClusterServiceClose() {                latch.countDown();            }            @Override            public void onTimeout(TimeValue timeout) {                logger.warn(&quot;timed out while waiting for initial discovery state - timeout: {}&quot;,                    initialStateTimeout);                latch.countDown();            }        }, state -&gt; state.nodes().getMasterNodeId() != null, initialStateTimeout);        try {            latch.await();        } catch (InterruptedException e) {            throw new ElasticsearchTimeoutException(&quot;Interrupted while waiting for initial discovery state&quot;);        }    }}if (NetworkModule.HTTP_ENABLED.get(settings)) {    injector.getInstance(HttpServerTransport.class).start();}if (WRITE_PORTS_FILE_SETTING.get(settings)) {    if (NetworkModule.HTTP_ENABLED.get(settings)) {        HttpServerTransport http = injector.getInstance(HttpServerTransport.class);        writePortsFile(&quot;http&quot;, http.boundAddress());    }    TransportService transport = injector.getInstance(TransportService.class);    writePortsFile(&quot;transport&quot;, transport.boundAddress());}</code></pre><p>5.3, 启动保活线程 keepAliveThread.start 进行心跳检测</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>过程很漫长，后面很多类的功能未了解，之后补上</p><p>有理解错误的地方请大家多多指教</p><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;本文探究Elasticsearch 6.3.2的启动流程&lt;/p&gt;
&lt;h4 id=&quot;环境准备&quot;&gt;&lt;a href=&quot;#环境准备&quot; class=&quot;
      
    
    </summary>
    
      <category term="大数据" scheme="http://laijianfeng.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="elasticsearch" scheme="http://laijianfeng.org/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Google guava工具类的介绍和使用</title>
    <link href="http://laijianfeng.org/2018/08/Google-guava%E5%B7%A5%E5%85%B7%E7%B1%BB%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BD%BF%E7%94%A8/"/>
    <id>http://laijianfeng.org/2018/08/Google-guava工具类的介绍和使用/</id>
    <published>2018-08-30T16:58:57.000Z</published>
    <updated>2018-08-30T16:59:59.729Z</updated>
    
    <content type="html"><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>工具类 就是封装平常用的方法，不需要你重复造轮子，节省开发人员时间，提高工作效率。谷歌作为大公司，当然会从日常的工作中提取中很多高效率的方法出来。所以就诞生了guava。</p><p>guava的优点：</p><ul><li>高效设计良好的API，被Google的开发者设计，实现和使用</li><li>遵循高效的java语法实践</li><li>使代码更刻度，简洁，简单</li><li>节约时间，资源，提高生产力</li></ul><p>Guava工程包含了若干被Google的 Java项目广泛依赖 的核心库，例如：</p><ul><li>集合 [collections]</li><li>缓存 [caching]</li><li>原生类型支持 [primitives support]</li><li>并发库 [concurrency libraries]</li><li>通用注解 [common annotations]</li><li>字符串处理 [string processing]</li><li>I/O 等等。</li></ul><p>这里借用龙果学院深入浅出Guava课程的一张图</p><p><img src="http://image.laijianfeng.org/20180830_234930.png" alt="龙果学院深入浅出Guava"></p><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>引入gradle依赖（引入Jar包）</p><pre><code>compile &#39;com.google.guava:guava:26.0-jre&#39;</code></pre><h4 id="1-集合的创建"><a href="#1-集合的创建" class="headerlink" title="1.集合的创建"></a>1.集合的创建</h4><pre><code>// 普通Collection的创建List&lt;String&gt; list = Lists.newArrayList();Set&lt;String&gt; set = Sets.newHashSet();Map&lt;String, String&gt; map = Maps.newHashMap();// 不变Collection的创建ImmutableList&lt;String&gt; iList = ImmutableList.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;);ImmutableSet&lt;String&gt; iSet = ImmutableSet.of(&quot;e1&quot;, &quot;e2&quot;);ImmutableMap&lt;String, String&gt; iMap = ImmutableMap.of(&quot;k1&quot;, &quot;v1&quot;, &quot;k2&quot;, &quot;v2&quot;);</code></pre><p>创建不可变集合 先理解什么是immutable(不可变)对象</p><ul><li>在多线程操作下，是线程安全的</li><li>所有不可变集合会比可变集合更有效的利用资源</li><li>中途不可改变</li></ul><pre><code>ImmutableList&lt;String&gt; immutableList = ImmutableList.of(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;);</code></pre><p>这声明了一个<strong>不可变</strong>的List集合，List中有数据1，2，3，4。类中的 操作集合的方法（譬如add, set, sort, replace等）都被声明过期，并且抛出异常。 而没用guava之前是需要声明并且加各种包裹集合才能实现这个功能</p><pre><code>  // add 方法  @Deprecated @Override  public final void add(int index, E element) {    throw new UnsupportedOperationException();  }</code></pre><p><strong>当我们需要一个map中包含key为String类型，value为List类型的时候</strong>，以前我们是这样写的</p><pre><code>Map&lt;String,List&lt;Integer&gt;&gt; map = new HashMap&lt;String,List&lt;Integer&gt;&gt;();List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();list.add(1);list.add(2);map.put(&quot;aa&quot;, list);System.out.println(map.get(&quot;aa&quot;));//[1, 2]</code></pre><p>而现在</p><pre><code>Multimap&lt;String,Integer&gt; map = ArrayListMultimap.create();        map.put(&quot;aa&quot;, 1);map.put(&quot;aa&quot;, 2);System.out.println(map.get(&quot;aa&quot;));  //[1, 2]</code></pre><p><strong>其他的黑科技集合</strong></p><pre><code>MultiSet: 无序+可重复   count()方法获取单词的次数  增强了可读性+操作简单创建方式:  Multiset&lt;String&gt; set = HashMultiset.create();Multimap: key-value  key可以重复  创建方式: Multimap&lt;String, String&gt; teachers = ArrayListMultimap.create();BiMap: 双向Map(Bidirectional Map) 键与值都不能重复创建方式:  BiMap&lt;String, String&gt; biMap = HashBiMap.create();Table: 双键的Map Map--&gt; Table--&gt;rowKey+columnKey+value  //和sql中的联合主键有点像创建方式: Table&lt;String, String, Integer&gt; tables = HashBasedTable.create();...等等(guava中还有很多java里面没有给出的集合类型)</code></pre><h4 id="2-将集合转换为特定规则的字符串"><a href="#2-将集合转换为特定规则的字符串" class="headerlink" title="2.将集合转换为特定规则的字符串"></a>2.将集合转换为特定规则的字符串</h4><p>以前我们将list转换为特定规则的字符串是这样写的:</p><pre><code>//use javaList&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(&quot;aa&quot;);list.add(&quot;bb&quot;);list.add(&quot;cc&quot;);String str = &quot;&quot;;for(int i=0; i&lt;list.size(); i++){    str = str + &quot;-&quot; +list.get(i);}//str 为-aa-bb-cc//use guavaList&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(&quot;aa&quot;);list.add(&quot;bb&quot;);list.add(&quot;cc&quot;);String result = Joiner.on(&quot;-&quot;).join(list);//result为  aa-bb-cc</code></pre><p>把map集合转换为特定规则的字符串</p><pre><code>Map&lt;String, Integer&gt; map = Maps.newHashMap();map.put(&quot;xiaoming&quot;, 12);map.put(&quot;xiaohong&quot;,13);String result = Joiner.on(&quot;,&quot;).withKeyValueSeparator(&quot;=&quot;).join(map);// result为 xiaoming=12,xiaohong=13</code></pre><h4 id="3-将String转换为特定的集合"><a href="#3-将String转换为特定的集合" class="headerlink" title="3.将String转换为特定的集合"></a>3.将String转换为特定的集合</h4><pre><code>//use javaList&lt;String&gt; list = new ArrayList&lt;String&gt;();String a = &quot;1-2-3-4-5-6&quot;;String[] strs = a.split(&quot;-&quot;);for(int i=0; i&lt;strs.length; i++){    list.add(strs[i]);}//use guavaString str = &quot;1-2-3-4-5-6&quot;;List&lt;String&gt; list = Splitter.on(&quot;-&quot;).splitToList(str);//list为  [1, 2, 3, 4, 5, 6]</code></pre><p>如果</p><pre><code>str=&quot;1-2-3-4- 5-  6  &quot;;</code></pre><p>guava还可以使用 <code>omitEmptyStrings().trimResults()</code> 去除空串与空格</p><pre><code>String str = &quot;1-2-3-4-  5-  6   &quot;;  List&lt;String&gt; list = Splitter.on(&quot;-&quot;).omitEmptyStrings().trimResults().splitToList(str);System.out.println(list);</code></pre><p><strong>将String转换为map</strong></p><pre><code>String str = &quot;xiaoming=11,xiaohong=23&quot;;Map&lt;String,String&gt; map = Splitter.on(&quot;,&quot;).withKeyValueSeparator(&quot;=&quot;).split(str);</code></pre><h4 id="4-guava还支持多个字符切割，或者特定的正则分隔"><a href="#4-guava还支持多个字符切割，或者特定的正则分隔" class="headerlink" title="4.guava还支持多个字符切割，或者特定的正则分隔"></a>4.guava还支持多个字符切割，或者特定的正则分隔</h4><pre><code>String input = &quot;aa.dd,,ff,,.&quot;;List&lt;String&gt; result = Splitter.onPattern(&quot;[.|,]&quot;).omitEmptyStrings().splitToList(input);</code></pre><p>关于字符串的操作 都是在Splitter这个类上进行的</p><pre><code>// 判断匹配结果boolean result = CharMatcher.inRange(&#39;a&#39;, &#39;z&#39;).or(CharMatcher.inRange(&#39;A&#39;, &#39;Z&#39;)).matches(&#39;K&#39;); //true// 保留数字文本  CharMatcher.digit() 已过时   retain 保留//String s1 = CharMatcher.digit().retainFrom(&quot;abc 123 efg&quot;); //123String s1 = CharMatcher.inRange(&#39;0&#39;, &#39;9&#39;).retainFrom(&quot;abc 123 efg&quot;); // 123// 删除数字文本  remove 删除// String s2 = CharMatcher.digit().removeFrom(&quot;abc 123 efg&quot;);    //abc  efgString s2 = CharMatcher.inRange(&#39;0&#39;, &#39;9&#39;).removeFrom(&quot;abc 123 efg&quot;); // abc  efg</code></pre><h4 id="5-集合的过滤"><a href="#5-集合的过滤" class="headerlink" title="5. 集合的过滤"></a>5. 集合的过滤</h4><p>我们对于集合的过滤，思路就是迭代，然后再具体对每一个数判断，这样的代码放在程序中，难免会显得很臃肿，虽然功能都有，但是很不好看。</p><p>guava写法</p><pre><code>//按照条件过滤ImmutableList&lt;String&gt; names = ImmutableList.of(&quot;begin&quot;, &quot;code&quot;, &quot;Guava&quot;, &quot;Java&quot;);Iterable&lt;String&gt; fitered = Iterables.filter(names, Predicates.or(Predicates.equalTo(&quot;Guava&quot;), Predicates.equalTo(&quot;Java&quot;)));System.out.println(fitered); // [Guava, Java]//自定义过滤条件   使用自定义回调方法对Map的每个Value进行操作ImmutableMap&lt;String, Integer&gt; m = ImmutableMap.of(&quot;begin&quot;, 12, &quot;code&quot;, 15);        // Function&lt;F, T&gt; F表示apply()方法input的类型，T表示apply()方法返回类型        Map&lt;String, Integer&gt; m2 = Maps.transformValues(m, new Function&lt;Integer, Integer&gt;() {            public Integer apply(Integer input) {                if(input&gt;12){                    return input;                }else{                    return input+1;                }            }        });System.out.println(m2);   //{begin=13, code=15}</code></pre><p>set的交集, 并集, 差集</p><pre><code>HashSet setA = newHashSet(1, 2, 3, 4, 5);  HashSet setB = newHashSet(4, 5, 6, 7, 8);  SetView union = Sets.union(setA, setB);    System.out.println(&quot;union:&quot;);  for (Integer integer : union)      System.out.println(integer);           //union 并集:12345867SetView difference = Sets.difference(setA, setB);  System.out.println(&quot;difference:&quot;);  for (Integer integer : difference)      System.out.println(integer);        //difference 差集:123SetView intersection = Sets.intersection(setA, setB);  System.out.println(&quot;intersection:&quot;);  for (Integer integer : intersection)      System.out.println(integer);  //intersection 交集:45</code></pre><p>map的交集，并集，差集</p><pre><code>HashMap&lt;String, Integer&gt; mapA = Maps.newHashMap();mapA.put(&quot;a&quot;, 1);mapA.put(&quot;b&quot;, 2);mapA.put(&quot;c&quot;, 3);HashMap&lt;String, Integer&gt; mapB = Maps.newHashMap();mapB.put(&quot;b&quot;, 20);mapB.put(&quot;c&quot;, 3);mapB.put(&quot;d&quot;, 4);MapDifference differenceMap = Maps.difference(mapA, mapB);differenceMap.areEqual();Map entriesDiffering = differenceMap.entriesDiffering();Map entriesOnlyLeft = differenceMap.entriesOnlyOnLeft();Map entriesOnlyRight = differenceMap.entriesOnlyOnRight();Map entriesInCommon = differenceMap.entriesInCommon();System.out.println(entriesDiffering);   // {b=(2, 20)}System.out.println(entriesOnlyLeft);    // {a=1}System.out.println(entriesOnlyRight);   // {d=4}System.out.println(entriesInCommon);    // {c=3}</code></pre><h4 id="6-检查参数"><a href="#6-检查参数" class="headerlink" title="6.检查参数"></a>6.检查参数</h4><pre><code>//use javaif(list!=null &amp;&amp; list.size()&gt;0)&#39;&#39;&#39;if(str!=null &amp;&amp; str.length()&gt;0)&#39;&#39;&#39;if(str !=null &amp;&amp; !str.isEmpty())//use guavaif(!Strings.isNullOrEmpty(str))//use javaif (count &lt;= 0) {    throw new IllegalArgumentException(&quot;must be positive: &quot; + count);         }    //use guavaPreconditions.checkArgument(count &gt; 0, &quot;must be positive: %s&quot;, count);  </code></pre><p>免去了很多麻烦！并且会使你的代码看上去更好看。而不是代码里面充斥着 <code>!=null</code>， <code>!=&quot;&quot;</code></p><p><strong>检查是否为空,不仅仅是字符串类型，其他类型的判断，全部都封装在 Preconditions类里，里面的方法全为静态</strong></p><p>其中的一个方法的源码</p><pre><code>@CanIgnoreReturnValuepublic static &lt;T&gt; T checkNotNull(T reference) {    if (reference == null) {      throw new NullPointerException();    }    return reference;}</code></pre><table><thead><tr><th>方法声明（不包括额外参数）</th><th>描述</th><th>检查失败时抛出的异常</th></tr></thead><tbody><tr><td>checkArgument(boolean)</td><td>检查boolean是否为true，用来检查传递给方法的参数。</td><td>IllegalArgumentException</td></tr><tr><td>checkNotNull(T)</td><td>检查value是否为null，该方法直接返回value，因此可以内嵌使用checkNotNull。</td><td>NullPointerException</td></tr><tr><td>checkState(boolean)</td><td>用来检查对象的某些状态。</td><td>IllegalStateException</td></tr><tr><td>checkElementIndex(int index, int size)</td><td>检查index作为索引值对某个列表、字符串或数组是否有效。   index &gt; 0 &amp;&amp; index &lt; size</td><td>IndexOutOfBoundsException</td></tr><tr><td>checkPositionIndexes(int start, int end, int size)</td><td>检查[start,end]表示的位置范围对某个列表、字符串或数组是否有效</td><td>IndexOutOfBoundsException</td></tr></tbody></table><h4 id="7-MoreObjects"><a href="#7-MoreObjects" class="headerlink" title="7. MoreObjects"></a>7. MoreObjects</h4><p>这个方法是在Objects过期后官方推荐使用的替代品，该类最大的好处就是不用大量的重写 <code>toString</code>，用一种很优雅的方式实现重写，或者在某个场景定制使用。</p><pre><code>Person person = new Person(&quot;aa&quot;,11);String str = MoreObjects.toStringHelper(&quot;Person&quot;).add(&quot;age&quot;, person.getAge()).toString();System.out.println(str);  //输出Person{age=11}</code></pre><h4 id="8-强大的Ordering排序器"><a href="#8-强大的Ordering排序器" class="headerlink" title="8.强大的Ordering排序器"></a>8.强大的Ordering排序器</h4><p>排序器[Ordering]是Guava流畅风格比较器[Comparator]的实现，它可以用来为构建复杂的比较器，以完成集合排序的功能。</p><pre><code>natural()    对可排序类型做自然排序，如数字按大小，日期按先后排序usingToString()    按对象的字符串形式做字典排序[lexicographical ordering]from(Comparator)    把给定的Comparator转化为排序器reverse()    获取语义相反的排序器nullsFirst()    使用当前排序器，但额外把null值排到最前面。nullsLast()    使用当前排序器，但额外把null值排到最后面。compound(Comparator)    合成另一个比较器，以处理当前排序器中的相等情况。lexicographical()    基于处理类型T的排序器，返回该类型的可迭代对象Iterable&lt;T&gt;的排序器。onResultOf(Function)    对集合中元素调用Function，再按返回值用当前排序器排序。</code></pre><p>示例</p><pre><code>Person person = new Person(&quot;aa&quot;,14);  //String name  ,Integer agePerson ps = new Person(&quot;bb&quot;,13);Ordering&lt;Person&gt; byOrdering = Ordering.natural().nullsFirst().onResultOf(new Function&lt;Person,String&gt;(){    public String apply(Person person){        return person.age.toString();    }});byOrdering.compare(person, ps);System.out.println(byOrdering.compare(person, ps)); //1      person的年龄比ps大 所以输出1</code></pre><h4 id="9-计算中间代码的运行时间"><a href="#9-计算中间代码的运行时间" class="headerlink" title="9.计算中间代码的运行时间"></a>9.计算中间代码的运行时间</h4><pre><code>Stopwatch stopwatch = Stopwatch.createStarted();for(int i=0; i&lt;100000; i++){    // do some thing}long nanos = stopwatch.elapsed(TimeUnit.MILLISECONDS);System.out.println(nanos);</code></pre><p>TimeUnit 可以指定时间输出精确到多少时间</p><h4 id="10-文件操作"><a href="#10-文件操作" class="headerlink" title="10.文件操作"></a>10.文件操作</h4><p>以前我们写文件读取的时候要定义缓冲区，各种条件判断，各种 <code>$%#$@#</code></p><p>而现在我们只需要使用好guava的api 就能使代码变得简洁，并且不用担心因为写错逻辑而背锅了</p><pre><code>File file = new File(&quot;test.txt&quot;);List&lt;String&gt; list = null;try {    list = Files.readLines(file, Charsets.UTF_8);} catch (Exception e) {}Files.copy(from,to);  //复制文件Files.deleteDirectoryContents(File directory); //删除文件夹下的内容(包括文件与子文件夹)  Files.deleteRecursively(File file); //删除文件或者文件夹  Files.move(File from, File to); //移动文件URL url = Resources.getResource(&quot;abc.xml&quot;); //获取classpath根下的abc.xml文件url</code></pre><p>Files类中还有许多方法可以用，可以多多翻阅</p><h4 id="11-guava缓存"><a href="#11-guava缓存" class="headerlink" title="11.guava缓存"></a>11.guava缓存</h4><p>guava的缓存设计的比较巧妙，可以很精巧的使用。guava缓存创建分为两种，一种是CacheLoader,另一种则是callback方式</p><p>CacheLoader:</p><pre><code>LoadingCache&lt;String,String&gt; cahceBuilder=CacheBuilder                .newBuilder()                .build(new CacheLoader&lt;String, String&gt;(){                    @Override                    public String load(String key) throws Exception {                                String strProValue=&quot;hello &quot;+key+&quot;!&quot;;                                        return strProValue;                    }                });        System.out.println(cahceBuilder.apply(&quot;begincode&quot;));  //hello begincode!System.out.println(cahceBuilder.get(&quot;begincode&quot;)); //hello begincode!System.out.println(cahceBuilder.get(&quot;wen&quot;)); //hello wen!System.out.println(cahceBuilder.apply(&quot;wen&quot;)); //hello wen!System.out.println(cahceBuilder.apply(&quot;da&quot;));//hello da!cahceBuilder.put(&quot;begin&quot;, &quot;code&quot;);System.out.println(cahceBuilder.get(&quot;begin&quot;)); //code</code></pre><p>api中已经把apply声明为过期，声明中推荐使用get方法获取值</p><p>callback方式:</p><pre><code> Cache&lt;String, String&gt; cache = CacheBuilder.newBuilder().maximumSize(1000).build();              String resultVal = cache.get(&quot;code&quot;, new Callable&lt;String&gt;() {                  public String call() {                      String strProValue=&quot;begin &quot;+&quot;code&quot;+&quot;!&quot;;                                    return strProValue;                }              });   System.out.println(&quot;value : &quot; + resultVal); //value : begin code!</code></pre><p>以上只是guava使用的一小部分，guava是个大的工具类，第一版guava是2010年发布的，每一版的更新和迭代都是一种创新。</p><p>jdk的升级很多都是借鉴guava里面的思想来进行的。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>代码可以在 <a href="https://github.com/whirlys/elastic-example/tree/master/guava" target="_blank" rel="noopener">https://github.com/whirlys/elastic-example/tree/master/guava</a> 下载</p><p>细节请翻看 guava 文档 <a href="https://github.com/google/guava/wiki" target="_blank" rel="noopener">https://github.com/google/guava/wiki</a></p><blockquote><p>参考：<br><a href="https://my.oschina.net/u/2551035/blog/802634" target="_blank" rel="noopener">Google guava工具类的介绍和使用</a><br><a href="https://blog.csdn.net/ac_dao_di/article/details/53750028" target="_blank" rel="noopener">Guava工具类学习</a></p></blockquote><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h3&gt;&lt;p&gt;工具类 就是封装平常用的方法，不需要你重复造轮子，节省开发人员时间，提高工作效率。谷歌作为大公司，当然会从日常的工作中提取中很多高效率的方法
      
    
    </summary>
    
      <category term="后端" scheme="http://laijianfeng.org/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
      <category term="java" scheme="http://laijianfeng.org/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch 中的 Guice</title>
    <link href="http://laijianfeng.org/2018/08/Elasticsearch-%E4%B8%AD%E7%9A%84-Guice/"/>
    <id>http://laijianfeng.org/2018/08/Elasticsearch-中的-Guice/</id>
    <published>2018-08-30T16:39:17.000Z</published>
    <updated>2018-08-30T16:40:14.535Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>Elasticsearch 源代码中使用了Guice框架进行依赖注入. 为了方便阅读源码, 此处我先通过模仿ES guice的使用方式简单写了一个基本Demo 方便理解, 之后再来理一下ES的Guice使用. 编写的测试类原理图如下:</p><p><img src="http://image.laijianfeng.org/2778947-7847f61cf5180bdc.webp" alt="ES Guice Demo"></p><p>总共有两个Module，一个是ToolModule，<strong>用于绑定</strong>IAnimal接口、ITool接口以及Map对象. 另一个是HumanModule 用于绑定Person对象。   </p><p>其中Person的构造函数通过 <code>@Inject</code> 注解注入其他实例</p><p>gradle 需要引入的 Jar 包</p><pre><code>compile group: &#39;com.google.inject.extensions&#39;, name: &#39;guice-multibindings&#39;, version: &#39;4.2.0&#39;compile group: &#39;com.google.inject&#39;, name: &#39;guice&#39;, version: &#39;4.2.0&#39;</code></pre><h3 id="1、Demo"><a href="#1、Demo" class="headerlink" title="1、Demo"></a>1、Demo</h3><h4 id="iTool接口与实现类"><a href="#iTool接口与实现类" class="headerlink" title="iTool接口与实现类"></a>iTool接口与实现类</h4><pre><code>public interface ITool {    public void doWork();}</code></pre><pre><code>import com.whirly.guice.example.ITool;public class IToolImpl implements ITool {    @Override    public void doWork() {        System.out.println(&quot;use tool to work&quot;);    }}</code></pre><h4 id="IAnimal-接口与实现类"><a href="#IAnimal-接口与实现类" class="headerlink" title="IAnimal 接口与实现类"></a>IAnimal 接口与实现类</h4><pre><code>public interface IAnimal {    void work();}</code></pre><pre><code>public class IAnimalImpl implements IAnimal {    @Override    public void work() {        System.out.println(&quot;animals can also do work&quot;);    }}</code></pre><h4 id="ToolModule的实现-它绑了三个实例"><a href="#ToolModule的实现-它绑了三个实例" class="headerlink" title="ToolModule的实现, 它绑了三个实例"></a>ToolModule的实现, 它绑了三个实例</h4><pre><code>public class ToolModule extends AbstractModule {    @Override    protected void configure() {        //此处注入的实例可以注入到其他类的构造函数中, 只要那个类使用@Inject进行注入即可        bind(IAnimal.class).to(IAnimalImpl.class);        bind(ITool.class).to(IToolImpl.class);        // 注入Map实例        MapBinder&lt;String, String&gt; mapBinder = MapBinder.newMapBinder(binder(), String.class, String.class);        mapBinder.addBinding(&quot;test1&quot;).toInstance(&quot;test1&quot;);        mapBinder.addBinding(&quot;test2&quot;).toInstance(&quot;test2&quot;);    }}</code></pre><p><code>bind(IAnimal.class).to(IAnimalImpl.class);bind(ITool.class).to(IToolImpl.class);</code>  是将接口与其具体实现绑定起来</p><p><code>MapBinder&lt;String,String&gt; mapBinder =MapBinder.newMapBinder(binder(), String.class, String.class);mapBinder.addBinding(&quot;test1&quot;).toInstance(&quot;test1&quot;);mapBinder.addBinding(&quot;test2&quot;).toInstance(&quot;test2&quot;);</code> 则是完成Map的绑定. </p><p>后面来看看Person类和HumanModule</p><h4 id="Person-类"><a href="#Person-类" class="headerlink" title="Person 类"></a>Person 类</h4><pre><code>public class Person {    private IAnimal iAnimal;    private ITool iTool;    private Map&lt;String, String&gt; map;    @Inject    public Person(IAnimal iAnimal, ITool iTool, Map&lt;String, String&gt; map) {        this.iAnimal = iAnimal;        this.iTool = iTool;        this.map = map;    }    public void startwork() {        iTool.doWork();        iAnimal.work();        for (Map.Entry entry : map.entrySet()) {            System.out.println(&quot;注入的map 是 &quot; + entry.getKey() + &quot; value &quot; + entry.getValue());        }    }}</code></pre><p>Person 类中由 <code>IAnimal</code>、<code>ITool</code> 和 <code>Map&lt;String, String&gt;</code> 这三个接口定义的变量，对象将通过 <code>@Inject</code> 从构造方法中注入进来</p><pre><code>public class HumanModule extends AbstractModule {    @Override    protected void configure() {        bind(Person.class).asEagerSingleton();    }}</code></pre><p>Person类的构造函数是通过注入的方式，注入对象实例的</p><p>最后 <code>CustomModuleBuilder</code> 进行<strong>统一管理所有的Module</strong>，实例化所有Module中的对象. 完成依赖注入。</p><p>这里的CustomModuleBuilder是修改自Elasticsearch中的ModulesBuilder，其原理是一样的。</p><p>就是一个迭代器，<strong>内部封装的是Module集合, 统一管理所有的Module</strong></p><h4 id="CustomModuleBuilder-统一管理-Module"><a href="#CustomModuleBuilder-统一管理-Module" class="headerlink" title="CustomModuleBuilder 统一管理 Module"></a>CustomModuleBuilder 统一管理 Module</h4><pre><code>public class CustomModuleBuilder implements Iterable&lt;Module&gt; {    private final List&lt;Module&gt; modules = new ArrayList&lt;&gt;();    public CustomModuleBuilder add(Module... newModules) {        for (Module module : newModules) {            modules.add(module);        }        return this;    }    @Override    public Iterator&lt;Module&gt; iterator() {        return modules.iterator();    }    public Injector createInjector() {        Injector injector = Guice.createInjector(modules);        return injector;    }}</code></pre><p>这样就可以从Main方法是如何进行使用的</p><h4 id="Main-方法"><a href="#Main-方法" class="headerlink" title="Main 方法"></a>Main 方法</h4><pre><code>public class Main {    public static void main(String[] args) {        CustomModuleBuilder moduleBuilder = new CustomModuleBuilder();        moduleBuilder.add(new ToolModule());        moduleBuilder.add(new HumanModule());        Injector injector = moduleBuilder.createInjector();        Person person = injector.getInstance(Person.class);        person.startwork();    }}</code></pre><p>运行结果</p><pre><code>use tool to workanimals can also do work注入的map 是 test1 value test1注入的map 是 test2 value test2</code></pre><p>通过CustomModuleBuilder 的createInjector获取Injector 对象, 根据Injector 对象取相应的具体实例对象.</p><h3 id="2、ES-中Guice的使用"><a href="#2、ES-中Guice的使用" class="headerlink" title="2、ES 中Guice的使用"></a>2、ES 中Guice的使用</h3><p>ES中TransportClient初始化时的Guice的使用是这样的, 如下图所示</p><p><img src="http://image.laijianfeng.org/2778947-ab2035e865492a2b.png" alt="ES中TransportClient初始化时的Guice的使用（ES版本不是6.3.2）"></p><h4 id="TransportClient的初始化代码"><a href="#TransportClient的初始化代码" class="headerlink" title="TransportClient的初始化代码"></a>TransportClient的初始化代码</h4><p>Elasticsearch 6.3.2 </p><pre><code>private static ClientTemplate buildTemplate(Settings providedSettings, Settings defaultSettings,                                            Collection&lt;Class&lt;? extends Plugin&gt;&gt; plugins, HostFailureListener failureListner) {    // 省略 ...    try {        // 省略 ...        // 创建一个迭代器, 然后将各个Module通过add方法加入进去        ModulesBuilder modules = new ModulesBuilder();        // plugin modules must be added here, before others or we can get crazy injection errors...        for (Module pluginModule : pluginsService.createGuiceModules()) {            modules.add(pluginModule);        }        modules.add(b -&gt; b.bind(ThreadPool.class).toInstance(threadPool));        ActionModule actionModule = new ActionModule(true, settings, null, settingsModule.getIndexScopedSettings(),                settingsModule.getClusterSettings(), settingsModule.getSettingsFilter(), threadPool,                pluginsService.filterPlugins(ActionPlugin.class), null, null, null);        modules.add(actionModule);        CircuitBreakerService circuitBreakerService = Node.createCircuitBreakerService(settingsModule.getSettings(),            settingsModule.getClusterSettings());        resourcesToClose.add(circuitBreakerService);        PageCacheRecycler pageCacheRecycler = new PageCacheRecycler(settings);        BigArrays bigArrays = new BigArrays(pageCacheRecycler, circuitBreakerService);        resourcesToClose.add(bigArrays);        modules.add(settingsModule);        NetworkModule networkModule = new NetworkModule(settings, true, pluginsService.filterPlugins(NetworkPlugin.class), threadPool,            bigArrays, pageCacheRecycler, circuitBreakerService, namedWriteableRegistry, xContentRegistry, networkService, null);        final Transport transport = networkModule.getTransportSupplier().get();        final TransportService transportService = new TransportService(settings, transport, threadPool,            networkModule.getTransportInterceptor(),            boundTransportAddress -&gt; DiscoveryNode.createLocal(settings, new TransportAddress(TransportAddress.META_ADDRESS, 0),                UUIDs.randomBase64UUID()), null, Collections.emptySet());        modules.add((b -&gt; {            b.bind(BigArrays.class).toInstance(bigArrays);            b.bind(PluginsService.class).toInstance(pluginsService);            b.bind(CircuitBreakerService.class).toInstance(circuitBreakerService);            b.bind(NamedWriteableRegistry.class).toInstance(namedWriteableRegistry);            b.bind(Transport.class).toInstance(transport);            b.bind(TransportService.class).toInstance(transportService);            b.bind(NetworkService.class).toInstance(networkService);        }));        // 注入所有module下的实例        Injector injector = modules.createInjector();        final TransportClientNodesService nodesService =            new TransportClientNodesService(settings, transportService, threadPool, failureListner == null                ? (t, e) -&gt; {} : failureListner);        // construct the list of client actions        final List&lt;ActionPlugin&gt; actionPlugins = pluginsService.filterPlugins(ActionPlugin.class);        final List&lt;GenericAction&gt; clientActions =                actionPlugins.stream().flatMap(p -&gt; p.getClientActions().stream()).collect(Collectors.toList());        // add all the base actions        final List&lt;? extends GenericAction&lt;?, ?&gt;&gt; baseActions =                actionModule.getActions().values().stream().map(ActionPlugin.ActionHandler::getAction).collect(Collectors.toList());        clientActions.addAll(baseActions);        final TransportProxyClient proxy = new TransportProxyClient(settings, transportService, nodesService, clientActions);        List&lt;LifecycleComponent&gt; pluginLifecycleComponents = new ArrayList&lt;&gt;(pluginsService.getGuiceServiceClasses().stream()            .map(injector::getInstance).collect(Collectors.toList()));        resourcesToClose.addAll(pluginLifecycleComponents);        // 启动服务        transportService.start();        transportService.acceptIncomingRequests();        ClientTemplate transportClient = new ClientTemplate(injector, pluginLifecycleComponents, nodesService, proxy, namedWriteableRegistry);        resourcesToClose.clear();        return transportClient;    } finally {        IOUtils.closeWhileHandlingException(resourcesToClose);    }}</code></pre><p>可以看到确实是先通 <code>过ModulesBuilder modules = new ModulesBuilder()</code> 创建一个迭代器, 然后将各个Module通过add方法加入进去, 最后通过 <code>Injector injector = modules.createInjector();</code> 创建Injector对象, <strong>之后便可根据Injector对象去获取实例了</strong>. </p><p>各个Module会绑定自己所需要的实例, 这里以 SettingsModule 举例:</p><pre><code>public class SettingsModule extends AbstractModule {    private final Settings settings;    private final Set&lt;String&gt; settingsFilterPattern = new HashSet&lt;&gt;();    private final Map&lt;String, Setting&lt;?&gt;&gt; nodeSettings = new HashMap&lt;&gt;();    private final Map&lt;String, Setting&lt;?&gt;&gt; indexSettings = new HashMap&lt;&gt;();    private final Logger logger;    private final IndexScopedSettings indexScopedSettings;    private final ClusterSettings clusterSettings;    private final SettingsFilter settingsFilter;    public SettingsModule(Settings settings, Setting&lt;?&gt;... additionalSettings) {        this(settings, Arrays.asList(additionalSettings), Collections.emptyList());    }    @Override    public void configure(Binder binder) {        binder.bind(Settings.class).toInstance(settings);        binder.bind(SettingsFilter.class).toInstance(settingsFilter);        binder.bind(ClusterSettings.class).toInstance(clusterSettings);        binder.bind(IndexScopedSettings.class).toInstance(indexScopedSettings);    }    //...}</code></pre><p>可以看到它绑定了四个,分别是 Settings.class，SettingsFilter.class，ClusterSettings.class，IndexScopedSettings.class</p><p>它们的实例对象都可以通过Injector来获取</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>示例代码可在 <a href="https://github.com/whirlys/elastic-example/tree/master/guice" target="_blank" rel="noopener">https://github.com/whirlys/elastic-example/tree/master/guice</a> 处下载</p><blockquote><p>参考：<br>kason_zhang <a href="https://www.jianshu.com/p/0a1e6267b46f" target="_blank" rel="noopener">Elasticsearch Guice 的使用</a></p></blockquote><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;Elasticsearch 源代码中使用了Guice框架进行依赖注入. 为了方便阅读源码, 此处我先通过模仿ES guice的使用方式简单写
      
    
    </summary>
    
      <category term="大数据" scheme="http://laijianfeng.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="elasticsearch" scheme="http://laijianfeng.org/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>鼓舞人心</title>
    <link href="http://laijianfeng.org/2018/08/%E9%BC%93%E8%88%9E%E4%BA%BA%E5%BF%83/"/>
    <id>http://laijianfeng.org/2018/08/鼓舞人心/</id>
    <published>2018-08-27T11:51:31.000Z</published>
    <updated>2018-08-27T11:52:52.757Z</updated>
    
    <content type="html"><![CDATA[<ol><li>所有的伟大，源于一个勇敢的开始</li></ol><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;所有的伟大，源于一个勇敢的开始&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E
      
    
    </summary>
    
      <category term="读书" scheme="http://laijianfeng.org/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
  </entry>
  
  <entry>
    <title>Elasticsearch 分布式特性</title>
    <link href="http://laijianfeng.org/2018/08/Elasticsearch-%E5%88%86%E5%B8%83%E5%BC%8F%E7%89%B9%E6%80%A7/"/>
    <id>http://laijianfeng.org/2018/08/Elasticsearch-分布式特性/</id>
    <published>2018-08-25T10:29:15.000Z</published>
    <updated>2018-08-25T10:32:23.330Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本文的主要内容：</p><ul><li>分布式介绍及cerebro</li><li>构建集群</li><li>副本与分片</li><li>集群状态与故障转移</li><li>文档分布式存储</li><li>脑裂问题</li><li>shard详解</li></ul><h3 id="分布式介绍及cerebro"><a href="#分布式介绍及cerebro" class="headerlink" title="分布式介绍及cerebro"></a>分布式介绍及cerebro</h3><p>ES支持集群模式，是一个分布式系统，其好处主要有两个：</p><ul><li>增大系统容量，如内存、磁盘，使得ES集群可以支持PB级的数据</li><li>提高系统可用性，即使部分节点停止服务，整个集群依然可以正常服务</li></ul><p>ES集群由多个ES实例组成</p><ul><li>不同集群通过集群名称来区分，可通过cluster.name进行修改，名称默认为elasticsearch</li><li>每个ES实例本质上是一个JVM进程，且有自己的名字，通过node.name进行修改</li></ul><h4 id="cerebro"><a href="#cerebro" class="headerlink" title="cerebro"></a>cerebro</h4><p>cerebro 是一个ES Web管理工具，项目地址 <a href="https://github.com/lmenezes/cerebro" target="_blank" rel="noopener">https://github.com/lmenezes/cerebro</a> </p><p>其配置文件为 conf/application.conf，启动 cerebro ，默认监听的地址为 0.0.0.0:9000</p><pre><code>bin/cerebro# 也可指定监听ip和端口号bin/cerebro -Dhttp.port=1234 -Dhttp.address=127.0.0.1</code></pre><p>访问 <a href="http://yourhost:9000" target="_blank" rel="noopener">http://yourhost:9000</a> ，填写要监控的 ES 地址：<a href="http://eshost:9200" target="_blank" rel="noopener">http://eshost:9200</a> 即可进入管理界面</p><p><img src="http://image.laijianfeng.org/20180825_150701.png" alt="cerebro管理界面"></p><p><img src="http://image.laijianfeng.org/20180825_151133.png" alt="cerebro 节点信息"></p><p><img src="http://image.laijianfeng.org/20180825_151323.png" alt="cerebro 集群配置"></p><p>在cerebro管理界面中我们可以看到 ES节点、索引、shard的分布、集群参数配置等多种信息</p><h3 id="构建集群"><a href="#构建集群" class="headerlink" title="构建集群"></a>构建集群</h3><p>如果只有一台机器，可以执行下面的命令，每次指定相同的集群名称，不同的节点名称和端口，即可在同一台机器上启动多个ES节点</p><pre><code>bin/elasticsearch -Ecluster.name=my_cluster -Enode.name=node1 -Ehttp.port=9200 -d</code></pre><p>作者的是在 virtualbox 上安装Ubuntu虚拟机，在安装好开发环境，正常启动ES之后，采取复制虚拟机的做法，复制后需要修改虚拟机的UUID，做法可自行上网搜索。</p><p>作者复制了两个，准备构建一个拥有三个ES节点的集群。启动虚拟机后可以进行关闭防火墙，配置hosts以使相互之间能够通过主机名访问，配置ssh免密访问等操作</p><p>分别修改ES节点中的 <code>cluster.name</code> 为相同名称，<code>node.name</code> 为各自的主机名，<code>network.host</code> 为 <code>0.0.0.0</code>，<code>discovery.zen.ping.unicast.hosts</code> 列表中中加入各自的 <code>node.name</code></p><p>在ES主目录下执行命令启动ES</p><pre><code>bin/elasticsearch</code></pre><p>查看日志可见集群搭建完毕</p><h4 id="Cluster-State-集群状态"><a href="#Cluster-State-集群状态" class="headerlink" title="Cluster State 集群状态"></a>Cluster State 集群状态</h4><p>与ES集群相关的数据称为cluster state，主要记录如下信息：</p><ul><li>节点信息，比如节点名称、连接地址等</li><li>索引信息，比如索引名称，配置等</li><li>其他。。</li></ul><h4 id="Master-Node-主节点"><a href="#Master-Node-主节点" class="headerlink" title="Master Node 主节点"></a>Master Node 主节点</h4><ul><li>可以修改cluster state的节点成为master节点，一个集群<strong>只能有一个</strong></li><li>cluster state存储在每个节点上，master维护最新版本并<strong>同步</strong>给其他节点</li><li>master节点是通过集群中所有节点<strong>选举产生</strong>的，可以<strong>被选举</strong>的节点成为master-eligible（候选）节点，相关配置如下：<code>node.master: true</code></li></ul><h4 id="Coordinating-Node"><a href="#Coordinating-Node" class="headerlink" title="Coordinating Node"></a>Coordinating Node</h4><ul><li><strong>处理请求</strong>的节点即为coordinating节点，该节点为所有节点的默认角色，不能取消</li><li>路由请求到正确的节点处理，比如创建索引的请求到master节点</li></ul><h4 id="Data-Node-数据节点"><a href="#Data-Node-数据节点" class="headerlink" title="Data Node 数据节点"></a>Data Node 数据节点</h4><ul><li><strong>存储数据</strong>的节点即为Data节点，默认节点都是data类型，相关配置如下：<code>node.data: true</code></li></ul><h3 id="副本与分片"><a href="#副本与分片" class="headerlink" title="副本与分片"></a>副本与分片</h3><h4 id="提高系统可用性"><a href="#提高系统可用性" class="headerlink" title="提高系统可用性"></a>提高系统可用性</h4><p>提高系统可用性可从两个方面考虑：服务可用性和数据可用性</p><p>服务可用性：</p><ul><li>2个节点的情况下，允许其中1个节点停止服务</li></ul><p>数据可用性</p><ul><li>引入副本（Replication）解决</li><li>每个节点上都有完备的数据</li></ul><h4 id="增大系统容量"><a href="#增大系统容量" class="headerlink" title="增大系统容量"></a>增大系统容量</h4><p>如何将数据分布于所有节点上？</p><ul><li>引入分片（shard）解决问题</li></ul><p>分片是ES支持PB级数据的基石</p><ul><li>分片存储了部分数据，可以分布于任意节点上</li><li>分片数在索引创建时指定且后续不允许再修改，默认为5个</li><li>分片有主分片和副本分片之分，以实现数据的高可用</li><li>副本分片的数据由主分片同步，可以有多个，从而提高读取的吞吐量</li></ul><h4 id="分片的分布"><a href="#分片的分布" class="headerlink" title="分片的分布"></a>分片的分布</h4><p>下图演示的是 3 个节点的集群中test_index的分片分布情况，创建时我们指定了3个分片和副本</p><pre><code>PUT test_index{  &quot;settings&quot;: {    &quot;number_of_replicas&quot;: 1,    &quot;number_of_shards&quot;: 3  }}</code></pre><p><img src="http://image.laijianfeng.org/20180825_164121.png" alt="主副分片的分布"></p><p>大致是均匀分布，实验中如果由于磁盘空间不足导致有分片未分配，为了测试可以将集群设置 <code>cluster.routing.allocation.disk.threshold_enabled</code> 设置为 false</p><ul><li><strong>此时增加节点是否能提高索引的数据容量？</strong></li></ul><p>不能，因为已经设置了分片数为 3 ，shard的数量已经确定，新增的节点无法利用，</p><ul><li><strong>此时增加副本数能否提高索引的读取吞吐量？</strong></li></ul><p>不能，因为新增的副本分片也是分布在这 3 台节点上，利用了同样的资源（CPU，内存，IO等）。如果要增加吞吐量，同时还需要增加节点的数量</p><ul><li><strong>分片数的设定很重要，需要提前规划好</strong><ul><li>过小会导致后续无法通过增加节点实现水平扩容</li><li>过大会导致一个节点上分布过多分片，造成资源浪费，同时会影响查询性能</li><li>shard的数量的确定：一般建议一个shard的数据量不要超过 <code>30G</code>，shard数量最小为 2</li></ul></li></ul><h3 id="Cluster-Health-集群健康"><a href="#Cluster-Health-集群健康" class="headerlink" title="Cluster Health 集群健康"></a>Cluster Health 集群健康</h3><p>通过如下API可以查看集群健康状况，状态status包括以下三种：</p><ul><li>green 健康状态，指所有主副分片都正常分配</li><li>yellow 指所有主分片都正常分配，但有副本分片未正常分配</li><li>red 有主分片未分配</li></ul><pre><code>GET _cluster/health# 结果{  &quot;cluster_name&quot;: &quot;elasticsearch&quot;,  &quot;status&quot;: &quot;yellow&quot;,  &quot;timed_out&quot;: false,  &quot;number_of_nodes&quot;: 1,  &quot;number_of_data_nodes&quot;: 1,  &quot;active_primary_shards&quot;: 115,  &quot;active_shards&quot;: 115,  &quot;relocating_shards&quot;: 0,  &quot;initializing_shards&quot;: 0,  &quot;unassigned_shards&quot;: 111,  &quot;delayed_unassigned_shards&quot;: 0,  &quot;number_of_pending_tasks&quot;: 0,  &quot;number_of_in_flight_fetch&quot;: 0,  &quot;task_max_waiting_in_queue_millis&quot;: 0,  &quot;active_shards_percent_as_number&quot;: 50.88495575221239}</code></pre><h4 id="Failover-故障转移"><a href="#Failover-故障转移" class="headerlink" title="Failover 故障转移"></a>Failover 故障转移</h4><p>集群由 3 个节点组成，名称分别为 master，Hadoop2，Hadoop3， 其中 master 为主节点，集群状态status为 green</p><p><img src="http://image.laijianfeng.org/20180825_174406.png" alt="集群状态green"></p><p><strong>如果此时 master 所在机器宕机导致服务终止，此时集群如何处理？</strong></p><p>Hadoop2 和 Hadoop3 发现 master 无法响应一段时间后会发起 master 主节点选举，比如这里选择 Hadoop2 为 master 节点。由于此时主分片 P0 和 P2 下线，集群状态变为 Red</p><p><img src="http://image.laijianfeng.org/20180825_174933.png" alt="节点master宕机"></p><p>node2 发现主分片 P0 和 P2 未分配，将 R0 和 R2 提升为主分片，此时由于所有主分片都正常分配，集群状态变为 yellow</p><p><img src="http://image.laijianfeng.org/20180825_175028.png" alt="image"></p><p>Hadoop2 为 P0 和 P2 生成新的副本，集群状态变为绿色</p><p><img src="http://image.laijianfeng.org/20180825_175235.png" alt="image"></p><p>最后看看 Hadoop2 打印的日志</p><p><img src="http://image.laijianfeng.org/20180825_175517.png" alt="image"></p><h3 id="文档分布式存储"><a href="#文档分布式存储" class="headerlink" title="文档分布式存储"></a>文档分布式存储</h3><p>文档最终会存储在分片上。文档选择分片需要文档到分片的<strong>映射算法</strong>，目的是使得文档均匀分布在所有分片上，以充分利用资源。</p><p>算法：</p><ul><li>随机选择或者round-robin算法？不可取，因为需要维护文档到分片的映射关系，成本巨大</li><li><strong>根据文档值实时计算对应的分片</strong></li></ul><h4 id="文档到分片的映射算法"><a href="#文档到分片的映射算法" class="headerlink" title="文档到分片的映射算法"></a>文档到分片的映射算法</h4><p>ES通过如下的公式计算文档对应的分片</p><ul><li><code>shard = hash(routing) % number_of_primary_shards</code></li><li>hash算法保证可以将数据均匀地分散在分片中</li><li>routing是一个关键参数，默认是文档id，也可以自行指定</li><li>number_of_primary_shards是主分片数</li></ul><p>该算法与主分片数相关，这也是分片数一旦确定后便不能更改的原因</p><h4 id="文档创建流程"><a href="#文档创建流程" class="headerlink" title="文档创建流程"></a>文档创建流程</h4><ol><li>Client向node3发起创建文档的请求</li><li>node3通过routing计算该文档应该存储在shard1上，查询cluster state后确认主分片P1在node2上，然后转发创建文档的请求到node2</li><li>P1 接收并执行创建文档请求后，将同样的请求发送到副本分片R1</li><li>R1接收并执行创建文档请求后，通知P1成功的结果</li><li>P1接收副本分片结果后，通知node3创建成功</li><li>node3返回结果到Client</li></ol><p><img src="http://image.laijianfeng.org/20180825_181026.png" alt="文档创建流程"></p><h4 id="文档读取流程"><a href="#文档读取流程" class="headerlink" title="文档读取流程"></a>文档读取流程</h4><ol><li>Client向node3发起获取文档1的请求</li><li>node3通过routing计算该文档在shard1上，查询cluster state后获取shard1的主副分片列表，然后以轮询的机制获取一个shard，比如这里是R1，然后转发读取文档的请求到node1</li><li>R1接收并执行读取文档请求后，将结果返回node3</li><li>node3返回结果给client</li></ol><p><img src="http://image.laijianfeng.org/20180825_181511.png" alt="文档读取流程"></p><h4 id="文档批量创建的流程"><a href="#文档批量创建的流程" class="headerlink" title="文档批量创建的流程"></a>文档批量创建的流程</h4><ol><li>client向node3发起批量创建文档的请求（bulk）</li><li>node3通过routing计算所有文档对应的shard，然后按照主shard分配对应执行的操作，同时发送请求到涉及的主shard，比如这里3个主shard都需要参与</li><li>主shard接收并执行请求后，将同样的请求同步到对应的副本shard</li><li>副本shard执行结果后返回到主shard，主shard再返回node3</li><li>node3整合结果后返回client</li></ol><p><img src="http://image.laijianfeng.org/20180825_181725.png" alt="文档批量创建的流程 bulk"></p><h4 id="文档批量读取的流程"><a href="#文档批量读取的流程" class="headerlink" title="文档批量读取的流程"></a>文档批量读取的流程</h4><ol><li>client向node3发起批量获取所有文档的请求（mget）</li><li>node3通过routing计算所有文档对应的shard，然后通过轮询的机制获取要参与shard，按照shard投建mget请求，通过发送请求到涉及shard，比如这里有2个shard需要参与</li><li>R1，R2返回文档结果</li><li>node3返回结果给client</li></ol><p><img src="http://image.laijianfeng.org/20180825_182023.png" alt="文档批量读取的流程 mget"></p><h3 id="脑裂问题"><a href="#脑裂问题" class="headerlink" title="脑裂问题"></a>脑裂问题</h3><p>脑裂问题，英文为split-brain，是分布式系统中的经典网络问题，如下图所示：</p><p>3个节点组成的集群，突然node1的网络和其他两个节点中断<br><img src="http://image.laijianfeng.org/20180807_1234.png" alt="image"></p><p>node2与node3会重新选举master，比如node2成为了新的master，此时会更新cluster state</p><p>node1自己组成集群后，也更新cluster state</p><p>同一个集群有两个master，而且维护不同的cluster state，网络恢复后无法选择正确的master</p><p><img src="http://image.laijianfeng.org/20180807_1235.png" alt="image"></p><p><strong>解决方案</strong>为仅在可选举master-eligible节点数大于等于quorum时才可以进行master选举</p><ul><li><code>quorum = master-eligible节点数/2 + 1</code>，例如3个master-eligible节点时，quorum 为2 </li><li>设定 <code>discovery.zen.minimun_master_nodes</code> 为 <code>quorum</code> 即可避免脑裂问题</li></ul><p><img src="http://image.laijianfeng.org/20180807_1236.png" alt="image"></p><h3 id="倒排索引的不可变更"><a href="#倒排索引的不可变更" class="headerlink" title="倒排索引的不可变更"></a>倒排索引的不可变更</h3><p>倒排索引一旦生成，不能更改<br>其好处如下：</p><ul><li>不用考虑并发写文件的问题，杜绝了锁机制带来的性能问题</li><li>由于文件不再更改，可以充分利用文件系统缓存，只需载入一次，只要内存足够，对该文件的读取都会从内存读取，性能高</li><li>利于生成缓存数据</li><li>利于对文件进行压缩存储，节省磁盘和内存存储空间</li></ul><p>坏处为需要写入新文档时，必须重新构建倒排索引文件，然后替换老文件后，新文档才能被检索，导致文档实时性差</p><h3 id="文档搜索实时性"><a href="#文档搜索实时性" class="headerlink" title="文档搜索实时性"></a>文档搜索实时性</h3><p><strong>解决方案</strong>是新文档直接生成新的倒排索引文件，查询的时候同时查询所有的倒排文件，然后做结果的汇总计算即可</p><p>Lucene便是采用了这种方案，它构建的单个倒排索引称为segment，合在一起称为index，与ES中的Index概念不同，ES中的一个shard对应一个Lucene Index</p><p>Lucene会有一个专门的文件来记录所有的segment信息，称为commit point<br><img src="http://image.laijianfeng.org/20180807_1237.png" alt="image"></p><h4 id="refresh"><a href="#refresh" class="headerlink" title="refresh"></a>refresh</h4><p>segment写入磁盘的过程依然很耗时，可以借助文件系统缓存的特性，现将segment在缓存中创建并开放查询来进一步提升实时性，该过程在ES中被称为<code>refresh</code></p><p>在refresh之前文档会先存储在一个buffer中，refresh时将buffer中的所有文档清空并生成segment</p><p>ES默认每1秒执行一次refresh，因此文档的实时性被提高到1秒，这也是ES被称为 近实时(Near Real Time)的原因<br><img src="http://image.laijianfeng.org/20180807_1238.png" alt="image"></p><h4 id="translog"><a href="#translog" class="headerlink" title="translog"></a>translog</h4><p>如果在内存中的segment还没有写入磁盘前发生了宕机，那么其中的文档就无法恢复了，如何解决这个问题呢？</p><ul><li>ES引入translog机制，写入文档到buffer时，同时将该操作写入translog</li><li>translog文件会即时写入磁盘(fsync)，6.x默认每个请求都会落盘</li></ul><p><img src="http://image.laijianfeng.org/20180807_1345.png" alt="image"></p><h4 id="flush"><a href="#flush" class="headerlink" title="flush"></a>flush</h4><p>flush负责将内存中的segment写入磁盘，主要做成如下的工作：</p><ul><li>将translog写入磁盘</li><li>将index buffer清空，其中的文档生成一个新的segment，相当于一个refresh操作</li><li>更新commit point并写入磁盘</li><li>执行fsync操作，将内存中的segment写入磁盘</li><li>删除旧的translog文件</li></ul><p><img src="http://image.laijianfeng.org/20180807_1239.png" alt="image"></p><p>flush发生的时机主要有如下几种情况：</p><ul><li>间隔时间达到时，默认是30分钟，5.x之前可以通过<code>index.translog.flush_threshold_period</code>修改，之后无法修改</li><li>translog占满时，其大小可以通过<code>index.translog.flush_threshold_size</code>控制，默认是512mb，每个index有自己的translog</li></ul><h4 id="refresh-1"><a href="#refresh-1" class="headerlink" title="refresh"></a>refresh</h4><p>refresh发生的时机主要有如下几种情况：</p><ul><li>间隔时间达到时，通过<code>index.settings.refresh_interval</code>来设定，默认是1秒</li><li><code>index.buffer</code>占满时，其大小通过<code>indices.memory.index_buffer_size</code>设置，默认为JVM heap的10%，所有shard共享</li><li>flush发生时也会发生refresh</li></ul><h4 id="删除与更新文档"><a href="#删除与更新文档" class="headerlink" title="删除与更新文档"></a>删除与更新文档</h4><p>segment一旦生成就不能更改，那么如果你要删除文档该如何操作？</p><ul><li>Lucene专门维护一个<code>.del</code>文件，记录所有已经删除的文档，注意<code>.del</code>上记录的是文档在Lucene内部的id</li><li>在查询结果返回前会过滤掉<code>.del</code>中所有的文档</li></ul><p>要更新文档如何进行呢？</p><ul><li>首先删除文档，然后再创建新文档</li></ul><h4 id="整体视角"><a href="#整体视角" class="headerlink" title="整体视角"></a>整体视角</h4><p>ES Index与Lucene Index的术语对照如下所示：<br><img src="http://image.laijianfeng.org/20180807_1346.png" alt="image"></p><h4 id="Segment-Merging"><a href="#Segment-Merging" class="headerlink" title="Segment Merging"></a>Segment Merging</h4><p>随着segment的增多，由于一次查询的segment数增多，查询速度会变慢<br>ES会定时在后台进行segment merge的操作，减少segment的数量<br>通过force_merge api可以手动强制做segment merge的操作</p><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;本文的主要内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分布式介绍及cerebro&lt;/li&gt;
&lt;li&gt;构建集群&lt;/li&gt;
&lt;li&gt;副本与分片&lt;/li&gt;

      
    
    </summary>
    
      <category term="大数据" scheme="http://laijianfeng.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="elasticsearch" scheme="http://laijianfeng.org/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>23个最有用的ES检索技巧(Java API实现)</title>
    <link href="http://laijianfeng.org/2018/08/23%E4%B8%AA%E6%9C%80%E6%9C%89%E7%94%A8%E7%9A%84ES%E6%A3%80%E7%B4%A2%E6%8A%80%E5%B7%A7-Java-API%E5%AE%9E%E7%8E%B0/"/>
    <id>http://laijianfeng.org/2018/08/23个最有用的ES检索技巧-Java-API实现/</id>
    <published>2018-08-25T05:19:00.000Z</published>
    <updated>2018-08-25T05:21:32.553Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本文是对 <code>23个最有用的Elasticseaerch检索技巧</code> 一文提到的ES检索技巧进行 Java API 的简单实现，但仅限于简单实现，并不考虑包括参数校验，异常处理，日志处理，安全等问题，仅供参考</p><p>代码见 <a href="https://github.com/whirlys/elastic-example/tree/master/UsefullESSearchSkill" target="_blank" rel="noopener">UsefullESSearchSkill</a> ,<strong>原查询语句请对照原文</strong></p><h4 id="运行环境"><a href="#运行环境" class="headerlink" title="运行环境"></a>运行环境</h4><p>JDK version : 10.0.2<br>gradle version : 4.7<br>Elasticsearch version : 6.3.2<br>IDEA version : 2018.2</p><p>运行前请启动 ES 实例，并修改 <code>application.properties</code> 文件中的ES配置</p><h3 id="类介绍"><a href="#类介绍" class="headerlink" title="类介绍"></a>类介绍</h3><h4 id="实体类-Book"><a href="#实体类-Book" class="headerlink" title="实体类 Book"></a>实体类 Book</h4><p>注意：日期 publish_date 的类型设置为 String 是避免 Java 到 ES 之间复杂的转换工作，在ES中该字段仍然被识别为 date 类型</p><pre><code>public class Book {    public static SimpleDateFormat simpleDateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;);    private String id;    private String title;    private List&lt;String&gt; authors;    private String summary;    private String publish_date;    private Integer num_reviews;    private String publisher;    ...}</code></pre><h4 id="公共类-Constants"><a href="#公共类-Constants" class="headerlink" title="公共类 Constants"></a>公共类 Constants</h4><p>定义了一些常用的常量</p><pre><code>public class Constants {    // 字段名    public static String ID = &quot;id&quot;;    public static String TITLE = &quot;title&quot;;    public static String AUTHORS = &quot;authors&quot;;    public static String SUMMARY = &quot;summary&quot;;    public static String PUBLISHDATE = &quot;publish_date&quot;;    public static String PUBLISHER = &quot;publisher&quot;;    public static String NUM_REVIEWS = &quot;num_reviews&quot;;    public static String TITLE_KEYWORD = &quot;title.keyword&quot;;    public static String PUBLISHER_KEYWORD = &quot;publisher.keyword&quot;;    // 过滤要返回的字段    public static String[] fetchFieldsTSPD = {ID, TITLE, SUMMARY, PUBLISHDATE};    public static String[] fetchFieldsTA = {ID, TITLE, AUTHORS};    public static String[] fetchFieldsSA = {ID, SUMMARY, AUTHORS};    public static String[] fetchFieldsTSA = {ID, TITLE, SUMMARY, AUTHORS};    public static String[] fetchFieldsTPPD = {ID, TITLE, PUBLISHER, PUBLISHDATE};    public static String[] fetchFieldsTSPN = {ID, TITLE, SUMMARY, PUBLISHER, NUM_REVIEWS};    // 高亮    public static HighlightBuilder highlightS = new HighlightBuilder().field(SUMMARY);}</code></pre><h4 id="公共类-EsConfig"><a href="#公共类-EsConfig" class="headerlink" title="公共类 EsConfig"></a>公共类 EsConfig</h4><p>创建 ES 客户端实例，ES 客户端用于与 ES 集群进行交互</p><pre><code>@Configurationpublic class EsConfig {    @Value(&quot;${elasticsearch.cluster-nodes}&quot;)    private String clusterNodes;    @Value(&quot;${elasticsearch.cluster-name}&quot;)    private String clusterName;    @Bean    public Client client() {        Settings settings = Settings.builder().put(&quot;cluster.name&quot;, clusterName)                .put(&quot;client.transport.sniff&quot;, true).build();        TransportClient client = new PreBuiltTransportClient(settings);        try {            if (clusterNodes != null &amp;&amp; !&quot;&quot;.equals(clusterNodes)) {                for (String node : clusterNodes.split(&quot;,&quot;)) {                    String[] nodeInfo = node.split(&quot;:&quot;);                    client.addTransportAddress(new TransportAddress(InetAddress.getByName(nodeInfo[0]), Integer.parseInt(nodeInfo[1])));                }            }        } catch (UnknownHostException e) {        }        return client;    }}</code></pre><h4 id="数据获取工具类-DataUtil"><a href="#数据获取工具类-DataUtil" class="headerlink" title="数据获取工具类 DataUtil"></a>数据获取工具类 DataUtil</h4><p>这里的数据也就是 <code>23个最有用的ES检索技巧</code> 文中用于实验的4条数据</p><pre><code>public class DataUtil {    public static SimpleDateFormat dateFormater = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;);    /**     * 模拟获取数据     */    public static List&lt;Book&gt; batchData() {        List&lt;Book&gt; list = new LinkedList&lt;&gt;();        Book book1 = new Book(&quot;1&quot;, &quot;Elasticsearch: The Definitive Guide&quot;, Arrays.asList(&quot;clinton gormley&quot;, &quot;zachary tong&quot;),                &quot;A distibuted real-time search and analytics engine&quot;, &quot;2015-02-07&quot;, 20, &quot;oreilly&quot;);        Book book2 = new Book(&quot;2&quot;, &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;, Arrays.asList(&quot;grant ingersoll&quot;, &quot;thomas morton&quot;, &quot;drew farris&quot;),                &quot;organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization&quot;,                &quot;2013-01-24&quot;, 12, &quot;manning&quot;);        Book book3 = new Book(&quot;3&quot;, &quot;Elasticsearch in Action&quot;, Arrays.asList(&quot;radu gheorge&quot;, &quot;matthew lee hinman&quot;, &quot;roy russo&quot;),                &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;,                &quot;2015-12-03&quot;, 18, &quot;manning&quot;);        Book book4 = new Book(&quot;4&quot;, &quot;Solr in Action&quot;, Arrays.asList(&quot;trey grainger&quot;, &quot;timothy potter&quot;), &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,                &quot;2014-04-05&quot;, 23, &quot;manning&quot;);        list.add(book1);        list.add(book2);        list.add(book3);        list.add(book4);        return list;    }    public static Date parseDate(String dateStr) {        try {            return dateFormater.parse(dateStr);        } catch (ParseException e) {        }        return null;    }</code></pre><h4 id="公共查询工具类-CommonQueryUtils"><a href="#公共查询工具类-CommonQueryUtils" class="headerlink" title="公共查询工具类 CommonQueryUtils"></a>公共查询工具类 CommonQueryUtils</h4><p>对执行完ES查询请求后的数据进行解析</p><pre><code>public class CommonQueryUtils {    public static Gson gson = new GsonBuilder().setDateFormat(&quot;YYYY-MM-dd&quot;).create();    /**     * 处理ES返回的数据，封装     */    public static List&lt;Book&gt; parseResponse(SearchResponse searchResponse) {        List&lt;Book&gt; list = new LinkedList&lt;&gt;();        for (SearchHit hit : searchResponse.getHits().getHits()) {            // 用gson直接解析            Book book = gson.fromJson(hit.getSourceAsString(), Book.class);            list.add(book);        }        return list;    }    /**     * 解析完数据后，构建 Response 对象     */    public static Response&lt;List&lt;Book&gt;&gt; buildResponse(SearchResponse searchResponse) {        // 超时处理        if (searchResponse.isTimedOut()) {            return new Response&lt;&gt;(ResponseCode.ESTIMEOUT);        }        // 处理ES返回的数据        List&lt;Book&gt; list = parseResponse(searchResponse);        // 有shard执行失败        if (searchResponse.getFailedShards() &gt; 0) {            return new Response&lt;&gt;(ResponseCode.FAILEDSHARDS, list);        }        return new Response&lt;&gt;(ResponseCode.OK, list);    }    ...}</code></pre><h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><h4 id="BulkTests"><a href="#BulkTests" class="headerlink" title="BulkTests"></a>BulkTests</h4><p>创建索引，以及使用 bulk API 批量插入数据</p><pre><code>@RunWith(SpringRunner.class)@SpringBootTestpublic class BulkTests {    // 在Test中 Autowired需要引入包 org.elasticsearch.plugin:transport-netty4-client:6.3.2，否则异常找不到Transport类    @Autowired    private Client client;    @Value(&quot;${elasticsearch.bookIndex}&quot;)    private String bookIndex;    @Value(&quot;${elasticsearch.bookType}&quot;)    private String bookType;    private Gson gson = new GsonBuilder().setDateFormat(&quot;YYYY-MM-dd&quot;).create();    /**     * 创建索引，设置 settings，设置mappings     */    @Test    public void createIndex() {        int settingShards = 1;        int settingReplicas = 0;        // 判断索引是否存在，存在则删除        IndicesExistsResponse indicesExistsResponse = client.admin().indices().prepareExists(bookIndex).get();        if (indicesExistsResponse.isExists()) {            System.out.println(&quot;索引 &quot; + bookIndex + &quot; 存在！&quot;);            // 删除索引，防止报异常  ResourceAlreadyExistsException[index [bookdb_index/yL05ZfXFQ4GjgOEM5x8tFQ] already exists            DeleteIndexResponse deleteResponse = client.admin().indices().prepareDelete(bookIndex).get();            if (deleteResponse.isAcknowledged()){                System.out.println(&quot;索引&quot; + bookIndex + &quot;已删除&quot;);            }else {                System.out.println(&quot;索引&quot; + bookIndex + &quot;删除失败&quot;);            }        } else {            System.out.println(&quot;索引 &quot; + bookIndex + &quot; 不存在！&quot;);        }        // 设置Settings        CreateIndexResponse response = client.admin().indices().prepareCreate(bookIndex)                .setSettings(Settings.builder()                        .put(&quot;index.number_of_shards&quot;, settingShards)                        .put(&quot;index.number_of_replicas&quot;, settingReplicas))                .get();        // 查看结果        GetSettingsResponse getSettingsResponse = client.admin().indices()                .prepareGetSettings(bookIndex).get();        System.out.println(&quot;索引设置结果&quot;);        for (ObjectObjectCursor&lt;String, Settings&gt; cursor : getSettingsResponse.getIndexToSettings()) {            String index = cursor.key;            Settings settings = cursor.value;            Integer shards = settings.getAsInt(&quot;index.number_of_shards&quot;, null);            Integer replicas = settings.getAsInt(&quot;index.number_of_replicas&quot;, null);            System.out.println(&quot;index:&quot; + index + &quot;, shards:&quot; + shards + &quot;, replicas:&quot; + replicas);            Assert.assertEquals(java.util.Optional.of(settingShards), java.util.Optional.of(shards));            Assert.assertEquals(java.util.Optional.of(settingReplicas), java.util.Optional.of(replicas));        }    }    /**     * Bulk 批量插入数据     */    @Test    public void bulk() {        List&lt;Book&gt; list = DateUtil.batchData();        BulkRequestBuilder bulkRequestBuilder = client.prepareBulk();        // 添加index操作到 bulk 中        list.forEach(book -&gt; {            // 新版的API中使用setSource时，参数的个数必须是偶数，否则需要加上 setSource(json, XContentType.JSON)            bulkRequestBuilder.add(client.prepareIndex(bookIndex, bookType, book.getId()).setSource(gson.toJson(book), XContentType.JSON));        });        BulkResponse responses = bulkRequestBuilder.get();        if (responses.hasFailures()) {            // bulk有失败            for (BulkItemResponse res : responses) {                System.out.println(res.getFailure());            }            Assert.assertTrue(false);        }    }}</code></pre><h3 id="开始查询"><a href="#开始查询" class="headerlink" title="开始查询"></a>开始查询</h3><h4 id="控制类"><a href="#控制类" class="headerlink" title="控制类"></a>控制类</h4><p>查询接口</p><pre><code>@RestController@RequestMapping(&quot;basicmatch&quot;)public class BasicMatchQueryController {    @Autowired    private BasicMatchQueryService basicMatchQueryService;    /**     * 1.1 对 &quot;guide&quot; 执行全文检索     * 测试：http://localhost:8080/basicmatch/multimatch?query=guide     */    @RequestMapping(&quot;multimatch&quot;)    public Response&lt;List&lt;Book&gt;&gt; multiMatch(@RequestParam(value = &quot;query&quot;, required = true) String query) {        return basicMatchQueryService.multiBatch(query);    }    /**     * 1.2 指定特定字段检索     * 测试：http://localhost:8080/basicmatch/match?title=in action&amp;from=0&amp;size=4     */    @RequestMapping(&quot;match&quot;)    public ResponsePage&lt;List&lt;Book&gt;&gt; match(MatchForm form) {        return basicMatchQueryService.match(form);    }    /**     * 2 对 &quot;guide&quot; 执行多字段检索     * 测试：http://localhost:8080/basicmatch/multifield?query=guide     */    @RequestMapping(&quot;multifield&quot;)    public Response&lt;List&lt;Book&gt;&gt; multiField(@RequestParam(value = &quot;query&quot;, required = true) String query) {        return basicMatchQueryService.multiField(query);    }    /**     * 3、 Boosting提升某字段得分的检索( Boosting): 将“摘要”字段的得分提高了3倍     * 测试：http://localhost:8080/basicmatch/multifieldboost?query=elasticsearch guide     */    @RequestMapping(&quot;multifieldboost&quot;)    public Response&lt;List&lt;Book&gt;&gt; multiFieldboost(@RequestParam(value = &quot;query&quot;, required = true) String query) {        return basicMatchQueryService.multiFieldboost(query);    }    /**     * 4、Bool检索( Bool Query)     * 测试：http://localhost:8080/basicmatch/bool?shouldTitles=Elasticsearch&amp;shouldTitles=Solr&amp;mustAuthors=clinton gormely&amp;mustNotAuthors=radu gheorge     */    @RequestMapping(&quot;bool&quot;)    public Response&lt;List&lt;Book&gt;&gt; bool(@ModelAttribute BoolForm form) {        return basicMatchQueryService.bool(form);    }    /**     * 5、 Fuzzy 模糊检索( Fuzzy Queries)     */    @RequestMapping(&quot;fuzzy&quot;)    public Response&lt;List&lt;Book&gt;&gt; fuzzy(String query) {        return basicMatchQueryService.fuzzy(query);    }    /**     * 6、 Wildcard Query 通配符检索     * 测试：http://localhost:8080/basicmatch/wildcard?pattern=t*     */    @RequestMapping(&quot;wildcard&quot;)    public Response&lt;List&lt;Book&gt;&gt; wildcard(String pattern) {        return basicMatchQueryService.wildcard(Constants.AUTHORS, pattern);    }    /**     * 7、正则表达式检索( Regexp Query)     * 测试：http://localhost:8080/basicmatch/regexp     */    @RequestMapping(&quot;regexp&quot;)    public Response&lt;List&lt;Book&gt;&gt; regexp(String regexp) {        // 由于Tomcat的原因，直接接收有特殊字符的 正则表达式 会异常，所以这里写死，不过多探究        // 若        regexp = &quot;t[a-z]*y&quot;;        return basicMatchQueryService.regexp(Constants.AUTHORS, regexp);    }    /**     * 8、匹配短语检索( Match Phrase Query)     * 测试：http://localhost:8080/basicmatch/phrase?query=search engine     */    @RequestMapping(&quot;phrase&quot;)    public Response&lt;List&lt;Book&gt;&gt; phrase(String query) {        return basicMatchQueryService.phrase(query);    }    /**     * 9、匹配词组前缀检索     * 测试：http://localhost:8080/basicmatch/phraseprefix?query=search en     */    @RequestMapping(&quot;phraseprefix&quot;)    public Response&lt;List&lt;Book&gt;&gt; phrasePrefix(String query) {        return basicMatchQueryService.phrasePrefix(query);    }    /**     * 10、字符串检索（ Query String）     * 测试：http://localhost:8080/basicmatch/querystring?query=(saerch~1 algorithm~1) AND (grant ingersoll)  OR (tom morton)     */    @RequestMapping(&quot;querystring&quot;)    public Response&lt;List&lt;Book&gt;&gt; queryString(String query) {        return basicMatchQueryService.queryString(query);    }    /**     * 11、简化的字符串检索 （Simple Query String）     * 测试：http://localhost:8080/basicmatch/simplequerystring?query=(saerch~1 algorithm~1) AND (grant ingersoll)  OR (tom morton)     */    @RequestMapping(&quot;simplequerystring&quot;)    public Response&lt;List&lt;Book&gt;&gt; simplequerystring(String query) {        // 这里写死，仅为测试        query = &quot;(saerch~1 algorithm~1) + (grant ingersoll)  | (tom morton)&quot;;        return basicMatchQueryService.simpleQueryString(query);    }    /**     * 12、Term=检索（指定字段检索）     * 测试：http://localhost:8080/basicmatch/term?query=manning     */    @RequestMapping(&quot;term&quot;)    public Response&lt;List&lt;Book&gt;&gt; term(String query) {        return basicMatchQueryService.term(query);    }    /**     * 13、Term排序检索-（Term Query - Sorted）     * 测试：http://localhost:8080/basicmatch/termsort?query=manning     */    @RequestMapping(&quot;termsort&quot;)    public Response&lt;List&lt;Book&gt;&gt; termsort(String query) {        return basicMatchQueryService.termsort(query);    }    /**     * 14、范围检索（Range query）     * 测试：http://localhost:8080/basicmatch/range?startDate=2015-01-01&amp;endDate=2015-12-31     */    @RequestMapping(&quot;range&quot;)    public Response&lt;List&lt;Book&gt;&gt; range(String startDate, String endDate) {        return basicMatchQueryService.range(startDate, endDate);    }    /**     * 15. 过滤检索     * 测试：http://localhost:8080/basicmatch/filter?query=elasticsearch&amp;gte=20     */    @RequestMapping(&quot;filter&quot;)    public Response&lt;List&lt;Book&gt;&gt; filter(String query, Integer gte, Integer lte) {        return basicMatchQueryService.filter(query, gte, lte);    }    /**     * 17、 Function 得分：Field值因子（ Function Score: Field Value Factor）     * 测试：http://localhost:8080/basicmatch/fieldvaluefactor?query=search engine     */    @RequestMapping(&quot;fieldvaluefactor&quot;)    public Response&lt;List&lt;Book&gt;&gt; fieldValueFactor(String query) {        return basicMatchQueryService.fieldValueFactor(query);    }    /**     * 18、 Function 得分：衰减函数( Function Score: Decay Functions )     * 测试：http://localhost:8080/basicmatch/decay?query=search engines&amp;origin=2014-06-15     */    @RequestMapping(&quot;decay&quot;)    public Response&lt;List&lt;Book&gt;&gt; decay(String query, @RequestParam(value = &quot;origin&quot;, defaultValue = &quot;2014-06-15&quot;) String origin) {        return basicMatchQueryService.decay(query, origin);    }    /**     * 19、Function得分：脚本得分（ Function Score: Script Scoring ）     * 测试：ES需要配置允许groovy脚本运行才可以     */    @RequestMapping(&quot;script&quot;)    public Response&lt;List&lt;Book&gt;&gt; script(String query, @RequestParam(value = &quot;threshold&quot;, defaultValue = &quot;2015-07-30&quot;) String threshold) {        return basicMatchQueryService.script(query, threshold);    }}</code></pre><h3 id="服务类"><a href="#服务类" class="headerlink" title="服务类"></a>服务类</h3><pre><code>@Servicepublic class BasicMatchQueryService {    @Autowired    private Client client;    @Value(&quot;${elasticsearch.bookIndex}&quot;)    private String bookIndex;    @Value(&quot;${elasticsearch.bookType}&quot;)    private String bookType;    /**     * 进行ES查询，执行请求前后打印出 查询语句 和 查询结果     */    private SearchResponse requestGet(String queryName, SearchRequestBuilder requestBuilder) {        System.out.println(queryName + &quot; 构建的查询：&quot; + requestBuilder.toString());        SearchResponse searchResponse = requestBuilder.get();        System.out.println(queryName + &quot; 搜索结果：&quot; + searchResponse.toString());        return searchResponse;    }    ...}</code></pre><h4 id="1-1-对-“guide”-执行全文检索-Multi-Match-Query"><a href="#1-1-对-“guide”-执行全文检索-Multi-Match-Query" class="headerlink" title="1.1 对 “guide” 执行全文检索 Multi Match Query"></a>1.1 对 “guide” 执行全文检索 Multi Match Query</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; multiBatch(String query) {        MultiMatchQueryBuilder queryBuilder = new MultiMatchQueryBuilder(query);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex)                .setTypes(bookType).setQuery(queryBuilder);        SearchResponse searchResponse = requestGet(&quot;multiBatch&quot;, requestBuilder);        return CommonQueryUtils.buildResponse(searchResponse);    }</code></pre><h4 id="1-2-在标题字段-title-中搜索带有-“in-action”-字样的图书"><a href="#1-2-在标题字段-title-中搜索带有-“in-action”-字样的图书" class="headerlink" title="1.2 在标题字段(title)中搜索带有 “in action” 字样的图书"></a>1.2 在标题字段(title)中搜索带有 “in action” 字样的图书</h4><pre><code>    public ResponsePage&lt;List&lt;Book&gt;&gt; match(MatchForm form) {        MatchQueryBuilder matchQueryBuilder = new MatchQueryBuilder(&quot;title&quot;, form.getTitle());        // 高亮        HighlightBuilder highlightBuilder = new HighlightBuilder().field(&quot;title&quot;).fragmentSize(200);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex)                .setTypes(bookType).setQuery(matchQueryBuilder)                .setFrom(form.getFrom()).setSize(form.getSize())                .highlighter(highlightBuilder)                // 设置 _source 要返回的字段                .setFetchSource(Constants.fetchFieldsTSPD, null);        ...    }</code></pre><h4 id="多字段检索-Multi-field-Search"><a href="#多字段检索-Multi-field-Search" class="headerlink" title="多字段检索 (Multi-field Search)"></a>多字段检索 (Multi-field Search)</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; multiField(String query) {        MultiMatchQueryBuilder queryBuilder = new MultiMatchQueryBuilder(query).field(&quot;title&quot;).field(&quot;summary&quot;);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex)                .setTypes(bookType).setQuery(queryBuilder);        ...    }</code></pre><h4 id="3、-Boosting提升某字段得分的检索-Boosting-将“摘要”字段的得分提高了3倍"><a href="#3、-Boosting提升某字段得分的检索-Boosting-将“摘要”字段的得分提高了3倍" class="headerlink" title="3、 Boosting提升某字段得分的检索( Boosting),将“摘要”字段的得分提高了3倍"></a>3、 Boosting提升某字段得分的检索( Boosting),将“摘要”字段的得分提高了3倍</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; multiFieldboost(String query) {        MultiMatchQueryBuilder queryBuilder = new MultiMatchQueryBuilder(query).field(&quot;title&quot;).field(&quot;summary&quot;, 3);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex)                .setTypes(bookType).setQuery(queryBuilder);        ...    }</code></pre><h4 id="4、Bool检索-Bool-Query"><a href="#4、Bool检索-Bool-Query" class="headerlink" title="4、Bool检索( Bool Query)"></a>4、Bool检索( Bool Query)</h4><pre><code>    /**     * 在标题中搜索一本名为 &quot;Elasticsearch&quot; 或 &quot;Solr&quot; 的书，     * AND由 &quot;clinton gormley&quot; 创作，但NOT由 &quot;radu gheorge&quot; 创作     */    public Response&lt;List&lt;Book&gt;&gt; bool(BoolForm form) {        BoolQueryBuilder boolQuery = new BoolQueryBuilder();        // 搜索标题 should        BoolQueryBuilder shouldTitleBool = new BoolQueryBuilder();        form.getShouldTitles().forEach(title -&gt; {            shouldTitleBool.should().add(new MatchQueryBuilder(&quot;title&quot;, title));        });        boolQuery.must().add(shouldTitleBool);        // match 作者        form.getMustAuthors().forEach(author -&gt; {            boolQuery.must().add(new MatchQueryBuilder(&quot;authors&quot;, author));        });        // not match 作者        form.getMustNotAuthors().forEach(author -&gt; {            boolQuery.mustNot().add(new MatchQueryBuilder(&quot;authors&quot;, author));        });        ...    }</code></pre><h4 id="5、-Fuzzy-模糊检索-Fuzzy-Queries"><a href="#5、-Fuzzy-模糊检索-Fuzzy-Queries" class="headerlink" title="5、 Fuzzy 模糊检索( Fuzzy Queries)"></a>5、 Fuzzy 模糊检索( Fuzzy Queries)</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; fuzzy(String query) {        MultiMatchQueryBuilder queryBuilder = new MultiMatchQueryBuilder(query)                .field(&quot;title&quot;).field(&quot;summary&quot;)                .fuzziness(Fuzziness.AUTO);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex)                .setTypes(bookType).setQuery(queryBuilder)                .setFetchSource(Constants.fetchFieldsTSPD, null)                .setSize(2);        ...    }</code></pre><h4 id="6、-Wildcard-Query-通配符检索"><a href="#6、-Wildcard-Query-通配符检索" class="headerlink" title="6、 Wildcard Query 通配符检索"></a>6、 Wildcard Query 通配符检索</h4><pre><code>    /**     * 要查找具有以 &quot;t&quot; 字母开头的作者的所有记录     */    public Response&lt;List&lt;Book&gt;&gt; wildcard(String fieldName, String pattern) {        WildcardQueryBuilder wildcardQueryBuilder = new WildcardQueryBuilder(fieldName, pattern);        HighlightBuilder highlightBuilder = new HighlightBuilder().field(Constants.AUTHORS, 200);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex)                .setTypes(bookType).setQuery(wildcardQueryBuilder)                .setFetchSource(Constants.fetchFieldsTA, null)                .highlighter(highlightBuilder);    }</code></pre><h4 id="7、正则表达式检索-Regexp-Query"><a href="#7、正则表达式检索-Regexp-Query" class="headerlink" title="7、正则表达式检索( Regexp Query)"></a>7、正则表达式检索( Regexp Query)</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; regexp(String fieldName, String regexp) {        RegexpQueryBuilder queryBuilder = new RegexpQueryBuilder(fieldName, regexp);        HighlightBuilder highlightBuilder = new HighlightBuilder().field(Constants.AUTHORS);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex)                .setQuery(queryBuilder).setTypes(bookType).highlighter(highlightBuilder)                .setFetchSource(Constants.fetchFieldsTA, null);    }</code></pre><h4 id="8、匹配短语检索-Match-Phrase-Query"><a href="#8、匹配短语检索-Match-Phrase-Query" class="headerlink" title="8、匹配短语检索( Match Phrase Query)"></a>8、匹配短语检索( Match Phrase Query)</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; phrase(String query) {        MultiMatchQueryBuilder queryBuilder = new MultiMatchQueryBuilder(query)                .field(Constants.TITLE).field(Constants.SUMMARY)                .type(MultiMatchQueryBuilder.Type.PHRASE).slop(3);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(queryBuilder)                .setFetchSource(Constants.fetchFieldsTSPD, null);    }</code></pre><h4 id="9、匹配词组前缀检索"><a href="#9、匹配词组前缀检索" class="headerlink" title="9、匹配词组前缀检索"></a>9、匹配词组前缀检索</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; phrasePrefix(String query) {        MatchPhrasePrefixQueryBuilder queryBuilder = new MatchPhrasePrefixQueryBuilder(Constants.SUMMARY, query)                .slop(3).maxExpansions(10);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(queryBuilder).setFetchSource(Constants.fetchFieldsTSPD, null);    }</code></pre><h4 id="10、字符串检索（-Query-String）"><a href="#10、字符串检索（-Query-String）" class="headerlink" title="10、字符串检索（ Query String）"></a>10、字符串检索（ Query String）</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; queryString(String query) {        QueryStringQueryBuilder queryBuilder = new QueryStringQueryBuilder(query);        queryBuilder.field(Constants.SUMMARY, 2).field(Constants.TITLE)                .field(Constants.AUTHORS).field(Constants.PUBLISHER);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(queryBuilder).setFetchSource(Constants.fetchFieldsTSA, null);    }</code></pre><h4 id="11、简化的字符串检索-（Simple-Query-String）"><a href="#11、简化的字符串检索-（Simple-Query-String）" class="headerlink" title="11、简化的字符串检索 （Simple Query String）"></a>11、简化的字符串检索 （Simple Query String）</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; simpleQueryString(String query) {        SimpleQueryStringBuilder queryBuilder = new SimpleQueryStringBuilder(query);        queryBuilder.field(Constants.SUMMARY, 2).field(Constants.TITLE)                .field(Constants.AUTHORS).field(Constants.PUBLISHER);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(queryBuilder).setFetchSource(Constants.fetchFieldsTSA, null)                .highlighter(Constants.highlightS);    }</code></pre><h4 id="12、Term-Terms检索（指定字段检索）"><a href="#12、Term-Terms检索（指定字段检索）" class="headerlink" title="12、Term/Terms检索（指定字段检索）"></a>12、Term/Terms检索（指定字段检索）</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; term(String query) {        TermQueryBuilder termQueryBuilder = new TermQueryBuilder(Constants.PUBLISHER, query);        // terms 查询        /*String[] values = {&quot;manning&quot;, &quot;oreilly&quot;};        TermsQueryBuilder termsQueryBuilder = new TermsQueryBuilder(Constants.PUBLISHER, values);*/        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(termQueryBuilder)                .setFetchSource(Constants.fetchFieldsTPPD, null);    }</code></pre><h4 id="13、Term排序检索-（Term-Query-Sorted）"><a href="#13、Term排序检索-（Term-Query-Sorted）" class="headerlink" title="13、Term排序检索-（Term Query - Sorted）"></a>13、Term排序检索-（Term Query - Sorted）</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; termsort(String query) {        TermQueryBuilder termQueryBuilder = new TermQueryBuilder(Constants.PUBLISHER, query);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(termQueryBuilder)                .addSort(Constants.PUBLISHER_KEYWORD, SortOrder.DESC)                .addSort(Constants.TITLE_KEYWORD, SortOrder.ASC)                .setFetchSource(Constants.fetchFieldsTPPD, null);    }</code></pre><h4 id="14、范围检索（Range-query）"><a href="#14、范围检索（Range-query）" class="headerlink" title="14、范围检索（Range query）"></a>14、范围检索（Range query）</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; range(String startDate, String endDate) {        RangeQueryBuilder queryBuilder = new RangeQueryBuilder(Constants.PUBLISHDATE)                .gte(startDate).lte(endDate);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(queryBuilder)                .setFetchSource(Constants.fetchFieldsTPPD, null);    }</code></pre><h4 id="15-过滤检索"><a href="#15-过滤检索" class="headerlink" title="15. 过滤检索"></a>15. 过滤检索</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; filter(String query, Integer gte, Integer lte) {        BoolQueryBuilder queryBuilder = new BoolQueryBuilder();        queryBuilder.must().add(new MultiMatchQueryBuilder(query).field(Constants.TITLE).field(Constants.SUMMARY));        if (gte != null || lte != null) {            RangeQueryBuilder rangeQueryBuilder = new RangeQueryBuilder(Constants.NUM_REVIEWS);            if (gte != null) {                rangeQueryBuilder.gte(gte);            }            if (lte != null) {                rangeQueryBuilder.lte(lte);            }            queryBuilder.filter().add(rangeQueryBuilder);        }        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(queryBuilder).setFetchSource(Constants.fetchFieldsTSPN, null);    }</code></pre><h4 id="17、-Function-得分：Field值因子（-Function-Score-Field-Value-Factor）"><a href="#17、-Function-得分：Field值因子（-Function-Score-Field-Value-Factor）" class="headerlink" title="17、 Function 得分：Field值因子（ Function Score: Field Value Factor）"></a>17、 Function 得分：Field值因子（ Function Score: Field Value Factor）</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; fieldValueFactor(String query) {        // query        MultiMatchQueryBuilder multiMatchQueryBuilder = new MultiMatchQueryBuilder(query)                .field(Constants.TITLE).field(Constants.SUMMARY);        // fieldValueFactor        FieldValueFactorFunctionBuilder fieldValueFactor = ScoreFunctionBuilders.fieldValueFactorFunction(Constants.NUM_REVIEWS)                .factor(2).modifier(FieldValueFactorFunction.Modifier.LOG1P);        // functionscore        FunctionScoreQueryBuilder queryBuilder = QueryBuilders.functionScoreQuery(multiMatchQueryBuilder, fieldValueFactor);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(queryBuilder).setFetchSource(Constants.fetchFieldsTSPN, null);    }</code></pre><h4 id="18、-Function-得分：衰减函数-Function-Score-Decay-Functions"><a href="#18、-Function-得分：衰减函数-Function-Score-Decay-Functions" class="headerlink" title="18、 Function 得分：衰减函数( Function Score: Decay Functions )"></a>18、 Function 得分：衰减函数( Function Score: Decay Functions )</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; decay(String query, String origin) {        MultiMatchQueryBuilder multiMatchQueryBuilder = new MultiMatchQueryBuilder(query)                .field(Constants.TITLE).field(Constants.SUMMARY);        ExponentialDecayFunctionBuilder exp = ScoreFunctionBuilders.exponentialDecayFunction(Constants.PUBLISHDATE, origin, &quot;30d&quot;, &quot;7d&quot;);        FunctionScoreQueryBuilder queryBuilder = QueryBuilders.functionScoreQuery(multiMatchQueryBuilder, exp).boostMode(CombineFunction.REPLACE);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(queryBuilder).setFetchSource(Constants.fetchFieldsTSPN, null);    }</code></pre><h4 id="19、Function得分：脚本得分（-Function-Score-Script-Scoring-）"><a href="#19、Function得分：脚本得分（-Function-Score-Script-Scoring-）" class="headerlink" title="19、Function得分：脚本得分（ Function Score: Script Scoring ）"></a>19、Function得分：脚本得分（ Function Score: Script Scoring ）</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; script(String query, String threshold) {        MultiMatchQueryBuilder multiMatchQueryBuilder = new MultiMatchQueryBuilder(query)                .field(Constants.TITLE).field(Constants.SUMMARY);        // 参数        Map&lt;String, Object&gt; params = new HashMap&lt;&gt;();        params.put(&quot;threshold&quot;, threshold);        // 脚本        String scriptStr = &quot;publish_date = doc[&#39;publish_date&#39;].value; num_reviews = doc[&#39;num_reviews&#39;].value; if (publish_date &gt; Date.parse(&#39;yyyy-MM-dd&#39;, threshold).getTime()) { return log(2.5 + num_reviews) }; return log(1 + num_reviews);&quot;;        Script script = new Script(ScriptType.INLINE, &quot;painless&quot;, scriptStr, params);        ScriptScoreFunctionBuilder scriptScoreFunctionBuilder = ScoreFunctionBuilders.scriptFunction(script);        FunctionScoreQueryBuilder queryBuilder = QueryBuilders.functionScoreQuery(multiMatchQueryBuilder, scriptScoreFunctionBuilder);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(queryBuilder).setFetchSource(Constants.fetchFieldsTSPN, null);    }</code></pre><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;本文是对 &lt;code&gt;23个最有用的Elasticseaerch检索技巧&lt;/code&gt; 一文提到的ES检索技巧进行 Java API 的简单
      
    
    </summary>
    
      <category term="大数据" scheme="http://laijianfeng.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="elasticsearch" scheme="http://laijianfeng.org/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>教你编译调试Elasticsearch 6.3.2源码</title>
    <link href="http://laijianfeng.org/2018/08/%E6%95%99%E4%BD%A0%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95Elasticsearch-6-3-2%E6%BA%90%E7%A0%81/"/>
    <id>http://laijianfeng.org/2018/08/教你编译调试Elasticsearch-6-3-2源码/</id>
    <published>2018-08-23T03:39:34.000Z</published>
    <updated>2018-08-30T13:10:53.919Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>想深入理解 Elasticsearch，阅读它的源码是很有必要的，一来可以了解它内部的具体实现，有助于调优，二来可以了解优秀开源项目的代码架构，提高我们的代码架构能力等</p><p>阅读Elasticsearch源码的第一步是搭建调试环境，然后作者在这个过程中遇到很多麻烦，在网上找不到想要的答案，历经千辛最后一一解决，所以记录下，帮助有需要的童鞋</p><h4 id="软件环境"><a href="#软件环境" class="headerlink" title="软件环境"></a>软件环境</h4><ul><li>操作系统：win7</li><li>Elasticsearch 源码版本: 6.3.2</li><li>JDK版本： 10.0.2</li><li>Gradle版本： 4.7</li><li>Intellij Idea版本： 2018.2</li></ul><h3 id="环境准备及工程导入"><a href="#环境准备及工程导入" class="headerlink" title="环境准备及工程导入"></a>环境准备及工程导入</h3><h4 id="1-安装JDK"><a href="#1-安装JDK" class="headerlink" title="1.安装JDK"></a>1.安装JDK</h4><p>Elasticsearch 6.3.3需要JDK1.9编译，否则后面步骤会报错。</p><p>Java SE Downloads 地址：<br><a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="noopener">http://www.oracle.com/technetwork/java/javase/downloads/index.html</a></p><p>作者装的是 JDK 10.0.2</p><h4 id="2-下载Elasticsearch源码，并且切换到6-3-2分支"><a href="#2-下载Elasticsearch源码，并且切换到6-3-2分支" class="headerlink" title="2.下载Elasticsearch源码，并且切换到6.3.2分支"></a>2.下载Elasticsearch源码，并且切换到6.3.2分支</h4><p>Elasticsearch github源码托管地址：<br><a href="https://github.com/elastic/elasticsearch.git" target="_blank" rel="noopener">https://github.com/elastic/elasticsearch.git</a></p><pre><code>git checkout v6.3.2</code></pre><p>也可直接下载源码包，地址在 <a href="https://github.com/elastic/elasticsearch/releases" target="_blank" rel="noopener">https://github.com/elastic/elasticsearch/releases</a></p><h4 id="3-下载gradle的安装包"><a href="#3-下载gradle的安装包" class="headerlink" title="3.下载gradle的安装包"></a>3.下载gradle的安装包</h4><p>查看 <code>elasticsearch\gradle\wrapper\gradle-wrapper.properties</code> 发现如下配置：</p><pre><code>distributionUrl=https://services.gradle.org/distributions/gradle-4.5-all.zip</code></pre><p>Elasticsearch 6.3.2需要安装gradle-4.5，官方下载地址：<br><a href="https://services.gradle.org/distributions/gradle-4.5-all.zip" target="_blank" rel="noopener">https://services.gradle.org/distributions/gradle-4.5-all.zip</a></p><blockquote><p>注意：由于国内网速问题，为了加快速度，进行第4步操作</p></blockquote><h4 id="4-拷贝文件"><a href="#4-拷贝文件" class="headerlink" title="4.拷贝文件"></a>4.拷贝文件</h4><p>将下载的gradle-4.5-all.zip包放到 <code>elasticsearch\gradle\wrapper</code> 目录下，<br>确保和 <code>elasticsearch\gradle\wrapper\gradle-wrapper.properties</code> 在同级目录，<br>然后修改 <code>elasticsearch\gradle\wrapper\gradle-wrapper.properties</code> 配置如下：</p><pre><code>distributionUrl=gradle-4.5-all.zip</code></pre><h4 id="5-修改源码Maven仓库地址"><a href="#5-修改源码Maven仓库地址" class="headerlink" title="5.修改源码Maven仓库地址"></a>5.修改源码Maven仓库地址</h4><p>国内下载国外仓库的jar包速度慢，需要替换Maven地址，设置为本地或者国内可用的Maven仓库。</p><p>需要修改下列文件的 maven URL 配置：</p><ul><li>elasticsearch\benchmarks\build.gradle</li><li>elasticsearch\client\benchmark\build.gradle</li></ul><p>修改源码中上面build.gradle文件里面的<code>repositories-maven-url</code>的值，<br>配置为可用的仓库地址，譬如修改为阿里云maven地址 <code>http://maven.aliyun.com/nexus/content/groups/public/</code>，修改示例如下：</p><pre><code>buildscript {    repositories {        maven {            url &#39;http://maven.aliyun.com/nexus/content/groups/public/&#39;        }    }    dependencies {        classpath &#39;com.github.jengelman.gradle.plugins:shadow:2.0.2&#39;    }}</code></pre><h4 id="6-修改全局Maven仓库地址"><a href="#6-修改全局Maven仓库地址" class="headerlink" title="6.修改全局Maven仓库地址"></a>6.修改全局Maven仓库地址</h4><p>在<code>USER_HOME/.gradle/</code>下面创建新文件 <code>init.gradle</code>，输入下面的内容并保存。</p><pre><code>allprojects{    repositories {        def REPOSITORY_URL = &#39;http://maven.aliyun.com/nexus/content/groups/public/&#39;        all {            ArtifactRepository repo -&gt;    if (repo instanceof MavenArtifactRepository) {                def url = repo.url.toString()                if (url.startsWith(&#39;https://repo.maven.org/maven2&#39;) || url.startsWith(&#39;https://jcenter.bintray.com/&#39;)) {                    project.logger.lifecycle &quot;Repository ${repo.url} replaced by $REPOSITORY_URL.&quot;                    remove repo                }            }        }        maven {            url REPOSITORY_URL        }    }}</code></pre><p>其中<code>USER_HOME/.gradle/</code>是自己的gradle安装目录，示例值：<code>C:\Users\Administrator\.gradle</code>，<br>如果没有<code>.gradle</code>目录，可用自己创建，或者先执行第7步，等gradle安装后再回来修改。<br>上面脚本把url匹配到的仓库都替换成了阿里云的仓库，<br>如果有未匹配到的导致编译失败，可用自己仿照着添加匹配条件。</p><h4 id="7-gradle编译源码"><a href="#7-gradle编译源码" class="headerlink" title="7.gradle编译源码"></a>7.gradle编译源码</h4><p>windows运行cmd，进入DOS命令行，然后切换到elasticsearch源码的根目录，执行如下命令，把elasticsearch编译为 idea 工程：</p><pre><code>gradlew idea</code></pre><p>编译失败则按照错误信息解决问题，可用使用如下命令帮助定位问题：</p><pre><code>gradlew idea -infogradlew idea -debug</code></pre><p>一般是Maven仓库地址不可用导致jar包无法下载，从而编译失败，此时请参考步骤5和6修改相关的仓库地址。</p><p>编译成功后打印日志：</p><pre><code>BUILD SUCCESSFUL in 1m 23s</code></pre><h4 id="8-idea-导入elasticsearch工程"><a href="#8-idea-导入elasticsearch工程" class="headerlink" title="8. idea 导入elasticsearch工程"></a>8. idea 导入elasticsearch工程</h4><p>idea 中 <code>File -&gt; New Project From Existing Sources</code> 选择你下载的 Elasticsearch 根目录，然后点 <code>open</code> ，之后 <code>Import project from external model -&gt; Gradle</code> , 选中 <code>Use auto-import</code>, 然后就可以了</p><p>导入进去后，gradle 又会编译一遍，需要等一会，好了之后如下：</p><p><img src="http://image.laijianfeng.org/20180822_142155.png" alt="IDEA导入Elasticsearch6.3.2之后"></p><h3 id="运行，开始-solve-error-模式"><a href="#运行，开始-solve-error-模式" class="headerlink" title="运行，开始 solve error 模式"></a>运行，开始 solve error 模式</h3><blockquote><p>前面的步骤都挺顺利，接下来遇到的 ERROR &amp; EXCEPTION 让作者耗费了好几天，心力交瘁，好在最终运行成功   </p></blockquote><p>在 <code>elasticsearch/server/src/main/org/elasticsearch/bootstrap</code> 下找到Elasticsearch的启动类 <code>Elasticsearch.java</code>，打开文件，右键 <code>Run Elasticsearch.main()</code>，运行main方法</p><p><strong>1、 报错如下：</strong></p><pre><code>ERROR: the system property [es.path.conf] must be set</code></pre><p>这是需要配置 es.path.conf 参数，我们先在 elasticsearch 源码目录下新建一个 home 目录，然后在 <a href="https://www.elastic.co/downloads/elasticsearch" target="_blank" rel="noopener"><code>https://www.elastic.co/downloads/elasticsearch</code></a> 下载一个同版本号的 Elasticsearch6.3.2 发行版，解压，将 config 目录拷贝到 home 目录中</p><p>然后打开 <code>Edit Configurations</code>，在 <code>VM options</code> 加入如下配置：</p><p><img src="http://image.laijianfeng.org/20180822_144736.png" alt="Edit Configurations"></p><pre><code>-Des.path.conf=D:\elasticsearch-6.3.2\home\config</code></pre><p>再次运行 <code>Run Elasticsearch.main()</code></p><p><strong>2、报错如下：</strong></p><pre><code>Exception in thread &quot;main&quot; java.lang.IllegalStateException: path.home is not configured    at org.elasticsearch.env.Environment.&lt;init&gt;(Environment.java:103)...</code></pre><p>需要配置 <code>path.home</code> 这个参数，在 VM options 中添加如下配置：</p><pre><code>-Des.path.home=D:\elasticsearch-6.3.2</code></pre><p>再次RUN</p><p><strong>3、报错如下：</strong></p><pre><code>2018-08-22 15:07:17,094 main ERROR Could not register mbeans java.security.AccessControlException: access denied (&quot;javax.management.MBeanTrustPermission&quot; &quot;register&quot;)...Caused by: java.nio.file.NoSuchFileException: D:\elasticsearch-6.3.2\modules\aggs-matrix-stats\plugin-descriptor.properties...</code></pre><p>在 VM options 中把 path.home 的值修改为如下：</p><pre><code>-Des.path.home=D:\elasticsearch-6.3.2\home</code></pre><p>然后把 ES6.3.2 发行版中的 <code>modules</code> 文件夹复制到 <code>home</code> 目录下，然后再次RUN</p><p><strong>4、报错如下：</strong></p><pre><code>2018-08-22 15:12:29,876 main ERROR Could not register mbeans java.security.AccessControlException: access denied (&quot;javax.management.MBeanTrustPermission&quot; &quot;register&quot;)...</code></pre><p>在 <code>VM options</code> 中加入</p><pre><code>-Dlog4j2.disable.jmx=true</code></pre><p>1、2、3、4 的配置最终如下：</p><p><img src="http://image.laijianfeng.org/20180823_013945.png" alt="image"></p><p>再次RUN</p><p><strong>5、报错如下：</strong></p><pre><code>[2018-08-23T00:53:17,003][ERROR][o.e.b.ElasticsearchUncaughtExceptionHandler] [] fatal error in thread [main], exitingjava.lang.NoClassDefFoundError: org/elasticsearch/plugins/ExtendedPluginsClassLoader    at org.elasticsearch.plugins.PluginsService.loadBundle(PluginsService.java:632) ~[main/:?]    at org.elasticsearch.plugins.PluginsService.loadBundles(PluginsService.java:557) ~[main/:?]    at org.elasticsearch.plugins.PluginsService.&lt;init&gt;(PluginsService.java:162) ~[main/:?]    at org.elasticsearch.node.Node.&lt;init&gt;(Node.java:311) ~[main/:?]    at org.elasticsearch.node.Node.&lt;init&gt;(Node.java:252) ~[main/:?]    at org.elasticsearch.bootstrap.Bootstrap$5.&lt;init&gt;(Bootstrap.java:213) ~[main/:?]    at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:213) ~[main/:?]    at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:326) ~[main/:?]    at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:136) ~[main/:?]    at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:127) ~[main/:?]    at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86) ~[main/:?]    at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124) ~[main/:?]    at org.elasticsearch.cli.Command.main(Command.java:90) ~[main/:?]    at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:93) ~[main/:?]    at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:86) ~[main/:?]Caused by: java.lang.ClassNotFoundException: org.elasticsearch.plugins.ExtendedPluginsClassLoader    at jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:582) ~[?:?]    at jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:190) ~[?:?]    at java.lang.ClassLoader.loadClass(ClassLoader.java:499) ~[?:?]    ... 15 more</code></pre><p>这个问题其实不算真正的问题，但是说起来挺好笑，为了解决这个问题耗费了作者好几天，心力交瘁，当最后发现问题所在的时候，哭笑不得 ~_~  正是所谓的 <code>踏破铁鞋无觅处，得来全不费工夫</code> </p><p><strong>解决方法：</strong> 打开 IDEA <code>Edit Configurations</code> ，给 <code>Include dependencies with Provided scope</code> 打上勾即可解决，很简单吧！！</p><p><img src="http://image.laijianfeng.org/20180823_011036.png" alt="image"></p><p>继续RUN，又来一个 Exception</p><p><strong>6、报错如下：</strong></p><pre><code>[2018-08-23T01:13:38,551][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [] uncaught exception in thread [main]org.elasticsearch.bootstrap.StartupException: java.security.AccessControlException: access denied (&quot;java.lang.RuntimePermission&quot; &quot;createClassLoader&quot;)    at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:140) ~[main/:?]    at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:127) ~[main/:?]    at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86) ~[main/:?]    at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124) ~[main/:?]    at org.elasticsearch.cli.Command.main(Command.java:90) ~[main/:?]    at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:93) ~[main/:?]    at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:86) ~[main/:?]Caused by: java.security.AccessControlException: access denied (&quot;java.lang.RuntimePermission&quot; &quot;createClassLoader&quot;)    at java.security.AccessControlContext.checkPermission(AccessControlContext.java:472) ~[?:?]    at java.security.AccessController.checkPermission(AccessController.java:895) ~[?:?]    at java.lang.SecurityManager.checkPermission(SecurityManager.java:335) ~[?:?]    at java.lang.SecurityManager.checkCreateClassLoader(SecurityManager.java:397) ~[?:?]...Exception: java.security.AccessControlException thrown from the UncaughtExceptionHandler in thread &quot;Thread-2&quot;</code></pre><p>这个问题也找了挺久，最终才发现解决方法（两种）：</p><p><strong>第一种：</strong> 在 <code>home/config</code> 目录下新建 <code>java.policy</code> 文件，填入下面内容</p><pre><code>grant {    permission java.lang.RuntimePermission &quot;createClassLoader&quot;;};</code></pre><p>然后在 <code>VM options</code> 加入 <code>java.security.policy</code> 的设置，指向该文件即可</p><pre><code>-Djava.security.policy=D:\elasticsearch-6.3.2\home\config\java.policy</code></pre><p><strong>第二种：</strong> 就是在 <code>%JAVA_HOME%/conf/security</code> 目录下（JDK10是这个路径，之前的版本不确定），我的目录是 <code>C:\Program Files\Java\jdk-10.0.2\conf\security</code>，打开 <code>java.policy</code> 文件，在 <code>grant</code> 中加入下面这句，赋予权限</p><pre><code>permission java.lang.RuntimePermission &quot;createClassLoader&quot;;</code></pre><p>效果如下：</p><p><img src="http://image.laijianfeng.org/20180823_013422.png" alt="java.policy"><br><img src="http://image.laijianfeng.org/20180823_012205.png" alt="createClassLoader"></p><p>再RUN，这次可终于运行起来了！！！</p><p>来看一下效果，浏览器访问 <code>http://localhost:9200/</code></p><p><img src="http://image.laijianfeng.org/20180823_012641.png" alt="image1"></p><p>浏览器访问 <code>http://localhost:9200/_cat/health?v</code></p><p><img src="http://image.laijianfeng.org/20180823_012827.png" alt="image"></p><p>一切正常，终于可以愉快的 DEBUG 源码啦！！！</p><h3 id="另一种源码调试方式：远程调试"><a href="#另一种源码调试方式：远程调试" class="headerlink" title="另一种源码调试方式：远程调试"></a>另一种源码调试方式：远程调试</h3><p>如果上面第五个报错之后解决不了无法继续进行，可以选择这种方式:</p><p>在 Elasticsearch 源码目录下打开 CMD，输入下面的命令启动一个 debug 实例</p><pre><code>gradlew run --debug-jvm</code></pre><p>如果启动失败可能需要先执行 <code>gradlew clean</code> 再 <code>gradlew run --debug-jvm</code> 或者 先退出 IDEA</p><p><img src="http://image.laijianfeng.org/20180823_111933.png" alt="image"></p><p>在 IDEA 中打开 <code>Edit Configurations</code>，添加 remote</p><p><img src="http://image.laijianfeng.org/20180823_104521.png" alt="image"></p><p>配置 host 和 port</p><p><img src="http://image.laijianfeng.org/20180823_110657.png" alt="image"></p><p>点击 debug，浏览器访问 <code>http://localhost:9200/</code>，即可看到ES返回的信息</p><p>随机调试一下， 打开 <code>elasticsearch/server/src/main/org/elasticsearch/rest/action/cat</code> 下的 <code>RestHealthAction</code> 类，在第 54 行出设置一个断点，然后浏览器访问 <code>http://localhost:9200/_cat/health</code>，可以看到断点已经捕获到该请求了</p><p><img src="http://image.laijianfeng.org/20180823_113341.png" alt="image"></p><p>运行成功，可以开始设置断点进行其他调试</p><h3 id="其他可能遇到的问题"><a href="#其他可能遇到的问题" class="headerlink" title="其他可能遇到的问题"></a>其他可能遇到的问题</h3><p><strong>1. 错误信息如下</strong></p><pre><code>JAVA8_HOME required to run tasks gradle</code></pre><p>配置环境变量 <code>JAVA8_HOME</code>，值为 JDK8 的安装目录</p><p><strong>2. 错误信息如下</strong></p><pre><code>[2018-08-22T13:07:23,197][INFO ][o.e.t.TransportService   ] [EFQliuV] publish_address {10.100.99.118:9300}, bound_addresses {[::]:9300}[2018-08-22T13:07:23,211][INFO ][o.e.b.BootstrapChecks    ] [EFQliuV] bound or publishing to a non-loopback address, enforcing bootstrap checksERROR: [1] bootstrap checks failed[1]: initial heap size [268435456] not equal to maximum heap size [4273995776]; this can cause resize pauses and prevents mlockall from locking the entire heap[2018-08-22T13:07:23,219][INFO ][o.e.n.Node               ] [EFQliuV] stopping ...2018-08-22 13:07:23,269 Thread-2 ERROR No log4j2 configuration file found. Using default configuration: logging only errors to the console. Set system property &#39;log4j2.debug&#39; to show Log4j2 internal initialization logging.Disconnected from the target VM, address: &#39;127.0.0.1:5272&#39;, transport: &#39;socket&#39;</code></pre><p>在 <code>Edit Configurations</code> 的 <code>VM options</code> 加入下面配置</p><pre><code>-Xms2g -Xmx2g </code></pre><blockquote><p>参考文档：</p><ol><li><a href="https://www.jianshu.com/p/61dfe6fb6625" target="_blank" rel="noopener">Eclipse导入Elasticsearch源码</a></li><li><a href="https://www.felayman.com/articles/2017/11/10/1510291087246.html" target="_blank" rel="noopener">Elasticsearch源码分析—环境准备(一)</a></li><li><a href="http://www.54tianzhisheng.cn/2018/08/05/es-code01/" target="_blank" rel="noopener">渣渣菜鸡的 ElasticSearch 源码解析 —— 环境搭建</a></li><li><a href="http://www.54tianzhisheng.cn/2018/08/14/idea-remote-debug-elasticsearch" target="_blank" rel="noopener">教你如何在 IDEA 远程 Debug ElasticSearch</a></li></ol></blockquote><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;想深入理解 Elasticsearch，阅读它的源码是很有必要的，一来可以了解它内部的具体实现，有助于调优，二来可以了解优秀开源项目的代码架
      
    
    </summary>
    
      <category term="大数据" scheme="http://laijianfeng.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="elasticsearch" scheme="http://laijianfeng.org/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>20180818音乐会</title>
    <link href="http://laijianfeng.org/2018/08/20180818%E9%9F%B3%E4%B9%90%E4%BC%9A/"/>
    <id>http://laijianfeng.org/2018/08/20180818音乐会/</id>
    <published>2018-08-18T14:44:24.000Z</published>
    <updated>2018-08-18T15:02:13.767Z</updated>
    
    <content type="html"><![CDATA[<div style="text-align: center"><br><br><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=116837&auto=1&height=66"></iframe><br><br></div><p>感受幸福，感受快乐，感受…悲伤….</p><p><img src="http://image.laijianfeng.org/20180818224224.jpg" alt="丹麦钢琴家克里斯蒂娜·比约克独奏音乐会"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div style=&quot;text-align: center&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=&quot;330&quot; height=&quot;86&quot; src=&quot;//
      
    
    </summary>
    
      <category term="生活杂记" scheme="http://laijianfeng.org/categories/%E7%94%9F%E6%B4%BB%E6%9D%82%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>Lucene初体验</title>
    <link href="http://laijianfeng.org/2018/08/Lucene%E5%88%9D%E4%BD%93%E9%AA%8C/"/>
    <id>http://laijianfeng.org/2018/08/Lucene初体验/</id>
    <published>2018-08-18T08:23:02.000Z</published>
    <updated>2018-08-18T08:27:00.998Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本文的简要内容：</p><ol><li>Lucene简介</li><li>体验Lucene Demo</li><li>Lucene 核心类介绍</li><li>Lucene 索引文件格式</li></ol><h3 id="Lucene简介"><a href="#Lucene简介" class="headerlink" title="Lucene简介"></a>Lucene简介</h3><p>Lucene是目前最流行的Java开源搜索引擎类库,最新版本为7.4.0。Lucene通常用于全文检索,Lucene具有简单高效跨平台等特点,因此有不少搜索引擎都是基于Lucene构建的,例如:Elasticsearch,Solr等等。</p><p>现代搜索引擎的两大核心就是索引和搜索，建立索引的过程就是对源数据进行处理，例如过滤掉一些特殊字符或词语，单词大小写转换，分词，建立倒排索引等支持后续高效准确的搜索。而搜索则是直接提供给用户的功能，尽管面向的用户不同，诸如百度，谷歌等互联网公司以及各种企业都提供了各自的搜索引擎。搜索过程需要对搜索关键词进行分词等处理，然后再引擎内部构建查询，还要根据相关度对搜索结果进行排序，最终把命中结果展示给用户。</p><p>Lucene只是一个提供索引和查询的<strong>类库</strong>，并不是一个应用，程序员需要根据自己的应用场景进行如数据获取、数据预处理、用户界面提供等工作。</p><p>搜索程序的典型组件如下所示：</p><p><img src="http://image.laijianfeng.org/20180818_132723.jpg" alt="搜索程序的典型组件"></p><p>下图为Lucene与应用程序的关系:</p><p><img src="http://image.laijianfeng.org/fig001.jpg" alt="Lucene与应用程序的关系"></p><h3 id="体验Lucene-Demo"><a href="#体验Lucene-Demo" class="headerlink" title="体验Lucene Demo"></a>体验Lucene Demo</h3><p>接下来先来看一个简单的demo</p><blockquote><p>note:<br>代码在 <a href="https://github.com/whirlys/elastic-example/tree/master/startlucene/src/main/java/startlucene" target="_blank" rel="noopener">start Lucene</a></p></blockquote><h4 id="引入-Maven-依赖"><a href="#引入-Maven-依赖" class="headerlink" title="引入 Maven 依赖"></a>引入 Maven 依赖</h4><pre><code>    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;        &lt;lucene.version&gt;7.4.0&lt;/lucene.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;junit&lt;/groupId&gt;            &lt;artifactId&gt;junit&lt;/artifactId&gt;            &lt;version&gt;4.11&lt;/version&gt;            &lt;scope&gt;test&lt;/scope&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;            &lt;artifactId&gt;lucene-core&lt;/artifactId&gt;            &lt;version&gt;${lucene.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;            &lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt;            &lt;version&gt;${lucene.version}&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;</code></pre><h4 id="索引类-IndexFiles-java"><a href="#索引类-IndexFiles-java" class="headerlink" title="索引类 IndexFiles.java"></a>索引类 IndexFiles.java</h4><pre><code>import org.apache.lucene.analysis.*;import org.apache.lucene.analysis.standard.*;import org.apache.lucene.document.*;import org.apache.lucene.index.*;import org.apache.lucene.store.*;import java.io.*;import java.nio.charset.*;import java.nio.file.*;import java.nio.file.attribute.*;public class IndexFiles {    public static void main(String[] args) {        String indexPath = &quot;D:/lucene_test/index&quot;; // 建立索引文件的目录        String docsPath = &quot;D:/lucene_test/docs&quot;; // 读取文本文件的目录        Path docDir = Paths.get(docsPath);        IndexWriter writer = null;        try {            // 存储索引数据的目录            Directory dir = FSDirectory.open(Paths.get(indexPath));            // 创建分析器            Analyzer analyzer = new StandardAnalyzer();            IndexWriterConfig iwc = new IndexWriterConfig(analyzer);            iwc.setOpenMode(IndexWriterConfig.OpenMode.CREATE);            writer = new IndexWriter(dir, iwc);            indexDocs(writer, docDir);            writer.close();        } catch (IOException e) {            e.printStackTrace();        }    }    private static void indexDocs(final IndexWriter writer, Path path) throws IOException {        if (Files.isDirectory(path)) {            Files.walkFileTree(path, new SimpleFileVisitor&lt;Path&gt;() {                @Override                public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) {                    try {                        indexDoc(writer, file);                    } catch (IOException ignore) {                        // 不索引那些不能读取的文件,忽略该异常                    }                    return FileVisitResult.CONTINUE;                }            });        } else {            indexDoc(writer, path);        }    }    private static void indexDoc(IndexWriter writer, Path file) throws IOException {        try (InputStream stream = Files.newInputStream(file)) {            // 创建一个新的空文档            Document doc = new Document();            // 添加字段            Field pathField = new StringField(&quot;path&quot;, file.toString(), Field.Store.YES);            doc.add(pathField);            Field contentsField = new TextField(&quot;contents&quot;,                    new BufferedReader(new InputStreamReader(stream, StandardCharsets.UTF_8)));            doc.add(contentsField);            System.out.println(&quot;adding &quot; + file);            // 写文档            writer.addDocument(doc);        }    }}</code></pre><h4 id="查询类-SearchFiles-java"><a href="#查询类-SearchFiles-java" class="headerlink" title="查询类 SearchFiles.java"></a>查询类 SearchFiles.java</h4><pre><code>import org.apache.lucene.analysis.*;import org.apache.lucene.analysis.standard.*;import org.apache.lucene.document.*;import org.apache.lucene.index.*;import org.apache.lucene.queryparser.classic.*;import org.apache.lucene.search.*;import org.apache.lucene.store.*;import java.io.*;import java.nio.charset.*;import java.nio.file.*;public class SearchFiles {    public static void main(String[] args) throws Exception {        String indexPath = &quot;D:/lucene_test/index&quot;; // 建立索引文件的目录        String field = &quot;contents&quot;;        IndexReader reader = DirectoryReader.open(FSDirectory.open(Paths.get(indexPath)));        IndexSearcher searcher = new IndexSearcher(reader);        Analyzer analyzer = new StandardAnalyzer();        BufferedReader in = null;        in = new BufferedReader(new InputStreamReader(System.in, StandardCharsets.UTF_8));        QueryParser parser = new QueryParser(field, analyzer);        System.out.println(&quot;Enter query:&quot;);        // 从Console读取要查询的语句        String line = in.readLine();        if (line == null || line.length() == -1) {            return;        }        line = line.trim();        if (line.length() == 0) {            return;        }        Query query = parser.parse(line);        System.out.println(&quot;Searching for:&quot; + query.toString(field));        doPagingSearch(searcher, query);        in.close();        reader.close();    }    private static void doPagingSearch(IndexSearcher searcher, Query query) throws IOException {        // TopDocs保存搜索结果        TopDocs results = searcher.search(query, 10);        ScoreDoc[] hits = results.scoreDocs;        int numTotalHits = Math.toIntExact(results.totalHits);        System.out.println(numTotalHits + &quot; total matching documents&quot;);        for (ScoreDoc hit : hits) {            Document document = searcher.doc(hit.doc);            System.out.println(&quot;文档:&quot; + document.get(&quot;path&quot;));            System.out.println(&quot;相关度:&quot; + hit.score);            System.out.println(&quot;================================&quot;);        }    }}</code></pre><h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><p>首先创建文件夹 <code>D:\lucene_test</code>，在 <code>lucene_test</code> 下再创建 <code>docs</code> 文件夹，用来存储要索引的测试文件</p><p>在 <code>docs</code> 下创建3个文件 test1.txt, test2.txt, test3.txt，分别写入 hello world、 hello lucene、 hello elasticsearch</p><p>运行索引类 IndexFiles.java，可看到Console输出</p><pre><code>adding D:\lucene_test\docs\test1.txtadding D:\lucene_test\docs\test2.txtadding D:\lucene_test\docs\test3.txt</code></pre><p><img src="http://image.laijianfeng.org/20180818_135449.png" alt="Lucene的索引文件"></p><p>运行查询类 SearchFiles.java，搜索 hello ，三个文件相关度一样</p><pre><code>Enter query:helloSearching for:hello3 total matching documents文档:D:\lucene_test\docs\test1.txt相关度:0.13353139================================文档:D:\lucene_test\docs\test2.txt相关度:0.13353139================================文档:D:\lucene_test\docs\test3.txt相关度:0.13353139================================</code></pre><p>搜索 hello lucene，test2.txt的相关度比其他两个高</p><pre><code>Enter query:hello luceneSearching for:hello lucene3 total matching documents文档:D:\lucene_test\docs\test2.txt相关度:1.1143606================================文档:D:\lucene_test\docs\test1.txt相关度:0.13353139================================文档:D:\lucene_test\docs\test3.txt相关度:0.13353139================================</code></pre><h3 id="Lucene-核心类介绍"><a href="#Lucene-核心类介绍" class="headerlink" title="Lucene 核心类介绍"></a>Lucene 核心类介绍</h3><h4 id="核心索引类"><a href="#核心索引类" class="headerlink" title="核心索引类"></a>核心索引类</h4><p>IndexWriter</p><pre><code>进行索引写操作的一个中心组件不能进行读取和搜索</code></pre><p>Directory</p><pre><code>Directory代表Lucene索引的存放位置常用的实现：    FSDerectory:表示一个存储在文件系统中的索引的位置    RAMDirectory:表示一个存储在内存当中的索引的位置作用：    IndexWriter通过获取Directory的一个具体实现，在Directory指向的位置中操作索引</code></pre><p>Analyzer</p><pre><code>Analyzer，分析器，相当于筛子，对内容进行过滤，分词，转换等作用：把过滤之后的数据交给indexWriter进行索引</code></pre><p>Document</p><pre><code>用来存放文档（数据），该文档为非结构化数据中抓取的相关数据通过Field(域)组成Document，类似于mysql中的一个个字段组成的一条记录</code></pre><p>Field</p><pre><code>Document中的一个字段</code></pre><h4 id="核心搜索类"><a href="#核心搜索类" class="headerlink" title="核心搜索类"></a>核心搜索类</h4><p>IndexSearcher</p><pre><code>IndexSearcher在建立好的索引上进行搜索它只能以 只读 的方式打开一个索引，所以可以有多个IndexSearcher的实例在一个索引上进行操作</code></pre><p>Term</p><pre><code>Term是搜索的基本单元，一个Term由 key:value 组成（类似于mysql中的  字段名称=查询的内容）例子： Query query = new TermQuery(new Term(&quot;filename&quot;, &quot;lucene&quot;));</code></pre><p>Query</p><pre><code>Query是一个抽象类，用来将用户输入的查询字符串封装成Lucene能够识别的Query</code></pre><p>TermQuery</p><pre><code>Query子类，Lucene支持的最基本的一个查询类例子：TermQuery termQuery = new TermQuery(new Term(&quot;filename&quot;, &quot;lucene&quot;));</code></pre><p>BooleanQuery</p><pre><code>BooleanQUery，布尔查询,是一个组合Query（多个查询条件的组合）BooleanQuery是可以嵌套的栗子：BooleanQuery query = new BooleanQuery();BooleanQuery query2 = new BooleanQuery();TermQuery termQuery1 = new TermQuery(new Term(&quot;fileName&quot;, &quot;lucene&quot;));TermQuery termQuery2 = new TermQuery(new Term(&quot;fileName&quot;, &quot;name&quot;));query2.add(termQuery1, Occur.SHOULD);query.add(termQuery2, Occur.SHOULD);query.add(query2, Occur.SHOULD);;        //BooleanQuery是可以嵌套的Occur枚举：    MUST    SHOULD    FILTER    MUST_NOT</code></pre><p>NumericRangeQuery</p><pre><code>数字区间查询栗子：Query newLongRange = NumericRangeQuery.newLongRange(&quot;fileSize&quot;,0l, 100l, true, true);</code></pre><p>PrefixQuery</p><pre><code>前缀查询，查询分词中含有指定字符开头的内容栗子：PrefixQuery query = new PrefixQuery(new Term(&quot;fileName&quot;,&quot;hell&quot;));</code></pre><p>PhraseQuery</p><pre><code>短语查询栗子1：    PhraseQuery query = new PhraseQuery();    query.add(new Term(&quot;fileName&quot;,&quot;lucene&quot;));</code></pre><p>FuzzyQuery</p><pre><code>模糊查询栗子：FuzzyQuery query = new FuzzyQuery(new Term(&quot;fileName&quot;,&quot;lucene&quot;));</code></pre><p>WildcardQuery</p><pre><code>通配符查询：* ：任意字符（0或多个）? : 一个字符栗子：WildcardQuery query = new WildcardQuery(new Term(&quot;fileName&quot;,&quot;*&quot;));</code></pre><p>RegexQuery</p><pre><code>正则表达式查询栗子：搜索含有最少1个字符，最多6个字符的RegexQuery query = new RegexQuery(new Term(&quot;fileName&quot;,&quot;[a-z]{1,6}&quot;));</code></pre><p>MultiFieldQueryParser</p><pre><code>查询多个field栗子：String[] fields = {&quot;fileName&quot;,&quot;fileContent&quot;};MultiFieldQueryParser queryParser = new MultiFieldQueryParser(fields, new StandardAnalyzer());Query query = queryParser.parse(&quot;fileName:lucene AND filePath:a&quot;);</code></pre><p>TopDocs</p><pre><code>TopDocs类是一个简单的指针容器,指针一般指向前N个排名的搜索结果,搜索结果即匹配条件的文档TopDocs会记录前N个结果中每个结果的int docID和浮点数型分数(反映相关度)栗子：    TermQuery searchingBooks = new TermQuery(new Term(&quot;subject&quot;,&quot;search&quot;));     Directory dir = TestUtil.getBookIndexDirectory();    IndexSearcher searcher = new IndexSearcher(dir);    TopDocs matches = searcher.search(searchingBooks, 10);</code></pre><h3 id="Lucene-6-0-索引文件格式"><a href="#Lucene-6-0-索引文件格式" class="headerlink" title="Lucene 6.0 索引文件格式"></a>Lucene 6.0 索引文件格式</h3><h4 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h4><p>谈到倒排索引，那么首先看看正排是什么样子的呢？假设文档1包含【中文、英文、日文】，文档2包含【英文、日文、韩文】，文档3包含【韩文，中文】，那么根据文档去查找内容的话</p><pre><code>文档1-&gt;【中文、英文、日文】文档2-&gt;【英文、日文、韩文】文档3-&gt;【韩文，中文】</code></pre><p>反过来，根据内容去查找文档</p><pre><code>中文-&gt;【文档1、文档3】英文-&gt;【文档1、文档2】日文-&gt;【文档1、文档2】韩文-&gt;【文档2、文档3】</code></pre><p>这就是倒排索引，而Lucene擅长的也正在于此</p><h4 id="段（Segments）"><a href="#段（Segments）" class="headerlink" title="段（Segments）"></a>段（Segments）</h4><p>Lucene的索引可能是由多个子索引或Segments组成。每个Segment是一个完全独立的索引，可以单独用于搜索，索引涉及</p><ol><li>为新添加的documents创建新的segments</li><li>合并已经存在的segments</li></ol><p>搜索可能涉及多个segments或多个索引，每个索引可能由一组segments组成</p><h4 id="文档编号"><a href="#文档编号" class="headerlink" title="文档编号"></a>文档编号</h4><p>Lucene通过一个整型的文档编号指向每个文档，第一个被加入索引的文档编号为0，后续加入的文档编号依次递增。<br>注意文档编号是可能发生变化的，所以在Lucene外部存储这些值时需要格外小心。</p><h4 id="索引结构概述"><a href="#索引结构概述" class="headerlink" title="索引结构概述"></a>索引结构概述</h4><p>每个segment索引包括信息</p><ul><li>Segment info：包含有关segment的元数据，例如文档编号，使用的文件</li><li>Field names：包含索引中使用的字段名称集合</li><li>Stored Field values：对于每个document，它包含属性-值对的列表，其中属性是字段名称。这些用于存储有关文档的辅助信息，例如其标题、url或访问数据库的标识符</li><li>Term dictionary：包含所有文档的所有索引字段中使用的所有terms的字典。字典还包括包含term的文档编号，以及指向term的频率和接近度的指针</li><li>Term Frequency data：对于字典中的每个term，包含该term的所有文档的数量以及该term在该文档中的频率，除非省略频率（IndexOptions.DOCS）</li><li>Term Proximity data：对于字典中的每个term，term在每个文档中出现的位置。注意，如果所有文档中的所有字段都省略位置数据，则不会存在</li><li>Normalization factors：对于每个文档中的每个字段，存储一个值，该值将乘以该字段上的匹配的分数</li><li>Term Vectors：对于每个文档中的每个字段，可以存储term vector，term vector由term文本和term频率组成</li><li>Per-document values：与存储的值类似，这些也以文档编号作为key，但通常旨在被加载到主存储器中以用于快速访问。存储的值通常用于汇总来自搜索的结果，而每个文档值对于诸如评分因子是有用的</li><li>Live documents：一个可选文件，指示哪些文档是活动的</li><li>Point values：可选的文件对，记录索引字段尺寸，以实现快速数字范围过滤和大数值（例如BigInteger、BigDecimal（1D）、地理形状交集（2D，3D））</li></ul><h4 id="文件命名"><a href="#文件命名" class="headerlink" title="文件命名"></a>文件命名</h4><p>属于一个段的所有文件具有相同的名称和不同的扩展名。当使用复合索引文件，这些文件（除了段信息文件、锁文件和已删除的文档文件）将压缩成单个.cfs文件。当任何索引文件被保存到目录时，它被赋予一个从未被使用过的文件名字</p><p><img src="http://image.laijianfeng.org/20180818_161352.png" alt="复合索引文件"></p><h4 id="文件扩展名摘要"><a href="#文件扩展名摘要" class="headerlink" title="文件扩展名摘要"></a>文件扩展名摘要</h4><table><thead><tr><th>名称</th><th>文件扩展名</th><th>简短描述</th></tr></thead><tbody><tr><td>Segments File</td><td>segments_N</td><td>保存了一个提交点（a commit point）的信息</td></tr><tr><td>Lock File</td><td>write.lock</td><td>防止多个IndexWriter同时写到一份索引文件中</td></tr><tr><td>Segment Info</td><td>.si</td><td>保存了索引段的元数据信息</td></tr><tr><td>Compound File</td><td>.cfs，.cfe</td><td>一个可选的虚拟文件，把所有索引信息都存储到复合索引文件中</td></tr><tr><td>Fields</td><td>.fnm</td><td>保存fields的相关信息</td></tr><tr><td>Field Index</td><td>.fdx</td><td>保存指向field data的指针</td></tr><tr><td>Field Data</td><td>.fdt</td><td>文档存储的字段的值</td></tr><tr><td>Term Dictionary</td><td>.tim</td><td>term词典，存储term信息</td></tr><tr><td>Term Index</td><td>.tip</td><td>到Term Dictionary的索引</td></tr><tr><td>Frequencies</td><td>.doc</td><td>由包含每个term以及频率的docs列表组成</td></tr><tr><td>Positions</td><td>.pos</td><td>存储出现在索引中的term的位置信息</td></tr><tr><td>Payloads</td><td>.pay</td><td>存储额外的per-position元数据信息，例如字符偏移和用户payloads</td></tr><tr><td>Norms</td><td>.nvd，.nvm</td><td>.nvm文件保存索引字段加权因子的元数据，.nvd文件保存索引字段加权数据</td></tr><tr><td>Per-Document Values</td><td>.dvd，.dvm</td><td>.dvm文件保存索引文档评分因子的元数据，.dvd文件保存索引文档评分数据</td></tr><tr><td>Term Vector Index</td><td>.tvx</td><td>将偏移存储到文档数据文件中</td></tr><tr><td>Term Vector Documents</td><td>.tvd</td><td>包含有term vectors的每个文档信息</td></tr><tr><td>Term Vector Fields</td><td>.tvf</td><td>字段级别有关term vectors的信息</td></tr><tr><td>Live Documents</td><td>.liv</td><td>哪些是有效文件的信息</td></tr><tr><td>Point values</td><td>.dii，.dim</td><td>保留索引点，如果有的话</td></tr></tbody></table><h4 id="锁文件"><a href="#锁文件" class="headerlink" title="锁文件"></a>锁文件</h4><p>默认情况下，存储在索引目录中的锁文件名为 <code>write.lock</code>。如果锁目录与索引目录不同，则锁文件将命名为“XXXX-write.lock”，其中XXXX是从索引目录的完整路径导出的唯一前缀。此锁文件确保每次只有一个写入程序在修改索引。</p><blockquote><p>参考：</p><ol><li><a href="http://sndragon.com/2018/05/03/Lucene%E5%88%9D%E8%AF%86%E5%8F%8A%E6%A0%B8%E5%BF%83%E7%B1%BB%E4%BB%8B%E7%BB%8D/" target="_blank" rel="noopener">Lucene初识及核心类介绍</a></li><li><a href="http://qguofeng.oschina.io/2018/03/17/Lucene/2018-03-17-Lucene%E6%A0%B8%E5%BF%83%E7%B1%BB/" target="_blank" rel="noopener">Lucene核心类</a></li><li><a href="http://codepub.cn/2016/12/05/Lucene-6-0-index-file-format/" target="_blank" rel="noopener">Lucene 6.0 索引文件格式</a></li><li>Lucene实战.pdf</li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;本文的简要内容：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Lucene简介&lt;/li&gt;
&lt;li&gt;体验Lucene Demo&lt;/li&gt;
&lt;li&gt;Lucene 
      
    
    </summary>
    
      <category term="大数据" scheme="http://laijianfeng.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="lucene" scheme="http://laijianfeng.org/tags/lucene/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch 6.x Mapping设置</title>
    <link href="http://laijianfeng.org/2018/08/Elasticsearch-6-x-Mapping%E8%AE%BE%E7%BD%AE/"/>
    <id>http://laijianfeng.org/2018/08/Elasticsearch-6-x-Mapping设置/</id>
    <published>2018-08-16T13:14:33.000Z</published>
    <updated>2018-08-16T13:19:49.268Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Mapping"><a href="#Mapping" class="headerlink" title="Mapping"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html" target="_blank" rel="noopener">Mapping</a></h3><p>类似于数据库中的表结构定义，主要作用如下：</p><ul><li>定义Index下字段名（Field Name）</li><li>定义字段的类型，比如数值型，字符串型、布尔型等</li><li>定义倒排索引的相关配置，比如是否索引、记录postion等   </li></ul><p>需要注意的是，在索引中定义太多字段可能会导致索引膨胀，出现内存不足和难以恢复的情况，下面有几个设置：</p><ul><li>index.mapping.total_fields.limit：一个索引中能定义的字段的最大数量，默认是 1000</li><li>index.mapping.depth.limit：字段的最大深度，以内部对象的数量来计算，默认是20</li><li>index.mapping.nested_fields.limit：索引中嵌套字段的最大数量，默认是50</li></ul><h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html" target="_blank" rel="noopener">数据类型</a></h3><h4 id="核心数据类型"><a href="#核心数据类型" class="headerlink" title="核心数据类型"></a>核心数据类型</h4><ul><li>字符串 - text<ul><li>用于全文索引，该类型的字段将通过分词器进行分词，最终用于构建索引</li></ul></li><li>字符串 - keyword<ul><li>不分词，只能搜索该字段的完整的值，只用于 filtering </li></ul></li><li>数值型 <ul><li>long：有符号64-bit integer：-2^63 ~ 2^63 - 1 </li><li>integer：有符号32-bit integer，-2^31 ~ 2^31 - 1 </li><li>short：有符号16-bit integer，-32768 ~ 32767</li><li>byte： 有符号8-bit integer，-128 ~ 127</li><li>double：64-bit IEEE 754 浮点数</li><li>float：32-bit IEEE 754 浮点数</li><li>half_float：16-bit IEEE 754 浮点数</li><li>scaled_float</li></ul></li><li>布尔 - boolean<ul><li>值：false, “false”, true, “true”</li></ul></li><li>日期 - date<ul><li>由于Json没有date类型，所以es通过识别字符串是否符合format定义的格式来判断是否为date类型</li><li>format默认为：<code>strict_date_optional_time||epoch_millis</code> <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-date-format.html" target="_blank" rel="noopener">format</a></li></ul></li><li>二进制 - binary<ul><li>该类型的字段把值当做经过 base64 编码的字符串，默认不存储，且不可搜索</li></ul></li><li><p>范围类型</p><ul><li>范围类型表示值是一个范围，而不是一个具体的值</li><li>譬如 age 的类型是 integer_range，那么值可以是  {“gte” : 10, “lte” : 20}；搜索 “term” : {“age”: 15} 可以搜索该值；搜索 “range”: {“age”: {“gte”:11, “lte”: 15}} 也可以搜索到</li><li>range参数 relation 设置匹配模式<ul><li>INTERSECTS ：默认的匹配模式，只要搜索值与字段值有交集即可匹配到</li><li>WITHIN：字段值需要完全包含在搜索值之内，也就是字段值是搜索值的子集才能匹配</li><li>CONTAINS：与WITHIN相反，只搜索字段值包含搜索值的文档</li></ul></li><li>integer_range</li><li>float_range</li><li>long_range</li><li>double_range</li><li>date_range：64-bit 无符号整数，时间戳（单位：毫秒）</li><li><p>ip_range：IPV4 或 IPV6 格式的字符串</p><p>​</p></li></ul></li></ul><pre><code># 创建range索引PUT range_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;properties&quot;: {        &quot;expected_attendees&quot;: {          &quot;type&quot;: &quot;integer_range&quot;        },        &quot;time_frame&quot;: {          &quot;type&quot;: &quot;date_range&quot;,           &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;        }      }    }  }}# 插入一个文档PUT range_index/_doc/1{  &quot;expected_attendees&quot; : {     &quot;gte&quot; : 10,    &quot;lte&quot; : 20  },  &quot;time_frame&quot; : {     &quot;gte&quot; : &quot;2015-10-31 12:00:00&quot;,     &quot;lte&quot; : &quot;2015-11-05&quot;  }}# 12在 10~20的范围内，可以搜索到文档1GET range_index/_search{  &quot;query&quot; : {    &quot;term&quot; : {      &quot;expected_attendees&quot; : {        &quot;value&quot;: 12      }    }  }}# within可以搜索到文档# 可以修改日期，然后分别对比CONTAINS，WITHIN，INTERSECTS的区别GET range_index/_search{  &quot;query&quot; : {    &quot;range&quot; : {      &quot;time_frame&quot; : {         &quot;gte&quot; : &quot;2015-11-02&quot;,        &quot;lte&quot; : &quot;2015-11-03&quot;,        &quot;relation&quot; : &quot;within&quot;       }    }  }}</code></pre><h4 id="复杂数据类型"><a href="#复杂数据类型" class="headerlink" title="复杂数据类型"></a>复杂数据类型</h4><ul><li>数组类型 Array<ul><li>字符串数组 [ “one”, “two” ]</li><li>整数数组 [ 1, 2 ]</li><li>数组的数组  [ 1, [ 2, 3 ]]，相当于 [ 1, 2, 3 ]</li><li>Object对象数组 [ { “name”: “Mary”, “age”: 12 }, { “name”: “John”, “age”: 10 }]</li><li>同一个数组只能存同类型的数据，不能混存，譬如 [ 10, “some string” ] 是错误的</li><li>数组中的 null 值将被 null_value 属性设置的值代替或者被忽略</li><li>空数组 [] 被当做 missing field 处理</li></ul></li><li><p>对象类型 Object</p><ul><li>对象类型可能有内部对象</li><li><p>被索引的形式为：manager.name.first</p><p>​</p></li></ul></li></ul><pre><code># tags字符串数组，lists 对象数组PUT my_index/_doc/1{  &quot;message&quot;: &quot;some arrays in this document...&quot;,  &quot;tags&quot;:  [ &quot;elasticsearch&quot;, &quot;wow&quot; ],   &quot;lists&quot;: [     {      &quot;name&quot;: &quot;prog_list&quot;,      &quot;description&quot;: &quot;programming list&quot;    },    {      &quot;name&quot;: &quot;cool_list&quot;,      &quot;description&quot;: &quot;cool stuff list&quot;    }  ]}</code></pre><ul><li>嵌套类型 Nested<ul><li>nested 类型是一种对象类型的特殊版本，它允许索引对象数组，<strong>独立地索引每个对象</strong></li></ul></li></ul><h4 id="嵌套类型与Object类型的区别"><a href="#嵌套类型与Object类型的区别" class="headerlink" title="嵌套类型与Object类型的区别"></a>嵌套类型与Object类型的区别</h4><p>通过例子来说明:</p><ol><li>插入一个文档，不设置mapping，此时 user 字段被自动识别为<strong>对象数组</strong></li></ol><pre><code>DELETE my_indexPUT my_index/_doc/1{  &quot;group&quot; : &quot;fans&quot;,  &quot;user&quot; : [     {      &quot;first&quot; : &quot;John&quot;,      &quot;last&quot; :  &quot;Smith&quot;    },    {      &quot;first&quot; : &quot;Alice&quot;,      &quot;last&quot; :  &quot;White&quot;    }  ]}</code></pre><ol start="2"><li>查询 user.first为 Alice，user.last 为 Smith的文档，理想中应该找不到匹配的文档</li><li>结果是查到了文档1，为什么呢？</li></ol><pre><code>GET my_index/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: [        { &quot;match&quot;: { &quot;user.first&quot;: &quot;Alice&quot; }},        { &quot;match&quot;: { &quot;user.last&quot;:  &quot;Smith&quot; }}      ]    }  }}</code></pre><ol start="4"><li>是由于Object对象类型在内部被转化成如下格式的文档：<pre><code>{&quot;group&quot; :        &quot;fans&quot;,&quot;user.first&quot; : [ &quot;alice&quot;, &quot;john&quot; ],&quot;user.last&quot; :  [ &quot;smith&quot;, &quot;white&quot; ]}</code></pre></li><li>user.first 和 user.last 扁平化为多值字段，alice 和 white 的<strong>关联关系丢失了</strong>。导致这个文档错误地匹配对 alice 和 smith 的查询</li><li>如果最开始就把user设置为 nested 嵌套对象呢？</li></ol><pre><code>DELETE my_indexPUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;properties&quot;: {        &quot;user&quot;: {          &quot;type&quot;: &quot;nested&quot;         }      }    }  }}PUT my_index/_doc/1{  &quot;group&quot;: &quot;fans&quot;,  &quot;user&quot;: [    {      &quot;first&quot;: &quot;John&quot;,      &quot;last&quot;: &quot;Smith&quot;    },    {      &quot;first&quot;: &quot;Alice&quot;,      &quot;last&quot;: &quot;White&quot;    }  ]}</code></pre><ol start="7"><li>再来进行查询，可以发现以下第一个查不到文档，第二个查询到文档1，符合我们预期</li></ol><pre><code>GET my_index/_search{  &quot;query&quot;: {    &quot;nested&quot;: {      &quot;path&quot;: &quot;user&quot;,      &quot;query&quot;: {        &quot;bool&quot;: {          &quot;must&quot;: [            { &quot;match&quot;: { &quot;user.first&quot;: &quot;Alice&quot; }},            { &quot;match&quot;: { &quot;user.last&quot;:  &quot;Smith&quot; }}           ]        }      }    }  }}GET my_index/_search{  &quot;query&quot;: {    &quot;nested&quot;: {      &quot;path&quot;: &quot;user&quot;,      &quot;query&quot;: {        &quot;bool&quot;: {          &quot;must&quot;: [            { &quot;match&quot;: { &quot;user.first&quot;: &quot;Alice&quot; }},            { &quot;match&quot;: { &quot;user.last&quot;:  &quot;White&quot; }}           ]        }      },      &quot;inner_hits&quot;: {         &quot;highlight&quot;: {          &quot;fields&quot;: {            &quot;user.first&quot;: {}          }        }      }    }  }}</code></pre><ol start="8"><li><p>nested对象将数组中每个对象作为独立隐藏文档来索引，这意味着每个嵌套对象都可以独立被搜索</p></li><li><p>需要注意的是：</p></li></ol><ul><li>使用 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-nested-query.html" target="_blank" rel="noopener">nested 查询</a>来搜索</li><li>使用 nested 和 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-reverse-nested-aggregation.html" target="_blank" rel="noopener">reverse_nested</a> 聚合来分析</li><li>使用 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-sort.html#nested-sorting" target="_blank" rel="noopener">nested sorting</a> 来排序</li><li>使用 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-inner-hits.html#nested-inner-hits" target="_blank" rel="noopener">nested inner hits</a> 来检索和高亮</li></ul><h4 id="地理位置数据类型"><a href="#地理位置数据类型" class="headerlink" title="地理位置数据类型"></a>地理位置数据类型</h4><ul><li>geo_point<ul><li>地理位置，其值可以有如下四中表现形式：<ul><li>object对象：”location”: {“lat”: 41.12, “lon”: -71.34}</li><li>字符串：”location”: “41.12,-71.34”</li><li><a href="http://geohash.gofreerange.com/" target="_blank" rel="noopener">geohash</a>：”location”: “drm3btev3e86” </li><li>数组：”location”: [ -71.34, 41.12 ] </li></ul></li><li>查询的时候通过 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-geo-bounding-box-query.html" target="_blank" rel="noopener">Geo Bounding Box Query </a> 进行查询</li></ul></li><li>geo_shape</li></ul><h4 id="专用数据类型"><a href="#专用数据类型" class="headerlink" title="专用数据类型"></a>专用数据类型</h4><ul><li>记录IP地址 ip</li><li>实现自动补全 completion</li><li>记录分词数 token_count</li><li>记录字符串hash值 murmur3</li><li>Percolator</li></ul><pre><code># ip类型，存储IPPUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;properties&quot;: {        &quot;ip_addr&quot;: {          &quot;type&quot;: &quot;ip&quot;        }      }    }  }}PUT my_index/_doc/1{  &quot;ip_addr&quot;: &quot;192.168.1.1&quot;}GET my_index/_search{  &quot;query&quot;: {    &quot;term&quot;: {      &quot;ip_addr&quot;: &quot;192.168.0.0/16&quot;    }  }}</code></pre><h4 id="多字段特性-multi-fields"><a href="#多字段特性-multi-fields" class="headerlink" title="多字段特性 multi-fields"></a>多字段特性 multi-fields</h4><ul><li>允许对同一个字段采用不同的配置，比如分词，常见例子如对人名实现拼音搜索，只需要在人名中新增一个<strong>子字段</strong>为 pinyin 即可</li><li>通过参数 fields 设置</li></ul><h4 id="设置Mapping"><a href="#设置Mapping" class="headerlink" title="设置Mapping"></a>设置Mapping</h4><p><img src="http://image.laijianfeng.org/20180804_024134.png" alt="image"></p><pre><code>GET my_index/_mapping# 结果{  &quot;my_index&quot;: {    &quot;mappings&quot;: {      &quot;doc&quot;: {        &quot;properties&quot;: {          &quot;age&quot;: {            &quot;type&quot;: &quot;integer&quot;          },          &quot;created&quot;: {            &quot;type&quot;: &quot;date&quot;          },          &quot;name&quot;: {            &quot;type&quot;: &quot;text&quot;          },          &quot;title&quot;: {            &quot;type&quot;: &quot;text&quot;          }        }      }    }  }}</code></pre><h3 id="Mapping参数"><a href="#Mapping参数" class="headerlink" title="Mapping参数"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-params.html" target="_blank" rel="noopener">Mapping参数</a></h3><h4 id="analyzer"><a href="#analyzer" class="headerlink" title="analyzer"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analyzer.html" target="_blank" rel="noopener">analyzer</a></h4><ul><li>分词器，默认为standard analyzer，当该字段被索引和搜索时对字段进行分词处理</li></ul><h4 id="boost"><a href="#boost" class="headerlink" title="boost"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-boost.html" target="_blank" rel="noopener">boost</a></h4><ul><li>字段权重，默认为1.0</li></ul><h4 id="dynamic"><a href="#dynamic" class="headerlink" title="dynamic"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic.html" target="_blank" rel="noopener">dynamic</a></h4><ul><li>Mapping中的字段类型一旦设定后，禁止直接修改，原因是：Lucene实现的倒排索引生成后不允许修改</li><li>只能新建一个索引，然后reindex数据</li><li>默认允许新增字段</li><li><p>通过dynamic参数来控制字段的新增：</p><ul><li>true（默认）允许自动新增字段</li><li>false 不允许自动新增字段，但是文档可以正常写入，但无法对新增字段进行查询等操作</li><li><p>strict 文档不能写入，报错</p><p>​</p></li></ul></li></ul><pre><code>PUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;dynamic&quot;: false,       &quot;properties&quot;: {        &quot;user&quot;: {           &quot;properties&quot;: {            &quot;name&quot;: {              &quot;type&quot;: &quot;text&quot;            },            &quot;social_networks&quot;: {               &quot;dynamic&quot;: true,              &quot;properties&quot;: {}            }          }        }      }    }  }}</code></pre><p>定义后my_index这个索引下不能自动新增字段，但是在user.social_networks下可以自动新增子字段</p><h4 id="copy-to"><a href="#copy-to" class="headerlink" title="copy_to"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/copy-to.html" target="_blank" rel="noopener">copy_to</a></h4><ul><li>将该字段复制到目标字段，实现类似_all的作用</li><li>不会出现在_source中，只用来搜索</li></ul><pre><code>DELETE my_indexPUT my_index{  &quot;mappings&quot;: {    &quot;doc&quot;: {      &quot;properties&quot;: {        &quot;first_name&quot;: {          &quot;type&quot;: &quot;text&quot;,          &quot;copy_to&quot;: &quot;full_name&quot;         },        &quot;last_name&quot;: {          &quot;type&quot;: &quot;text&quot;,          &quot;copy_to&quot;: &quot;full_name&quot;         },        &quot;full_name&quot;: {          &quot;type&quot;: &quot;text&quot;        }      }    }  }}PUT my_index/doc/1{  &quot;first_name&quot;: &quot;John&quot;,  &quot;last_name&quot;: &quot;Smith&quot;}GET my_index/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;full_name&quot;: {         &quot;query&quot;: &quot;John Smith&quot;,        &quot;operator&quot;: &quot;and&quot;      }    }  }}</code></pre><h4 id="index"><a href="#index" class="headerlink" title="index"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-index.html" target="_blank" rel="noopener">index</a></h4><ul><li>控制当前字段是否索引，默认为true，即记录索引，false不记录，即不可搜索</li></ul><h4 id="index-options"><a href="#index-options" class="headerlink" title="index_options"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index-options.html" target="_blank" rel="noopener">index_options</a></h4><ul><li>index_options参数控制将哪些信息添加到倒排索引，以用于搜索和突出显示，可选的值有：docs，freqs，positions，offsets</li><li>docs：只索引 doc id</li><li>freqs：索引 doc id 和词频，平分时可能要用到词频</li><li>positions：索引 doc id、词频、位置，做 proximity or phrase queries 时可能要用到位置信息</li><li>offsets：索引doc id、词频、位置、开始偏移和结束偏移，高亮功能需要用到offsets</li></ul><h4 id="fielddata"><a href="#fielddata" class="headerlink" title="fielddata"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/fielddata.html" target="_blank" rel="noopener">fielddata</a></h4><ul><li>是否预加载 fielddata，默认为false</li><li>Elasticsearch第一次查询时完整加载这个字段所有 Segment 中的倒排索引到内存中</li><li>如果我们有一些 5 GB 的索引段，并希望加载 10 GB 的 fielddata 到内存中，这个过程可能会要数十秒</li><li>将 fielddate 设置为 true ,将载入 fielddata 的代价转移到索引刷新的时候，而不是查询时，从而大大提高了搜索体验</li><li>参考：<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/preload-fielddata.html" target="_blank" rel="noopener">预加载 fielddata</a></li></ul><h4 id="eager-global-ordinals"><a href="#eager-global-ordinals" class="headerlink" title="eager_global_ordinals"></a>eager_global_ordinals</h4><ul><li>是否预构建全局序号，默认false</li><li>参考：<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/preload-fielddata.html#global-ordinals" target="_blank" rel="noopener">预构建全局序号（Eager global ordinals）</a></li></ul><h4 id="doc-values"><a href="#doc-values" class="headerlink" title="doc_values"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/doc-values.html" target="_blank" rel="noopener">doc_values</a></h4><ul><li>参考：<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/docvalues-and-fielddata.html" target="_blank" rel="noopener">Doc Values and Fielddata</a></li></ul><h4 id="fields"><a href="#fields" class="headerlink" title="fields"></a>fields</h4><ul><li>该参数的目的是为了实现 multi-fields</li><li>一个字段，多种数据类型</li><li>譬如：一个字段 city 的数据类型为 text ，用于全文索引，可以通过 fields 为该字段定义 keyword 类型，用于排序和聚合</li></ul><pre><code># 设置 mappingPUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;properties&quot;: {        &quot;city&quot;: {          &quot;type&quot;: &quot;text&quot;,          &quot;fields&quot;: {            &quot;raw&quot;: {               &quot;type&quot;:  &quot;keyword&quot;            }          }        }      }    }  }}# 插入两条数据PUT my_index/_doc/1{  &quot;city&quot;: &quot;New York&quot;}PUT my_index/_doc/2{  &quot;city&quot;: &quot;York&quot;}# 查询，city用于全文索引 match，city.raw用于排序和聚合GET my_index/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;city&quot;: &quot;york&quot;     }  },  &quot;sort&quot;: {    &quot;city.raw&quot;: &quot;asc&quot;   },  &quot;aggs&quot;: {    &quot;Cities&quot;: {      &quot;terms&quot;: {        &quot;field&quot;: &quot;city.raw&quot;       }    }  }}</code></pre><h4 id="format"><a href="#format" class="headerlink" title="format"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-date-format.html" target="_blank" rel="noopener">format</a></h4><ul><li>由于JSON没有date类型，Elasticsearch预先通过format参数定义时间格式，将匹配的字符串识别为date类型，转换为时间戳（单位：毫秒）</li><li>format默认为：<code>strict_date_optional_time||epoch_millis</code></li><li>Elasticsearch内建的时间格式:</li></ul><table><thead><tr><th>名称</th><th>格式</th></tr></thead><tbody><tr><td>epoch_millis</td><td>时间戳（单位：毫秒）</td></tr><tr><td>epoch_second</td><td>时间戳（单位：秒）</td></tr><tr><td>date_optional_time</td><td></td></tr><tr><td>basic_date</td><td>yyyyMMdd</td></tr><tr><td>basic_date_time</td><td>yyyyMMdd’T’HHmmss.SSSZ</td></tr><tr><td>basic_date_time_no_millis</td><td>yyyyMMdd’T’HHmmssZ</td></tr><tr><td>basic_ordinal_date</td><td>yyyyDDD</td></tr><tr><td>basic_ordinal_date_time</td><td>yyyyDDD’T’HHmmss.SSSZ</td></tr><tr><td>basic_ordinal_date_time_no_millis</td><td>yyyyDDD’T’HHmmssZ</td></tr><tr><td>basic_time</td><td>HHmmss.SSSZ</td></tr><tr><td>basic_time_no_millis</td><td>HHmmssZ</td></tr><tr><td>basic_t_time</td><td>‘T’HHmmss.SSSZ</td></tr><tr><td>basic_t_time_no_millis</td><td>‘T’HHmmssZ</td></tr></tbody></table><ul><li>上述名称加前缀 <code>strict_</code> 表示为严格格式</li><li>更多的查看文档</li></ul><h4 id="properties"><a href="#properties" class="headerlink" title="properties"></a>properties</h4><ul><li>用于_doc，object和nested类型的字段定义<strong>子字段</strong></li></ul><pre><code>PUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {       &quot;properties&quot;: {        &quot;manager&quot;: {           &quot;properties&quot;: {            &quot;age&quot;:  { &quot;type&quot;: &quot;integer&quot; },            &quot;name&quot;: { &quot;type&quot;: &quot;text&quot;  }          }        },        &quot;employees&quot;: {           &quot;type&quot;: &quot;nested&quot;,          &quot;properties&quot;: {            &quot;age&quot;:  { &quot;type&quot;: &quot;integer&quot; },            &quot;name&quot;: { &quot;type&quot;: &quot;text&quot;  }          }        }      }    }  }}PUT my_index/_doc/1 {  &quot;region&quot;: &quot;US&quot;,  &quot;manager&quot;: {    &quot;name&quot;: &quot;Alice White&quot;,    &quot;age&quot;: 30  },  &quot;employees&quot;: [    {      &quot;name&quot;: &quot;John Smith&quot;,      &quot;age&quot;: 34    },    {      &quot;name&quot;: &quot;Peter Brown&quot;,      &quot;age&quot;: 26    }  ]}</code></pre><h4 id="normalizer"><a href="#normalizer" class="headerlink" title="normalizer"></a>normalizer</h4><ul><li>与 analyzer 类似，只不过 analyzer 用于 text 类型字段，分词产生多个 token，而 normalizer 用于 keyword 类型，只产生一个 token（整个字段的值作为一个token，而不是分词拆分为多个token）</li><li>定义一个自定义 normalizer，使用大写uppercase过滤器</li></ul><pre><code>PUT test_index_4{  &quot;settings&quot;: {    &quot;analysis&quot;: {      &quot;normalizer&quot;: {        &quot;my_normalizer&quot;: {          &quot;type&quot;: &quot;custom&quot;,          &quot;char_filter&quot;: [],          &quot;filter&quot;: [&quot;uppercase&quot;, &quot;asciifolding&quot;]        }      }    }  },  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;properties&quot;: {        &quot;foo&quot;: {          &quot;type&quot;: &quot;keyword&quot;,          &quot;normalizer&quot;: &quot;my_normalizer&quot;        }      }    }  }}# 插入数据POST test_index_4/_doc/1{  &quot;foo&quot;: &quot;hello world&quot;}POST test_index_4/_doc/2{  &quot;foo&quot;: &quot;Hello World&quot;}POST test_index_4/_doc/3{  &quot;foo&quot;: &quot;hello elasticsearch&quot;}# 搜索hello，结果为空，而不是3条！！ GET test_index_4/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;foo&quot;: &quot;hello&quot;    }  }}# 搜索 hello world，结果2条，1 和 2GET test_index_4/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;foo&quot;: &quot;hello world&quot;    }  }}</code></pre><h4 id="其他字段"><a href="#其他字段" class="headerlink" title="其他字段"></a>其他字段</h4><ul><li>coerce<ul><li>强制类型转换，把json中的值转为ES中字段的数据类型，譬如：把字符串”5”转为integer的5</li><li>coerce默认为 true</li><li>如果coerce设置为 false，当json的值与es字段类型不匹配将会 rejected</li><li>通过 “settings”: { “index.mapping.coerce”: false } 设置索引的 coerce</li></ul></li><li>enabled<ul><li>是否索引，默认为 true</li><li>可以在_doc和字段两个粒度进行设置</li></ul></li><li>ignore_above<ul><li>设置能被索引的字段的长度</li><li>超过这个长度，该字段将不被索引，所以无法搜索，但聚合的terms可以看到</li></ul></li><li>null_value<ul><li>该字段定义遇到null值时的处理策略，默认为Null，即空值，此时ES会忽略该值</li><li>通过设定该值可以设定字段为 null 时的默认值</li></ul></li><li>ignore_malformed<ul><li>当数据类型不匹配且 coerce 强制转换时,默认情况会抛出异常,并拒绝整个文档的插入</li><li>若设置该参数为 true，则忽略该异常，并强制赋值，但是不会被索引，其他字段则照常</li></ul></li><li>norms<ul><li>norms 存储各种标准化因子，为后续查询计算文档对该查询的匹配分数提供依据</li><li>norms 参数对<strong>评分</strong>很有用，但需要占用大量的磁盘空间</li><li>如果不需要计算字段的评分，可以取消该字段 norms 的功能</li></ul></li><li>position_increment_gap<ul><li>与 proximity queries（近似查询）和 phrase queries（短语查询）有关</li><li>默认值 100</li></ul></li><li>search_analyzer<ul><li>搜索分词器，查询时使用</li><li>默认与 analyzer 一样</li></ul></li><li>similarity<ul><li>设置相关度算法，ES5.x 和 ES6.x 默认的算法为 BM25</li><li>另外也可选择 classic 和 boolean</li></ul></li><li>store<ul><li>store 的意思是：是否在 _source 之外在独立存储一份，默认值为 false</li><li>es在存储数据的时候把json对象存储到”_source”字段里，”_source”把所有字段保存为一份文档存储（读取需要1次IO），要取出某个字段则通过 source filtering 过滤</li><li>当字段比较多或者内容比较多，并且不需要取出所有字段的时候，可以把特定字段的store设置为true单独存储（读取需要1次IO），同时在_source设置exclude</li><li>关于该字段的理解，参考： <a href="https://blog.csdn.net/helllochun/article/details/52136954" target="_blank" rel="noopener">es设置mapping store属性</a></li></ul></li><li>term_vector<ul><li>与倒排索引相关</li></ul></li></ul><h3 id="Dynamic-Mapping"><a href="#Dynamic-Mapping" class="headerlink" title="Dynamic Mapping"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-mapping.html" target="_blank" rel="noopener">Dynamic Mapping</a></h3><p>ES是依靠JSON文档的字段类型来实现自动识别字段类型，支持的类型如下：</p><table><thead><tr><th>JSON 类型</th><th>ES 类型</th></tr></thead><tbody><tr><td>null</td><td>忽略</td></tr><tr><td>boolean</td><td>boolean</td></tr><tr><td>浮点类型</td><td>float</td></tr><tr><td>整数</td><td>long</td></tr><tr><td>object</td><td>object</td></tr><tr><td>array</td><td>由第一个非 null 值的类型决定</td></tr><tr><td>string</td><td>匹配为日期则设为date类型（默认开启）；<br>匹配为数字则设置为 float或long类型（默认关闭）；<br>设为text类型，并附带keyword的子字段</td></tr></tbody></table><p>举栗子</p><pre><code>POST my_index/doc{  &quot;username&quot;:&quot;whirly&quot;,  &quot;age&quot;:22,  &quot;birthday&quot;:&quot;1995-01-01&quot;}GET my_index/_mapping# 结果{  &quot;my_index&quot;: {    &quot;mappings&quot;: {      &quot;doc&quot;: {        &quot;properties&quot;: {          &quot;age&quot;: {            &quot;type&quot;: &quot;long&quot;          },          &quot;birthday&quot;: {            &quot;type&quot;: &quot;date&quot;          },          &quot;username&quot;: {            &quot;type&quot;: &quot;text&quot;,            &quot;fields&quot;: {              &quot;keyword&quot;: {                &quot;type&quot;: &quot;keyword&quot;,                &quot;ignore_above&quot;: 256              }            }          }        }      }    }  }}</code></pre><h4 id="日期的自动识别"><a href="#日期的自动识别" class="headerlink" title="日期的自动识别"></a>日期的自动识别</h4><ul><li>dynamic_date_formats 参数为自动识别的日期格式，默认为 [ “strict_date_optional_time”,”yyyy/MM/dd HH:mm:ss Z||yyyy/MM/dd Z”]</li><li>date_detection可以关闭日期自动识别机制</li></ul><pre><code># 自定义日期识别格式PUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;dynamic_date_formats&quot;: [&quot;MM/dd/yyyy&quot;]    }  }}# 关闭日期自动识别机制PUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;date_detection&quot;: false    }  }}</code></pre><h4 id="数字的自动识别"><a href="#数字的自动识别" class="headerlink" title="数字的自动识别"></a>数字的自动识别</h4><ul><li>字符串是数字时，默认不会自动识别为整形，因为字符串中出现数字完全是合理的</li><li>numeric_detection 参数可以开启字符串中数字的自动识别</li></ul><h3 id="Dynamic-templates"><a href="#Dynamic-templates" class="headerlink" title="Dynamic templates"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-templates.html" target="_blank" rel="noopener">Dynamic templates</a></h3><p>允许根据ES自动识别的数据类型、字段名等来动态设定字段类型，可以实现如下效果：</p><ul><li>所有字符串类型都设定为keyword类型，即不分词</li><li>所有以message开头的字段都设定为text类型，即分词</li><li>所有以long_开头的字段都设定为long类型</li><li>所有自动匹配为double类型的都设定为float类型，以节省空间</li></ul><h4 id="Dynamic-templates-API"><a href="#Dynamic-templates-API" class="headerlink" title="Dynamic templates API"></a>Dynamic templates API</h4><pre><code>&quot;dynamic_templates&quot;: [    {      &quot;my_template_name&quot;: {         ...  match conditions ...         &quot;mapping&quot;: { ... }       }    },    ...]</code></pre><p>匹配规则一般有如下几个参数：</p><ul><li>match_mapping_type 匹配ES自动识别的字段类型，如boolean，long，string等</li><li>match, unmatch 匹配字段名</li><li>match_pattern 匹配正则表达式</li><li>path_match, path_unmatch 匹配路径</li></ul><pre><code># double类型的字段设定为float以节省空间PUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;dynamic_templates&quot;: [        {          &quot;integers&quot;: {            &quot;match_mapping_type&quot;: &quot;double&quot;,            &quot;mapping&quot;: {              &quot;type&quot;: &quot;float&quot;            }          }        }      ]    }  }}</code></pre><h5 id="自定义Mapping的建议"><a href="#自定义Mapping的建议" class="headerlink" title="自定义Mapping的建议"></a>自定义Mapping的建议</h5><ol><li>写入一条文档到ES的临时索引中，获取ES自动生成的Mapping</li><li>修改步骤1得到的Mapping，自定义相关配置</li><li>使用步骤2的Mapping创建实际所需索引</li></ol><h3 id="Index-Template-索引模板"><a href="#Index-Template-索引模板" class="headerlink" title="Index Template 索引模板"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/indices-templates.html" target="_blank" rel="noopener">Index Template 索引模板</a></h3><ul><li>索引模板，主要用于在新建索引时自动应用预先设定的配置，简化索引创建的操作步骤<ul><li>可以设定索引的setting和mapping</li><li>可以有多个模板，根据order设置，order大的覆盖小的配置</li></ul></li><li>索引模板API，endpoint为 _template</li></ul><pre><code># 创建索引模板，匹配 test-index-map 开头的索引PUT _template/template_1{  &quot;index_patterns&quot;: [&quot;test-index-map*&quot;],  &quot;order&quot;: 2,  &quot;settings&quot;: {    &quot;number_of_shards&quot;: 1  },  &quot;mappings&quot;: {    &quot;doc&quot;: {      &quot;_source&quot;: {        &quot;enabled&quot;: false      },      &quot;properties&quot;: {        &quot;name&quot;: {          &quot;type&quot;: &quot;keyword&quot;        },        &quot;created_at&quot;: {          &quot;type&quot;: &quot;date&quot;,          &quot;format&quot;: &quot;YYYY/MM/dd HH:mm:ss&quot;        }      }    }  }}# 插入一个文档POST test-index-map_1/doc{  &quot;name&quot; : &quot;小旋锋&quot;,  &quot;created_at&quot;: &quot;2018/08/16 20:11:11&quot;}# 获取该索引的信息，可以发现 settings 和 mappings 和索引模板里设置的一样GET test-index-map_1# 删除DELETE /_template/template_1# 查询GET /_template/template_1</code></pre><blockquote><p>参考文档： </p><ol><li>elasticsearch 官方文档</li><li><a href="https://coding.imooc.com/class/181.html" target="_blank" rel="noopener">慕课网 Elastic Stack从入门到实践</a></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Mapping&quot;&gt;&lt;a href=&quot;#Mapping&quot; class=&quot;headerlink&quot; title=&quot;Mapping&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/
      
    
    </summary>
    
      <category term="大数据" scheme="http://laijianfeng.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="elasticsearch" scheme="http://laijianfeng.org/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>倒排索引与分词</title>
    <link href="http://laijianfeng.org/2018/08/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E4%B8%8E%E5%88%86%E8%AF%8D/"/>
    <id>http://laijianfeng.org/2018/08/倒排索引与分词/</id>
    <published>2018-08-15T15:50:57.000Z</published>
    <updated>2018-08-16T13:22:20.517Z</updated>
    
    <content type="html"><![CDATA[<h3 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h3><ul><li>正排索引：文档id到单词的关联关系</li><li>倒排索引：单词到文档id的关联关系</li></ul><p>示例：<br>对以下三个文档去除停用词后构造倒排索引<br><img src="http://image.laijianfeng.org/20180803_223406.png" alt="image"></p><h4 id="倒排索引-查询过程"><a href="#倒排索引-查询过程" class="headerlink" title="倒排索引-查询过程"></a>倒排索引-查询过程</h4><p>查询包含“搜索引擎”的文档</p><ol><li>通过倒排索引获得“搜索引擎”对应的文档id列表，有1，3</li><li>通过正排索引查询1和3的完整内容</li><li>返回最终结果</li></ol><h4 id="倒排索引-组成"><a href="#倒排索引-组成" class="headerlink" title="倒排索引-组成"></a>倒排索引-组成</h4><ul><li>单词词典（Term Dictionary）</li><li>倒排列表（Posting List）</li></ul><h4 id="单词词典（Term-Dictionary）"><a href="#单词词典（Term-Dictionary）" class="headerlink" title="单词词典（Term Dictionary）"></a>单词词典（Term Dictionary）</h4><p>单词词典的实现一般用B+树，B+树构造的可视化过程网址: <a href="https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html" target="_blank" rel="noopener">B+ Tree Visualization</a></p><blockquote><p>关于B树和B+树</p><ol><li><a href="https://zh.wikipedia.org/wiki/B%E6%A0%91" target="_blank" rel="noopener">维基百科-B树</a></li><li><a href="https://zh.wikipedia.org/wiki/B%2B%E6%A0%91" target="_blank" rel="noopener">维基百科-B+树</a></li><li><a href="https://www.cnblogs.com/nullzx/p/8729425.html" target="_blank" rel="noopener">B树和B+树的插入、删除图文详解</a></li></ol></blockquote><p><img src="http://image.laijianfeng.org/20180803_225118.png" alt="image"></p><h4 id="倒排列表（Posting-List）"><a href="#倒排列表（Posting-List）" class="headerlink" title="倒排列表（Posting List）"></a>倒排列表（Posting List）</h4><ul><li>倒排列表记录了单词对应的文档集合，有倒排索引项（Posting）组成</li><li>倒排索引项主要包含如下信息：<ol><li>文档id用于获取原始信息</li><li>单词频率（TF，Term Frequency），记录该单词在该文档中出现的次数，用于后续相关性算分</li><li>位置（Posting），记录单词在文档中的分词位置（多个），用于做词语搜索（Phrase Query）</li><li>偏移（Offset），记录单词在文档的开始和结束位置，用于高亮显示</li></ol></li></ul><p><img src="http://image.laijianfeng.org/20180803_225931.png" alt="image"></p><p>B+树<strong>内部结点存索引，叶子结点存数据</strong>，这里的 单词词典就是B+树索引，倒排列表就是数据，整合在一起后如下所示</p><p><img src="http://image.laijianfeng.org/20180803_232214.png" alt="image"></p><p>ES存储的是一个JSON格式的文档，其中包含多个字段，每个字段会有自己的倒排索引</p><h3 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h3><p>分词是将文本转换成一系列单词（Term or Token）的过程，也可以叫文本分析，在ES里面称为Analysis</p><p><img src="http://image.laijianfeng.org/20180803_232909.png" alt="image"></p><h4 id="分词器"><a href="#分词器" class="headerlink" title="分词器"></a>分词器</h4><p>分词器是ES中专门处理分词的组件，英文为Analyzer，它的组成如下：</p><ul><li>Character Filters：针对原始文本进行处理，比如去除html标签</li><li>Tokenizer：将原始文本按照一定规则切分为单词</li><li>Token Filters：针对Tokenizer处理的单词进行再加工，比如转小写、删除或增新等处理</li></ul><p>分词器调用顺序<br><img src="http://image.laijianfeng.org/20180803_234047.png" alt="image"></p><h3 id="Analyze-API"><a href="#Analyze-API" class="headerlink" title="Analyze API"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis.html" target="_blank" rel="noopener">Analyze API</a></h3><p>ES提供了一个可以测试分词的API接口，方便验证分词效果，endpoint是_analyze</p><ul><li>可以直接指定analyzer进行测试</li></ul><p><img src="http://image.laijianfeng.org/20180803_234732.png" alt="image"></p><ul><li>可以直接指定索引中的字段进行测试</li></ul><pre><code>POST test_index/doc{  &quot;username&quot;: &quot;whirly&quot;,  &quot;age&quot;:22}POST test_index/_analyze{  &quot;field&quot;: &quot;username&quot;,  &quot;text&quot;: [&quot;hello world&quot;]}</code></pre><ul><li>可以自定义分词器进行测试</li></ul><pre><code>POST _analyze{  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;filter&quot;: [&quot;lowercase&quot;],  &quot;text&quot;: [&quot;Hello World&quot;]}</code></pre><h3 id="预定义的分词器"><a href="#预定义的分词器" class="headerlink" title="预定义的分词器"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-analyzers.html" target="_blank" rel="noopener">预定义的分词器</a></h3><p>ES自带的分词器有如下：</p><ul><li>Standard Analyzer<ul><li>默认分词器</li><li>按词切分，支持多语言</li><li>小写处理</li></ul></li><li>Simple Analyzer<ul><li>按照非字母切分</li><li>小写处理</li></ul></li><li>Whitespace Analyzer<ul><li>空白字符作为分隔符</li></ul></li><li>Stop Analyzer<ul><li>相比Simple Analyzer多了去除请用词处理</li><li>停用词指语气助词等修饰性词语，如the, an, 的， 这等</li></ul></li><li>Keyword Analyzer<ul><li>不分词，直接将输入作为一个单词输出</li></ul></li><li>Pattern Analyzer<ul><li>通过正则表达式自定义分隔符</li><li>默认是\W+，即非字词的符号作为分隔符</li></ul></li><li>Language Analyzer<ul><li>提供了30+种常见语言的分词器</li></ul></li></ul><p>示例：停用词分词器</p><pre><code>POST _analyze{  &quot;analyzer&quot;: &quot;stop&quot;,  &quot;text&quot;: [&quot;The 2 QUICK Brown Foxes jumped over the lazy dog&#39;s bone.&quot;]}</code></pre><p>结果</p><pre><code>{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;quick&quot;,      &quot;start_offset&quot;: 6,      &quot;end_offset&quot;: 11,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 1    },    {      &quot;token&quot;: &quot;brown&quot;,      &quot;start_offset&quot;: 12,      &quot;end_offset&quot;: 17,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 2    },    {      &quot;token&quot;: &quot;foxes&quot;,      &quot;start_offset&quot;: 18,      &quot;end_offset&quot;: 23,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 3    },    {      &quot;token&quot;: &quot;jumped&quot;,      &quot;start_offset&quot;: 24,      &quot;end_offset&quot;: 30,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 4    },    {      &quot;token&quot;: &quot;over&quot;,      &quot;start_offset&quot;: 31,      &quot;end_offset&quot;: 35,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 5    },    {      &quot;token&quot;: &quot;lazy&quot;,      &quot;start_offset&quot;: 40,      &quot;end_offset&quot;: 44,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 7    },    {      &quot;token&quot;: &quot;dog&quot;,      &quot;start_offset&quot;: 45,      &quot;end_offset&quot;: 48,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 8    },    {      &quot;token&quot;: &quot;s&quot;,      &quot;start_offset&quot;: 49,      &quot;end_offset&quot;: 50,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 9    },    {      &quot;token&quot;: &quot;bone&quot;,      &quot;start_offset&quot;: 51,      &quot;end_offset&quot;: 55,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 10    }  ]}</code></pre><h3 id="中文分词"><a href="#中文分词" class="headerlink" title="中文分词"></a>中文分词</h3><ul><li>难点<ul><li>中文分词指的是将一个汉字序列切分为一个一个的单独的词。在英文中，单词之间以空格作为自然分界词，汉语中词没有一个形式上的分界符</li><li>上下文不同，分词结果迥异，比如交叉歧义问题</li></ul></li><li>常见分词系统<ul><li><a href="https://github.com/medcl/elasticsearch-analysis-ik" target="_blank" rel="noopener">IK</a>：实现中英文单词的切分，可自定义词库，支持热更新分词词典</li><li><a href="https://github.com/sing1ee/elasticsearch-jieba-plugin" target="_blank" rel="noopener">jieba</a>：支持分词和词性标注，支持繁体分词，自定义词典，并行分词等</li><li><a href="https://github.com/hankcs/HanLP" target="_blank" rel="noopener">Hanlp</a>：由一系列模型与算法组成的Java工具包，目标是普及自然语言处理在生产环境中的应用</li><li><a href="https://github.com/microbun/elasticsearch-thulac-plugin" target="_blank" rel="noopener">THUAC</a>：中文分词和词性标注</li></ul></li></ul><h4 id="安装ik中文分词插件"><a href="#安装ik中文分词插件" class="headerlink" title="安装ik中文分词插件"></a>安装ik中文分词插件</h4><pre><code># 在Elasticsearch安装目录下执行命令，然后重启esbin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.3.0/elasticsearch-analysis-ik-6.3.0.zip# 如果由于网络慢，安装失败，可以先下载好zip压缩包，将下面命令改为实际的路径，执行，然后重启esbin/elasticsearch-plugin install file:///path/to/elasticsearch-analysis-ik-6.3.0.zip</code></pre><ul><li>ik测试 - ik_smart</li></ul><pre><code>POST _analyze{  &quot;analyzer&quot;: &quot;ik_smart&quot;,  &quot;text&quot;: [&quot;公安部：各地校车将享最高路权&quot;]}# 结果{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;公安部&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 3,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 0    },    {      &quot;token&quot;: &quot;各地&quot;,      &quot;start_offset&quot;: 4,      &quot;end_offset&quot;: 6,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 1    },    {      &quot;token&quot;: &quot;校车&quot;,      &quot;start_offset&quot;: 6,      &quot;end_offset&quot;: 8,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 2    },    {      &quot;token&quot;: &quot;将&quot;,      &quot;start_offset&quot;: 8,      &quot;end_offset&quot;: 9,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 3    },    {      &quot;token&quot;: &quot;享&quot;,      &quot;start_offset&quot;: 9,      &quot;end_offset&quot;: 10,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 4    },    {      &quot;token&quot;: &quot;最高&quot;,      &quot;start_offset&quot;: 10,      &quot;end_offset&quot;: 12,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 5    },    {      &quot;token&quot;: &quot;路&quot;,      &quot;start_offset&quot;: 12,      &quot;end_offset&quot;: 13,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 6    },    {      &quot;token&quot;: &quot;权&quot;,      &quot;start_offset&quot;: 13,      &quot;end_offset&quot;: 14,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 7    }  ]}</code></pre><ul><li>ik测试 - ik_max_word</li></ul><pre><code>POST _analyze{  &quot;analyzer&quot;: &quot;ik_max_word&quot;,  &quot;text&quot;: [&quot;公安部：各地校车将享最高路权&quot;]}# 结果{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;公安部&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 3,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 0    },    {      &quot;token&quot;: &quot;公安&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 2,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 1    },    {      &quot;token&quot;: &quot;部&quot;,      &quot;start_offset&quot;: 2,      &quot;end_offset&quot;: 3,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 2    },    {      &quot;token&quot;: &quot;各地&quot;,      &quot;start_offset&quot;: 4,      &quot;end_offset&quot;: 6,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 3    },    {      &quot;token&quot;: &quot;校车&quot;,      &quot;start_offset&quot;: 6,      &quot;end_offset&quot;: 8,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 4    },    {      &quot;token&quot;: &quot;将&quot;,      &quot;start_offset&quot;: 8,      &quot;end_offset&quot;: 9,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 5    },    {      &quot;token&quot;: &quot;享&quot;,      &quot;start_offset&quot;: 9,      &quot;end_offset&quot;: 10,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 6    },    {      &quot;token&quot;: &quot;最高&quot;,      &quot;start_offset&quot;: 10,      &quot;end_offset&quot;: 12,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 7    },    {      &quot;token&quot;: &quot;路&quot;,      &quot;start_offset&quot;: 12,      &quot;end_offset&quot;: 13,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 8    },    {      &quot;token&quot;: &quot;权&quot;,      &quot;start_offset&quot;: 13,      &quot;end_offset&quot;: 14,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 9    }  ]}</code></pre><ul><li><p>ik两种分词模式ik_max_word 和 ik_smart 什么区别?</p><ul><li><p>ik_max_word: 会将文本做最细粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,和,国国,国歌”，会穷尽各种可能的组合；</p></li><li><p>ik_smart: 会做最粗粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,国歌”。</p></li></ul></li></ul><h3 id="自定义分词"><a href="#自定义分词" class="headerlink" title="自定义分词"></a>自定义分词</h3><p>当自带的分词无法满足需求时，可以自定义分词，通过定义Character Filters、Tokenizer和Token Filters实现</p><h4 id="Character-Filters"><a href="#Character-Filters" class="headerlink" title="Character Filters"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-charfilters.html" target="_blank" rel="noopener">Character Filters</a></h4><ul><li>在Tokenizer之前对原始文本进行处理，比如增加、删除或替换字符等</li><li>自带的如下:<ul><li>HTML Strip Character Filter：去除HTML标签和转换HTML实体</li><li>Mapping Character Filter：进行字符替换操作</li><li>Pattern Replace Character Filter：进行正则匹配替换</li></ul></li><li>会影响后续tokenizer解析的position和offset信息</li></ul><h4 id="Character-Filters测试"><a href="#Character-Filters测试" class="headerlink" title="Character Filters测试"></a>Character Filters测试</h4><pre><code>POST _analyze{  &quot;tokenizer&quot;: &quot;keyword&quot;,  &quot;char_filter&quot;: [&quot;html_strip&quot;],  &quot;text&quot;: [&quot;&lt;p&gt;I&amp;apos;m so &lt;b&gt;happy&lt;/b&gt;!&lt;/p&gt;&quot;]}# 结果{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;&quot;&quot;I&#39;m so happy!&quot;&quot;&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 32,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 0    }  ]}</code></pre><h4 id="Tokenizers"><a href="#Tokenizers" class="headerlink" title="Tokenizers"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenizers.html" target="_blank" rel="noopener">Tokenizers</a></h4><ul><li>将原始文本按照一定规则切分为单词（term or token）</li><li>自带的如下：<ul><li>standard 按照单词进行分割</li><li>letter 按照非字符类进行分割</li><li>whitespace 按照空格进行分割</li><li>UAX URL Email 按照standard进行分割，但不会分割邮箱和URL</li><li>Ngram 和 Edge NGram 连词分割</li><li>Path Hierarchy 按照文件路径进行分割</li></ul></li></ul><h4 id="Tokenizers-测试"><a href="#Tokenizers-测试" class="headerlink" title="Tokenizers 测试"></a>Tokenizers 测试</h4><pre><code>POST _analyze{  &quot;tokenizer&quot;: &quot;path_hierarchy&quot;,  &quot;text&quot;: [&quot;/path/to/file&quot;]}# 结果{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;/path&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 5,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 0    },    {      &quot;token&quot;: &quot;/path/to&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 8,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 0    },    {      &quot;token&quot;: &quot;/path/to/file&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 13,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 0    }  ]}</code></pre><h4 id="Token-Filters"><a href="#Token-Filters" class="headerlink" title="Token Filters"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenfilters.html" target="_blank" rel="noopener">Token Filters</a></h4><ul><li>对于tokenizer输出的单词（term）进行增加、删除、修改等操作</li><li>自带的如下：<ul><li>lowercase 将所有term转为小写</li><li>stop 删除停用词</li><li>Ngram 和 Edge NGram 连词分割</li><li>Synonym 添加近义词的term</li></ul></li></ul><h4 id="Token-Filters测试"><a href="#Token-Filters测试" class="headerlink" title="Token Filters测试"></a>Token Filters测试</h4><pre><code>POST _analyze{  &quot;text&quot;: [    &quot;a Hello World!&quot;  ],  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;filter&quot;: [    &quot;stop&quot;,    &quot;lowercase&quot;,    {      &quot;type&quot;: &quot;ngram&quot;,      &quot;min_gram&quot;: 4,      &quot;max_gram&quot;: 4    }  ]}# 结果{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;hell&quot;,      &quot;start_offset&quot;: 2,      &quot;end_offset&quot;: 7,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 1    },    {      &quot;token&quot;: &quot;ello&quot;,      &quot;start_offset&quot;: 2,      &quot;end_offset&quot;: 7,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 1    },    {      &quot;token&quot;: &quot;worl&quot;,      &quot;start_offset&quot;: 8,      &quot;end_offset&quot;: 13,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 2    },    {      &quot;token&quot;: &quot;orld&quot;,      &quot;start_offset&quot;: 8,      &quot;end_offset&quot;: 13,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 2    }  ]}</code></pre><h4 id="自定义分词-1"><a href="#自定义分词-1" class="headerlink" title="自定义分词"></a>自定义分词</h4><p>自定义分词需要在索引配置中设定 char_filter、tokenizer、filter、analyzer等</p><p>自定义分词示例:</p><ul><li>分词器名称：my_custom\</li><li>过滤器将token转为大写</li></ul><pre><code>PUT test_index_1{  &quot;settings&quot;: {    &quot;analysis&quot;: {      &quot;analyzer&quot;: {        &quot;my_custom_analyzer&quot;: {          &quot;type&quot;:      &quot;custom&quot;,          &quot;tokenizer&quot;: &quot;standard&quot;,          &quot;char_filter&quot;: [            &quot;html_strip&quot;          ],          &quot;filter&quot;: [            &quot;uppercase&quot;,            &quot;asciifolding&quot;          ]        }      }    }  }}</code></pre><h4 id="自定义分词器测试"><a href="#自定义分词器测试" class="headerlink" title="自定义分词器测试"></a>自定义分词器测试</h4><pre><code>POST test_index_1/_analyze{  &quot;analyzer&quot;: &quot;my_custom_analyzer&quot;,  &quot;text&quot;: [&quot;&lt;p&gt;I&amp;apos;m so &lt;b&gt;happy&lt;/b&gt;!&lt;/p&gt;&quot;]}# 结果{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;I&#39;M&quot;,      &quot;start_offset&quot;: 3,      &quot;end_offset&quot;: 11,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 0    },    {      &quot;token&quot;: &quot;SO&quot;,      &quot;start_offset&quot;: 12,      &quot;end_offset&quot;: 14,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 1    },    {      &quot;token&quot;: &quot;HAPPY&quot;,      &quot;start_offset&quot;: 18,      &quot;end_offset&quot;: 27,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 2    }  ]}</code></pre><h4 id="分词使用说明"><a href="#分词使用说明" class="headerlink" title="分词使用说明"></a>分词使用说明</h4><p>分词会在如下两个时机使用：</p><ul><li>创建或更新文档时(Index Time)，会对相应的文档进行分词处理</li><li>查询时（Search Time），会对查询语句进行分词<ul><li>查询时通过analyzer指定分词器</li><li>通过index mapping设置search_analyzer实现</li><li>一般不需要特别指定查询时分词器，直接使用索引分词器即可，否则会出现无法匹配的情况</li></ul></li></ul><h4 id="分词使用建议"><a href="#分词使用建议" class="headerlink" title="分词使用建议"></a>分词使用建议</h4><ul><li>明确字段是否需要分词，不需要分词的字段就将type设置为keyword，可以节省空间和提高写性能</li><li>善用_analyze API，查看文档的分词结果</li></ul><blockquote><p>更多内容请访问我的个人网站： <a href="http://laijianfeng.org">http://laijianfeng.org</a><br>参考文档： </p><ol><li>elasticsearch 官方文档</li><li><a href="https://coding.imooc.com/class/181.html" target="_blank" rel="noopener">慕课网 Elastic Stack从入门到实践</a></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;倒排索引&quot;&gt;&lt;a href=&quot;#倒排索引&quot; class=&quot;headerlink&quot; title=&quot;倒排索引&quot;&gt;&lt;/a&gt;倒排索引&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;正排索引：文档id到单词的关联关系&lt;/li&gt;
&lt;li&gt;倒排索引：单词到文档id的关联关系&lt;/li&gt;
&lt;/ul&gt;

      
    
    </summary>
    
      <category term="大数据" scheme="http://laijianfeng.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="elasticsearch" scheme="http://laijianfeng.org/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch初体验</title>
    <link href="http://laijianfeng.org/2018/08/ElasticSearch%E5%88%9D%E4%BD%93%E9%AA%8C/"/>
    <id>http://laijianfeng.org/2018/08/ElasticSearch初体验/</id>
    <published>2018-08-15T11:37:25.000Z</published>
    <updated>2018-08-15T11:43:46.489Z</updated>
    
    <content type="html"><![CDATA[<h3 id="需要明白的问题"><a href="#需要明白的问题" class="headerlink" title="需要明白的问题"></a>需要明白的问题</h3><ol><li>什么是倒排索引？它的组成是什么？</li><li>常见的相关性算分方法有哪些？</li><li>为什么查询语句没有返回预期的文档？</li><li>常用的数据类型有哪些？Text和Keyword的区别是什么？</li><li>集群是如何搭建起来的？是如何实现故障转移的？</li><li>Shard具体是由什么组成的？</li></ol><h2 id="Elastic-Stack"><a href="#Elastic-Stack" class="headerlink" title="Elastic Stack"></a>Elastic Stack</h2><p>构建在开源基础之上, Elastic Stack 让您能够安全可靠地获取任何来源、任何格式的数据，并且能够实时地对数据进行搜索、分析和可视化</p><p><strong>Elasticsearch</strong> 是基于 JSON 的分布式搜索和分析引擎，专为实现水平扩展、高可用和管理便捷性而设计。</p><p><strong>Kibana</strong> 能够以图表的形式呈现数据，并且具有可扩展的用户界面，供您全方位配置和管理 Elastic Stack。</p><p><strong>Logstash</strong> 是动态数据收集管道，拥有可扩展的插件生态系统，能够与 Elasticsearch 产生强大的协同作用。</p><p><strong>Beats</strong> 是轻量型采集器的平台，从边缘机器向 Logstash 和 Elasticsearch 发送数据。</p><h3 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/_basic_concepts.html" target="_blank" rel="noopener">基础概念</a></h3><ul><li>文档 Document ：用户存储在ES中的数据文档</li><li>索引 Index ：由具有一些相同字段的文档的集合</li><li>类型 Type :  允许将不同类型的文档存储在同一索引中，6.0开始官方不允许在一个index下建立多个type，统一type名称：doc</li><li>节点 Node ：一个Elasticsearch的运行实例，是集群的构成单元，存储部分或全部数据，并参与集群的索引和搜索功能</li><li>集群 Cluster ：由一个或多个节点组成的集合，共同保存所有的数据，对外提供服务（包括跨所有节点的联合索引和搜索功能等）</li><li>分片 Shards ：分片是为了解决存储大规模数据的问题，将数据切分分别存储到不同的分片中</li><li>副本 Replicas ：副本可以在分片或节点发生故障时提高可用性，而且由于可以在所有副本上进行并行搜索，所以也可以提高集群的吞吐量</li><li>近实时 Near Realtime(NRT)：从索引文档到可搜索文档的时间有一点延迟（通常为一秒）</li></ul><blockquote><p>note:</p><ol><li>在创建索引的时候如果没有配置索引Mapping，一个索引默认有5个shard和1个副本，一个索引总共有10个shard（算上副本shard）</li><li>Elasticsearch 的shard实际上是一个Lucene索引，截止Lucene-5843，一个Lucene索引限制的最大文档数为2,147,483,519 (= Integer.MAX_VALUE - 128)</li></ol></blockquote><h3 id="安装Elasticsearch-amp-Kibana"><a href="#安装Elasticsearch-amp-Kibana" class="headerlink" title="安装Elasticsearch &amp; Kibana"></a>安装Elasticsearch &amp; Kibana</h3><p>ES和Kibana的安装很简单，前提需要先安装好Java8，然后执行以下命令即可</p><h5 id="elasticsearch单节点最简安装"><a href="#elasticsearch单节点最简安装" class="headerlink" title="elasticsearch单节点最简安装"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/_installation.html" target="_blank" rel="noopener">elasticsearch单节点最简安装</a></h5><pre><code># 在Ubuntu16.04上安装，方式有很多种，选择二进制压缩包的方式安装# 1. 在普通用户家目录下，下载压缩包curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.3.2.tar.gz# 2. 解压tar -xvf elasticsearch-6.3.2.tar.gz# 3. 移动至/opt目录下sudo mv elasticsearch-6.3.2 /opt# 4. 修改配置文件elasticsearch.yml中的 network.host 值为 0.0.0.0，其他的配置参考官方文档cd /opt/elasticsearch-6.3.2vi config/elasticsearch.yml# 5. 启动单节点，然后浏览器访问host:9200即可看到ES集群信息bin/elasticsearch</code></pre><p><img src="http://image.laijianfeng.org/20180815_153244.png" alt="image"></p><h5 id="kibana最简安装"><a href="#kibana最简安装" class="headerlink" title="kibana最简安装"></a><a href="https://www.elastic.co/guide/en/kibana/current/targz.html" target="_blank" rel="noopener">kibana最简安装</a></h5><pre><code>wget https://artifacts.elastic.co/downloads/kibana/kibana-6.3.2-linux-x86_64.tar.gzshasum -a 512 kibana-6.3.2-linux-x86_64.tar.gz tar -xzf kibana-6.3.2-linux-x86_64.tar.gzsudo mv kibana-6.3.2-linux-x86_64 /optcd /opt/kibana-6.3.2-linux-x86_64# 修改 config/kibana.yml中 server.host: 0.0.0.0# 启动Kibana，访问 host:5601即可进入kibana界面</code></pre><p><img src="http://image.laijianfeng.org/20180815_153435.png" alt="image"></p><h3 id="交互方式-Rest-API"><a href="#交互方式-Rest-API" class="headerlink" title="交互方式 Rest API"></a>交互方式 Rest API</h3><p>Elasticsearch集群对外提供RESTful API</p><ul><li>Curl命令行</li><li>Kibana Devtools</li><li>Java API</li><li>其他各种API，如Python API等</li></ul><blockquote><p>note:<br>我们后面主要使用 Kibana Devtools 这种交互方式</p></blockquote><p><img src="http://image.laijianfeng.org/20180815_154136.png" alt="image"></p><h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html" target="_blank" rel="noopener">数据类型</a></h3><ul><li>字符串： text（分词）, keyword（不分词）</li><li>数值型： long, integer, byte, double, float, half_float, scaled_float</li><li>布尔： boolean</li><li>日期： date</li><li>二进制： binary</li><li>范围类型： integer_range, float_range, long_range, double_range, date_range</li><li>复杂数据类型： Array, Object, Nested</li><li>地理： geo_point， geo_shape</li><li>专业： ip，completion， token_count， murmur3， Percolator， join</li><li>组合的</li></ul><h3 id="探索ES集群"><a href="#探索ES集群" class="headerlink" title="探索ES集群"></a>探索ES集群</h3><p>Check your cluster, node, and index health, status, and statistics<br>Administer your cluster, node, and index data and metadata<br>Perform CRUD (Create, Read, Update, and Delete) and search operations against your indexes<br>Execute advanced search operations such as paging, sorting, filtering, scripting, aggregations, and many others</p><h5 id="使用-cat-API探索集群的健康情况"><a href="#使用-cat-API探索集群的健康情况" class="headerlink" title="使用_cat API探索集群的健康情况"></a>使用_cat API探索集群的健康情况</h5><pre><code>GET /_cat/health?v# 结果epoch      timestamp cluster       status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent1534319381 15:49:41  elasticsearch green           3         3    118  59    0    0        0             0                  -                100.0%</code></pre><p>集群的健康状态(status)有三种:</p><ul><li>green：一切正常（集群功能齐全）</li><li>yellow：所有数据都可用，但存在一些副本未分配（群集功能齐全）</li><li>red：一些数据由于某种原因不可用（群集部分功能失效）</li></ul><h5 id="查看节点信息"><a href="#查看节点信息" class="headerlink" title="查看节点信息"></a>查看节点信息</h5><pre><code>GET /_cat/nodes?v# 结果（我的ES集群安装了三个节点）ip            heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name10.100.97.207           30          96  13    0.15    0.08     0.08 mdi       *      master10.100.97.246           68          96   3    0.00    0.00     0.00 mdi       -      hadoop210.100.98.22            15          97   2    0.00    0.02     0.04 mdi       -      hadoop3</code></pre><h5 id="查看索引信息"><a href="#查看索引信息" class="headerlink" title="查看索引信息"></a>查看索引信息</h5><pre><code>GET /_cat/indices?v# 结果health status index                           uuid                   pri rep docs.count docs.deleted store.size pri.store.sizegreen  open   logstash-2015.05.20             4BjPjpq6RhOSCNUPMsY0MQ   5   1       4750            0     46.8mb         24.5mbgreen  open   logstash-2015.05.18             mDkUKHSWR0a8UeZlKzts8Q   5   1       4631            0     45.6mb         23.8mbgreen  open   hockey                          g1omiazvRSOE117w_uy_wA   5   1         11            0     45.3kb         22.6kbgreen  open   .kibana                         AGdo8im_TxC04ARexUxqxw   1   1        143           10    665.6kb        332.8kbgreen  open   shakespeare                     5009bDa7T16f5qTeyOdTlw   5   1     111396            0     43.9mb           22mbgreen  open   logstash-2015.05.19             az4Jen4nT7-J9yRYpZ0A9A   5   1       4624            0     44.7mb         23.1mb...</code></pre><h3 id="操作数据"><a href="#操作数据" class="headerlink" title="操作数据"></a>操作数据</h3><h5 id="插入文档并查询"><a href="#插入文档并查询" class="headerlink" title="插入文档并查询"></a>插入文档并查询</h5><pre><code># 插入一个文档PUT /customer/_doc/1?pretty{  &quot;name&quot;: &quot;John Doe&quot;}# 结果{  &quot;_index&quot;: &quot;customer&quot;,  &quot;_type&quot;: &quot;_doc&quot;,  &quot;_id&quot;: &quot;1&quot;,  &quot;_version&quot;: 1,  &quot;result&quot;: &quot;updated&quot;,  &quot;_shards&quot;: {    &quot;total&quot;: 2,    &quot;successful&quot;: 2,    &quot;failed&quot;: 0  },  &quot;_seq_no&quot;: 1,  &quot;_primary_term&quot;: 1}# 查询该文档GET /customer/_doc/1#结果{  &quot;_index&quot;: &quot;customer&quot;,  &quot;_type&quot;: &quot;_doc&quot;,  &quot;_id&quot;: &quot;1&quot;,  &quot;_version&quot;: 1,  &quot;found&quot;: true,  &quot;_source&quot;: {    &quot;name&quot;: &quot;John Doe&quot;  }}</code></pre><blockquote><p>note:</p><ol><li><code>customer</code> 为索引名，<code>_doc</code> 为type，1为文档_id，需要注意的是：在es6.x建议索引的type值固定为<code>_doc</code>，在之后的版本将删除type了；文档id若不指定，es会自动分配一个_id给文档</li><li>插入文档后，查看索引信息<code>GET /_cat/indices?v</code>可以看到多了 customer 的索引信息</li><li>文档结果，_source字段是原始的json内容，其他的为文档元数据</li></ol></blockquote><h5 id="文档元数据"><a href="#文档元数据" class="headerlink" title="文档元数据"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-fields.html" target="_blank" rel="noopener">文档元数据</a></h5><p>用于标注文档的元信息</p><ul><li>_index: 文档所在的索引名</li><li>_type: 文档所在的类型名</li><li>_id: 文档的唯一id</li><li>_uid: 组合id，由_type和_id组成（6.0开始_type不再起作用，同_id一样）</li><li>_source: 文档的原始json数据，可以从这里获取每个字段的内容</li><li>_all: 整合所有字段内容到该字段，默认禁用</li><li>_routing 默认值为 _id，决定文档存储在哪个shard上：<code>shard_num = hash(_routing) % num_primary_shards</code> </li></ul><h5 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h5><pre><code>DELETE customer#结果{  &quot;acknowledged&quot;: true}GET /_cat/indices?v# 再次查看索引信息，可以发现 customer 不存在，已被删除</code></pre><h5 id="更新文档"><a href="#更新文档" class="headerlink" title="更新文档"></a>更新文档</h5><pre><code>PUT /customer/_doc/1?pretty{  &quot;name&quot;: &quot;John Doe&quot;}POST /customer/_doc/1/_update{  &quot;doc&quot;: { &quot;name&quot;: &quot;Jane Doe&quot; }}POST /customer/_doc/1/_update{  &quot;doc&quot;: { &quot;name&quot;: &quot;Jane Doe&quot;, &quot;age&quot;: 20 }}# 可以看到 \_version的值一直在增加</code></pre><h5 id="删除文档"><a href="#删除文档" class="headerlink" title="删除文档"></a>删除文档</h5><pre><code>DELETE /customer/_doc/2</code></pre><h5 id="批量操作"><a href="#批量操作" class="headerlink" title="批量操作"></a>批量操作</h5><p>es提供了<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/docs-bulk.html" target="_blank" rel="noopener">_bulk API</a>供批量操作，可以提高索引、更新、删除等操作的效率</p><p>_bulk操作的类型有四种：</p><ul><li>index 索引：若已存在，则覆盖，文档不存在则创建</li><li>create 创建：文档不存在则异常</li><li>delete 删除</li><li>update 更新</li></ul><pre><code># _bulk 任务：# 1. index创建 customer索引下id为3的文档# 2. delete删除 customer索引下id为3的文档# 3. create创建 customer索引下id为3的文档# 4. update更新 customer索引下id为3的文档POST _bulk{&quot;index&quot;:{&quot;_index&quot;:&quot;customer&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;3&quot;}}{&quot;name&quot;:&quot;whirly&quot;}{&quot;delete&quot;:{&quot;_index&quot;:&quot;customer&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;3&quot;}}{&quot;create&quot;:{&quot;_index&quot;:&quot;customer&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;3&quot;}}{&quot;name&quot;:&quot;whirly2&quot;}{&quot;update&quot;:{&quot;_index&quot;:&quot;customer&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;3&quot;}}{&quot;doc&quot;:{&quot;name&quot;:&quot;whirly3&quot;}}</code></pre><p><img src="http://image.laijianfeng.org/20180815_164226.png" alt="image"></p><blockquote><p>note:</p><ol><li>批量查询用的是 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/docs-multi-get.html" target="_blank" rel="noopener">Multi Get API</a></li></ol></blockquote><h3 id="探索数据"><a href="#探索数据" class="headerlink" title="探索数据"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/_exploring_your_data.html" target="_blank" rel="noopener">探索数据</a></h3><p>一个<a href="https://raw.githubusercontent.com/elastic/elasticsearch/master/docs/src/test/resources/accounts.json" target="_blank" rel="noopener">简单的数据集</a>，数据结构如下：</p><pre><code>{    &quot;account_number&quot;: 0,    &quot;balance&quot;: 16623,    &quot;firstname&quot;: &quot;Bradshaw&quot;,    &quot;lastname&quot;: &quot;Mckenzie&quot;,    &quot;age&quot;: 29,    &quot;gender&quot;: &quot;F&quot;,    &quot;address&quot;: &quot;244 Columbus Place&quot;,    &quot;employer&quot;: &quot;Euron&quot;,    &quot;email&quot;: &quot;bradshawmckenzie@euron.com&quot;,    &quot;city&quot;: &quot;Hobucken&quot;,    &quot;state&quot;: &quot;CO&quot;}</code></pre><p>导入这个简单的数据集到es中</p><pre><code># 下载wget https://raw.githubusercontent.com/elastic/elasticsearch/master/docs/src/test/resources/accounts.json# 导入curl -H &quot;Content-Type: application/json&quot; -XPOST &quot;localhost:9200/bank/_doc/_bulk?pretty&amp;refresh&quot; --data-binary &quot;@accounts.json&quot;</code></pre><p>上述命令是通过 _bulk API 将 account.json 的内容插入 bank 索引中，type 为 _doc</p><pre><code># account.json的内容:{&quot;index&quot;:{&quot;_id&quot;:&quot;1&quot;}}{&quot;account_number&quot;:1,&quot;balance&quot;:39225,&quot;firstname&quot;:&quot;Amber&quot;,&quot;lastname&quot;:&quot;Duke&quot;,&quot;age&quot;:32,&quot;gender&quot;:&quot;M&quot;,&quot;address&quot;:&quot;880 Holmes Lane&quot;,&quot;employer&quot;:&quot;Pyrami&quot;,&quot;email&quot;:&quot;amberduke@pyrami.com&quot;,&quot;city&quot;:&quot;Brogan&quot;,&quot;state&quot;:&quot;IL&quot;}...# 导入完成后可以看到 bank 索引已存在 1000 条数据GET bank/_search</code></pre><h5 id="查询数据-API"><a href="#查询数据-API" class="headerlink" title="查询数据 API"></a>查询数据 API</h5><p>任务：查询所有数据，根据 account_number 字段升序排序</p><ol><li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/search-uri-request.html#search-uri-request" target="_blank" rel="noopener">URI Search 方式</a></p><pre><code>GET /bank/_search?q=*&amp;sort=account_number:asc&amp;pretty</code></pre></li><li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/search-request-body.html" target="_blank" rel="noopener">Request Body Search</a> 方式</p><pre><code>GET /bank/_search{&quot;query&quot;: { &quot;match_all&quot;: {} },&quot;sort&quot;: [ { &quot;account_number&quot;: &quot;asc&quot; }]}</code></pre></li></ol><p>结果</p><pre><code>{  &quot;took&quot;: 41,  &quot;timed_out&quot;: false,  &quot;_shards&quot;: {    &quot;total&quot;: 5,    &quot;successful&quot;: 5,    &quot;skipped&quot;: 0,    &quot;failed&quot;: 0  },  &quot;hits&quot;: {    &quot;total&quot;: 1000,    &quot;max_score&quot;: null,    &quot;hits&quot;: [      {        &quot;_index&quot;: &quot;bank&quot;,        &quot;_type&quot;: &quot;account&quot;,        &quot;_id&quot;: &quot;0&quot;,        &quot;_score&quot;: null,        &quot;_source&quot;: {          &quot;account_number&quot;: 0,          &quot;balance&quot;: 16623,          &quot;firstname&quot;: &quot;Bradshaw&quot;,          &quot;lastname&quot;: &quot;Mckenzie&quot;,          &quot;age&quot;: 29,          &quot;gender&quot;: &quot;F&quot;,          &quot;address&quot;: &quot;244 Columbus Place&quot;,          &quot;employer&quot;: &quot;Euron&quot;,          &quot;email&quot;: &quot;bradshawmckenzie@euron.com&quot;,          &quot;city&quot;: &quot;Hobucken&quot;,          &quot;state&quot;: &quot;CO&quot;        },        &quot;sort&quot;: [          0        ]      }...    ]  }}</code></pre><p>各个参数意思：</p><ul><li>took：本次查询耗费的时间（单位：毫秒）</li><li>timed_out：是否超时</li><li>_shards：本次查询搜索的 shard 的数量，包括成功的和失败的</li><li>hits：查询结果</li><li>hits.total：匹配的文档数量</li><li>hits.hits：匹配的文档，默认返回10个文档</li><li>hits.sort：排序的值</li><li>_score：文档的得分</li><li>hits.max_score：所有文档最高的得分</li></ul><h3 id="简要介绍-Query-DSL"><a href="#简要介绍-Query-DSL" class="headerlink" title="简要介绍 Query DSL"></a>简要介绍 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/query-dsl.html" target="_blank" rel="noopener">Query DSL</a></h3><p>这个Elasticsearch提供的基于 json 的查询语言，我们通过一个小任务来了解一下</p><p>任务要求：</p><ol><li>查询 firstname 中为 “R” 开头，年龄在 20 到 30 岁之间的人物信息</li><li>限制返回的字段为 firstname,city,address,email,balance</li><li>根据年龄倒序排序，返回前十条数据</li><li>对 firstname 字段进行高亮显示</li><li>同时求所有匹配人物的 平均balance</li></ol><pre><code>GET bank/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: [        {          &quot;match_phrase_prefix&quot;: {            &quot;firstname&quot;: &quot;R&quot;          }        }      ],      &quot;filter&quot;: {        &quot;range&quot;: {          &quot;age&quot;: {            &quot;gte&quot;: 20,            &quot;lte&quot;: 30          }        }      }    }  },  &quot;from&quot;: 0,  &quot;size&quot;: 10,  &quot;sort&quot;: [    {      &quot;age&quot;: {        &quot;order&quot;: &quot;desc&quot;      }    }  ],  &quot;_source&quot;: [    &quot;firstname&quot;,    &quot;city&quot;,    &quot;address&quot;,    &quot;email&quot;,    &quot;balance&quot;  ],  &quot;highlight&quot;: {    &quot;fields&quot;: {      &quot;firstname&quot;: {}    }  },  &quot;aggs&quot;: {    &quot;avg_age&quot;: {      &quot;avg&quot;: {        &quot;field&quot;: &quot;balance&quot;      }    }  }}</code></pre><p>其中：</p><ul><li>query 部分可以写各种查询条件</li><li>from, size 设置要返回的文档的起始序号</li><li>sort 设置排序规则</li><li>_source 设置要返回的文档的字段</li><li>highlight 设置高亮的字段</li><li>aggs 为设置聚合统计规则</li></ul><h5 id="更多查询示例"><a href="#更多查询示例" class="headerlink" title="更多查询示例"></a>更多查询示例</h5><ul><li>match_all 查询 bank 索引所有文档</li></ul><pre><code>GET /bank/_search{  &quot;query&quot;: {    &quot;match_all&quot;: {}  },  &quot;size&quot;: 2}</code></pre><ul><li>match 全文搜索，查询 address 字段值为 mill lane 的所有文档</li></ul><pre><code>GET /bank/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;address&quot;: &quot;mill lane&quot;    }  }}</code></pre><ul><li>match_phrase 短语匹配</li></ul><pre><code>GET /bank/_search{  &quot;query&quot;: {    &quot;match_phrase&quot;: {      &quot;address&quot;: &quot;mill lane&quot;    }  }}</code></pre><blockquote><p>note:<br>match 和 match_phrase 的区别：</p><ul><li>match 中会分词，将 mill lane 拆分为 mill 和 lane， 实际查询 address 中有 mill <strong>或者</strong> lane 的文档</li><li>match_phrase：将 mill lane 作为一个整体查询，实际查询 address 中有 mill lane 的文档</li></ul></blockquote><ul><li>布尔查询（多条件查询）</li></ul><pre><code>GET /bank/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: [        { &quot;match&quot;: { &quot;age&quot;: &quot;40&quot; } }      ],      &quot;must_not&quot;: [        { &quot;match&quot;: { &quot;state&quot;: &quot;ID&quot; } }      ]    }  }}</code></pre><ul><li>布尔查询-过滤<br>查询 bank 索引中 balance 值在 20000 到 30000 之间的文档</li></ul><pre><code>GET /bank/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: { &quot;match_all&quot;: {} },      &quot;filter&quot;: {        &quot;range&quot;: {          &quot;balance&quot;: {            &quot;gte&quot;: 20000,            &quot;lte&quot;: 30000          }        }      }    }  }}</code></pre><ul><li>聚合查询<br>对所有文档进行聚合，state 值相同的分到同一个桶里，分桶结果命名为 group_by_state ，再对每个桶里的文档的 balance 字段求平均值，结果命名为 average_balance，通过设置 size 的值为0，不返回任何文档内容</li></ul><pre><code>GET /bank/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;group_by_state&quot;: {      &quot;terms&quot;: {        &quot;field&quot;: &quot;state.keyword&quot;      },      &quot;aggs&quot;: {        &quot;average_balance&quot;: {          &quot;avg&quot;: {            &quot;field&quot;: &quot;balance&quot;          }        }      }    }  }}</code></pre><p>分别计算 age 值在 20~30 ，30~40，40~50 三个年龄段的男和女的平均存款balance</p><pre><code>GET /bank/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;group_by_age&quot;: {      &quot;range&quot;: {        &quot;field&quot;: &quot;age&quot;,        &quot;ranges&quot;: [          {            &quot;from&quot;: 20,            &quot;to&quot;: 30          },          {            &quot;from&quot;: 30,            &quot;to&quot;: 40          },          {            &quot;from&quot;: 40,            &quot;to&quot;: 50          }        ]      },      &quot;aggs&quot;: {        &quot;group_by_gender&quot;: {          &quot;terms&quot;: {            &quot;field&quot;: &quot;gender.keyword&quot;          },          &quot;aggs&quot;: {            &quot;average_balance&quot;: {              &quot;avg&quot;: {                &quot;field&quot;: &quot;balance&quot;              }            }          }        }      }    }  }}</code></pre><blockquote><p>参考文档：</p><ol><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started.html" target="_blank" rel="noopener">elasticsearch 官方文档 Getting Started</a></li><li>慕课网 <a href="https://coding.imooc.com/class/181.html" target="_blank" rel="noopener">Elastic Stack从入门到实践</a></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;需要明白的问题&quot;&gt;&lt;a href=&quot;#需要明白的问题&quot; class=&quot;headerlink&quot; title=&quot;需要明白的问题&quot;&gt;&lt;/a&gt;需要明白的问题&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;什么是倒排索引？它的组成是什么？&lt;/li&gt;
&lt;li&gt;常见的相关性算分方法有哪些？&lt;/li
      
    
    </summary>
    
      <category term="大数据" scheme="http://laijianfeng.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="elasticsearch" scheme="http://laijianfeng.org/tags/elasticsearch/"/>
    
  </entry>
  
</feed>
