<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>Elasticsearch 6.x Mapping设置</title>
      <link href="/2018/08/Elasticsearch-6-x-Mapping%E8%AE%BE%E7%BD%AE/"/>
      <url>/2018/08/Elasticsearch-6-x-Mapping%E8%AE%BE%E7%BD%AE/</url>
      <content type="html"><![CDATA[<h3 id="Mapping"><a href="#Mapping" class="headerlink" title="Mapping"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html" target="_blank" rel="noopener">Mapping</a></h3><p>类似于数据库中的表结构定义，主要作用如下：</p><ul><li>定义Index下字段名（Field Name）</li><li>定义字段的类型，比如数值型，字符串型、布尔型等</li><li>定义倒排索引的相关配置，比如是否索引、记录postion等   </li></ul><p>需要注意的是，在索引中定义太多字段可能会导致索引膨胀，出现内存不足和难以恢复的情况，下面有几个设置：</p><ul><li>index.mapping.total_fields.limit：一个索引中能定义的字段的最大数量，默认是 1000</li><li>index.mapping.depth.limit：字段的最大深度，以内部对象的数量来计算，默认是20</li><li>index.mapping.nested_fields.limit：索引中嵌套字段的最大数量，默认是50</li></ul><h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html" target="_blank" rel="noopener">数据类型</a></h3><h4 id="核心数据类型"><a href="#核心数据类型" class="headerlink" title="核心数据类型"></a>核心数据类型</h4><ul><li>字符串 - text<ul><li>用于全文索引，该类型的字段将通过分词器进行分词，最终用于构建索引</li></ul></li><li>字符串 - keyword<ul><li>不分词，只能搜索该字段的完整的值，只用于 filtering </li></ul></li><li>数值型 <ul><li>long：有符号64-bit integer：-2^63 ~ 2^63 - 1 </li><li>integer：有符号32-bit integer，-2^31 ~ 2^31 - 1 </li><li>short：有符号16-bit integer，-32768 ~ 32767</li><li>byte： 有符号8-bit integer，-128 ~ 127</li><li>double：64-bit IEEE 754 浮点数</li><li>float：32-bit IEEE 754 浮点数</li><li>half_float：16-bit IEEE 754 浮点数</li><li>scaled_float</li></ul></li><li>布尔 - boolean<ul><li>值：false, “false”, true, “true”</li></ul></li><li>日期 - date<ul><li>由于Json没有date类型，所以es通过识别字符串是否符合format定义的格式来判断是否为date类型</li><li>format默认为：<code>strict_date_optional_time||epoch_millis</code> <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-date-format.html" target="_blank" rel="noopener">format</a></li></ul></li><li>二进制 - binary<ul><li>该类型的字段把值当做经过 base64 编码的字符串，默认不存储，且不可搜索</li></ul></li><li><p>范围类型</p><ul><li>范围类型表示值是一个范围，而不是一个具体的值</li><li>譬如 age 的类型是 integer_range，那么值可以是  {“gte” : 10, “lte” : 20}；搜索 “term” : {“age”: 15} 可以搜索该值；搜索 “range”: {“age”: {“gte”:11, “lte”: 15}} 也可以搜索到</li><li>range参数 relation 设置匹配模式<ul><li>INTERSECTS ：默认的匹配模式，只要搜索值与字段值有交集即可匹配到</li><li>WITHIN：字段值需要完全包含在搜索值之内，也就是字段值是搜索值的子集才能匹配</li><li>CONTAINS：与WITHIN相反，只搜索字段值包含搜索值的文档</li></ul></li><li>integer_range</li><li>float_range</li><li>long_range</li><li>double_range</li><li>date_range：64-bit 无符号整数，时间戳（单位：毫秒）</li><li><p>ip_range：IPV4 或 IPV6 格式的字符串</p><p>​</p></li></ul></li></ul><pre><code># 创建range索引PUT range_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;properties&quot;: {        &quot;expected_attendees&quot;: {          &quot;type&quot;: &quot;integer_range&quot;        },        &quot;time_frame&quot;: {          &quot;type&quot;: &quot;date_range&quot;,           &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;        }      }    }  }}# 插入一个文档PUT range_index/_doc/1{  &quot;expected_attendees&quot; : {     &quot;gte&quot; : 10,    &quot;lte&quot; : 20  },  &quot;time_frame&quot; : {     &quot;gte&quot; : &quot;2015-10-31 12:00:00&quot;,     &quot;lte&quot; : &quot;2015-11-05&quot;  }}# 12在 10~20的范围内，可以搜索到文档1GET range_index/_search{  &quot;query&quot; : {    &quot;term&quot; : {      &quot;expected_attendees&quot; : {        &quot;value&quot;: 12      }    }  }}# within可以搜索到文档# 可以修改日期，然后分别对比CONTAINS，WITHIN，INTERSECTS的区别GET range_index/_search{  &quot;query&quot; : {    &quot;range&quot; : {      &quot;time_frame&quot; : {         &quot;gte&quot; : &quot;2015-11-02&quot;,        &quot;lte&quot; : &quot;2015-11-03&quot;,        &quot;relation&quot; : &quot;within&quot;       }    }  }}</code></pre><h4 id="复杂数据类型"><a href="#复杂数据类型" class="headerlink" title="复杂数据类型"></a>复杂数据类型</h4><ul><li>数组类型 Array<ul><li>字符串数组 [ “one”, “two” ]</li><li>整数数组 [ 1, 2 ]</li><li>数组的数组  [ 1, [ 2, 3 ]]，相当于 [ 1, 2, 3 ]</li><li>Object对象数组 [ { “name”: “Mary”, “age”: 12 }, { “name”: “John”, “age”: 10 }]</li><li>同一个数组只能存同类型的数据，不能混存，譬如 [ 10, “some string” ] 是错误的</li><li>数组中的 null 值将被 null_value 属性设置的值代替或者被忽略</li><li>空数组 [] 被当做 missing field 处理</li></ul></li><li><p>对象类型 Object</p><ul><li>对象类型可能有内部对象</li><li><p>被索引的形式为：manager.name.first</p><p>​</p></li></ul></li></ul><pre><code># tags字符串数组，lists 对象数组PUT my_index/_doc/1{  &quot;message&quot;: &quot;some arrays in this document...&quot;,  &quot;tags&quot;:  [ &quot;elasticsearch&quot;, &quot;wow&quot; ],   &quot;lists&quot;: [     {      &quot;name&quot;: &quot;prog_list&quot;,      &quot;description&quot;: &quot;programming list&quot;    },    {      &quot;name&quot;: &quot;cool_list&quot;,      &quot;description&quot;: &quot;cool stuff list&quot;    }  ]}</code></pre><ul><li>嵌套类型 Nested<ul><li>nested 类型是一种对象类型的特殊版本，它允许索引对象数组，<strong>独立地索引每个对象</strong></li></ul></li></ul><h4 id="嵌套类型与Object类型的区别"><a href="#嵌套类型与Object类型的区别" class="headerlink" title="嵌套类型与Object类型的区别"></a>嵌套类型与Object类型的区别</h4><p>通过例子来说明:</p><ol><li>插入一个文档，不设置mapping，此时 user 字段被自动识别为<strong>对象数组</strong></li></ol><pre><code>DELETE my_indexPUT my_index/_doc/1{  &quot;group&quot; : &quot;fans&quot;,  &quot;user&quot; : [     {      &quot;first&quot; : &quot;John&quot;,      &quot;last&quot; :  &quot;Smith&quot;    },    {      &quot;first&quot; : &quot;Alice&quot;,      &quot;last&quot; :  &quot;White&quot;    }  ]}</code></pre><ol start="2"><li>查询 user.first为 Alice，user.last 为 Smith的文档，理想中应该找不到匹配的文档</li><li>结果是查到了文档1，为什么呢？</li></ol><pre><code>GET my_index/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: [        { &quot;match&quot;: { &quot;user.first&quot;: &quot;Alice&quot; }},        { &quot;match&quot;: { &quot;user.last&quot;:  &quot;Smith&quot; }}      ]    }  }}</code></pre><ol start="4"><li>是由于Object对象类型在内部被转化成如下格式的文档：<pre><code>{&quot;group&quot; :        &quot;fans&quot;,&quot;user.first&quot; : [ &quot;alice&quot;, &quot;john&quot; ],&quot;user.last&quot; :  [ &quot;smith&quot;, &quot;white&quot; ]}</code></pre></li><li>user.first 和 user.last 扁平化为多值字段，alice 和 white 的<strong>关联关系丢失了</strong>。导致这个文档错误地匹配对 alice 和 smith 的查询</li><li>如果最开始就把user设置为 nested 嵌套对象呢？</li></ol><pre><code>DELETE my_indexPUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;properties&quot;: {        &quot;user&quot;: {          &quot;type&quot;: &quot;nested&quot;         }      }    }  }}PUT my_index/_doc/1{  &quot;group&quot;: &quot;fans&quot;,  &quot;user&quot;: [    {      &quot;first&quot;: &quot;John&quot;,      &quot;last&quot;: &quot;Smith&quot;    },    {      &quot;first&quot;: &quot;Alice&quot;,      &quot;last&quot;: &quot;White&quot;    }  ]}</code></pre><ol start="7"><li>再来进行查询，可以发现以下第一个查不到文档，第二个查询到文档1，符合我们预期</li></ol><pre><code>GET my_index/_search{  &quot;query&quot;: {    &quot;nested&quot;: {      &quot;path&quot;: &quot;user&quot;,      &quot;query&quot;: {        &quot;bool&quot;: {          &quot;must&quot;: [            { &quot;match&quot;: { &quot;user.first&quot;: &quot;Alice&quot; }},            { &quot;match&quot;: { &quot;user.last&quot;:  &quot;Smith&quot; }}           ]        }      }    }  }}GET my_index/_search{  &quot;query&quot;: {    &quot;nested&quot;: {      &quot;path&quot;: &quot;user&quot;,      &quot;query&quot;: {        &quot;bool&quot;: {          &quot;must&quot;: [            { &quot;match&quot;: { &quot;user.first&quot;: &quot;Alice&quot; }},            { &quot;match&quot;: { &quot;user.last&quot;:  &quot;White&quot; }}           ]        }      },      &quot;inner_hits&quot;: {         &quot;highlight&quot;: {          &quot;fields&quot;: {            &quot;user.first&quot;: {}          }        }      }    }  }}</code></pre><ol start="8"><li><p>nested对象将数组中每个对象作为独立隐藏文档来索引，这意味着每个嵌套对象都可以独立被搜索</p></li><li><p>需要注意的是：</p></li></ol><ul><li>使用 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-nested-query.html" target="_blank" rel="noopener">nested 查询</a>来搜索</li><li>使用 nested 和 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-reverse-nested-aggregation.html" target="_blank" rel="noopener">reverse_nested</a> 聚合来分析</li><li>使用 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-sort.html#nested-sorting" target="_blank" rel="noopener">nested sorting</a> 来排序</li><li>使用 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-inner-hits.html#nested-inner-hits" target="_blank" rel="noopener">nested inner hits</a> 来检索和高亮</li></ul><h4 id="地理位置数据类型"><a href="#地理位置数据类型" class="headerlink" title="地理位置数据类型"></a>地理位置数据类型</h4><ul><li>geo_point<ul><li>地理位置，其值可以有如下四中表现形式：<ul><li>object对象：”location”: {“lat”: 41.12, “lon”: -71.34}</li><li>字符串：”location”: “41.12,-71.34”</li><li><a href="http://geohash.gofreerange.com/" target="_blank" rel="noopener">geohash</a>：”location”: “drm3btev3e86” </li><li>数组：”location”: [ -71.34, 41.12 ] </li></ul></li><li>查询的时候通过 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-geo-bounding-box-query.html" target="_blank" rel="noopener">Geo Bounding Box Query </a> 进行查询</li></ul></li><li>geo_shape</li></ul><h4 id="专用数据类型"><a href="#专用数据类型" class="headerlink" title="专用数据类型"></a>专用数据类型</h4><ul><li>记录IP地址 ip</li><li>实现自动补全 completion</li><li>记录分词数 token_count</li><li>记录字符串hash值 murmur3</li><li>Percolator</li></ul><pre><code># ip类型，存储IPPUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;properties&quot;: {        &quot;ip_addr&quot;: {          &quot;type&quot;: &quot;ip&quot;        }      }    }  }}PUT my_index/_doc/1{  &quot;ip_addr&quot;: &quot;192.168.1.1&quot;}GET my_index/_search{  &quot;query&quot;: {    &quot;term&quot;: {      &quot;ip_addr&quot;: &quot;192.168.0.0/16&quot;    }  }}</code></pre><h4 id="多字段特性-multi-fields"><a href="#多字段特性-multi-fields" class="headerlink" title="多字段特性 multi-fields"></a>多字段特性 multi-fields</h4><ul><li>允许对同一个字段采用不同的配置，比如分词，常见例子如对人名实现拼音搜索，只需要在人名中新增一个<strong>子字段</strong>为 pinyin 即可</li><li>通过参数 fields 设置</li></ul><h4 id="设置Mapping"><a href="#设置Mapping" class="headerlink" title="设置Mapping"></a>设置Mapping</h4><p><img src="http://image.laijianfeng.org/20180804_024134.png" alt="image"></p><pre><code>GET my_index/_mapping# 结果{  &quot;my_index&quot;: {    &quot;mappings&quot;: {      &quot;doc&quot;: {        &quot;properties&quot;: {          &quot;age&quot;: {            &quot;type&quot;: &quot;integer&quot;          },          &quot;created&quot;: {            &quot;type&quot;: &quot;date&quot;          },          &quot;name&quot;: {            &quot;type&quot;: &quot;text&quot;          },          &quot;title&quot;: {            &quot;type&quot;: &quot;text&quot;          }        }      }    }  }}</code></pre><h3 id="Mapping参数"><a href="#Mapping参数" class="headerlink" title="Mapping参数"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-params.html" target="_blank" rel="noopener">Mapping参数</a></h3><h4 id="analyzer"><a href="#analyzer" class="headerlink" title="analyzer"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analyzer.html" target="_blank" rel="noopener">analyzer</a></h4><ul><li>分词器，默认为standard analyzer，当该字段被索引和搜索时对字段进行分词处理</li></ul><h4 id="boost"><a href="#boost" class="headerlink" title="boost"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-boost.html" target="_blank" rel="noopener">boost</a></h4><ul><li>字段权重，默认为1.0</li></ul><h4 id="dynamic"><a href="#dynamic" class="headerlink" title="dynamic"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic.html" target="_blank" rel="noopener">dynamic</a></h4><ul><li>Mapping中的字段类型一旦设定后，禁止直接修改，原因是：Lucene实现的倒排索引生成后不允许修改</li><li>只能新建一个索引，然后reindex数据</li><li>默认允许新增字段</li><li><p>通过dynamic参数来控制字段的新增：</p><ul><li>true（默认）允许自动新增字段</li><li>false 不允许自动新增字段，但是文档可以正常写入，但无法对新增字段进行查询等操作</li><li><p>strict 文档不能写入，报错</p><p>​</p></li></ul></li></ul><pre><code>PUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;dynamic&quot;: false,       &quot;properties&quot;: {        &quot;user&quot;: {           &quot;properties&quot;: {            &quot;name&quot;: {              &quot;type&quot;: &quot;text&quot;            },            &quot;social_networks&quot;: {               &quot;dynamic&quot;: true,              &quot;properties&quot;: {}            }          }        }      }    }  }}</code></pre><p>定义后my_index这个索引下不能自动新增字段，但是在user.social_networks下可以自动新增子字段</p><h4 id="copy-to"><a href="#copy-to" class="headerlink" title="copy_to"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/copy-to.html" target="_blank" rel="noopener">copy_to</a></h4><ul><li>将该字段复制到目标字段，实现类似_all的作用</li><li>不会出现在_source中，只用来搜索</li></ul><pre><code>DELETE my_indexPUT my_index{  &quot;mappings&quot;: {    &quot;doc&quot;: {      &quot;properties&quot;: {        &quot;first_name&quot;: {          &quot;type&quot;: &quot;text&quot;,          &quot;copy_to&quot;: &quot;full_name&quot;         },        &quot;last_name&quot;: {          &quot;type&quot;: &quot;text&quot;,          &quot;copy_to&quot;: &quot;full_name&quot;         },        &quot;full_name&quot;: {          &quot;type&quot;: &quot;text&quot;        }      }    }  }}PUT my_index/doc/1{  &quot;first_name&quot;: &quot;John&quot;,  &quot;last_name&quot;: &quot;Smith&quot;}GET my_index/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;full_name&quot;: {         &quot;query&quot;: &quot;John Smith&quot;,        &quot;operator&quot;: &quot;and&quot;      }    }  }}</code></pre><h4 id="index"><a href="#index" class="headerlink" title="index"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-index.html" target="_blank" rel="noopener">index</a></h4><ul><li>控制当前字段是否索引，默认为true，即记录索引，false不记录，即不可搜索</li></ul><h4 id="index-options"><a href="#index-options" class="headerlink" title="index_options"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index-options.html" target="_blank" rel="noopener">index_options</a></h4><ul><li>index_options参数控制将哪些信息添加到倒排索引，以用于搜索和突出显示，可选的值有：docs，freqs，positions，offsets</li><li>docs：只索引 doc id</li><li>freqs：索引 doc id 和词频，平分时可能要用到词频</li><li>positions：索引 doc id、词频、位置，做 proximity or phrase queries 时可能要用到位置信息</li><li>offsets：索引doc id、词频、位置、开始偏移和结束偏移，高亮功能需要用到offsets</li></ul><h4 id="fielddata"><a href="#fielddata" class="headerlink" title="fielddata"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/fielddata.html" target="_blank" rel="noopener">fielddata</a></h4><ul><li>是否预加载 fielddata，默认为false</li><li>Elasticsearch第一次查询时完整加载这个字段所有 Segment 中的倒排索引到内存中</li><li>如果我们有一些 5 GB 的索引段，并希望加载 10 GB 的 fielddata 到内存中，这个过程可能会要数十秒</li><li>将 fielddate 设置为 true ,将载入 fielddata 的代价转移到索引刷新的时候，而不是查询时，从而大大提高了搜索体验</li><li>参考：<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/preload-fielddata.html" target="_blank" rel="noopener">预加载 fielddata</a></li></ul><h4 id="eager-global-ordinals"><a href="#eager-global-ordinals" class="headerlink" title="eager_global_ordinals"></a>eager_global_ordinals</h4><ul><li>是否预构建全局序号，默认false</li><li>参考：<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/preload-fielddata.html#global-ordinals" target="_blank" rel="noopener">预构建全局序号（Eager global ordinals）</a></li></ul><h4 id="doc-values"><a href="#doc-values" class="headerlink" title="doc_values"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/doc-values.html" target="_blank" rel="noopener">doc_values</a></h4><ul><li>参考：<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/docvalues-and-fielddata.html" target="_blank" rel="noopener">Doc Values and Fielddata</a></li></ul><h4 id="fields"><a href="#fields" class="headerlink" title="fields"></a>fields</h4><ul><li>该参数的目的是为了实现 multi-fields</li><li>一个字段，多种数据类型</li><li>譬如：一个字段 city 的数据类型为 text ，用于全文索引，可以通过 fields 为该字段定义 keyword 类型，用于排序和聚合</li></ul><pre><code># 设置 mappingPUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;properties&quot;: {        &quot;city&quot;: {          &quot;type&quot;: &quot;text&quot;,          &quot;fields&quot;: {            &quot;raw&quot;: {               &quot;type&quot;:  &quot;keyword&quot;            }          }        }      }    }  }}# 插入两条数据PUT my_index/_doc/1{  &quot;city&quot;: &quot;New York&quot;}PUT my_index/_doc/2{  &quot;city&quot;: &quot;York&quot;}# 查询，city用于全文索引 match，city.raw用于排序和聚合GET my_index/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;city&quot;: &quot;york&quot;     }  },  &quot;sort&quot;: {    &quot;city.raw&quot;: &quot;asc&quot;   },  &quot;aggs&quot;: {    &quot;Cities&quot;: {      &quot;terms&quot;: {        &quot;field&quot;: &quot;city.raw&quot;       }    }  }}</code></pre><h4 id="format"><a href="#format" class="headerlink" title="format"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-date-format.html" target="_blank" rel="noopener">format</a></h4><ul><li>由于JSON没有date类型，Elasticsearch预先通过format参数定义时间格式，将匹配的字符串识别为date类型，转换为时间戳（单位：毫秒）</li><li>format默认为：<code>strict_date_optional_time||epoch_millis</code></li><li>Elasticsearch内建的时间格式:</li></ul><table><thead><tr><th>名称</th><th>格式</th></tr></thead><tbody><tr><td>epoch_millis</td><td>时间戳（单位：毫秒）</td></tr><tr><td>epoch_second</td><td>时间戳（单位：秒）</td></tr><tr><td>date_optional_time</td><td></td></tr><tr><td>basic_date</td><td>yyyyMMdd</td></tr><tr><td>basic_date_time</td><td>yyyyMMdd’T’HHmmss.SSSZ</td></tr><tr><td>basic_date_time_no_millis</td><td>yyyyMMdd’T’HHmmssZ</td></tr><tr><td>basic_ordinal_date</td><td>yyyyDDD</td></tr><tr><td>basic_ordinal_date_time</td><td>yyyyDDD’T’HHmmss.SSSZ</td></tr><tr><td>basic_ordinal_date_time_no_millis</td><td>yyyyDDD’T’HHmmssZ</td></tr><tr><td>basic_time</td><td>HHmmss.SSSZ</td></tr><tr><td>basic_time_no_millis</td><td>HHmmssZ</td></tr><tr><td>basic_t_time</td><td>‘T’HHmmss.SSSZ</td></tr><tr><td>basic_t_time_no_millis</td><td>‘T’HHmmssZ</td></tr></tbody></table><ul><li>上述名称加前缀 <code>strict_</code> 表示为严格格式</li><li>更多的查看文档</li></ul><h4 id="properties"><a href="#properties" class="headerlink" title="properties"></a>properties</h4><ul><li>用于_doc，object和nested类型的字段定义<strong>子字段</strong></li></ul><pre><code>PUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {       &quot;properties&quot;: {        &quot;manager&quot;: {           &quot;properties&quot;: {            &quot;age&quot;:  { &quot;type&quot;: &quot;integer&quot; },            &quot;name&quot;: { &quot;type&quot;: &quot;text&quot;  }          }        },        &quot;employees&quot;: {           &quot;type&quot;: &quot;nested&quot;,          &quot;properties&quot;: {            &quot;age&quot;:  { &quot;type&quot;: &quot;integer&quot; },            &quot;name&quot;: { &quot;type&quot;: &quot;text&quot;  }          }        }      }    }  }}PUT my_index/_doc/1 {  &quot;region&quot;: &quot;US&quot;,  &quot;manager&quot;: {    &quot;name&quot;: &quot;Alice White&quot;,    &quot;age&quot;: 30  },  &quot;employees&quot;: [    {      &quot;name&quot;: &quot;John Smith&quot;,      &quot;age&quot;: 34    },    {      &quot;name&quot;: &quot;Peter Brown&quot;,      &quot;age&quot;: 26    }  ]}</code></pre><h4 id="normalizer"><a href="#normalizer" class="headerlink" title="normalizer"></a>normalizer</h4><ul><li>与 analyzer 类似，只不过 analyzer 用于 text 类型字段，分词产生多个 token，而 normalizer 用于 keyword 类型，只产生一个 token（整个字段的值作为一个token，而不是分词拆分为多个token）</li><li>定义一个自定义 normalizer，使用大写uppercase过滤器</li></ul><pre><code>PUT test_index_4{  &quot;settings&quot;: {    &quot;analysis&quot;: {      &quot;normalizer&quot;: {        &quot;my_normalizer&quot;: {          &quot;type&quot;: &quot;custom&quot;,          &quot;char_filter&quot;: [],          &quot;filter&quot;: [&quot;uppercase&quot;, &quot;asciifolding&quot;]        }      }    }  },  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;properties&quot;: {        &quot;foo&quot;: {          &quot;type&quot;: &quot;keyword&quot;,          &quot;normalizer&quot;: &quot;my_normalizer&quot;        }      }    }  }}# 插入数据POST test_index_4/_doc/1{  &quot;foo&quot;: &quot;hello world&quot;}POST test_index_4/_doc/2{  &quot;foo&quot;: &quot;Hello World&quot;}POST test_index_4/_doc/3{  &quot;foo&quot;: &quot;hello elasticsearch&quot;}# 搜索hello，结果为空，而不是3条！！ GET test_index_4/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;foo&quot;: &quot;hello&quot;    }  }}# 搜索 hello world，结果2条，1 和 2GET test_index_4/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;foo&quot;: &quot;hello world&quot;    }  }}</code></pre><h4 id="其他字段"><a href="#其他字段" class="headerlink" title="其他字段"></a>其他字段</h4><ul><li>coerce<ul><li>强制类型转换，把json中的值转为ES中字段的数据类型，譬如：把字符串”5”转为integer的5</li><li>coerce默认为 true</li><li>如果coerce设置为 false，当json的值与es字段类型不匹配将会 rejected</li><li>通过 “settings”: { “index.mapping.coerce”: false } 设置索引的 coerce</li></ul></li><li>enabled<ul><li>是否索引，默认为 true</li><li>可以在_doc和字段两个粒度进行设置</li></ul></li><li>ignore_above<ul><li>设置能被索引的字段的长度</li><li>超过这个长度，该字段将不被索引，所以无法搜索，但聚合的terms可以看到</li></ul></li><li>null_value<ul><li>该字段定义遇到null值时的处理策略，默认为Null，即空值，此时ES会忽略该值</li><li>通过设定该值可以设定字段为 null 时的默认值</li></ul></li><li>ignore_malformed<ul><li>当数据类型不匹配且 coerce 强制转换时,默认情况会抛出异常,并拒绝整个文档的插入</li><li>若设置该参数为 true，则忽略该异常，并强制赋值，但是不会被索引，其他字段则照常</li></ul></li><li>norms<ul><li>norms 存储各种标准化因子，为后续查询计算文档对该查询的匹配分数提供依据</li><li>norms 参数对<strong>评分</strong>很有用，但需要占用大量的磁盘空间</li><li>如果不需要计算字段的评分，可以取消该字段 norms 的功能</li></ul></li><li>position_increment_gap<ul><li>与 proximity queries（近似查询）和 phrase queries（短语查询）有关</li><li>默认值 100</li></ul></li><li>search_analyzer<ul><li>搜索分词器，查询时使用</li><li>默认与 analyzer 一样</li></ul></li><li>similarity<ul><li>设置相关度算法，ES5.x 和 ES6.x 默认的算法为 BM25</li><li>另外也可选择 classic 和 boolean</li></ul></li><li>store<ul><li>store 的意思是：是否在 _source 之外在独立存储一份，默认值为 false</li><li>es在存储数据的时候把json对象存储到”_source”字段里，”_source”把所有字段保存为一份文档存储（读取需要1次IO），要取出某个字段则通过 source filtering 过滤</li><li>当字段比较多或者内容比较多，并且不需要取出所有字段的时候，可以把特定字段的store设置为true单独存储（读取需要1次IO），同时在_source设置exclude</li><li>关于该字段的理解，参考： <a href="https://blog.csdn.net/helllochun/article/details/52136954" target="_blank" rel="noopener">es设置mapping store属性</a></li></ul></li><li>term_vector<ul><li>与倒排索引相关</li></ul></li></ul><h3 id="Dynamic-Mapping"><a href="#Dynamic-Mapping" class="headerlink" title="Dynamic Mapping"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-mapping.html" target="_blank" rel="noopener">Dynamic Mapping</a></h3><p>ES是依靠JSON文档的字段类型来实现自动识别字段类型，支持的类型如下：</p><table><thead><tr><th>JSON 类型</th><th>ES 类型</th></tr></thead><tbody><tr><td>null</td><td>忽略</td></tr><tr><td>boolean</td><td>boolean</td></tr><tr><td>浮点类型</td><td>float</td></tr><tr><td>整数</td><td>long</td></tr><tr><td>object</td><td>object</td></tr><tr><td>array</td><td>由第一个非 null 值的类型决定</td></tr><tr><td>string</td><td>匹配为日期则设为date类型（默认开启）；<br>匹配为数字则设置为 float或long类型（默认关闭）；<br>设为text类型，并附带keyword的子字段</td></tr></tbody></table><p>举栗子</p><pre><code>POST my_index/doc{  &quot;username&quot;:&quot;whirly&quot;,  &quot;age&quot;:22,  &quot;birthday&quot;:&quot;1995-01-01&quot;}GET my_index/_mapping# 结果{  &quot;my_index&quot;: {    &quot;mappings&quot;: {      &quot;doc&quot;: {        &quot;properties&quot;: {          &quot;age&quot;: {            &quot;type&quot;: &quot;long&quot;          },          &quot;birthday&quot;: {            &quot;type&quot;: &quot;date&quot;          },          &quot;username&quot;: {            &quot;type&quot;: &quot;text&quot;,            &quot;fields&quot;: {              &quot;keyword&quot;: {                &quot;type&quot;: &quot;keyword&quot;,                &quot;ignore_above&quot;: 256              }            }          }        }      }    }  }}</code></pre><h4 id="日期的自动识别"><a href="#日期的自动识别" class="headerlink" title="日期的自动识别"></a>日期的自动识别</h4><ul><li>dynamic_date_formats 参数为自动识别的日期格式，默认为 [ “strict_date_optional_time”,”yyyy/MM/dd HH:mm:ss Z||yyyy/MM/dd Z”]</li><li>date_detection可以关闭日期自动识别机制</li></ul><pre><code># 自定义日期识别格式PUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;dynamic_date_formats&quot;: [&quot;MM/dd/yyyy&quot;]    }  }}# 关闭日期自动识别机制PUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;date_detection&quot;: false    }  }}</code></pre><h4 id="数字的自动识别"><a href="#数字的自动识别" class="headerlink" title="数字的自动识别"></a>数字的自动识别</h4><ul><li>字符串是数字时，默认不会自动识别为整形，因为字符串中出现数字完全是合理的</li><li>numeric_detection 参数可以开启字符串中数字的自动识别</li></ul><h3 id="Dynamic-templates"><a href="#Dynamic-templates" class="headerlink" title="Dynamic templates"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-templates.html" target="_blank" rel="noopener">Dynamic templates</a></h3><p>允许根据ES自动识别的数据类型、字段名等来动态设定字段类型，可以实现如下效果：</p><ul><li>所有字符串类型都设定为keyword类型，即不分词</li><li>所有以message开头的字段都设定为text类型，即分词</li><li>所有以long_开头的字段都设定为long类型</li><li>所有自动匹配为double类型的都设定为float类型，以节省空间</li></ul><h4 id="Dynamic-templates-API"><a href="#Dynamic-templates-API" class="headerlink" title="Dynamic templates API"></a>Dynamic templates API</h4><pre><code>&quot;dynamic_templates&quot;: [    {      &quot;my_template_name&quot;: {         ...  match conditions ...         &quot;mapping&quot;: { ... }       }    },    ...]</code></pre><p>匹配规则一般有如下几个参数：</p><ul><li>match_mapping_type 匹配ES自动识别的字段类型，如boolean，long，string等</li><li>match, unmatch 匹配字段名</li><li>match_pattern 匹配正则表达式</li><li>path_match, path_unmatch 匹配路径</li></ul><pre><code># double类型的字段设定为float以节省空间PUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;dynamic_templates&quot;: [        {          &quot;integers&quot;: {            &quot;match_mapping_type&quot;: &quot;double&quot;,            &quot;mapping&quot;: {              &quot;type&quot;: &quot;float&quot;            }          }        }      ]    }  }}</code></pre><h5 id="自定义Mapping的建议"><a href="#自定义Mapping的建议" class="headerlink" title="自定义Mapping的建议"></a>自定义Mapping的建议</h5><ol><li>写入一条文档到ES的临时索引中，获取ES自动生成的Mapping</li><li>修改步骤1得到的Mapping，自定义相关配置</li><li>使用步骤2的Mapping创建实际所需索引</li></ol><h3 id="Index-Template-索引模板"><a href="#Index-Template-索引模板" class="headerlink" title="Index Template 索引模板"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/indices-templates.html" target="_blank" rel="noopener">Index Template 索引模板</a></h3><ul><li>索引模板，主要用于在新建索引时自动应用预先设定的配置，简化索引创建的操作步骤<ul><li>可以设定索引的setting和mapping</li><li>可以有多个模板，根据order设置，order大的覆盖小的配置</li></ul></li><li>索引模板API，endpoint为 _template</li></ul><pre><code># 创建索引模板，匹配 test-index-map 开头的索引PUT _template/template_1{  &quot;index_patterns&quot;: [&quot;test-index-map*&quot;],  &quot;order&quot;: 2,  &quot;settings&quot;: {    &quot;number_of_shards&quot;: 1  },  &quot;mappings&quot;: {    &quot;doc&quot;: {      &quot;_source&quot;: {        &quot;enabled&quot;: false      },      &quot;properties&quot;: {        &quot;name&quot;: {          &quot;type&quot;: &quot;keyword&quot;        },        &quot;created_at&quot;: {          &quot;type&quot;: &quot;date&quot;,          &quot;format&quot;: &quot;YYYY/MM/dd HH:mm:ss&quot;        }      }    }  }}# 插入一个文档POST test-index-map_1/doc{  &quot;name&quot; : &quot;小旋锋&quot;,  &quot;created_at&quot;: &quot;2018/08/16 20:11:11&quot;}# 获取该索引的信息，可以发现 settings 和 mappings 和索引模板里设置的一样GET test-index-map_1# 删除DELETE /_template/template_1# 查询GET /_template/template_1</code></pre><blockquote><p>参考文档： </p><ol><li>elasticsearch 官方文档</li><li><a href="https://coding.imooc.com/class/181.html" target="_blank" rel="noopener">慕课网 Elastic Stack从入门到实践</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>倒排索引与分词</title>
      <link href="/2018/08/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E4%B8%8E%E5%88%86%E8%AF%8D/"/>
      <url>/2018/08/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E4%B8%8E%E5%88%86%E8%AF%8D/</url>
      <content type="html"><![CDATA[<h3 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h3><ul><li>正排索引：文档id到单词的关联关系</li><li>倒排索引：单词到文档id的关联关系</li></ul><p>示例：<br>对以下三个文档去除停用词后构造倒排索引<br><img src="http://image.laijianfeng.org/20180803_223406.png" alt="image"></p><h4 id="倒排索引-查询过程"><a href="#倒排索引-查询过程" class="headerlink" title="倒排索引-查询过程"></a>倒排索引-查询过程</h4><p>查询包含“搜索引擎”的文档</p><ol><li>通过倒排索引获得“搜索引擎”对应的文档id列表，有1，3</li><li>通过正排索引查询1和3的完整内容</li><li>返回最终结果</li></ol><h4 id="倒排索引-组成"><a href="#倒排索引-组成" class="headerlink" title="倒排索引-组成"></a>倒排索引-组成</h4><ul><li>单词词典（Term Dictionary）</li><li>倒排列表（Posting List）</li></ul><h4 id="单词词典（Term-Dictionary）"><a href="#单词词典（Term-Dictionary）" class="headerlink" title="单词词典（Term Dictionary）"></a>单词词典（Term Dictionary）</h4><p>单词词典的实现一般用B+树，B+树构造的可视化过程网址: <a href="https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html" target="_blank" rel="noopener">B+ Tree Visualization</a></p><blockquote><p>关于B树和B+树</p><ol><li><a href="https://zh.wikipedia.org/wiki/B%E6%A0%91" target="_blank" rel="noopener">维基百科-B树</a></li><li><a href="https://zh.wikipedia.org/wiki/B%2B%E6%A0%91" target="_blank" rel="noopener">维基百科-B+树</a></li><li><a href="https://www.cnblogs.com/nullzx/p/8729425.html" target="_blank" rel="noopener">B树和B+树的插入、删除图文详解</a></li></ol></blockquote><p><img src="http://image.laijianfeng.org/20180803_225118.png" alt="image"></p><h4 id="倒排列表（Posting-List）"><a href="#倒排列表（Posting-List）" class="headerlink" title="倒排列表（Posting List）"></a>倒排列表（Posting List）</h4><ul><li>倒排列表记录了单词对应的文档集合，有倒排索引项（Posting）组成</li><li>倒排索引项主要包含如下信息：<ol><li>文档id用于获取原始信息</li><li>单词频率（TF，Term Frequency），记录该单词在该文档中出现的次数，用于后续相关性算分</li><li>位置（Posting），记录单词在文档中的分词位置（多个），用于做词语搜索（Phrase Query）</li><li>偏移（Offset），记录单词在文档的开始和结束位置，用于高亮显示</li></ol></li></ul><p><img src="http://image.laijianfeng.org/20180803_225931.png" alt="image"></p><p>B+树<strong>内部结点存索引，叶子结点存数据</strong>，这里的 单词词典就是B+树索引，倒排列表就是数据，整合在一起后如下所示</p><p><img src="http://image.laijianfeng.org/20180803_232214.png" alt="image"></p><p>ES存储的是一个JSON格式的文档，其中包含多个字段，每个字段会有自己的倒排索引</p><h3 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h3><p>分词是将文本转换成一系列单词（Term or Token）的过程，也可以叫文本分析，在ES里面称为Analysis</p><p><img src="http://image.laijianfeng.org/20180803_232909.png" alt="image"></p><h4 id="分词器"><a href="#分词器" class="headerlink" title="分词器"></a>分词器</h4><p>分词器是ES中专门处理分词的组件，英文为Analyzer，它的组成如下：</p><ul><li>Character Filters：针对原始文本进行处理，比如去除html标签</li><li>Tokenizer：将原始文本按照一定规则切分为单词</li><li>Token Filters：针对Tokenizer处理的单词进行再加工，比如转小写、删除或增新等处理</li></ul><p>分词器调用顺序<br><img src="http://image.laijianfeng.org/20180803_234047.png" alt="image"></p><h3 id="Analyze-API"><a href="#Analyze-API" class="headerlink" title="Analyze API"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis.html" target="_blank" rel="noopener">Analyze API</a></h3><p>ES提供了一个可以测试分词的API接口，方便验证分词效果，endpoint是_analyze</p><ul><li>可以直接指定analyzer进行测试</li></ul><p><img src="http://image.laijianfeng.org/20180803_234732.png" alt="image"></p><ul><li>可以直接指定索引中的字段进行测试</li></ul><pre><code>POST test_index/doc{  &quot;username&quot;: &quot;whirly&quot;,  &quot;age&quot;:22}POST test_index/_analyze{  &quot;field&quot;: &quot;username&quot;,  &quot;text&quot;: [&quot;hello world&quot;]}</code></pre><ul><li>可以自定义分词器进行测试</li></ul><pre><code>POST _analyze{  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;filter&quot;: [&quot;lowercase&quot;],  &quot;text&quot;: [&quot;Hello World&quot;]}</code></pre><h3 id="预定义的分词器"><a href="#预定义的分词器" class="headerlink" title="预定义的分词器"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-analyzers.html" target="_blank" rel="noopener">预定义的分词器</a></h3><p>ES自带的分词器有如下：</p><ul><li>Standard Analyzer<ul><li>默认分词器</li><li>按词切分，支持多语言</li><li>小写处理</li></ul></li><li>Simple Analyzer<ul><li>按照非字母切分</li><li>小写处理</li></ul></li><li>Whitespace Analyzer<ul><li>空白字符作为分隔符</li></ul></li><li>Stop Analyzer<ul><li>相比Simple Analyzer多了去除请用词处理</li><li>停用词指语气助词等修饰性词语，如the, an, 的， 这等</li></ul></li><li>Keyword Analyzer<ul><li>不分词，直接将输入作为一个单词输出</li></ul></li><li>Pattern Analyzer<ul><li>通过正则表达式自定义分隔符</li><li>默认是\W+，即非字词的符号作为分隔符</li></ul></li><li>Language Analyzer<ul><li>提供了30+种常见语言的分词器</li></ul></li></ul><p>示例：停用词分词器</p><pre><code>POST _analyze{  &quot;analyzer&quot;: &quot;stop&quot;,  &quot;text&quot;: [&quot;The 2 QUICK Brown Foxes jumped over the lazy dog&#39;s bone.&quot;]}</code></pre><p>结果</p><pre><code>{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;quick&quot;,      &quot;start_offset&quot;: 6,      &quot;end_offset&quot;: 11,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 1    },    {      &quot;token&quot;: &quot;brown&quot;,      &quot;start_offset&quot;: 12,      &quot;end_offset&quot;: 17,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 2    },    {      &quot;token&quot;: &quot;foxes&quot;,      &quot;start_offset&quot;: 18,      &quot;end_offset&quot;: 23,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 3    },    {      &quot;token&quot;: &quot;jumped&quot;,      &quot;start_offset&quot;: 24,      &quot;end_offset&quot;: 30,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 4    },    {      &quot;token&quot;: &quot;over&quot;,      &quot;start_offset&quot;: 31,      &quot;end_offset&quot;: 35,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 5    },    {      &quot;token&quot;: &quot;lazy&quot;,      &quot;start_offset&quot;: 40,      &quot;end_offset&quot;: 44,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 7    },    {      &quot;token&quot;: &quot;dog&quot;,      &quot;start_offset&quot;: 45,      &quot;end_offset&quot;: 48,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 8    },    {      &quot;token&quot;: &quot;s&quot;,      &quot;start_offset&quot;: 49,      &quot;end_offset&quot;: 50,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 9    },    {      &quot;token&quot;: &quot;bone&quot;,      &quot;start_offset&quot;: 51,      &quot;end_offset&quot;: 55,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 10    }  ]}</code></pre><h3 id="中文分词"><a href="#中文分词" class="headerlink" title="中文分词"></a>中文分词</h3><ul><li>难点<ul><li>中文分词指的是将一个汉字序列切分为一个一个的单独的词。在英文中，单词之间以空格作为自然分界词，汉语中词没有一个形式上的分界符</li><li>上下文不同，分词结果迥异，比如交叉歧义问题</li></ul></li><li>常见分词系统<ul><li><a href="https://github.com/medcl/elasticsearch-analysis-ik" target="_blank" rel="noopener">IK</a>：实现中英文单词的切分，可自定义词库，支持热更新分词词典</li><li><a href="https://github.com/sing1ee/elasticsearch-jieba-plugin" target="_blank" rel="noopener">jieba</a>：支持分词和词性标注，支持繁体分词，自定义词典，并行分词等</li><li><a href="https://github.com/hankcs/HanLP" target="_blank" rel="noopener">Hanlp</a>：由一系列模型与算法组成的Java工具包，目标是普及自然语言处理在生产环境中的应用</li><li><a href="https://github.com/microbun/elasticsearch-thulac-plugin" target="_blank" rel="noopener">THUAC</a>：中文分词和词性标注</li></ul></li></ul><h4 id="安装ik中文分词插件"><a href="#安装ik中文分词插件" class="headerlink" title="安装ik中文分词插件"></a>安装ik中文分词插件</h4><pre><code># 在Elasticsearch安装目录下执行命令，然后重启esbin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.3.0/elasticsearch-analysis-ik-6.3.0.zip# 如果由于网络慢，安装失败，可以先下载好zip压缩包，将下面命令改为实际的路径，执行，然后重启esbin/elasticsearch-plugin install file:///path/to/elasticsearch-analysis-ik-6.3.0.zip</code></pre><ul><li>ik测试 - ik_smart</li></ul><pre><code>POST _analyze{  &quot;analyzer&quot;: &quot;ik_smart&quot;,  &quot;text&quot;: [&quot;公安部：各地校车将享最高路权&quot;]}# 结果{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;公安部&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 3,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 0    },    {      &quot;token&quot;: &quot;各地&quot;,      &quot;start_offset&quot;: 4,      &quot;end_offset&quot;: 6,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 1    },    {      &quot;token&quot;: &quot;校车&quot;,      &quot;start_offset&quot;: 6,      &quot;end_offset&quot;: 8,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 2    },    {      &quot;token&quot;: &quot;将&quot;,      &quot;start_offset&quot;: 8,      &quot;end_offset&quot;: 9,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 3    },    {      &quot;token&quot;: &quot;享&quot;,      &quot;start_offset&quot;: 9,      &quot;end_offset&quot;: 10,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 4    },    {      &quot;token&quot;: &quot;最高&quot;,      &quot;start_offset&quot;: 10,      &quot;end_offset&quot;: 12,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 5    },    {      &quot;token&quot;: &quot;路&quot;,      &quot;start_offset&quot;: 12,      &quot;end_offset&quot;: 13,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 6    },    {      &quot;token&quot;: &quot;权&quot;,      &quot;start_offset&quot;: 13,      &quot;end_offset&quot;: 14,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 7    }  ]}</code></pre><ul><li>ik测试 - ik_max_word</li></ul><pre><code>POST _analyze{  &quot;analyzer&quot;: &quot;ik_max_word&quot;,  &quot;text&quot;: [&quot;公安部：各地校车将享最高路权&quot;]}# 结果{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;公安部&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 3,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 0    },    {      &quot;token&quot;: &quot;公安&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 2,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 1    },    {      &quot;token&quot;: &quot;部&quot;,      &quot;start_offset&quot;: 2,      &quot;end_offset&quot;: 3,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 2    },    {      &quot;token&quot;: &quot;各地&quot;,      &quot;start_offset&quot;: 4,      &quot;end_offset&quot;: 6,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 3    },    {      &quot;token&quot;: &quot;校车&quot;,      &quot;start_offset&quot;: 6,      &quot;end_offset&quot;: 8,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 4    },    {      &quot;token&quot;: &quot;将&quot;,      &quot;start_offset&quot;: 8,      &quot;end_offset&quot;: 9,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 5    },    {      &quot;token&quot;: &quot;享&quot;,      &quot;start_offset&quot;: 9,      &quot;end_offset&quot;: 10,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 6    },    {      &quot;token&quot;: &quot;最高&quot;,      &quot;start_offset&quot;: 10,      &quot;end_offset&quot;: 12,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 7    },    {      &quot;token&quot;: &quot;路&quot;,      &quot;start_offset&quot;: 12,      &quot;end_offset&quot;: 13,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 8    },    {      &quot;token&quot;: &quot;权&quot;,      &quot;start_offset&quot;: 13,      &quot;end_offset&quot;: 14,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 9    }  ]}</code></pre><ul><li><p>ik两种分词模式ik_max_word 和 ik_smart 什么区别?</p><ul><li><p>ik_max_word: 会将文本做最细粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,和,国国,国歌”，会穷尽各种可能的组合；</p></li><li><p>ik_smart: 会做最粗粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,国歌”。</p></li></ul></li></ul><h3 id="自定义分词"><a href="#自定义分词" class="headerlink" title="自定义分词"></a>自定义分词</h3><p>当自带的分词无法满足需求时，可以自定义分词，通过定义Character Filters、Tokenizer和Token Filters实现</p><h4 id="Character-Filters"><a href="#Character-Filters" class="headerlink" title="Character Filters"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-charfilters.html" target="_blank" rel="noopener">Character Filters</a></h4><ul><li>在Tokenizer之前对原始文本进行处理，比如增加、删除或替换字符等</li><li>自带的如下:<ul><li>HTML Strip Character Filter：去除HTML标签和转换HTML实体</li><li>Mapping Character Filter：进行字符替换操作</li><li>Pattern Replace Character Filter：进行正则匹配替换</li></ul></li><li>会影响后续tokenizer解析的position和offset信息</li></ul><h4 id="Character-Filters测试"><a href="#Character-Filters测试" class="headerlink" title="Character Filters测试"></a>Character Filters测试</h4><pre><code>POST _analyze{  &quot;tokenizer&quot;: &quot;keyword&quot;,  &quot;char_filter&quot;: [&quot;html_strip&quot;],  &quot;text&quot;: [&quot;&lt;p&gt;I&amp;apos;m so &lt;b&gt;happy&lt;/b&gt;!&lt;/p&gt;&quot;]}# 结果{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;&quot;&quot;I&#39;m so happy!&quot;&quot;&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 32,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 0    }  ]}</code></pre><h4 id="Tokenizers"><a href="#Tokenizers" class="headerlink" title="Tokenizers"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenizers.html" target="_blank" rel="noopener">Tokenizers</a></h4><ul><li>将原始文本按照一定规则切分为单词（term or token）</li><li>自带的如下：<ul><li>standard 按照单词进行分割</li><li>letter 按照非字符类进行分割</li><li>whitespace 按照空格进行分割</li><li>UAX URL Email 按照standard进行分割，但不会分割邮箱和URL</li><li>Ngram 和 Edge NGram 连词分割</li><li>Path Hierarchy 按照文件路径进行分割</li></ul></li></ul><h4 id="Tokenizers-测试"><a href="#Tokenizers-测试" class="headerlink" title="Tokenizers 测试"></a>Tokenizers 测试</h4><pre><code>POST _analyze{  &quot;tokenizer&quot;: &quot;path_hierarchy&quot;,  &quot;text&quot;: [&quot;/path/to/file&quot;]}# 结果{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;/path&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 5,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 0    },    {      &quot;token&quot;: &quot;/path/to&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 8,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 0    },    {      &quot;token&quot;: &quot;/path/to/file&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 13,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 0    }  ]}</code></pre><h4 id="Token-Filters"><a href="#Token-Filters" class="headerlink" title="Token Filters"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenfilters.html" target="_blank" rel="noopener">Token Filters</a></h4><ul><li>对于tokenizer输出的单词（term）进行增加、删除、修改等操作</li><li>自带的如下：<ul><li>lowercase 将所有term转为小写</li><li>stop 删除停用词</li><li>Ngram 和 Edge NGram 连词分割</li><li>Synonym 添加近义词的term</li></ul></li></ul><h4 id="Token-Filters测试"><a href="#Token-Filters测试" class="headerlink" title="Token Filters测试"></a>Token Filters测试</h4><pre><code>POST _analyze{  &quot;text&quot;: [    &quot;a Hello World!&quot;  ],  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;filter&quot;: [    &quot;stop&quot;,    &quot;lowercase&quot;,    {      &quot;type&quot;: &quot;ngram&quot;,      &quot;min_gram&quot;: 4,      &quot;max_gram&quot;: 4    }  ]}# 结果{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;hell&quot;,      &quot;start_offset&quot;: 2,      &quot;end_offset&quot;: 7,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 1    },    {      &quot;token&quot;: &quot;ello&quot;,      &quot;start_offset&quot;: 2,      &quot;end_offset&quot;: 7,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 1    },    {      &quot;token&quot;: &quot;worl&quot;,      &quot;start_offset&quot;: 8,      &quot;end_offset&quot;: 13,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 2    },    {      &quot;token&quot;: &quot;orld&quot;,      &quot;start_offset&quot;: 8,      &quot;end_offset&quot;: 13,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 2    }  ]}</code></pre><h4 id="自定义分词-1"><a href="#自定义分词-1" class="headerlink" title="自定义分词"></a>自定义分词</h4><p>自定义分词需要在索引配置中设定 char_filter、tokenizer、filter、analyzer等</p><p>自定义分词示例:</p><ul><li>分词器名称：my_custom\</li><li>过滤器将token转为大写</li></ul><pre><code>PUT test_index_1{  &quot;settings&quot;: {    &quot;analysis&quot;: {      &quot;analyzer&quot;: {        &quot;my_custom_analyzer&quot;: {          &quot;type&quot;:      &quot;custom&quot;,          &quot;tokenizer&quot;: &quot;standard&quot;,          &quot;char_filter&quot;: [            &quot;html_strip&quot;          ],          &quot;filter&quot;: [            &quot;uppercase&quot;,            &quot;asciifolding&quot;          ]        }      }    }  }}</code></pre><h4 id="自定义分词器测试"><a href="#自定义分词器测试" class="headerlink" title="自定义分词器测试"></a>自定义分词器测试</h4><pre><code>POST test_index_1/_analyze{  &quot;analyzer&quot;: &quot;my_custom_analyzer&quot;,  &quot;text&quot;: [&quot;&lt;p&gt;I&amp;apos;m so &lt;b&gt;happy&lt;/b&gt;!&lt;/p&gt;&quot;]}# 结果{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;I&#39;M&quot;,      &quot;start_offset&quot;: 3,      &quot;end_offset&quot;: 11,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 0    },    {      &quot;token&quot;: &quot;SO&quot;,      &quot;start_offset&quot;: 12,      &quot;end_offset&quot;: 14,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 1    },    {      &quot;token&quot;: &quot;HAPPY&quot;,      &quot;start_offset&quot;: 18,      &quot;end_offset&quot;: 27,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 2    }  ]}</code></pre><h4 id="分词使用说明"><a href="#分词使用说明" class="headerlink" title="分词使用说明"></a>分词使用说明</h4><p>分词会在如下两个时机使用：</p><ul><li>创建或更新文档时(Index Time)，会对相应的文档进行分词处理</li><li>查询时（Search Time），会对查询语句进行分词<ul><li>查询时通过analyzer指定分词器</li><li>通过index mapping设置search_analyzer实现</li><li>一般不需要特别指定查询时分词器，直接使用索引分词器即可，否则会出现无法匹配的情况</li></ul></li></ul><h4 id="分词使用建议"><a href="#分词使用建议" class="headerlink" title="分词使用建议"></a>分词使用建议</h4><ul><li>明确字段是否需要分词，不需要分词的字段就将type设置为keyword，可以节省空间和提高写性能</li><li>善用_analyze API，查看文档的分词结果</li></ul><blockquote><p>更多内容请访问我的个人网站： <a href="http://laijianfeng.org">http://laijianfeng.org</a><br>参考文档： </p><ol><li>elasticsearch 官方文档</li><li><a href="https://coding.imooc.com/class/181.html" target="_blank" rel="noopener">慕课网 Elastic Stack从入门到实践</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ElasticSearch初体验</title>
      <link href="/2018/08/ElasticSearch%E5%88%9D%E4%BD%93%E9%AA%8C/"/>
      <url>/2018/08/ElasticSearch%E5%88%9D%E4%BD%93%E9%AA%8C/</url>
      <content type="html"><![CDATA[<h3 id="需要明白的问题"><a href="#需要明白的问题" class="headerlink" title="需要明白的问题"></a>需要明白的问题</h3><ol><li>什么是倒排索引？它的组成是什么？</li><li>常见的相关性算分方法有哪些？</li><li>为什么查询语句没有返回预期的文档？</li><li>常用的数据类型有哪些？Text和Keyword的区别是什么？</li><li>集群是如何搭建起来的？是如何实现故障转移的？</li><li>Shard具体是由什么组成的？</li></ol><h2 id="Elastic-Stack"><a href="#Elastic-Stack" class="headerlink" title="Elastic Stack"></a>Elastic Stack</h2><p>构建在开源基础之上, Elastic Stack 让您能够安全可靠地获取任何来源、任何格式的数据，并且能够实时地对数据进行搜索、分析和可视化</p><p><strong>Elasticsearch</strong> 是基于 JSON 的分布式搜索和分析引擎，专为实现水平扩展、高可用和管理便捷性而设计。</p><p><strong>Kibana</strong> 能够以图表的形式呈现数据，并且具有可扩展的用户界面，供您全方位配置和管理 Elastic Stack。</p><p><strong>Logstash</strong> 是动态数据收集管道，拥有可扩展的插件生态系统，能够与 Elasticsearch 产生强大的协同作用。</p><p><strong>Beats</strong> 是轻量型采集器的平台，从边缘机器向 Logstash 和 Elasticsearch 发送数据。</p><h3 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/_basic_concepts.html" target="_blank" rel="noopener">基础概念</a></h3><ul><li>文档 Document ：用户存储在ES中的数据文档</li><li>索引 Index ：由具有一些相同字段的文档的集合</li><li>类型 Type :  允许将不同类型的文档存储在同一索引中，6.0开始官方不允许在一个index下建立多个type，统一type名称：doc</li><li>节点 Node ：一个Elasticsearch的运行实例，是集群的构成单元，存储部分或全部数据，并参与集群的索引和搜索功能</li><li>集群 Cluster ：由一个或多个节点组成的集合，共同保存所有的数据，对外提供服务（包括跨所有节点的联合索引和搜索功能等）</li><li>分片 Shards ：分片是为了解决存储大规模数据的问题，将数据切分分别存储到不同的分片中</li><li>副本 Replicas ：副本可以在分片或节点发生故障时提高可用性，而且由于可以在所有副本上进行并行搜索，所以也可以提高集群的吞吐量</li><li>近实时 Near Realtime(NRT)：从索引文档到可搜索文档的时间有一点延迟（通常为一秒）</li></ul><blockquote><p>note:</p><ol><li>在创建索引的时候如果没有配置索引Mapping，一个索引默认有5个shard和1个副本，一个索引总共有10个shard（算上副本shard）</li><li>Elasticsearch 的shard实际上是一个Lucene索引，截止Lucene-5843，一个Lucene索引限制的最大文档数为2,147,483,519 (= Integer.MAX_VALUE - 128)</li></ol></blockquote><h3 id="安装Elasticsearch-amp-Kibana"><a href="#安装Elasticsearch-amp-Kibana" class="headerlink" title="安装Elasticsearch &amp; Kibana"></a>安装Elasticsearch &amp; Kibana</h3><p>ES和Kibana的安装很简单，前提需要先安装好Java8，然后执行以下命令即可</p><h5 id="elasticsearch单节点最简安装"><a href="#elasticsearch单节点最简安装" class="headerlink" title="elasticsearch单节点最简安装"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/_installation.html" target="_blank" rel="noopener">elasticsearch单节点最简安装</a></h5><pre><code># 在Ubuntu16.04上安装，方式有很多种，选择二进制压缩包的方式安装# 1. 在普通用户家目录下，下载压缩包curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.3.2.tar.gz# 2. 解压tar -xvf elasticsearch-6.3.2.tar.gz# 3. 移动至/opt目录下sudo mv elasticsearch-6.3.2 /opt# 4. 修改配置文件elasticsearch.yml中的 network.host 值为 0.0.0.0，其他的配置参考官方文档cd /opt/elasticsearch-6.3.2vi config/elasticsearch.yml# 5. 启动单节点，然后浏览器访问host:9200即可看到ES集群信息bin/elasticsearch</code></pre><p><img src="http://image.laijianfeng.org/20180815_153244.png" alt="image"></p><h5 id="kibana最简安装"><a href="#kibana最简安装" class="headerlink" title="kibana最简安装"></a><a href="https://www.elastic.co/guide/en/kibana/current/targz.html" target="_blank" rel="noopener">kibana最简安装</a></h5><pre><code>wget https://artifacts.elastic.co/downloads/kibana/kibana-6.3.2-linux-x86_64.tar.gzshasum -a 512 kibana-6.3.2-linux-x86_64.tar.gz tar -xzf kibana-6.3.2-linux-x86_64.tar.gzsudo mv kibana-6.3.2-linux-x86_64 /optcd /opt/kibana-6.3.2-linux-x86_64# 修改 config/kibana.yml中 server.host: 0.0.0.0# 启动Kibana，访问 host:5601即可进入kibana界面</code></pre><p><img src="http://image.laijianfeng.org/20180815_153435.png" alt="image"></p><h3 id="交互方式-Rest-API"><a href="#交互方式-Rest-API" class="headerlink" title="交互方式 Rest API"></a>交互方式 Rest API</h3><p>Elasticsearch集群对外提供RESTful API</p><ul><li>Curl命令行</li><li>Kibana Devtools</li><li>Java API</li><li>其他各种API，如Python API等</li></ul><blockquote><p>note:<br>我们后面主要使用 Kibana Devtools 这种交互方式</p></blockquote><p><img src="http://image.laijianfeng.org/20180815_154136.png" alt="image"></p><h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html" target="_blank" rel="noopener">数据类型</a></h3><ul><li>字符串： text（分词）, keyword（不分词）</li><li>数值型： long, integer, byte, double, float, half_float, scaled_float</li><li>布尔： boolean</li><li>日期： date</li><li>二进制： binary</li><li>范围类型： integer_range, float_range, long_range, double_range, date_range</li><li>复杂数据类型： Array, Object, Nested</li><li>地理： geo_point， geo_shape</li><li>专业： ip，completion， token_count， murmur3， Percolator， join</li><li>组合的</li></ul><h3 id="探索ES集群"><a href="#探索ES集群" class="headerlink" title="探索ES集群"></a>探索ES集群</h3><p>Check your cluster, node, and index health, status, and statistics<br>Administer your cluster, node, and index data and metadata<br>Perform CRUD (Create, Read, Update, and Delete) and search operations against your indexes<br>Execute advanced search operations such as paging, sorting, filtering, scripting, aggregations, and many others</p><h5 id="使用-cat-API探索集群的健康情况"><a href="#使用-cat-API探索集群的健康情况" class="headerlink" title="使用_cat API探索集群的健康情况"></a>使用_cat API探索集群的健康情况</h5><pre><code>GET /_cat/health?v# 结果epoch      timestamp cluster       status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent1534319381 15:49:41  elasticsearch green           3         3    118  59    0    0        0             0                  -                100.0%</code></pre><p>集群的健康状态(status)有三种:</p><ul><li>green：一切正常（集群功能齐全）</li><li>yellow：所有数据都可用，但存在一些副本未分配（群集功能齐全）</li><li>red：一些数据由于某种原因不可用（群集部分功能失效）</li></ul><h5 id="查看节点信息"><a href="#查看节点信息" class="headerlink" title="查看节点信息"></a>查看节点信息</h5><pre><code>GET /_cat/nodes?v# 结果（我的ES集群安装了三个节点）ip            heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name10.100.97.207           30          96  13    0.15    0.08     0.08 mdi       *      master10.100.97.246           68          96   3    0.00    0.00     0.00 mdi       -      hadoop210.100.98.22            15          97   2    0.00    0.02     0.04 mdi       -      hadoop3</code></pre><h5 id="查看索引信息"><a href="#查看索引信息" class="headerlink" title="查看索引信息"></a>查看索引信息</h5><pre><code>GET /_cat/indices?v# 结果health status index                           uuid                   pri rep docs.count docs.deleted store.size pri.store.sizegreen  open   logstash-2015.05.20             4BjPjpq6RhOSCNUPMsY0MQ   5   1       4750            0     46.8mb         24.5mbgreen  open   logstash-2015.05.18             mDkUKHSWR0a8UeZlKzts8Q   5   1       4631            0     45.6mb         23.8mbgreen  open   hockey                          g1omiazvRSOE117w_uy_wA   5   1         11            0     45.3kb         22.6kbgreen  open   .kibana                         AGdo8im_TxC04ARexUxqxw   1   1        143           10    665.6kb        332.8kbgreen  open   shakespeare                     5009bDa7T16f5qTeyOdTlw   5   1     111396            0     43.9mb           22mbgreen  open   logstash-2015.05.19             az4Jen4nT7-J9yRYpZ0A9A   5   1       4624            0     44.7mb         23.1mb...</code></pre><h3 id="操作数据"><a href="#操作数据" class="headerlink" title="操作数据"></a>操作数据</h3><h5 id="插入文档并查询"><a href="#插入文档并查询" class="headerlink" title="插入文档并查询"></a>插入文档并查询</h5><pre><code># 插入一个文档PUT /customer/_doc/1?pretty{  &quot;name&quot;: &quot;John Doe&quot;}# 结果{  &quot;_index&quot;: &quot;customer&quot;,  &quot;_type&quot;: &quot;_doc&quot;,  &quot;_id&quot;: &quot;1&quot;,  &quot;_version&quot;: 1,  &quot;result&quot;: &quot;updated&quot;,  &quot;_shards&quot;: {    &quot;total&quot;: 2,    &quot;successful&quot;: 2,    &quot;failed&quot;: 0  },  &quot;_seq_no&quot;: 1,  &quot;_primary_term&quot;: 1}# 查询该文档GET /customer/_doc/1#结果{  &quot;_index&quot;: &quot;customer&quot;,  &quot;_type&quot;: &quot;_doc&quot;,  &quot;_id&quot;: &quot;1&quot;,  &quot;_version&quot;: 1,  &quot;found&quot;: true,  &quot;_source&quot;: {    &quot;name&quot;: &quot;John Doe&quot;  }}</code></pre><blockquote><p>note:</p><ol><li><code>customer</code> 为索引名，<code>_doc</code> 为type，1为文档_id，需要注意的是：在es6.x建议索引的type值固定为<code>_doc</code>，在之后的版本将删除type了；文档id若不指定，es会自动分配一个_id给文档</li><li>插入文档后，查看索引信息<code>GET /_cat/indices?v</code>可以看到多了 customer 的索引信息</li><li>文档结果，_source字段是原始的json内容，其他的为文档元数据</li></ol></blockquote><h5 id="文档元数据"><a href="#文档元数据" class="headerlink" title="文档元数据"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-fields.html" target="_blank" rel="noopener">文档元数据</a></h5><p>用于标注文档的元信息</p><ul><li>_index: 文档所在的索引名</li><li>_type: 文档所在的类型名</li><li>_id: 文档的唯一id</li><li>_uid: 组合id，由_type和_id组成（6.0开始_type不再起作用，同_id一样）</li><li>_source: 文档的原始json数据，可以从这里获取每个字段的内容</li><li>_all: 整合所有字段内容到该字段，默认禁用</li><li>_routing 默认值为 _id，决定文档存储在哪个shard上：<code>shard_num = hash(_routing) % num_primary_shards</code> </li></ul><h5 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h5><pre><code>DELETE customer#结果{  &quot;acknowledged&quot;: true}GET /_cat/indices?v# 再次查看索引信息，可以发现 customer 不存在，已被删除</code></pre><h5 id="更新文档"><a href="#更新文档" class="headerlink" title="更新文档"></a>更新文档</h5><pre><code>PUT /customer/_doc/1?pretty{  &quot;name&quot;: &quot;John Doe&quot;}POST /customer/_doc/1/_update{  &quot;doc&quot;: { &quot;name&quot;: &quot;Jane Doe&quot; }}POST /customer/_doc/1/_update{  &quot;doc&quot;: { &quot;name&quot;: &quot;Jane Doe&quot;, &quot;age&quot;: 20 }}# 可以看到 \_version的值一直在增加</code></pre><h5 id="删除文档"><a href="#删除文档" class="headerlink" title="删除文档"></a>删除文档</h5><pre><code>DELETE /customer/_doc/2</code></pre><h5 id="批量操作"><a href="#批量操作" class="headerlink" title="批量操作"></a>批量操作</h5><p>es提供了<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/docs-bulk.html" target="_blank" rel="noopener">_bulk API</a>供批量操作，可以提高索引、更新、删除等操作的效率</p><p>_bulk操作的类型有四种：</p><ul><li>index 索引：若已存在，则覆盖，文档不存在则创建</li><li>create 创建：文档不存在则异常</li><li>delete 删除</li><li>update 更新</li></ul><pre><code># _bulk 任务：# 1. index创建 customer索引下id为3的文档# 2. delete删除 customer索引下id为3的文档# 3. create创建 customer索引下id为3的文档# 4. update更新 customer索引下id为3的文档POST _bulk{&quot;index&quot;:{&quot;_index&quot;:&quot;customer&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;3&quot;}}{&quot;name&quot;:&quot;whirly&quot;}{&quot;delete&quot;:{&quot;_index&quot;:&quot;customer&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;3&quot;}}{&quot;create&quot;:{&quot;_index&quot;:&quot;customer&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;3&quot;}}{&quot;name&quot;:&quot;whirly2&quot;}{&quot;update&quot;:{&quot;_index&quot;:&quot;customer&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;3&quot;}}{&quot;doc&quot;:{&quot;name&quot;:&quot;whirly3&quot;}}</code></pre><p><img src="http://image.laijianfeng.org/20180815_164226.png" alt="image"></p><blockquote><p>note:</p><ol><li>批量查询用的是 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/docs-multi-get.html" target="_blank" rel="noopener">Multi Get API</a></li></ol></blockquote><h3 id="探索数据"><a href="#探索数据" class="headerlink" title="探索数据"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/_exploring_your_data.html" target="_blank" rel="noopener">探索数据</a></h3><p>一个<a href="https://raw.githubusercontent.com/elastic/elasticsearch/master/docs/src/test/resources/accounts.json" target="_blank" rel="noopener">简单的数据集</a>，数据结构如下：</p><pre><code>{    &quot;account_number&quot;: 0,    &quot;balance&quot;: 16623,    &quot;firstname&quot;: &quot;Bradshaw&quot;,    &quot;lastname&quot;: &quot;Mckenzie&quot;,    &quot;age&quot;: 29,    &quot;gender&quot;: &quot;F&quot;,    &quot;address&quot;: &quot;244 Columbus Place&quot;,    &quot;employer&quot;: &quot;Euron&quot;,    &quot;email&quot;: &quot;bradshawmckenzie@euron.com&quot;,    &quot;city&quot;: &quot;Hobucken&quot;,    &quot;state&quot;: &quot;CO&quot;}</code></pre><p>导入这个简单的数据集到es中</p><pre><code># 下载wget https://raw.githubusercontent.com/elastic/elasticsearch/master/docs/src/test/resources/accounts.json# 导入curl -H &quot;Content-Type: application/json&quot; -XPOST &quot;localhost:9200/bank/_doc/_bulk?pretty&amp;refresh&quot; --data-binary &quot;@accounts.json&quot;</code></pre><p>上述命令是通过 _bulk API 将 account.json 的内容插入 bank 索引中，type 为 _doc</p><pre><code># account.json的内容:{&quot;index&quot;:{&quot;_id&quot;:&quot;1&quot;}}{&quot;account_number&quot;:1,&quot;balance&quot;:39225,&quot;firstname&quot;:&quot;Amber&quot;,&quot;lastname&quot;:&quot;Duke&quot;,&quot;age&quot;:32,&quot;gender&quot;:&quot;M&quot;,&quot;address&quot;:&quot;880 Holmes Lane&quot;,&quot;employer&quot;:&quot;Pyrami&quot;,&quot;email&quot;:&quot;amberduke@pyrami.com&quot;,&quot;city&quot;:&quot;Brogan&quot;,&quot;state&quot;:&quot;IL&quot;}...# 导入完成后可以看到 bank 索引已存在 1000 条数据GET bank/_search</code></pre><h5 id="查询数据-API"><a href="#查询数据-API" class="headerlink" title="查询数据 API"></a>查询数据 API</h5><p>任务：查询所有数据，根据 account_number 字段升序排序</p><ol><li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/search-uri-request.html#search-uri-request" target="_blank" rel="noopener">URI Search 方式</a></p><pre><code>GET /bank/_search?q=*&amp;sort=account_number:asc&amp;pretty</code></pre></li><li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/search-request-body.html" target="_blank" rel="noopener">Request Body Search</a> 方式</p><pre><code>GET /bank/_search{&quot;query&quot;: { &quot;match_all&quot;: {} },&quot;sort&quot;: [ { &quot;account_number&quot;: &quot;asc&quot; }]}</code></pre></li></ol><p>结果</p><pre><code>{  &quot;took&quot;: 41,  &quot;timed_out&quot;: false,  &quot;_shards&quot;: {    &quot;total&quot;: 5,    &quot;successful&quot;: 5,    &quot;skipped&quot;: 0,    &quot;failed&quot;: 0  },  &quot;hits&quot;: {    &quot;total&quot;: 1000,    &quot;max_score&quot;: null,    &quot;hits&quot;: [      {        &quot;_index&quot;: &quot;bank&quot;,        &quot;_type&quot;: &quot;account&quot;,        &quot;_id&quot;: &quot;0&quot;,        &quot;_score&quot;: null,        &quot;_source&quot;: {          &quot;account_number&quot;: 0,          &quot;balance&quot;: 16623,          &quot;firstname&quot;: &quot;Bradshaw&quot;,          &quot;lastname&quot;: &quot;Mckenzie&quot;,          &quot;age&quot;: 29,          &quot;gender&quot;: &quot;F&quot;,          &quot;address&quot;: &quot;244 Columbus Place&quot;,          &quot;employer&quot;: &quot;Euron&quot;,          &quot;email&quot;: &quot;bradshawmckenzie@euron.com&quot;,          &quot;city&quot;: &quot;Hobucken&quot;,          &quot;state&quot;: &quot;CO&quot;        },        &quot;sort&quot;: [          0        ]      }...    ]  }}</code></pre><p>各个参数意思：</p><ul><li>took：本次查询耗费的时间（单位：毫秒）</li><li>timed_out：是否超时</li><li>_shards：本次查询搜索的 shard 的数量，包括成功的和失败的</li><li>hits：查询结果</li><li>hits.total：匹配的文档数量</li><li>hits.hits：匹配的文档，默认返回10个文档</li><li>hits.sort：排序的值</li><li>_score：文档的得分</li><li>hits.max_score：所有文档最高的得分</li></ul><h3 id="简要介绍-Query-DSL"><a href="#简要介绍-Query-DSL" class="headerlink" title="简要介绍 Query DSL"></a>简要介绍 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/query-dsl.html" target="_blank" rel="noopener">Query DSL</a></h3><p>这个Elasticsearch提供的基于 json 的查询语言，我们通过一个小任务来了解一下</p><p>任务要求：</p><ol><li>查询 firstname 中为 “R” 开头，年龄在 20 到 30 岁之间的人物信息</li><li>限制返回的字段为 firstname,city,address,email,balance</li><li>根据年龄倒序排序，返回前十条数据</li><li>对 firstname 字段进行高亮显示</li><li>同时求所有匹配人物的 平均balance</li></ol><pre><code>GET bank/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: [        {          &quot;match_phrase_prefix&quot;: {            &quot;firstname&quot;: &quot;R&quot;          }        }      ],      &quot;filter&quot;: {        &quot;range&quot;: {          &quot;age&quot;: {            &quot;gte&quot;: 20,            &quot;lte&quot;: 30          }        }      }    }  },  &quot;from&quot;: 0,  &quot;size&quot;: 10,  &quot;sort&quot;: [    {      &quot;age&quot;: {        &quot;order&quot;: &quot;desc&quot;      }    }  ],  &quot;_source&quot;: [    &quot;firstname&quot;,    &quot;city&quot;,    &quot;address&quot;,    &quot;email&quot;,    &quot;balance&quot;  ],  &quot;highlight&quot;: {    &quot;fields&quot;: {      &quot;firstname&quot;: {}    }  },  &quot;aggs&quot;: {    &quot;avg_age&quot;: {      &quot;avg&quot;: {        &quot;field&quot;: &quot;balance&quot;      }    }  }}</code></pre><p>其中：</p><ul><li>query 部分可以写各种查询条件</li><li>from, size 设置要返回的文档的起始序号</li><li>sort 设置排序规则</li><li>_source 设置要返回的文档的字段</li><li>highlight 设置高亮的字段</li><li>aggs 为设置聚合统计规则</li></ul><h5 id="更多查询示例"><a href="#更多查询示例" class="headerlink" title="更多查询示例"></a>更多查询示例</h5><ul><li>match_all 查询 bank 索引所有文档</li></ul><pre><code>GET /bank/_search{  &quot;query&quot;: {    &quot;match_all&quot;: {}  },  &quot;size&quot;: 2}</code></pre><ul><li>match 全文搜索，查询 address 字段值为 mill lane 的所有文档</li></ul><pre><code>GET /bank/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;address&quot;: &quot;mill lane&quot;    }  }}</code></pre><ul><li>match_phrase 短语匹配</li></ul><pre><code>GET /bank/_search{  &quot;query&quot;: {    &quot;match_phrase&quot;: {      &quot;address&quot;: &quot;mill lane&quot;    }  }}</code></pre><blockquote><p>note:<br>match 和 match_phrase 的区别：</p><ul><li>match 中会分词，将 mill lane 拆分为 mill 和 lane， 实际查询 address 中有 mill <strong>或者</strong> lane 的文档</li><li>match_phrase：将 mill lane 作为一个整体查询，实际查询 address 中有 mill lane 的文档</li></ul></blockquote><ul><li>布尔查询（多条件查询）</li></ul><pre><code>GET /bank/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: [        { &quot;match&quot;: { &quot;age&quot;: &quot;40&quot; } }      ],      &quot;must_not&quot;: [        { &quot;match&quot;: { &quot;state&quot;: &quot;ID&quot; } }      ]    }  }}</code></pre><ul><li>布尔查询-过滤<br>查询 bank 索引中 balance 值在 20000 到 30000 之间的文档</li></ul><pre><code>GET /bank/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: { &quot;match_all&quot;: {} },      &quot;filter&quot;: {        &quot;range&quot;: {          &quot;balance&quot;: {            &quot;gte&quot;: 20000,            &quot;lte&quot;: 30000          }        }      }    }  }}</code></pre><ul><li>聚合查询<br>对所有文档进行聚合，state 值相同的分到同一个桶里，分桶结果命名为 group_by_state ，再对每个桶里的文档的 balance 字段求平均值，结果命名为 average_balance，通过设置 size 的值为0，不返回任何文档内容</li></ul><pre><code>GET /bank/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;group_by_state&quot;: {      &quot;terms&quot;: {        &quot;field&quot;: &quot;state.keyword&quot;      },      &quot;aggs&quot;: {        &quot;average_balance&quot;: {          &quot;avg&quot;: {            &quot;field&quot;: &quot;balance&quot;          }        }      }    }  }}</code></pre><p>分别计算 age 值在 20~30 ，30~40，40~50 三个年龄段的男和女的平均存款balance</p><pre><code>GET /bank/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;group_by_age&quot;: {      &quot;range&quot;: {        &quot;field&quot;: &quot;age&quot;,        &quot;ranges&quot;: [          {            &quot;from&quot;: 20,            &quot;to&quot;: 30          },          {            &quot;from&quot;: 30,            &quot;to&quot;: 40          },          {            &quot;from&quot;: 40,            &quot;to&quot;: 50          }        ]      },      &quot;aggs&quot;: {        &quot;group_by_gender&quot;: {          &quot;terms&quot;: {            &quot;field&quot;: &quot;gender.keyword&quot;          },          &quot;aggs&quot;: {            &quot;average_balance&quot;: {              &quot;avg&quot;: {                &quot;field&quot;: &quot;balance&quot;              }            }          }        }      }    }  }}</code></pre><blockquote><p>参考文档：</p><ol><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started.html" target="_blank" rel="noopener">elasticsearch 官方文档 Getting Started</a></li><li>慕课网 <a href="https://coding.imooc.com/class/181.html" target="_blank" rel="noopener">Elastic Stack从入门到实践</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>使用hexo+github pages搭建博客</title>
      <link href="/2018/05/%E4%BD%BF%E7%94%A8hexo-github-pages%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/"/>
      <url>/2018/05/%E4%BD%BF%E7%94%A8hexo-github-pages%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</url>
      <content type="html"><![CDATA[<h2 id="为什么写博客"><a href="#为什么写博客" class="headerlink" title="为什么写博客"></a>为什么写博客</h2><p>就如我在博客主页上所说，主要有三点：</p><ol><li>记录与分享</li><li>锤炼技术，提高写作能力和表达能力</li><li>树立个人品牌，提高影响力</li></ol><p>而在此博客之前，我在CSDN上写过一些博客，截止于2018年5月23日，个人资料如下：</p><img title="小旋锋的csdn个人资料" alt="小旋锋的csdn个人资料" src="http://image.laijianfeng.org/static/images/201805/20180523_232554.png"><p>当我在CSDN上写博客的时候，几乎每天都会去看看阅读量增加了多少，排名增加了多少，又增加了几个粉丝或者新评论，每每都会带给我兴奋感，让我感到写博客其实是一件很有意义的事情，并且反过来推动我学习和记录，写更多的博客。</p><p>而为什么现在要重新整一个博客呢？主要是因为之前CSDN的博客更多的是转载和低质量的，而博主即将毕业，正走在程序员的职业道路上，需要树立个人品牌，写博客是目前对我比较合适且能做到的方式。</p><p>而独立博客自由度更高，第三方博客平台推广则更快，所以最终决定采用独立博客首发，第三方平台分发引流的模式。</p><p>我的第三方平台账户：</p><ul><li><a href="https://www.jianshu.com/u/ae269fd3620a" target="_blank" rel="noopener">小旋锋的简书</a></li><li><a href="https://blog.csdn.net/wwwdc1012" target="_blank" rel="noopener">小旋锋的csdn博客</a></li><li><a href="https://www.zhihu.com/people/whirlys/activities" target="_blank" rel="noopener">小旋锋的知乎</a></li><li><a href="http://image.laijianfeng.org/static/images/201805/20180523_230522.jpg" target="_blank" rel="noopener">小旋锋的微信公众号</a></li></ul><h2 id="Hexo主题选择"><a href="#Hexo主题选择" class="headerlink" title="Hexo主题选择"></a>Hexo主题选择</h2><p><a href="https://hexo.io/zh-cn/docs/index.html" target="_blank" rel="noopener">Hexo</a> 是一个快速、简洁且高效的博客框架，可托管于github pages，可免去维护服务器的麻烦，博主们可更专注于内容的创作，并且Hexo主题众多，总有一款适合你。</p><p>我对主题的要求主要有：</p><ol><li>不要太大众</li><li>大气美观</li><li>功能齐全</li></ol><p>经过了几天的搜索之后，筛选了几个比较满意的Hexo主题如下：</p><ol><li><a href="http://blog.zhangruipeng.me/hexo-theme-hueman/about/index.html" target="_blank" rel="noopener">Hueman</a></li><li><a href="http://jacman.wuchong.me/2014/11/20/how-to-use-jacman/" target="_blank" rel="noopener">jacman</a></li><li><a href="https://www.haomwei.com/" target="_blank" rel="noopener">大道至简</a></li><li><a href="http://threehao.com/" target="_blank" rel="noopener">Loo’s Blog</a></li><li><a href="http://yelog.org/2017/03/23/3-hexo-instruction/" target="_blank" rel="noopener">3-hexo</a></li></ol><p>最终选择了 <a href="http://yelog.org/2017/03/23/3-hexo-instruction/" target="_blank" rel="noopener">3-hexo</a> 这款主题，当然还有很多不错的主题。</p><h2 id="搭建步骤"><a href="#搭建步骤" class="headerlink" title="搭建步骤"></a>搭建步骤</h2><h3 id="1-根据-Hexo官网-步骤安装-git，node-js"><a href="#1-根据-Hexo官网-步骤安装-git，node-js" class="headerlink" title="1. 根据 Hexo官网 步骤安装 git，node.js"></a>1. 根据 <a href="https://hexo.io/zh-cn/docs/index.html" target="_blank" rel="noopener">Hexo官网</a> 步骤安装 git，node.js</h3><h3 id="2-安装Hexo"><a href="#2-安装Hexo" class="headerlink" title="2. 安装Hexo"></a>2. 安装Hexo</h3><pre><code class="javascript">npm install -g hexo-cli</code></pre><p>安装 Hexo 完成后，新建一个博客的主目录，然后执行以下命令：</p><pre><code class="shell">hexo init &lt;folder&gt;cd &lt;folder&gt;npm install</code></pre><p>新建完成之后该目录的目录结构如下:</p><p>.</p><p>├── _config.yml        # 网站的 配置 信息</p><p>├── package.json        # 应用程序的信息</p><p>├── scaffolds            # 模板文件夹</p><p>├── source            # 博文源文件目录</p><p>|   ├── _drafts        # 草稿文件夹</p><p>|   └── _posts            # 博文文件夹</p><p>└── themes            # 主题文件夹</p><p>再执行以下命令，访问 <a href="http://localhost:4000" target="_blank" rel="noopener">http://localhost:4000</a> 即可快速体验Hexo</p><pre><code class="shell">hexo ghexo s</code></pre><img src="http://image.laijianfeng.org/static/images/201805/20180524_003246.png"><h3 id="3-根据-Hexo文档-对网站做一些简单的配置，然后修改主题为-3-hexo"><a href="#3-根据-Hexo文档-对网站做一些简单的配置，然后修改主题为-3-hexo" class="headerlink" title="3. 根据 Hexo文档 对网站做一些简单的配置，然后修改主题为 3-hexo"></a>3. 根据 <a href="https://hexo.io/zh-cn/docs/configuration.html" target="_blank" rel="noopener">Hexo文档</a> 对网站做一些简单的配置，然后修改主题为 <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank" rel="noopener">3-hexo</a></h3><p>安装</p><pre><code class="shell">git clone https://github.com/yelog/hexo-theme-3-hexo.git themes/3-hexo</code></pre><p>修改hexo根目录的_config.yml中的theme参数</p><pre><code class="javascript">theme: 3-hexo</code></pre><p>然后执行 hexo clean &amp; hexo g &amp; hexo s 即可看到效果</p><p>更多的主题配置可见 <a href="http://yelog.org/2017/03/23/3-hexo-instruction/" target="_blank" rel="noopener">3-hexo使用说明</a></p><h3 id="4-配置-github-pages"><a href="#4-配置-github-pages" class="headerlink" title="4. 配置 github pages"></a>4. 配置 github pages</h3><p>到github上创建一个新的空仓库，名字格式为 账户名.github.io，譬如我的github账户名是 <a href="https://github.com/whirlys" target="_blank" rel="noopener">whirlys</a>，所以我的github pages 仓库的名字应为 whirlys.github.io</p><p>安装插件</p><pre><code class="shell">npm install hexo-deployer-git --save</code></pre><p>然后配置 Hexo根目录的 _config.yml，xxx为你的用户名，注意还需要加入你的 github 用户名和密码，不然后面推送失败（但是上传代码时注意防止密码泄露）</p><pre><code class="shell">deploy:  type: git  repo: https://[github用户名]:[github密码]@github.com/xxx/xxx.github.io.git  branch: master</code></pre><p>如果你是第一次配置 github 远程仓库，你还须将你电脑的ssh key 配置到 github 上，具体可参考 <a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001374385852170d9c7adf13c30429b9660d0eb689dd43a000" target="_blank" rel="noopener">git远程仓库</a></p><p>推送Hexo到github</p><pre><code class="shell">hexo deploy</code></pre><p>访问 xxx.github.io 即可看到你的 github pages 博客了</p><h3 id="5-绑定私有域名"><a href="#5-绑定私有域名" class="headerlink" title="5. 绑定私有域名"></a>5. 绑定私有域名</h3><p>我的域名为 laijianfeng.org，是一年前买 腾讯云1元学生主机 时送的，当然可以选择其他域名提供商</p><p>在 hexo source 目录下新建一个 CNAME 文件（没有后缀名），在文件里填入你的域名，然后 hexo d 推送到github</p><p>登录域名提供商网站，进入域名解析页面，分别添加两条记录</p><table><thead><tr><th>主机记录</th><th>记录类型</th><th>线路类型</th><th>记录值</th></tr></thead><tbody><tr><td>@</td><td>CNAME</td><td>默认</td><td>xxx.github.io</td></tr><tr><td>www</td><td>CNAME</td><td>默认</td><td><a href="http://www.xxx.github.io" target="_blank" rel="noopener">www.xxx.github.io</a></td></tr></tbody></table><p>等待十分钟之后，访问你的域名即可跳转到你的博客</p><h3 id="6-其他的配置"><a href="#6-其他的配置" class="headerlink" title="6. 其他的配置"></a>6. 其他的配置</h3><ul><li>接入评论，3-hexo主题中已经集成了多种评论，我选择了gitment，具体的配置参考 <a href="http://yelog.org/2017/06/26/gitment/" target="_blank" rel="noopener">完美替代多说-gitment</a>，如果gitment遇到问题，譬如报Error：validation failed异常，可参考 <a href="http://xichen.pub/2018/01/31/2018-01-31-gitment/" target="_blank" rel="noopener">添加Gitment评论系统踩过的坑</a> 以及 <a href="https://github.com/imsun/gitment/issues" target="_blank" rel="noopener">gitment issue</a>上的解决方法</li><li>使用七牛云图床，参考 <a href="http://skyhacks.org/2017/08/02/UseQiniudnToStorePic/" target="_blank" rel="noopener">使用七牛为Hexo存储图片</a> 和 <a href="https://github.com/gyk001/hexo-qiniu-sync" target="_blank" rel="noopener">Hexo七牛同步插件</a></li><li>代码高亮，字数统计，参考 <a href="http://yelog.org/2017/03/07/3-hexo/" target="_blank" rel="noopener">Hexo主题3-hexo</a></li></ul>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 博客 </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
