<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>MySQL Binlog 解析工具 Maxwell 详解</title>
      <link href="/2019/03/MySQL-Binlog-%E8%A7%A3%E6%9E%90%E5%B7%A5%E5%85%B7-Maxwell-%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/03/MySQL-Binlog-%E8%A7%A3%E6%9E%90%E5%B7%A5%E5%85%B7-Maxwell-%E8%AF%A6%E8%A7%A3/</url>
      <content type="html"><![CDATA[<h3 id="maxwell-简介"><a href="#maxwell-简介" class="headerlink" title="maxwell 简介"></a>maxwell 简介</h3><p>Maxwell是一个能实时读取MySQL二进制日志binlog，并生成 JSON 格式的消息，作为生产者发送给 Kafka，Kinesis、RabbitMQ、Redis、Google Cloud Pub/Sub、文件或其它平台的应用程序。它的常见应用场景有ETL、维护缓存、收集表级别的dml指标、增量到搜索引擎、数据分区迁移、切库binlog回滚方案等。官网(<a href="http://maxwells-daemon.io)、GitHub(https://github.com/zendesk/maxwell)" target="_blank" rel="noopener">http://maxwells-daemon.io)、GitHub(https://github.com/zendesk/maxwell)</a></p><p>Maxwell主要提供了下列功能：</p><ul><li>支持 <code>SELECT * FROM table</code> 的方式进行全量数据初始化</li><li>支持在主库发生failover后，自动恢复binlog位置(GTID)</li><li>可以对数据进行分区，解决数据倾斜问题，发送到kafka的数据支持database、table、column等级别的数据分区</li><li>工作方式是伪装为Slave，接收binlog events，然后根据schemas信息拼装，可以接受ddl、xid、row等各种event</li></ul><p>除了Maxwell外，目前常用的MySQL Binlog解析工具主要有阿里的canal、mysql_streamer，三个工具对比如下：</p><p><img src="http://image.laijianfeng.org/20190310_163023.png" alt="canal、maxwell、mysql_streamer对比"></p><p>canal 由Java开发，分为服务端和客户端，拥有众多的衍生应用，性能稳定，功能强大；canal 需要自己编写客户端来消费canal解析到的数据。</p><p>maxwell相对于canal的优势是使用简单，它直接将数据变更输出为json字符串，不需要再编写客户端。</p><h4 id="快速开始"><a href="#快速开始" class="headerlink" title="快速开始"></a>快速开始</h4><p>首先MySQL需要先启用binlog，关于什么是MySQL binlog，可以参考文章《<a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483875&amp;idx=1&amp;sn=2cdc232fa3036da52a826964996506a8&amp;chksm=e9c2edeedeb564f891b34ef1e47418bbe6b8cb6dcb7f48b5fa73b15cf1d63172df1a173c75d0&amp;scene=0&amp;xtrack=1&amp;key=e3977f8a79490c6345befb88d0bbf74cbdc6b508a52e61ea076c830a5b64c552def6c6ad848d4bcc7a1d21e53e30eb5c1ead33acdb97df779d0e6fa8a0fbe4bda32c04077ea0d3511bc9f9490ad0b46c&amp;ascene=1&amp;uin=MjI4MTc0ODEwOQ%3D%3D&amp;devicetype=Windows+7&amp;version=62060719&amp;lang=zh_CN&amp;pass_ticket=h8jyrQ71hQc872LxydZS%2F3aU1JXFbp4raQ1KvY908BcKBeSBtXFgBY9IS9ZaLEDi" target="_blank" rel="noopener">MySQL Binlog 介绍</a>》</p><pre><code>$ vi my.cnf[mysqld]server_id=1log-bin=masterbinlog_format=row</code></pre><p>创建Maxwell用户，并赋予 maxwell 库的一些权限</p><pre><code class="sql">CREATE USER &#39;maxwell&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39;;GRANT ALL ON maxwell.* TO &#39;maxwell&#39;@&#39;%&#39;;GRANT SELECT, REPLICATION CLIENT, REPLICATION SLAVE on *.* to &#39;maxwell&#39;@&#39;%&#39;; </code></pre><p>使用 maxwell 之前需要先启动 kafka</p><pre><code>wget http://mirrors.tuna.tsinghua.edu.cn/apache/kafka/2.1.0/kafka_2.11-2.1.0.tgztar -xzf kafka_2.11-2.1.0.tgzcd kafka_2.11-2.1.0# 启动Zookeeperbin/zookeeper-server-start.sh config/zookeeper.properties</code></pre><p>单机启动 kafka 之前，需要修改一下配置文件，打开配置文件 <code>vi config/server.properties</code>，在文件最后加入 <code>advertised.host.name</code> 的配置，值为 kafka 所在机器的IP</p><pre><code>advertised.host.name=10.100.97.246</code></pre><p>不然后面通过 docker 启动 maxwell 将会报异常（其中的 hadoop2 是我的主机名）</p><pre><code>17:45:21,446 DEBUG NetworkClient - [Producer clientId=producer-1] Error connecting to node hadoop2:9092 (id: 0 rack: null)java.io.IOException: Can&#39;t resolve address: hadoop2:9092        at org.apache.kafka.common.network.Selector.connect(Selector.java:217) ~[kafka-clients-1.0.0.jar:?]        at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:793) [kafka-clients-1.0.0.jar:?]        at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:230) [kafka-clients-1.0.0.jar:?]        at org.apache.kafka.clients.producer.internals.Sender.sendProducerData(Sender.java:263) [kafka-clients-1.0.0.jar:?]        at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:238) [kafka-clients-1.0.0.jar:?]        at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:176) [kafka-clients-1.0.0.jar:?]        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_181]Caused by: java.nio.channels.UnresolvedAddressException        at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_181]        at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_181]        at org.apache.kafka.common.network.Selector.connect(Selector.java:214) ~[kafka-clients-1.0.0.jar:?]        ... 6 more</code></pre><p>接着可以启动 kafka</p><pre><code>bin/kafka-server-start.sh config/server.properties</code></pre><p>测试 kafka</p><pre><code># 创建一个 topicbin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test# 列出所有 topicbin/kafka-topics.sh --list --zookeeper localhost:2181# 启动一个生产者，然后随意发送一些消息bin/kafka-console-producer.sh --broker-list localhost:9092 --topic testThis is a messageThis is another message# 在另一个终端启动一下消费者，观察所消费的消息bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginningThis is a messageThis is another message</code></pre><p>通过 docker 快速安装并使用 Maxwell （当然之前需要自行安装 docker）</p><pre><code># 拉取镜像 docker pull zendesk/maxwell# 启动maxwell，并将解析出的binlog输出到控制台docker run -ti --rm zendesk/maxwell bin/maxwell --user=&#39;maxwell&#39; --password=&#39;123456&#39; --host=&#39;10.100.97.246&#39; --producer=stdout</code></pre><p>测试Maxwell，首先创建一张简单的表，然后增改删数据</p><pre><code class="sql">CREATE TABLE `test` (  `id` bigint(20) NOT NULL AUTO_INCREMENT,  `age` int(11) DEFAULT NULL,  `name` varchar(255) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;insert into test values(1,22,&quot;小旋锋&quot;);update test set name=&#39;whirly&#39; where id=1;delete from test where id=1;</code></pre><p>观察docker控制台的输出，从输出的日志中可以看出Maxwell解析出的binlog的JSON字符串的格式</p><pre><code>{&quot;database&quot;:&quot;test&quot;,&quot;table&quot;:&quot;test&quot;,&quot;type&quot;:&quot;insert&quot;,&quot;ts&quot;:1552153502,&quot;xid&quot;:832,&quot;commit&quot;:true,&quot;data&quot;:{&quot;id&quot;:1,&quot;age&quot;:22,&quot;name&quot;:&quot;小旋锋&quot;}}{&quot;database&quot;:&quot;test&quot;,&quot;table&quot;:&quot;test&quot;,&quot;type&quot;:&quot;update&quot;,&quot;ts&quot;:1552153502,&quot;xid&quot;:833,&quot;commit&quot;:true,&quot;data&quot;:{&quot;id&quot;:1,&quot;age&quot;:22,&quot;name&quot;:&quot;whirly&quot;},&quot;old&quot;:{&quot;name&quot;:&quot;小旋锋&quot;}}{&quot;database&quot;:&quot;test&quot;,&quot;table&quot;:&quot;test&quot;,&quot;type&quot;:&quot;delete&quot;,&quot;ts&quot;:1552153502,&quot;xid&quot;:834,&quot;commit&quot;:true,&quot;data&quot;:{&quot;id&quot;:1,&quot;age&quot;:22,&quot;name&quot;:&quot;whirly&quot;}}</code></pre><p>输出到 Kafka，关闭 docker，重新设置启动参数</p><pre><code>docker run -it --rm zendesk/maxwell bin/maxwell --user=&#39;maxwell&#39; \    --password=&#39;123456&#39; --host=&#39;10.100.97.246&#39; --producer=kafka \    --kafka.bootstrap.servers=&#39;10.100.97.246:9092&#39; --kafka_topic=maxwell --log_level=debug</code></pre><p>然后启动一个消费者来消费 maxwell topic的消息，观察其输出；再一次执行增改删数据的SQL，仍然可以得到相同的输出</p><pre><code>bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic maxwell</code></pre><h4 id="输出JSON字符串的格式"><a href="#输出JSON字符串的格式" class="headerlink" title="输出JSON字符串的格式"></a>输出JSON字符串的格式</h4><ul><li>data 最新的数据，修改后的数据</li><li>old 旧数据，修改前的数据</li><li>type 操作类型，有insert, update, delete, database-create, database-alter, database-drop, table-create, table-alter, table-drop，bootstrap-insert，int(未知类型)</li><li>xid 事务id</li><li>commit 同一个xid代表同一个事务，事务的最后一条语句会有commit，可以利用这个重现事务</li><li>server_id </li><li>thread_id </li><li>运行程序时添加参数–output_ddl，可以捕捉到ddl语句</li><li>datetime列会输出为”YYYY-MM-DD hh:mm:ss”，如果遇到”0000-00-00 00:00:00”会原样输出</li><li>maxwell支持多种编码，但仅输出utf8编码</li><li>maxwell的TIMESTAMP总是作为UTC处理，如果要调整为自己的时区，需要在后端逻辑上进行处理</li></ul><p>与输出格式相关的配置如下</p><table><thead><tr><th>选项</th><th>参数值</th><th>描述</th><th>默认值</th></tr></thead><tbody><tr><td><code>output_binlog_position</code></td><td>BOOLEAN</td><td>是否包含 binlog position</td><td>false</td></tr><tr><td><code>output_gtid_position</code></td><td>BOOLEAN</td><td>是否包含 gtid position</td><td>false</td></tr><tr><td><code>output_commit_info</code></td><td>BOOLEAN</td><td>是否包含 commit and xid</td><td>true</td></tr><tr><td><code>output_xoffset</code></td><td>BOOLEAN</td><td>是否包含 virtual tx-row offset</td><td>false</td></tr><tr><td><code>output_nulls</code></td><td>BOOLEAN</td><td>是否包含值为NULL的字段</td><td>true</td></tr><tr><td><code>output_server_id</code></td><td>BOOLEAN</td><td>是否包含 server_id</td><td>false</td></tr><tr><td><code>output_thread_id</code></td><td>BOOLEAN</td><td>是否包含 thread_id</td><td>false</td></tr><tr><td><code>output_schema_id</code></td><td>BOOLEAN</td><td>是否包含 schema_id</td><td>false</td></tr><tr><td><code>output_row_query</code></td><td>BOOLEAN</td><td>是否包含 INSERT/UPDATE/DELETE 语句. Mysql需要开启 <code>binlog_rows_query_log_events</code></td><td>false</td></tr><tr><td><code>output_ddl</code></td><td>BOOLEAN</td><td>是否包含 DDL (table-alter, table-create, etc) events</td><td>false</td></tr><tr><td><code>output_null_zerodates</code></td><td>BOOLEAN</td><td>是否将 ‘0000-00-00’ 转换为 null?</td><td>false</td></tr></tbody></table><h3 id="进阶使用"><a href="#进阶使用" class="headerlink" title="进阶使用"></a>进阶使用</h3><h4 id="基本的配置"><a href="#基本的配置" class="headerlink" title="基本的配置"></a>基本的配置</h4><table><thead><tr><th>选项</th><th>参数值</th><th>描述</th><th>默认值</th></tr></thead><tbody><tr><td><code>config</code></td><td></td><td>配置文件 <code>config.properties</code> 的路径</td><td></td></tr><tr><td><code>log_level</code></td><td><code>debug,info,warn,error</code></td><td>日志级别</td><td>info</td></tr><tr><td><code>daemon</code></td><td></td><td>指定Maxwell实例作为守护进程到后台运行</td><td></td></tr><tr><td><code>env_config_prefix</code></td><td>STRING</td><td>匹配该前缀的环境变量将被视为配置值</td></tr></tbody></table><p>可以把Maxwell的启动参数写到一个配置文件 <code>config.properties</code> 中，然后通过 config 选项指定，<code>bin/maxwell --config config.properties</code></p><pre><code>user=maxwellpassword=123456host=10.100.97.246producer=kafkakafka.bootstrap.servers=10.100.97.246:9092kafka_topic=maxwell</code></pre><h4 id="mysql-配置选项"><a href="#mysql-配置选项" class="headerlink" title="mysql 配置选项"></a>mysql 配置选项</h4><p>Maxwell 根据用途将 MySQL 划分为3种角色：</p><ul><li><p><code>host</code>：主机，建maxwell库表，存储捕获到的schema等信息</p><ul><li>主要有六张表，bootstrap用于数据初始化，schemas记录所有的binlog文件信息，databases记录了所有的数据库信息，tables记录了所有的表信息，columns记录了所有的字段信息，positions记录了读取binlog的位移信息，heartbeats记录了心跳信息</li></ul></li><li><p><code>replication_host</code>：复制主机，Event监听，读取该主机binlog</p><ul><li>将<code>host</code>和<code>replication_host</code>分开，可以避免 <code>replication_user</code> 往生产库里写数据</li></ul></li><li><p><code>schema_host</code>：schema主机，捕获表结构schema的主机</p><ul><li>binlog里面没有字段信息，所以maxwell需要从数据库查出schema，存起来。</li><li><code>schema_host</code>一般用不到，但在<code>binlog-proxy</code>场景下就很实用。比如要将已经离线的binlog通过maxwell生成json流，于是自建一个mysql server里面没有结构，只用于发送binlog，此时表机构就可以制动从 schema_host 获取。</li></ul></li></ul><p>通常，这三个主机都是同一个，<code>schema_host</code> 只在有 <code>replication_host</code> 的时候使用。</p><p>与MySQL相关的有下列配置</p><table><thead><tr><th>选项</th><th>参数值</th><th>描述</th><th>默认值</th></tr></thead><tbody><tr><td><code>host</code></td><td>STRING</td><td>mysql 地址</td><td>localhost</td></tr><tr><td><code>user</code></td><td>STRING</td><td>mysql 用户名</td><td></td></tr><tr><td><code>password</code></td><td>STRING</td><td>mysql 密码</td><td>(no password)</td></tr><tr><td><code>port</code></td><td>INT</td><td>mysql 端口    3306</td><td></td></tr><tr><td><code>jdbc_options</code></td><td>STRING</td><td>mysql jdbc connection options</td><td>DEFAULT_JDBC_OPTS</td></tr><tr><td><code>ssl</code></td><td>SSL_OPT</td><td>SSL behavior for mysql cx</td><td>DISABLED</td></tr><tr><td><code>schema_database</code></td><td>STRING</td><td>Maxwell用于维护的schema和position将使用的数据库</td><td>maxwell</td></tr><tr><td><code>client_id</code></td><td>STRING</td><td>用于标识Maxwell实例的唯一字符串</td><td>maxwell</td></tr><tr><td><code>replica_server_id</code></td><td>LONG</td><td>用于标识Maxwell实例的唯一数字</td><td>6379 (see notes)</td></tr><tr><td><code>master_recovery</code></td><td>BOOLEAN</td><td>enable experimental master recovery code</td><td>false</td></tr><tr><td><code>gtid_mode</code></td><td>BOOLEAN</td><td>是否开启基于GTID的复制</td><td>false</td></tr><tr><td><code>recapture_schema</code></td><td>BOOLEAN</td><td>重新捕获最新的表结构(schema)，不可在 config.properties中配置</td><td>false</td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td><code>replication_host</code></td><td>STRING</td><td>server to replicate from. See split server roles</td><td>schema-store host</td></tr><tr><td><code>replication_password</code></td><td>STRING</td><td>password on replication server</td><td>(none)</td></tr><tr><td><code>replication_port</code></td><td>INT</td><td>port on replication server</td><td>3306</td></tr><tr><td><code>replication_user</code></td><td>STRING</td><td>user on replication server</td><td></td></tr><tr><td><code>replication_ssl</code></td><td>SSL_OPT</td><td>SSL behavior for replication cx cx</td><td>DISABLED</td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td><code>schema_host</code></td><td>STRING</td><td>server to capture schema from. See split server roles</td><td>schema-store host</td></tr><tr><td><code>schema_password</code></td><td>STRING</td><td>password on schema-capture server</td><td>(none)</td></tr><tr><td><code>schema_port</code></td><td>INT</td><td>port on schema-capture server</td><td>3306</td></tr><tr><td><code>schema_user</code></td><td>STRING</td><td>user on schema-capture server</td><td></td></tr><tr><td><code>schema_ssl</code></td><td>SSL_OPT</td><td>SSL behavior for schema-capture server</td><td>DISABLED</td></tr></tbody></table><h4 id="生产者的配置"><a href="#生产者的配置" class="headerlink" title="生产者的配置"></a>生产者的配置</h4><p>仅介绍kafka，其他的生产者的配置详见官方文档。</p><p>kafka是maxwell支持最完善的一个生产者，并且内置了多个版本的kafka客户端(0.8.2.2, 0.9.0.1, 0.10.0.1, 0.10.2.1 or 0.11.0.1, 1.0.0.)，默认 kafka_version=1.0.0（当前Maxwell版本1.20.0）</p><p>Maxwell 会将消息投递到Kafka的Topic中，该Topic由 <code>kafka_topic</code> 选项指定，默认值为 <code>maxwell</code>，除了指定为静态的Topic，还可以指定为动态的，譬如 <code>namespace_%{database}_%{table}</code>，<code>%{database}</code> 和 <code>%{table}</code> 将被具体的消息的 database 和 table 替换。</p><p>Maxwell 读取配置时，如果配置项是以 <code>kafka.</code> 开头，那么该配置将设置到 Kafka Producer 客户端的连接参数中去，譬如</p><pre><code>kafka.acks = 1kafka.compression.type = snappykafka.retries=5</code></pre><p>下面是Maxwell通用生产者和Kafka生产者的配置参数</p><table><thead><tr><th>选项</th><th>参数值</th><th>描述</th><th>默认值</th></tr></thead><tbody><tr><td><code>producer</code></td><td>PRODUCER_TYPE</td><td>生产者类型</td><td>stdout</td></tr><tr><td><code>custom_producer.factory</code></td><td>CLASS_NAME</td><td>自定义消费者的工厂类</td><td></td></tr><tr><td><code>producer_ack_timeout</code></td><td>PRODUCER_ACK_TIMEOUT</td><td>异步消费认为消息丢失的超时时间（毫秒ms）</td><td></td></tr><tr><td><code>producer_partition_by</code></td><td>PARTITION_BY</td><td>输入到kafka/kinesis的分区函数</td><td>database</td></tr><tr><td><code>producer_partition_columns</code></td><td>STRING</td><td>若按列分区，以逗号分隔的列名称</td><td></td></tr><tr><td><code>producer_partition_by_fallback</code></td><td>PARTITION_BY_FALLBACK</td><td><code>producer_partition_by=column</code>时需要，当列不存在是使用</td><td></td></tr><tr><td><code>ignore_producer_error</code></td><td>BOOLEAN</td><td>为false时，在kafka/kinesis发生错误时退出程序；为true时，仅记录日志 See also <code>dead_letter_topic</code></td><td>true</td></tr><tr><td><code>kafka.bootstrap.servers</code></td><td>STRING</td><td>kafka 集群列表，<code>HOST:PORT[,HOST:PORT]</code></td><td></td></tr><tr><td><code>kafka_topic</code></td><td>STRING</td><td>kafka topic</td><td>maxwell</td></tr><tr><td><code>dead_letter_topic</code></td><td>STRING</td><td>详见官方文档</td><td></td></tr><tr><td><code>kafka_version</code></td><td>KAFKA_VERSION</td><td>指定maxwell的 kafka 生产者客户端版本，不可在config.properties中配置</td><td>0.11.0.1</td></tr><tr><td><code>kafka_partition_hash</code></td><td><code>default,murmur3</code></td><td>选择kafka分区时使用的hash方法</td><td>default</td></tr><tr><td><code>kafka_key_format</code></td><td><code>array,hash</code></td><td>how maxwell outputs kafka keys, either a hash or an array of hashes</td><td>hash</td></tr><tr><td><code>ddl_kafka_topic</code></td><td>STRING</td><td>当<code>output_ddl</code>为true时, 所有DDL的消息都将投递到该topic</td><td><code>kafka_topic</code></td></tr></tbody></table><h4 id="过滤器配置"><a href="#过滤器配置" class="headerlink" title="过滤器配置"></a>过滤器配置</h4><p>Maxwell 可以通过 <code>--filter</code> 配置项来指定过滤规则，通过 <code>exclude</code> 排除，通过 <code>include</code> 包含，值可以为具体的数据库、数据表、数据列，甚至用 Javascript 来定义复杂的过滤规则；可以用正则表达式描述，有几个来自官网的例子</p><pre><code># 仅匹配foodb数据库的tbl表和所有table_数字的表--filter=&#39;exclude: foodb.*, include: foodb.tbl, include: foodb./table_\d+/&#39;# 排除所有库所有表，仅匹配db1数据库--filter = &#39;exclude: *.*, include: db1.*&#39;# 排除含db.tbl.col列值为reject的所有更新--filter = &#39;exclude: db.tbl.col = reject&#39;# 排除任何包含col_a列的更新--filter = &#39;exclude: *.*.col_a = *&#39;# blacklist 黑名单，完全排除bad_db数据库，若要恢复，必须删除maxwell库--filter = &#39;blacklist: bad_db.*&#39; </code></pre><h4 id="数据初始化"><a href="#数据初始化" class="headerlink" title="数据初始化"></a>数据初始化</h4><p>Maxwell 启动后将从maxwell库中获取上一次停止时position，从该断点处开始读取binlog。如果binlog已经清除了，那么怎样可以通过maxwell把整张表都复制出来呢？也就是数据初始化该怎么做？</p><p>对整张表进行操作，人为地产生binlog？譬如找一个不影响业务的字段譬如update_time，然后加一秒，再减一秒？ </p><pre><code class="sql">update test set update_time = DATE_ADD(update_time,intever 1 second);update test set update_time = DATE_ADD(update_time,intever -1 second);</code></pre><p>这样明显存在几个大问题：</p><ul><li>不存在一个不重要的字段怎么办？每个字段都很重要，不能随便地修改！</li><li>如果整张表很大，修改的过程耗时很长，影响了业务！</li><li>将产生大量非业务的binlog！</li></ul><p>针对数据初始化的问题，Maxwell 提供了一个命令工具 <code>maxwell-bootstrap</code> 帮助我们完成数据初始化，<code>maxwell-bootstrap</code> 是基于 <code>SELECT * FROM table</code> 的方式进行全量数据初始化，不会产生多余的binlog！</p><p>这个工具有下面这些参数：</p><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td><code>--log_level LOG_LEVEL</code></td><td>日志级别（DEBUG, INFO, WARN or ERROR）</td></tr><tr><td><code>--user USER</code></td><td>mysql 用户名</td></tr><tr><td><code>--password PASSWORD</code></td><td>mysql 密码</td></tr><tr><td><code>--host HOST</code></td><td>mysql 地址</td></tr><tr><td><code>--port PORT</code></td><td>mysql 端口</td></tr><tr><td><code>--database DATABASE</code></td><td>要bootstrap的表所在的数据库</td></tr><tr><td><code>--table TABLE</code></td><td>要引导的表</td></tr><tr><td><code>--where WHERE_CLAUSE</code></td><td>设置过滤条件</td></tr><tr><td><code>--client_id CLIENT_ID</code></td><td>指定执行引导操作的Maxwell实例</td></tr></tbody></table><p>实验一番，下面将引导 <code>test</code> 数据库中 <code>test</code> 表，首先是准备几条测试用的数据</p><pre><code class="sql">INSERT INTO `test` VALUES (1, 1, &#39;1&#39;);INSERT INTO `test` VALUES (2, 2, &#39;2&#39;);INSERT INTO `test` VALUES (3, 3, &#39;3&#39;);INSERT INTO `test` VALUES (4, 4, &#39;4&#39;);</code></pre><p>然后 <code>reset master;</code> 清空binlog，删除 maxwell 库中的表。接着使用快速开始中的命令，启动Kafka、Maxwell和Kafka消费者，然后启动 <code>maxwell-bootstrap</code></p><pre><code>docker run -it --rm zendesk/maxwell bin/maxwell-bootstrap --user maxwell  \    --password 123456 --host 10.100.97.246  --database test --table test --client_id maxwell</code></pre><p>注意：<code>--bootstrapper=sync</code> 时，在处理bootstrap时，会阻塞正常的binlog解析；<code>--bootstrapper=async</code> 时，不会阻塞。</p><p>也可以执行下面的SQL，在 <code>maxwell.bootstrap</code> 表中插入记录，手动触发</p><pre><code class="sql">insert into maxwell.bootstrap (database_name, table_name) values (&#39;test&#39;, &#39;test&#39;);</code></pre><p>就可以在 kafka 消费者端看见引导过来的数据了</p><pre><code>{&quot;database&quot;:&quot;maxwell&quot;,&quot;table&quot;:&quot;bootstrap&quot;,&quot;type&quot;:&quot;insert&quot;,&quot;ts&quot;:1552199115,&quot;xid&quot;:36738,&quot;commit&quot;:true,&quot;data&quot;:{&quot;id&quot;:3,&quot;database_name&quot;:&quot;test&quot;,&quot;table_name&quot;:&quot;test&quot;,&quot;where_clause&quot;:null,&quot;is_complete&quot;:0,&quot;inserted_rows&quot;:0,&quot;total_rows&quot;:0,&quot;created_at&quot;:null,&quot;started_at&quot;:null,&quot;completed_at&quot;:null,&quot;binlog_file&quot;:null,&quot;binlog_position&quot;:0,&quot;client_id&quot;:&quot;maxwell&quot;}}{&quot;database&quot;:&quot;test&quot;,&quot;table&quot;:&quot;test&quot;,&quot;type&quot;:&quot;bootstrap-start&quot;,&quot;ts&quot;:1552199115,&quot;data&quot;:{}}{&quot;database&quot;:&quot;test&quot;,&quot;table&quot;:&quot;test&quot;,&quot;type&quot;:&quot;bootstrap-insert&quot;,&quot;ts&quot;:1552199115,&quot;data&quot;:{&quot;id&quot;:1,&quot;age&quot;:1,&quot;name&quot;:&quot;1&quot;}}{&quot;database&quot;:&quot;test&quot;,&quot;table&quot;:&quot;test&quot;,&quot;type&quot;:&quot;bootstrap-insert&quot;,&quot;ts&quot;:1552199115,&quot;data&quot;:{&quot;id&quot;:2,&quot;age&quot;:2,&quot;name&quot;:&quot;2&quot;}}{&quot;database&quot;:&quot;test&quot;,&quot;table&quot;:&quot;test&quot;,&quot;type&quot;:&quot;bootstrap-insert&quot;,&quot;ts&quot;:1552199115,&quot;data&quot;:{&quot;id&quot;:3,&quot;age&quot;:3,&quot;name&quot;:&quot;3&quot;}}{&quot;database&quot;:&quot;test&quot;,&quot;table&quot;:&quot;test&quot;,&quot;type&quot;:&quot;bootstrap-insert&quot;,&quot;ts&quot;:1552199115,&quot;data&quot;:{&quot;id&quot;:4,&quot;age&quot;:4,&quot;name&quot;:&quot;4&quot;}}{&quot;database&quot;:&quot;maxwell&quot;,&quot;table&quot;:&quot;bootstrap&quot;,&quot;type&quot;:&quot;update&quot;,&quot;ts&quot;:1552199115,&quot;xid&quot;:36756,&quot;commit&quot;:true,&quot;data&quot;:{&quot;id&quot;:3,&quot;database_name&quot;:&quot;test&quot;,&quot;table_name&quot;:&quot;test&quot;,&quot;where_clause&quot;:null,&quot;is_complete&quot;:1,&quot;inserted_rows&quot;:4,&quot;total_rows&quot;:0,&quot;created_at&quot;:null,&quot;started_at&quot;:&quot;2019-03-10 14:25:15&quot;,&quot;completed_at&quot;:&quot;2019-03-10 14:25:15&quot;,&quot;binlog_file&quot;:&quot;mysql-bin.000001&quot;,&quot;binlog_position&quot;:64446,&quot;client_id&quot;:&quot;maxwell&quot;},&quot;old&quot;:{&quot;is_complete&quot;:0,&quot;inserted_rows&quot;:1,&quot;completed_at&quot;:null}}{&quot;database&quot;:&quot;test&quot;,&quot;table&quot;:&quot;test&quot;,&quot;type&quot;:&quot;bootstrap-complete&quot;,&quot;ts&quot;:1552199115,&quot;data&quot;:{}}</code></pre><p>中间的4条便是 <code>test.test</code> 的binlog数据了，注意这里的 type 是 <code>bootstrap-insert</code>，而不是 <code>insert</code>。</p><p>然后再一次查看binlog，<code>show binlog events;</code>，会发现只有与 <code>maxwell</code> 相关的binlog，并没有 <code>test.test</code> 相关的binlog，所以 <code>maxwell-bootstrap</code> 命令并不会产生多余的 binlog，当数据表的数量很大时，这个好处会更加明显</p><p>Bootstrap 的过程是 <code>bootstrap-start -&gt; bootstrap-insert -&gt; bootstrap-complete</code>，其中，start和complete的data字段为空，不携带数据。</p><p>在进行bootstrap过程中，如果maxwell崩溃，重启时，bootstrap会完全重新开始，不管之前进行到多少，若不希望这样，可以到数据库中设置 <code>is_complete</code> 字段值为1(表示完成)，或者删除该行</p><h4 id="Maxwell监控"><a href="#Maxwell监控" class="headerlink" title="Maxwell监控"></a>Maxwell监控</h4><p>Maxwell 提供了 <code>base logging mechanism, JMX, HTTP or by push to Datadog</code> 这四种监控方式，与监控相关的配置项有下列这些：</p><table><thead><tr><th>选项</th><th>参数值</th><th>描述</th><th>默认值</th></tr></thead><tbody><tr><td><code>metrics_prefix</code></td><td>STRING</td><td>指标的前缀</td><td>MaxwellMetrics</td></tr><tr><td><code>metrics_type</code></td><td><code>slf4j,jmx,http,datadog</code></td><td>发布指标的方式</td><td></td></tr><tr><td><code>metrics_jvm</code></td><td>BOOLEAN</td><td>是否收集JVM信息</td><td>false</td></tr><tr><td><code>metrics_slf4j_interval</code></td><td>SECONDS</td><td>将指标记录到日志的频率，<code>metrics_type</code>须配置为slf4j</td><td>60</td></tr><tr><td><code>http_port</code></td><td>INT</td><td><code>metrics_type</code>为http时，发布指标绑定的端口</td><td>8080</td></tr><tr><td><code>http_path_prefix</code></td><td>STRING</td><td>http的路径前缀</td><td>/</td></tr><tr><td><code>http_bind_address</code></td><td>STRING</td><td>http发布指标绑定的地址</td><td>all addresses</td></tr><tr><td><code>http_diagnostic</code></td><td>BOOLEAN</td><td>http是否开启diagnostic后缀</td><td>false</td></tr><tr><td><code>http_diagnostic_timeout</code></td><td>MILLISECONDS</td><td>http diagnostic 响应超时时间</td><td>10000</td></tr><tr><td><code>metrics_datadog_type</code></td><td><code>udp,http</code></td><td><code>metrics_type</code>为datadog时发布指标的方式</td><td>udp</td></tr><tr><td><code>metrics_datadog_tags</code></td><td>STRING</td><td>提供给 datadog 的标签，如 tag1:value1,tag2:value2</td><td></td></tr><tr><td><code>metrics_datadog_interval</code></td><td>INT</td><td>推指标到datadog的频率，单位秒</td><td>60</td></tr><tr><td><code>metrics_datadog_apikey</code></td><td>STRING</td><td>当 <code>metrics_datadog_type=http</code> 时datadog用的api key</td><td></td></tr><tr><td><code>metrics_datadog_host</code></td><td>STRING</td><td>当<code>metrics_datadog_type=udp</code>时推指标的目标地址</td><td>localhost</td></tr><tr><td><code>metrics_datadog_port</code></td><td>INT</td><td>当<code>metrics_datadog_type=udp</code> 时推指标的端口</td><td>8125</td></tr></tbody></table><p>具体可以得到哪些监控指标呢？有如下，注意所有指标都预先配置了指标前缀 <code>metrics_prefix</code></p><table><thead><tr><th>指标</th><th>类型</th><th>说明</th></tr></thead><tbody><tr><td><code>messages.succeeded</code></td><td>Counters</td><td>成功发送到kafka的消息数量</td></tr><tr><td><code>messages.failed</code></td><td>Counters</td><td>发送失败的消息数量</td></tr><tr><td><code>row.count</code></td><td>Counters</td><td>已处理的binlog行数，注意并非所有binlog都发往kafka</td></tr><tr><td><code>messages.succeeded.meter</code></td><td>Meters</td><td>消息成功发送到Kafka的速率</td></tr><tr><td><code>messages.failed.meter</code></td><td>Meters</td><td>消息发送失败到kafka的速率</td></tr><tr><td><code>row.meter</code></td><td>Meters</td><td>行(row)从binlog连接器到达maxwell的速率</td></tr><tr><td><code>replication.lag</code></td><td>Gauges</td><td>从数据库事务提交到Maxwell处理该事务之间所用的时间（毫秒）</td></tr><tr><td><code>inflightmessages.count</code></td><td>Gauges</td><td>当前正在处理的消息数（等待来自目的地的确认，或在消息之前）</td></tr><tr><td><code>message.publish.time</code></td><td>Timers</td><td>向kafka发送record所用的时间（毫秒）</td></tr><tr><td><code>message.publish.age</code></td><td>Timers</td><td>从数据库产生事件到发送到Kafka之间的时间（毫秒），精确度为+/-500ms</td></tr><tr><td><code>replication.queue.time</code></td><td>Timers</td><td>将一个binlog事件送到处理队列所用的时间（毫秒）</td></tr></tbody></table><p>上述有些指标为kafka特有的，并不支持所有的生产者。</p><p>实验一番，通过 http 方式获取监控指标</p><pre><code>docker run -p 8080:8080 -it --rm zendesk/maxwell bin/maxwell --user=&#39;maxwell&#39; \    --password=&#39;123456&#39; --host=&#39;10.100.97.246&#39; --producer=kafka \    --kafka.bootstrap.servers=&#39;10.100.97.246:9092&#39; --kafka_topic=maxwell --log_level=debug \    --metrics_type=http  --metrics_jvm=true --http_port=8080</code></pre><p>上面的配置大部分与前面的相同，不同的有 <code>-p 8080:8080</code> docker端口映射，以及 <code>--metrics_type=http  --metrics_jvm=true --http_port=8080</code>，配置了通过http方式发布指标，启用收集JVM信息，端口为8080，之后可以通过 <code>http://10.100.97.246:8080/metrics</code> 便可获取所有的指标</p><p><img src="http://image.laijianfeng.org/20190310_234508.png" alt="Maxwell监控"></p><p>http 方式有四种后缀，分别对应四种不同的格式</p><table><thead><tr><th>endpoint</th><th>说明</th></tr></thead><tbody><tr><td><code>/metrics</code></td><td>所有指标以JSON格式返回</td></tr><tr><td><code>/prometheus</code></td><td>所有指标以Prometheus格式返回（Prometheus是一套开源的监控&amp;报警&amp;时间序列数据库的组合）</td></tr><tr><td><code>/healthcheck</code></td><td>返回Maxwell过去15分钟是否健康</td></tr><tr><td><code>/ping</code></td><td>简单的测试，返回 <code>pong</code></td></tr></tbody></table><p>如果是通过 JMX 的方式收集Maxwell监控指标，可以 <code>JAVA_OPTS</code> 环境变量配置JMX访问权限</p><pre><code>export JAVA_OPTS=&quot;-Dcom.sun.management.jmxremote \-Dcom.sun.management.jmxremote.port=9010 \-Dcom.sun.management.jmxremote.local.only=false \-Dcom.sun.management.jmxremote.authenticate=false \-Dcom.sun.management.jmxremote.ssl=false \-Djava.rmi.server.hostname=10.100.97.246&quot;</code></pre><h4 id="多个Maxwell实例"><a href="#多个Maxwell实例" class="headerlink" title="多个Maxwell实例"></a>多个Maxwell实例</h4><p>在不同的配置下，Maxwell可以在同一个主服务器上运行多个实例。如果希望让生产者以不同的配置运行，例如将来自不同组的表(table)的事件投递到不同的Topic中，这将非常有用。Maxwell的每个实例都必须配置一个唯一的client_id，以便区分的binlog位置。</p><h4 id="GTID-支持"><a href="#GTID-支持" class="headerlink" title="GTID 支持"></a>GTID 支持</h4><p>Maxwell 从1.8.0版本开始支持基于GTID的复制(<a href="https://dev.mysql.com/doc/refman/5.6/en/replication-gtids.html" target="_blank" rel="noopener">GTID-based replication</a>)，在GTID模式下，Maxwell将在主机更改后透明地选择新的复制位置。</p><p><strong>什么是GTID Replication？</strong></p><p>GTID (Global Transaction ID) 是对于一个已提交事务的编号，并且是一个全局唯一的编号。</p><p>从 MySQL 5.6.5 开始新增了一种基于 GTID 的复制方式。通过 GTID 保证了每个在主库上提交的事务在集群中有一个唯一的ID。这种方式强化了数据库的主备一致性，故障恢复以及容错能力。</p><p>在原来基于二进制日志的复制中，从库需要告知主库要从哪个偏移量进行增量同步，如果指定错误会造成数据的遗漏，从而造成数据的不一致。借助GTID，在发生主备切换的情况下，MySQL的其它从库可以自动在新主库上找到正确的复制位置，这大大简化了复杂复制拓扑下集群的维护，也减少了人为设置复制位置发生误操作的风险。另外，基于GTID的复制可以忽略已经执行过的事务，减少了数据发生不一致的风险。</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><h4 id="timestamp-column"><a href="#timestamp-column" class="headerlink" title="timestamp column"></a>timestamp column</h4><p>maxwell对时间类型（datetime, timestamp, date）都是<strong>当做字符串处理</strong>的，这也是为了保证数据一致(比如<code>0000-00-00 00:00:00</code>这样的时间在timestamp里是非法的，但mysql却认，解析成java或者python类型就是null/None)。</p><p>如果MySQL表上的字段是 timestamp 类型，是有时区的概念，<strong>binlog解析出来的是标准UTC时间</strong>，但用户看到的是本地时间。比如 <code>f_create_time timestamp</code> 创建时间是北京时间 <code>2018-01-05 21:01:01</code>，那么mysql实际存储的是 <code>2018-01-05 13:01:01</code>，binlog里面也是这个时间字符串。如果不做消费者不做时区转换，会少8个小时。</p><p>与其每个客户端都要考虑这个问题，我觉得更合理的做法是提供时区参数，然后maxwell自动处理时区问题，否则要么客户端先需要知道哪些列是timestamp类型，或者连接上原库缓存上这些类型。</p><h4 id="binary-column"><a href="#binary-column" class="headerlink" title="binary column"></a>binary column</h4><p>maxwell可以处理binary类型的列，如blob、varbinary，它的做法就是对二进制列使用 <code>base64_encode</code>，当做字符串输出到json。消费者拿到这个列数据后，不能直接拼装，需要 <code>base64_decode</code>。</p><h4 id="表结构不同步"><a href="#表结构不同步" class="headerlink" title="表结构不同步"></a>表结构不同步</h4><p>如果是拿比较老的binlog，放到新的mysql server上去用maxwell拉去，有可能表结构已经发生了变化，比如binlog里面字段比 <code>schema_host</code> 里面的字段多一个。目前这种情况没有发现异常，比如阿里RDS默认会为 无主键无唯一索引的表，增加一个<code>__##alibaba_rds_rowid##__</code>，在 <code>show create table</code> 和 <code>schema</code> 里面都看不到这个隐藏主键，但binlog里面会有，同步到从库。</p><p>另外我们有通过git去管理结构版本，如果真有这种场景，也可以应对。</p><h4 id="大事务binlog"><a href="#大事务binlog" class="headerlink" title="大事务binlog"></a>大事务binlog</h4><p>当一个事物产生的binlog量非常大的时候，比如迁移日表数据，maxwell为了控制内存使用，会自动将处理不过来的binlog放到文件系统</p><pre><code>Using kafka version: 0.11.0.121:16:07,109 WARN  MaxwellMetrics - Metrics will not be exposed: metricsReportingType not configured.21:16:07,380 INFO  SchemaStoreSchema - Creating maxwell database21:16:07,540 INFO  Maxwell - Maxwell v?? is booting (RabbitmqProducer), starting at Position[BinlogPosition[mysql-bin.006235:24980714],lastHeartbeat=0]21:16:07,649 INFO  AbstractSchemaStore - Maxwell is capturing initial schema21:16:08,267 INFO  BinlogConnectorReplicator - Setting initial binlog pos to: mysql-bin.006235:2498071421:16:08,324 INFO  BinaryLogClient - Connected to rm-xxxxxxxxxxx.mysql.rds.aliyuncs.com:3306 at mysql-bin.006235/24980714 (sid:6379, cid:9182598)21:16:08,325 INFO  BinlogConnectorLifecycleListener - Binlog connected.03:15:36,104 INFO  ListWithDiskBuffer - Overflowed in-memory buffer, spilling over into /tmp/maxwell7935334910787514257events03:17:14,880 INFO  ListWithDiskBuffer - Overflowed in-memory buffer, spilling over into /tmp/maxwell3143086481692829045events</code></pre><p>但是遇到另外一个问题，overflow随后就出现异常 <code>EventDataDeserializationException: Failed to deserialize data of EventHeaderV4</code>，当我另起一个maxwell指点之前的binlog postion开始解析，却有没有抛异常。事后的数据也表明并没有数据丢失。</p><p>问题产生的原因还不明，<code>Caused by: java.net.SocketException: Connection reset</code>，感觉像读取 binlog 流的时候还没读取到完整的event，异常关闭了连接。这个问题比较顽固，github上面类似问题都没有达到明确的解决。（这也从侧面告诉我们，大表数据迁移，也要批量进行，不要一个<code>insert into .. select</code> 搞定）</p><pre><code>03:18:20,586 INFO  ListWithDiskBuffer - Overflowed in-memory buffer, spilling over into /tmp/maxwell5229190074667071141events03:19:31,289 WARN  BinlogConnectorLifecycleListener - Communication failure.com.github.shyiko.mysql.binlog.event.deserialization.EventDataDeserializationException: Failed to deserialize data of EventHeaderV4{timestamp=1514920657000, eventType=WRITE_ROWS, serverId=2115082720, headerLength=19, dataLength=8155, nextPosition=520539918, flags=0}        at com.github.shyiko.mysql.binlog.event.deserialization.EventDeserializer.deserializeEventData(EventDeserializer.java:216) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]        at com.github.shyiko.mysql.binlog.event.deserialization.EventDeserializer.nextEvent(EventDeserializer.java:184) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]        at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:890) [mysql-binlog-connector-java-0.13.0.jar:0.13.0]        at com.github.shyiko.mysql.binlog.BinaryLogClient.connect(BinaryLogClient.java:559) [mysql-binlog-connector-java-0.13.0.jar:0.13.0]        at com.github.shyiko.mysql.binlog.BinaryLogClient$7.run(BinaryLogClient.java:793) [mysql-binlog-connector-java-0.13.0.jar:0.13.0]        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]Caused by: java.net.SocketException: Connection reset        at java.net.SocketInputStream.read(SocketInputStream.java:210) ~[?:1.8.0_121]        at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[?:1.8.0_121]        at com.github.shyiko.mysql.binlog.io.BufferedSocketInputStream.read(BufferedSocketInputStream.java:51) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]        at com.github.shyiko.mysql.binlog.io.ByteArrayInputStream.readWithinBlockBoundaries(ByteArrayInputStream.java:202) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]        at com.github.shyiko.mysql.binlog.io.ByteArrayInputStream.read(ByteArrayInputStream.java:184) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]        at com.github.shyiko.mysql.binlog.io.ByteArrayInputStream.readInteger(ByteArrayInputStream.java:46) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]        at com.github.shyiko.mysql.binlog.event.deserialization.AbstractRowsEventDataDeserializer.deserializeLong(AbstractRowsEventDataDeserializer.java:212) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]        at com.github.shyiko.mysql.binlog.event.deserialization.AbstractRowsEventDataDeserializer.deserializeCell(AbstractRowsEventDataDeserializer.java:150) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]        at com.github.shyiko.mysql.binlog.event.deserialization.AbstractRowsEventDataDeserializer.deserializeRow(AbstractRowsEventDataDeserializer.java:132) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]        at com.github.shyiko.mysql.binlog.event.deserialization.WriteRowsEventDataDeserializer.deserializeRows(WriteRowsEventDataDeserializer.java:64) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]        at com.github.shyiko.mysql.binlog.event.deserialization.WriteRowsEventDataDeserializer.deserialize(WriteRowsEventDataDeserializer.java:56) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]        at com.github.shyiko.mysql.binlog.event.deserialization.WriteRowsEventDataDeserializer.deserialize(WriteRowsEventDataDeserializer.java:32) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]        at com.github.shyiko.mysql.binlog.event.deserialization.EventDeserializer.deserializeEventData(EventDeserializer.java:210) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]        ... 5 more03:19:31,514 INFO  BinlogConnectorLifecycleListener - Binlog disconnected.03:19:31,590 WARN  BinlogConnectorReplicator - replicator stopped at position: mysql-bin.006236:520531744 -- restarting03:19:31,595 INFO  BinaryLogClient - Connected to rm-xxxxxx.mysql.rds.aliyuncs.com:3306 at mysql-bin.006236/520531744 (sid:6379, cid:9220521)</code></pre><h4 id="tableMapCache"><a href="#tableMapCache" class="headerlink" title="tableMapCache"></a>tableMapCache</h4><p>前面讲过，如果我只想获取某几个表的binlog变更，需要用 include_tables 来过滤，但如果mysql server上现在删了一个表t1，但我的binlog是从昨天开始读取，被删的那个表t1在maxwell启动的时候是拉取不到表结构的。然后昨天的binlog里面有 t1 的变更，因为找不到表结构给来组装成json，会抛异常。</p><p>手动在 <code>maxwell.tables/columns</code> 里面插入记录是可行的。但这个问题的根本是，maxwell在binlog过滤的时候，只在处理row_event的时候，而对 tableMapCache 要求binlog里面的所有表都要有。</p><p>自己（seanlook）提交了一个commit，可以在做 tableMapCache 的时候也仅要求缓存 include_dbs/tables 这些表： <a href="https://github.com/seanlook/maxwell/commit/2618b70303078bf910a1981b69943cca75ee04fb" target="_blank" rel="noopener">https://github.com/seanlook/maxwell/commit/2618b70303078bf910a1981b69943cca75ee04fb</a></p><h4 id="提高消费性能"><a href="#提高消费性能" class="headerlink" title="提高消费性能"></a>提高消费性能</h4><p>在用rabbitmq时，<code>routing_key</code> 是 <code>%db%.%table%</code>，但某些表产生的binlog增量非常大，就会导致各队列消息量很不平均，目前因为还没做到事务xid或者thread_id级别的并发回放，所以最小队列粒度也是表，尽量单独放一个队列，其它数据量小的合在一起。</p><h4 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h4><p>Maxwell 在 maxwell 库中维护了 binlog 的位移等信息，由于一些原因譬如 <code>reset master;</code>，导致 maxwell 库中的记录与实际的binlog对不上，这时将报异常，这是可以手动修正binlog位移或者直接清空/删除 maxwell 库重建</p><pre><code>com.github.shyiko.mysql.binlog.network.ServerException: Could not find first log file name in binary log index file        at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:885)        at com.github.shyiko.mysql.binlog.BinaryLogClient.connect(BinaryLogClient.java:564)        at com.github.shyiko.mysql.binlog.BinaryLogClient$7.run(BinaryLogClient.java:796)        at java.lang.Thread.run(Thread.java:748)</code></pre><p>以及</p><pre><code>com.github.shyiko.mysql.binlog.network.ServerException: A slave with the same server_uuid/server_id as this slave has connected to the master; the first event &#39;mysql-bin.000001&#39; at 760357, the last event read from &#39;./mysql-bin.000001&#39; at 1888540, the last byte read from &#39;./mysql-bin.000001&#39; at 1888540.        at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:885)        at com.github.shyiko.mysql.binlog.BinaryLogClient.connect(BinaryLogClient.java:564)        at com.github.shyiko.mysql.binlog.BinaryLogClient$7.run(BinaryLogClient.java:796)        at java.lang.Thread.run(Thread.java:748)</code></pre><h4 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h4><ul><li><a href="http://maxwells-daemon.io/filtering/" target="_blank" rel="noopener">Maxwell’s Daemon Doc</a></li><li><a href="http://pdf.us/2018/08/24/1750.html" target="_blank" rel="noopener">轻风博客.MySQL Binlog解析工具Maxwell 1.17.1 的安装和使用</a></li><li><a href="http://seanlook.com/2018/01/13/maxwell-binlog/" target="_blank" rel="noopener">Sean.自建Binlog订阅服务 —— Maxwell</a></li><li><a href="https://www.hi-linux.com/posts/47176.html" target="_blank" rel="noopener">MySQL 5.7 基于 GTID 的主从复制实践</a></li></ul><p><img src="http://image.laijianfeng.org/20190116_014816.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>MySQL Binlog 介绍</title>
      <link href="/2019/03/MySQL-Binlog-%E4%BB%8B%E7%BB%8D/"/>
      <url>/2019/03/MySQL-Binlog-%E4%BB%8B%E7%BB%8D/</url>
      <content type="html"><![CDATA[<h3 id="Binlog-简介"><a href="#Binlog-简介" class="headerlink" title="Binlog 简介"></a>Binlog 简介</h3><p>MySQL中一般有以下几种日志：</p><table><thead><tr><th>日志类型</th><th>写入日志的信息</th></tr></thead><tbody><tr><td>错误日志</td><td>记录在启动，运行或停止mysqld时遇到的问题</td></tr><tr><td>通用查询日志</td><td>记录建立的客户端连接和执行的语句</td></tr><tr><td>二进制日志</td><td>记录更改数据的语句</td></tr><tr><td>中继日志</td><td>从复制主服务器接收的数据更改</td></tr><tr><td>慢查询日志</td><td>记录所有执行时间超过 <code>long_query_time</code> 秒的所有查询或不使用索引的查询</td></tr><tr><td>DDL日志（元数据日志）</td><td>元数据操作由DDL语句执行</td></tr></tbody></table><p>本文主要介绍二进制日志 binlog。</p><p>MySQL 的二进制日志 binlog 可以说是 MySQL 最重要的日志，它记录了所有的 <code>DDL</code> 和 <code>DML</code> 语句（除了数据查询语句select、show等），<strong>以事件形式记录</strong>，还包含语句所执行的消耗的时间，MySQL的二进制日志是事务安全型的。binlog 的主要目的是<strong>复制和恢复</strong>。</p><h4 id="Binlog日志的两个最重要的使用场景"><a href="#Binlog日志的两个最重要的使用场景" class="headerlink" title="Binlog日志的两个最重要的使用场景"></a>Binlog日志的两个最重要的使用场景</h4><ul><li><strong>MySQL主从复制</strong>：MySQL Replication在Master端开启binlog，Master把它的二进制日志传递给slaves来达到master-slave数据一致的目的</li><li><strong>数据恢复</strong>：通过使用 mysqlbinlog工具来使恢复数据</li></ul><h4 id="启用-Binlog"><a href="#启用-Binlog" class="headerlink" title="启用 Binlog"></a>启用 Binlog</h4><blockquote><p>注：笔者实验的MySQL版本为：5.7.22</p></blockquote><p>一般来说开启binlog日志大概会有1%的性能损耗。</p><p>启用binlog，通过配置 <code>/etc/my.cnf</code> 或 <code>/etc/mysql/mysql.conf.d/mysqld.cnf</code> 配置文件的 <code>log-bin</code> 选项：</p><p>在配置文件中加入 <code>log-bin</code> 配置，表示启用binlog，如果没有给定值，写成 <code>log-bin=</code>，则默认名称为主机名。（注：名称若带有小数点，则只取第一个小数点前的部分作为名称）</p><pre><code>[mysqld]log-bin=my-binlog-name</code></pre><p>也可以通过 <code>SET SQL_LOG_BIN=1</code> 命令来启用 binlog，通过 <code>SET SQL_LOG_BIN=0</code> 命令停用 binlog。启用 binlog 之后须重启MySQL才能生效。</p><h4 id="常用的Binlog操作命令"><a href="#常用的Binlog操作命令" class="headerlink" title="常用的Binlog操作命令"></a>常用的Binlog操作命令</h4><pre><code># 是否启用binlog日志show variables like &#39;log_bin&#39;;# 查看详细的日志配置信息show global variables like &#39;%log%&#39;;# mysql数据存储目录show variables like &#39;%dir%&#39;;# 查看binlog的目录show global variables like &quot;%log_bin%&quot;;# 查看当前服务器使用的biglog文件及大小show binary logs;# 查看主服务器使用的biglog文件及大小# 查看最新一个binlog日志文件名称和Positionshow master status;# 事件查询命令# IN &#39;log_name&#39; ：指定要查询的binlog文件名(不指定就是第一个binlog文件)# FROM pos ：指定从哪个pos起始点开始查起(不指定就是从整个文件首个pos点开始算)# LIMIT [offset,] ：偏移量(不指定就是0)# row_count ：查询总条数(不指定就是所有行)show binlog events [IN &#39;log_name&#39;] [FROM pos] [LIMIT [offset,] row_count];# 查看 binlog 内容show binlog events;# 查看具体一个binlog文件的内容 （in 后面为binlog的文件名）show binlog events in &#39;master.000003&#39;;# 设置binlog文件保存事件，过期删除，单位天set global expire_log_days=3; # 删除当前的binlog文件reset master; # 删除slave的中继日志reset slave;# 删除指定日期前的日志索引中binlog日志文件purge master logs before &#39;2019-03-09 14:00:00&#39;;# 删除指定日志文件purge master logs to &#39;master.000003&#39;;</code></pre><h4 id="写-Binlog-的时机"><a href="#写-Binlog-的时机" class="headerlink" title="写 Binlog 的时机"></a>写 Binlog 的时机</h4><p>对支持事务的引擎如InnoDB而言，必须要提交了事务才会记录binlog。binlog 什么时候<strong>刷新到磁盘</strong>跟参数 <code>sync_binlog</code> 相关。</p><ul><li>如果设置为0，则表示MySQL不控制binlog的刷新，由文件系统去控制它缓存的刷新；</li><li>如果设置为不为0的值，则表示每 <code>sync_binlog</code> 次事务，MySQL调用文件系统的刷新操作刷新binlog到磁盘中。</li><li>设为1是最安全的，在系统故障时最多丢失一个事务的更新，但是会对性能有所影响。</li></ul><p>如果 <code>sync_binlog=0</code> 或 <code>sync_binlog大于1</code>，当发生电源故障或操作系统崩溃时，可能有一部分已提交但其binlog未被同步到磁盘的事务会被丢失，恢复程序将无法恢复这部分事务。</p><p>在MySQL 5.7.7之前，默认值 sync_binlog 是0，MySQL 5.7.7和更高版本使用默认值1，这是最安全的选择。一般情况下会设置为100或者0，牺牲一定的一致性来获取更好的性能。</p><h4 id="Binlog-文件以及扩展"><a href="#Binlog-文件以及扩展" class="headerlink" title="Binlog 文件以及扩展"></a>Binlog 文件以及扩展</h4><p>binlog日志包括两类文件:</p><ul><li>二进制日志索引文件（文件名后缀为.index）用于记录所有有效的的二进制文件</li><li>二进制日志文件（文件名后缀为.00000*）记录数据库所有的DDL和DML语句事件</li></ul><p>binlog是一个二进制文件集合，每个binlog文件以一个4字节的魔数开头，接着是一组Events:</p><ul><li>魔数：0xfe62696e对应的是0xfebin；</li><li>Event：每个Event包含header和data两个部分；header提供了Event的创建时间，哪个服务器等信息，data部分提供的是针对该Event的具体信息，如具体数据的修改；</li><li>第一个Event用于描述binlog文件的格式版本，这个格式就是event写入binlog文件的格式；</li><li>其余的Event按照第一个Event的格式版本写入；</li><li>最后一个Event用于说明下一个binlog文件；</li><li>binlog的索引文件是一个文本文件，其中内容为当前的binlog文件列表</li></ul><p>当遇到以下3种情况时，MySQL会重新生成一个新的日志文件，文件序号递增：</p><ul><li>MySQL服务器停止或重启时</li><li>使用 <code>flush logs</code> 命令；</li><li>当 binlog 文件大小超过 <code>max_binlog_size</code> 变量的值时；</li></ul><blockquote><p><code>max_binlog_size</code> 的最小值是4096字节，最大值和默认值是 1GB (1073741824字节)。事务被写入到binlog的一个块中，所以它不会在几个二进制日志之间被拆分。因此，如果你有很大的事务，为了保证事务的完整性，不可能做切换日志的动作，只能将该事务的日志都记录到当前日志文件中，直到事务结束，你可能会看到binlog文件大于 max_binlog_size 的情况。</p></blockquote><h4 id="Binlog-的日志格式"><a href="#Binlog-的日志格式" class="headerlink" title="Binlog 的日志格式"></a>Binlog 的日志格式</h4><p>记录在二进制日志中的事件的格式取决于二进制记录格式。支持三种格式类型：</p><ul><li>STATEMENT：基于SQL语句的复制（statement-based replication, SBR）</li><li>ROW：基于行的复制（row-based replication, RBR）</li><li>MIXED：混合模式复制（mixed-based replication, MBR）</li></ul><p>在 <code>MySQL 5.7.7</code> 之前，默认的格式是 <code>STATEMENT</code>，在 <code>MySQL 5.7.7</code> 及更高版本中，默认值是 <code>ROW</code>。日志格式通过 <code>binlog-format</code> 指定，如 <code>binlog-format=STATEMENT</code>、<code>binlog-format=ROW</code>、<code>binlog-format=MIXED</code>。</p><h5 id="Statement"><a href="#Statement" class="headerlink" title="Statement"></a>Statement</h5><p>每一条会修改数据的sql都会记录在binlog中</p><p>优点：不需要记录每一行的变化，减少了binlog日志量，节约了IO, 提高了性能。</p><p>缺点：由于记录的只是执行语句，为了这些语句能在slave上正确运行，因此还必须记录每条语句在执行的时候的一些相关信息，以保证所有语句能在slave得到和在master端执行的时候相同的结果。另外mysql的复制，像一些特定函数的功能，slave与master要保持一致会有很多相关问题。</p><h5 id="Row"><a href="#Row" class="headerlink" title="Row"></a>Row</h5><p>5.1.5版本的MySQL才开始支持 <code>row level</code> 的复制,它不记录sql语句上下文相关信息，仅保存哪条记录被修改。</p><p>优点： binlog中可以不记录执行的sql语句的上下文相关的信息，仅需要记录那一条记录被修改成什么了。所以row的日志内容会非常清楚的记录下每一行数据修改的细节。而且不会出现某些特定情况下的存储过程，或function，以及trigger的调用和触发无法被正确复制的问题.</p><p>缺点:所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生大量的日志内容。</p><blockquote><p>注：将二进制日志格式设置为ROW时，有些更改仍然使用基于语句的格式，包括所有DDL语句，例如CREATE TABLE， ALTER TABLE，或 DROP TABLE。</p></blockquote><h5 id="Mixed"><a href="#Mixed" class="headerlink" title="Mixed"></a>Mixed</h5><p>从5.1.8版本开始，MySQL提供了Mixed格式，实际上就是Statement与Row的结合。<br>在Mixed模式下，一般的语句修改使用statment格式保存binlog，如一些函数，statement无法完成主从复制的操作，则采用row格式保存binlog，MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式，也就是在Statement和Row之间选择一种。</p><h4 id="mysqlbinlog-命令的使用"><a href="#mysqlbinlog-命令的使用" class="headerlink" title="mysqlbinlog 命令的使用"></a>mysqlbinlog 命令的使用</h4><p>服务器以二进制格式将binlog日志写入binlog文件，如何要以文本格式显示其内容，可以使用 mysqlbinlog 命令。</p><pre><code class="shell"># mysqlbinlog 的执行格式mysqlbinlog [options] log_file ...# 查看bin-log二进制文件（shell方式）mysqlbinlog -v --base64-output=decode-rows /var/lib/mysql/master.000003# 查看bin-log二进制文件（带查询条件）mysqlbinlog -v --base64-output=decode-rows /var/lib/mysql/master.000003 \    --start-datetime=&quot;2019-03-01 00:00:00&quot;  \    --stop-datetime=&quot;2019-03-10 00:00:00&quot;   \    --start-position=&quot;5000&quot;    \    --stop-position=&quot;20000&quot;</code></pre><p>设置日志格式为ROW时，在我的机器上输出了以下信息</p><pre><code>/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#190308 10:05:03 server id 1  end_log_pos 123 CRC32 0xff02e23d     Start: binlog v 4, server v 5.7.22-log created 190308 10:05:03# Warning: this binlog is either in use or was not closed properly.# at 123#190308 10:05:03 server id 1  end_log_pos 154 CRC32 0xb81da4c5     Previous-GTIDs# [empty]# at 154#190308 10:05:09 server id 1  end_log_pos 219 CRC32 0xfb30d42c     Anonymous_GTID    last_committed=0    sequence_number=1    rbr_only=yes/*!50718 SET TRANSACTION ISOLATION LEVEL READ COMMITTED*//*!*/;SET @@SESSION.GTID_NEXT= &#39;ANONYMOUS&#39;/*!*/;# at 219......# at 21019#190308 10:10:09 server id 1  end_log_pos 21094 CRC32 0x7a405abc     Query    thread_id=113    exec_time=0    error_code=0SET TIMESTAMP=1552011009/*!*/;BEGIN/*!*/;# at 21094#190308 10:10:09 server id 1  end_log_pos 21161 CRC32 0xdb7a2b35     Table_map: `maxwell`.`positions` mapped to number 110# at 21161#190308 10:10:09 server id 1  end_log_pos 21275 CRC32 0xec3be372     Update_rows: table id 110 flags: STMT_END_F### UPDATE `maxwell`.`positions`### WHERE###   @1=1###   @2=&#39;master.000003&#39;###   @3=20262###   @4=NULL###   @5=&#39;maxwell&#39;###   @6=NULL###   @7=1552011005707### SET###   @1=1###   @2=&#39;master.000003&#39;###   @3=20923###   @4=NULL###   @5=&#39;maxwell&#39;###   @6=NULL###   @7=1552011009790# at 21275#190308 10:10:09 server id 1  end_log_pos 21306 CRC32 0xe6c4346d     Xid = 13088COMMIT/*!*/;SET @@SESSION.GTID_NEXT= &#39;AUTOMATIC&#39; /* added by mysqlbinlog */ /*!*/;DELIMITER ;# End of log file/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/;</code></pre><p>截取其中的一段进行分析：</p><pre><code># at 21019#190308 10:10:09 server id 1  end_log_pos 21094 CRC32 0x7a405abc     Query    thread_id=113    exec_time=0    error_code=0SET TIMESTAMP=1552011009/*!*/;BEGIN/*!*/;</code></pre><p>上面输出包括信息：</p><ul><li>position: 位于文件中的位置，即第一行的（# at 21019）,说明该事件记录从文件第21019个字节开始</li><li>timestamp: 事件发生的时间戳，即第二行的（#190308 10:10:09）</li><li>server id: 服务器标识（1）</li><li>end_log_pos 表示下一个事件开始的位置（即当前事件的结束位置+1）</li><li>thread_id: 执行该事件的线程id （thread_id=113）</li><li>exec_time: 事件执行的花费时间</li><li>error_code: 错误码，0意味着没有发生错误</li><li>type:事件类型Query</li></ul><h4 id="Binlog-事件类型"><a href="#Binlog-事件类型" class="headerlink" title="Binlog 事件类型"></a>Binlog 事件类型</h4><p>binlog 事件的结构主要有3个版本：</p><ul><li>v1: 在 MySQL 3.23 中使用</li><li>v3: 在 MySQL 4.0.2 到 4.1 中使用</li><li>v4: 在 MySQL 5.0 及以上版本中使用</li></ul><p>现在一般不会使用MySQL5.0以下版本，所以下面仅介绍v4版本的binlog事件类型。binlog 的事件类型较多，本文在此做一些简单的汇总</p><table><thead><tr><th>事件类型</th><th>说明</th></tr></thead><tbody><tr><td>UNKNOWN_EVENT</td><td>此事件从不会被触发，也不会被写入binlog中；发生在当读取binlog时，不能被识别其他任何事件，那被视为UNKNOWN_EVENT</td></tr><tr><td>START_EVENT_V3</td><td>每个binlog文件开始的时候写入的事件，此事件被用在MySQL3.23 – 4.1，MYSQL5.0以后已经被 FORMAT_DESCRIPTION_EVENT 取代</td></tr><tr><td>QUERY_EVENT</td><td>执行更新语句时会生成此事件，包括：create，insert，update，delete；</td></tr><tr><td>STOP_EVENT</td><td>当mysqld停止时生成此事件</td></tr><tr><td>ROTATE_EVENT</td><td>当mysqld切换到新的binlog文件生成此事件，切换到新的binlog文件可以通过执行flush logs命令或者binlog文件大于 <code>max_binlog_size</code> 参数配置的大小；</td></tr><tr><td>INTVAR_EVENT</td><td>当sql语句中使用了AUTO_INCREMENT的字段或者LAST_INSERT_ID()函数；此事件没有被用在binlog_format为ROW模式的情况下</td></tr><tr><td>LOAD_EVENT</td><td>执行LOAD DATA INFILE 语句时产生此事件，在MySQL 3.23版本中使用</td></tr><tr><td>SLAVE_EVENT</td><td>未使用</td></tr><tr><td>CREATE_FILE_EVENT</td><td>执行LOAD DATA INFILE 语句时产生此事件，在MySQL4.0和4.1版本中使用</td></tr><tr><td>APPEND_BLOCK_EVENT</td><td>执行LOAD DATA INFILE 语句时产生此事件，在MySQL4.0版本中使用</td></tr><tr><td>EXEC_LOAD_EVENT</td><td>执行LOAD DATA INFILE 语句时产生此事件，在MySQL4.0和4.1版本中使用</td></tr><tr><td>DELETE_FILE_EVENT</td><td>执行LOAD DATA INFILE 语句时产生此事件，在MySQL4.0版本中使用</td></tr><tr><td>NEW_LOAD_EVENT</td><td>执行LOAD DATA INFILE 语句时产生此事件，在MySQL4.0和4.1版本中使用</td></tr><tr><td>RAND_EVENT</td><td>执行包含RAND()函数的语句产生此事件，此事件没有被用在binlog_format为ROW模式的情况下</td></tr><tr><td>USER_VAR_EVENT</td><td>执行包含了用户变量的语句产生此事件，此事件没有被用在binlog_format为ROW模式的情况下</td></tr><tr><td>FORMAT_DESCRIPTION_EVENT</td><td>描述事件，被写在每个binlog文件的开始位置，用在MySQL5.0以后的版本中，代替了START_EVENT_V3</td></tr><tr><td>XID_EVENT</td><td>支持XA的存储引擎才有，本地测试的数据库存储引擎是innodb，所有上面出现了XID_EVENT；innodb事务提交产生了QUERY_EVENT的BEGIN声明，QUERY_EVENT以及COMMIT声明，如果是myIsam存储引擎也会有BEGIN和COMMIT声明，只是COMMIT类型不是XID_EVENT</td></tr><tr><td>BEGIN_LOAD_QUERY_EVENT</td><td>执行LOAD DATA INFILE 语句时产生此事件，在MySQL5.0版本中使用</td></tr><tr><td>EXECUTE_LOAD_QUERY_EVENT</td><td>执行LOAD DATA INFILE 语句时产生此事件，在MySQL5.0版本中使用</td></tr><tr><td>TABLE_MAP_EVENT</td><td>用在binlog_format为ROW模式下，将表的定义映射到一个数字，在行操作事件之前记录（包括：WRITE_ROWS_EVENT，UPDATE_ROWS_EVENT，DELETE_ROWS_EVENT）</td></tr><tr><td>PRE_GA_WRITE_ROWS_EVENT</td><td>已过期，被 WRITE_ROWS_EVENT 代替</td></tr><tr><td>PRE_GA_UPDATE_ROWS_EVENT</td><td>已过期，被 UPDATE_ROWS_EVENT 代替</td></tr><tr><td>PRE_GA_DELETE_ROWS_EVENT</td><td>已过期，被 DELETE_ROWS_EVENT 代替</td></tr><tr><td>WRITE_ROWS_EVENT</td><td>用在binlog_format为ROW模式下，对应 insert 操作</td></tr><tr><td>UPDATE_ROWS_EVENT</td><td>用在binlog_format为ROW模式下，对应 update 操作</td></tr><tr><td>DELETE_ROWS_EVENT</td><td>用在binlog_format为ROW模式下，对应 delete 操作</td></tr><tr><td>INCIDENT_EVENT</td><td>主服务器发生了不正常的事件，通知从服务器并告知可能会导致数据处于不一致的状态</td></tr><tr><td>HEARTBEAT_LOG_EVENT</td><td>主服务器告诉从服务器，主服务器还活着，不写入到日志文件中</td></tr></tbody></table><h4 id="Binlog-事件的结构"><a href="#Binlog-事件的结构" class="headerlink" title="Binlog 事件的结构"></a>Binlog 事件的结构</h4><p>一个事件对象分为事件头和事件体，事件的结构如下：</p><pre><code>+=====================================+| event  | timestamp         0 : 4    || header +----------------------------+|        | type_code         4 : 1    ||        +----------------------------+|        | server_id         5 : 4    ||        +----------------------------+|        | event_length      9 : 4    ||        +----------------------------+|        | next_position    13 : 4    ||        +----------------------------+|        | flags            17 : 2    ||        +----------------------------+|        | extra_headers    19 : x-19 |+=====================================+| event  | fixed part        x : y    || data   +----------------------------+|        | variable part              |+=====================================+</code></pre><p>如果事件头的长度是 <code>x</code> 字节，那么事件体的长度为 <code>(event_length - x)</code> 字节；设事件体中 <code>fixed part</code> 的长度为 <code>y</code> 字节，那么 <code>variable part</code> 的长度为 <code>(event_length - (x + y))</code> 字节</p><h4 id="Binlog-Event-简要分析"><a href="#Binlog-Event-简要分析" class="headerlink" title="Binlog Event 简要分析"></a>Binlog Event 简要分析</h4><p>从一个最简单的实例来分析Event，包括创建表，插入数据，更新数据，删除数据；</p><pre><code class="sql">CREATE TABLE `test` (  `id` bigint(20) NOT NULL AUTO_INCREMENT,  `age` int(11) DEFAULT NULL,  `name` varchar(255) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;insert into test values(1,22,&quot;小旋锋&quot;);update test set name=&#39;whirly&#39; where id=1;delete from test where id=1;</code></pre><p>日志格式为<code>STATEMENT</code>，查看所有的Event</p><p><img src="http://image.laijianfeng.org/20190309_185754.png" alt="STATEMENT格式下create、insert、update、delete操作产生的binlog事件"></p><p>日志格式为<code>ROW</code>时是下面这样，可以发现又有一些不同</p><p><img src="http://image.laijianfeng.org/20190309_191336.png" alt="ROW格式下create、insert、update、delete操作产生的binlog事件"></p><p>关于Event的分析，有需要可以查看参考文档进行推算。</p><h4 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h4><ul><li><a href="http://www.searchdoc.cn/rdbms/mysql/dev.mysql.com/doc/refman/5.7/en/binary-log.com.coder114.cn.html" target="_blank" rel="noopener">MySQL 5.7参考手册.二进制日志</a></li><li><a href="https://dev.mysql.com/doc/internals/en/binary-log.html" target="_blank" rel="noopener">MySQL Internals Manual.The Binary Log</a></li><li><a href="https://blog.csdn.net/u013256816/article/details/53020335" target="_blank" rel="noopener">朱小厮.MySQL Binlog解析</a></li><li><a href="https://www.jianshu.com/p/c16686b35807" target="_blank" rel="noopener">七把刀.MySQL binlog格式解析</a></li><li><a href="https://www.cnblogs.com/kevingrace/p/5907254.html" target="_blank" rel="noopener">散尽浮华.Mysql之binlog日志说明及利用binlog日志恢复数据操作记录</a></li><li><a href="http://blog.jobbole.com/113073/" target="_blank" rel="noopener">MySql Binlog 初识</a></li><li><a href="https://yq.aliyun.com/articles/57731#" target="_blank" rel="noopener">MySQL5.7杀手级新特性：GTID原理与实战</a></li><li><a href="https://www.hi-linux.com/posts/47176.html" target="_blank" rel="noopener">MySQL 5.7 基于 GTID 的主从复制实践</a></li></ul><p><img src="http://image.laijianfeng.org/20190116_014816.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>利用Zookeeper实现 - 分布式锁</title>
      <link href="/2019/01/%E5%88%A9%E7%94%A8Zookeeper%E5%AE%9E%E7%8E%B0-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
      <url>/2019/01/%E5%88%A9%E7%94%A8Zookeeper%E5%AE%9E%E7%8E%B0-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</url>
      <content type="html"><![CDATA[<p>在许多场景中，<strong>数据一致性</strong>是一个比较重要的话题，在单机环境中，我们可以通过Java提供的<strong>并发API</strong>来解决；而在分布式环境(会遇到网络故障、消息重复、消息丢失等各种问题)下要复杂得多，常见的解决方案是<strong>分布式事务</strong>、<strong>分布式锁</strong>等。</p><p>本文主要探讨如何利用Zookeeper来实现分布式锁。</p><h3 id="关于分布式锁"><a href="#关于分布式锁" class="headerlink" title="关于分布式锁"></a>关于分布式锁</h3><p>分布式锁是控制分布式系统之间<strong>同步访问共享资源</strong>的一种方式。</p><p>在<strong>实现</strong>分布式锁的过程中需要注意的：</p><ul><li>锁的可重入性(递归调用不应该被阻塞、避免死锁)</li><li>锁的超时(避免死锁、死循环等意外情况)</li><li>锁的阻塞(保证原子性等)</li><li>锁的特性支持(阻塞锁、可重入锁、公平锁、联锁、信号量、读写锁)</li></ul><p>在<strong>使用</strong>分布式锁时需要注意：</p><ul><li>分布式锁的开销(分布式锁一般能不用就不用，有些场景可以用乐观锁代替)</li><li>加锁的粒度(控制加锁的粒度，可以优化系统的性能)</li><li>加锁的方式</li></ul><p>以下是几种常见的实现分布式锁的方案及其优缺点。</p><h4 id="基于数据库"><a href="#基于数据库" class="headerlink" title="基于数据库"></a>基于数据库</h4><p><strong>1. 基于数据库表</strong></p><p>最简单的方式可能就是直接创建一张锁表，当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。给某字段添加唯一性约束，如果有多个请求同时提交到数据库的话，<strong>数据库会保证只有一个操作可以成功</strong>，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。</p><p>会引入数据库单点、无失效时间、不阻塞、不可重入等问题。</p><p><strong>2. 基于数据库排他锁</strong></p><p>如果使用的是MySql的InnoDB引擎，在查询语句后面增加<code>for update</code>，数据库会在查询过程中(须通过唯一索引查询)给数据库表增加排他锁，我们可以认为获得排它锁的线程即可获得分布式锁，通过 connection.commit() 操作来释放锁。</p><p>会引入数据库单点、不可重入、无法保证一定使用行锁(部分情况下MySQL自动使用表锁而不是行锁)、排他锁长时间不提交导致占用数据库连接等问题。</p><p><strong>3. 数据库实现分布式锁总结</strong></p><p>优点：</p><ul><li>直接借助数据库，容易理解。</li></ul><p>缺点：</p><ul><li>会引入更多的问题，使整个方案变得越来越复杂</li><li>操作数据库需要一定的开销，有一定的性能问题</li><li>使用数据库的行级锁并不一定靠谱，尤其是当我们的锁表并不大的时候</li></ul><h4 id="基于缓存"><a href="#基于缓存" class="headerlink" title="基于缓存"></a>基于缓存</h4><p>相比较于基于数据库实现分布式锁的方案来说，基于缓存来实现在性能方面会表现的更好一点。目前有很多成熟的缓存产品，包括Redis、memcached、tair等。</p><p>这里以Redis为例举出几种实现方法：</p><p><strong>1. 基于 redis 的 setnx()、expire() 方法做分布式锁</strong></p><p>setnx 的含义就是 <code>SET if Not Exists</code>，其主要有两个参数 <code>setnx(key, value)</code>。该方法是原子的，如果 key 不存在，则设置当前 key 成功，返回 1；如果当前 key 已经存在，则设置当前 key 失败，返回 0。</p><p>expire 设置过期时间，要注意的是 setnx 命令不能设置 key 的超时时间，只能通过 expire() 来对 key 设置。</p><p><strong>2. 基于 redis 的 setnx()、get()、getset()方法做分布式锁</strong></p><p>getset 这个命令主要有两个参数 <code>getset(key，newValue)</code>，该方法是原子的，对 key 设置 newValue 这个值，并且返回 key 原来的旧值。</p><p><strong>3. 基于 Redlock 做分布式锁</strong></p><p>Redlock 是 Redis 的作者 antirez 给出的集群模式的 Redis 分布式锁，它基于 N 个完全独立的 Redis 节点（通常情况下 N 可以设置成 5）</p><p><strong>4. 基于 redisson 做分布式锁</strong></p><p>redisson 是 redis 官方的分布式锁组件，GitHub 地址：<a href="https://github.com/redisson/redisson" target="_blank" rel="noopener">https://github.com/redisson/redisson</a></p><p><strong>基于缓存实现分布式锁总结</strong></p><p>优点：</p><ul><li>性能好</li></ul><p>缺点：</p><ul><li>实现中需要考虑的因素太多</li><li>通过超时时间来控制锁的失效时间并不是十分的靠谱</li></ul><h4 id="基于Zookeeper"><a href="#基于Zookeeper" class="headerlink" title="基于Zookeeper"></a>基于Zookeeper</h4><p><strong>大致思想</strong>为：每个客户端对某个方法加锁时，在 Zookeeper 上与该方法对应的指定节点的目录下，<strong>生成一个唯一的临时有序节点</strong>。 判断是否获取锁的方式很简单，只需要判断有序节点中<strong>序号最小的一个</strong>。 当释放锁的时候，只需将这个临时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题</p><p><strong>Zookeeper实现分布式锁总结</strong></p><p>优点：</p><ul><li>有效的解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题</li><li>实现较为简单</li></ul><p>缺点：</p><ul><li>性能上不如使用缓存实现的分布式锁，因为每次在创建锁和释放锁的过程中，都要动态创建、销毁临时节点来实现锁功能</li><li>需要对Zookeeper的原理有所了解</li></ul><h3 id="Zookeeper-如何实现分布式锁？"><a href="#Zookeeper-如何实现分布式锁？" class="headerlink" title="Zookeeper 如何实现分布式锁？"></a>Zookeeper 如何实现分布式锁？</h3><p>下面讲如何实现排他锁和共享锁，以及如何解决羊群效应。</p><h4 id="排他锁"><a href="#排他锁" class="headerlink" title="排他锁"></a>排他锁</h4><p>排他锁，又称写锁或独占锁。如果事务T1对数据对象O1加上了排他锁，那么在整个加锁期间，只允许事务T1对O1进行读取或更新操作，其他任务事务都不能对这个数据对象进行任何操作，直到T1释放了排他锁。</p><p>排他锁核心是<strong>保证当前有且仅有一个事务获得锁，并且锁释放之后，所有正在等待获取锁的事务都能够被通知到</strong>。</p><p>Zookeeper 的强一致性特性，能够很好地保证在分布式高并发情况下<strong>节点的创建一定能够保证全局唯一性</strong>，即Zookeeper将会保证客户端无法重复创建一个已经存在的数据节点。可以利用Zookeeper这个特性，实现排他锁。</p><ul><li><strong>定义锁</strong>：通过Zookeeper上的数据节点来表示一个锁</li><li><strong>获取锁</strong>：客户端通过调用 <code>create</code> 方法创建表示锁的临时节点，可以认为创建成功的客户端获得了锁，同时可以让没有获得锁的节点在该节点上注册Watcher监听，以便实时监听到lock节点的变更情况</li><li><strong>释放锁</strong>：以下两种情况都可以让锁释放<ul><li>当前获得锁的客户端发生宕机或异常，那么Zookeeper上这个临时节点就会被删除</li><li>正常执行完业务逻辑，客户端主动删除自己创建的临时节点</li></ul></li></ul><p>基于Zookeeper实现排他锁流程：</p><p><img src="http://image.laijianfeng.org/20190124_133414.jpg" alt="基于Zookeeper实现排他锁流程"></p><h4 id="共享锁"><a href="#共享锁" class="headerlink" title="共享锁"></a>共享锁</h4><p>共享锁，又称读锁。如果事务T1对数据对象O1加上了共享锁，那么当前事务只能对O1进行<strong>读取操作</strong>，其他事务也只能对这个数据对象加共享锁，直到该数据对象上的所有共享锁都被释放。</p><p>共享锁与排他锁的区别在于，加了排他锁之后，数据对象只对当前事务可见，而加了共享锁之后，数据对象对所有事务都可见。</p><ul><li><strong>定义锁</strong>：通过Zookeeper上的数据节点来表示一个锁，是一个类似于 <code>/lockpath/[hostname]-请求类型-序号</code> 的临时顺序节点</li><li><strong>获取锁</strong>：客户端通过调用 <code>create</code> 方法创建表示锁的临时顺序节点，如果是读请求，则创建 <code>/lockpath/[hostname]-R-序号</code> 节点，如果是写请求则创建 <code>/lockpath/[hostname]-W-序号</code> 节点</li><li><strong>判断读写顺序</strong>：大概分为4个步骤<ul><li>1)创建完节点后，获取 <code>/lockpath</code> 节点下的所有子节点，并对该节点注册子节点变更的Watcher监听</li><li>2)确定自己的节点序号在所有子节点中的顺序</li><li>3.1)对于读请求：1. 如果没有比自己序号更小的子节点，或者比自己序号小的子节点都是读请求，那么表明自己已经成功获取到了共享锁，同时开始执行读取逻辑 2. 如果有比自己序号小的子节点有写请求，那么等待 3. </li><li>3.2)对于写请求，如果自己不是序号最小的节点，那么等待</li><li>4)接收到Watcher通知后，重复步骤1)</li></ul></li><li><strong>释放锁</strong>：与排他锁逻辑一致</li></ul><p><img src="http://image.laijianfeng.org/2019-01-28_20-08-52.jpg" alt="Zookeeper实现共享锁节点树"></p><p>基于Zookeeper实现共享锁流程：</p><p><img src="http://image.laijianfeng.org/2019-01-28_20-08-50.jpg" alt="基于Zookeeper实现共享锁流程"></p><h4 id="羊群效应"><a href="#羊群效应" class="headerlink" title="羊群效应"></a>羊群效应</h4><p>在实现共享锁的 “判断读写顺序” 的第1个步骤是：创建完节点后，获取 <code>/lockpath</code> 节点下的所有子节点，并对该节点注册子节点变更的Watcher监听。这样的话，任何一次客户端移除共享锁之后，Zookeeper将会发送子节点变更的Watcher通知给所有机器，系统中将有大量的 “Watcher通知” 和 “子节点列表获取” 这个操作重复执行，然后所有节点再判断自己是否是序号最小的节点(写请求)或者判断比自己序号小的子节点是否都是读请求(读请求)，从而继续等待下一次通知。</p><p>然而，这些重复操作很多都是 “无用的”，实际上<strong>每个锁竞争者只需要关注序号比自己小的那个节点是否存在即可</strong></p><p>当集群规模比较大时，这些 “无用的” 操作不仅会对Zookeeper造成巨大的性能影响和网络冲击，更为严重的是，如果同一时间有多个客户端释放了共享锁，Zookeeper服务器就会在短时间内向其余客户端发送大量的事件通知–这就是所谓的 “<strong>羊群效应</strong>“。</p><p><strong>改进后的分布式锁实现</strong>：</p><p>具体实现如下：</p><ul><li><ol><li>客户端调用 <code>create</code> 方法创建一个类似于 <code>/lockpath/[hostname]-请求类型-序号</code> 的临时顺序节点</li></ol></li><li><ol start="2"><li>客户端调用 <code>getChildren</code> 方法获取所有已经创建的子节点列表(这里不注册任何Watcher)</li></ol></li><li><ol start="3"><li>如果无法获取任何共享锁，那么调用 <code>exist</code> 来对比自己小的那个节点注册Watcher<ul><li>读请求：向比自己序号小的最后一个<strong>写请求节点</strong>注册Watcher监听</li><li>写请求：向比自己序号小的最后一个<strong>节点</strong>注册Watcher监听</li></ul></li></ol></li><li><ol start="4"><li>等待Watcher监听，继续进入步骤2</li></ol></li></ul><p>Zookeeper羊群效应改进前后Watcher监听图</p><p><img src="http://image.laijianfeng.org/2019-01-28_20-08-53.jpg" alt="Zookeeper羊群效应改进前后"></p><h3 id="基于Curator客户端实现分布式锁"><a href="#基于Curator客户端实现分布式锁" class="headerlink" title="基于Curator客户端实现分布式锁"></a>基于Curator客户端实现分布式锁</h3><p>Apache Curator是一个Zookeeper的开源客户端，它提供了Zookeeper各种应用场景（Recipe，如共享锁服务、master选举、分布式计数器等）的抽象封装，接下来将利用Curator提供的类来实现分布式锁。</p><p>Curator提供的跟分布式锁相关的类有5个，分别是：</p><ul><li>Shared Reentrant Lock 可重入锁</li><li>Shared Lock 共享不可重入锁</li><li>Shared Reentrant Read Write Lock 可重入读写锁</li><li>Shared Semaphore 信号量</li><li>Multi Shared Lock 多锁</li></ul><blockquote><p>关于错误处理：还是强烈推荐使用ConnectionStateListener处理连接状态的改变。当连接LOST时你不再拥有锁。</p></blockquote><h4 id="可重入锁"><a href="#可重入锁" class="headerlink" title="可重入锁"></a>可重入锁</h4><p>Shared Reentrant Lock，全局可重入锁，所有客户端都可以请求，同一个客户端在拥有锁的同时，可以多次获取，不会被阻塞。它是由类 <code>InterProcessMutex</code> 来实现，它的主要方法：</p><pre><code class="java">// 构造方法public InterProcessMutex(CuratorFramework client, String path)public InterProcessMutex(CuratorFramework client, String path, LockInternalsDriver driver)// 通过acquire获得锁,并提供超时机制：public void acquire() throws Exceptionpublic boolean acquire(long time, TimeUnit unit) throws Exception// 撤销锁public void makeRevocable(RevocationListener&lt;InterProcessMutex&gt; listener)public void makeRevocable(final RevocationListener&lt;InterProcessMutex&gt; listener, Executor executor)</code></pre><p>定义一个 FakeLimitedResource 类来模拟一个共享资源，该资源一次只能被一个线程使用，直到使用结束，下一个线程才能使用，否则会抛出异常</p><pre><code class="java">public class FakeLimitedResource {    private final AtomicBoolean inUse = new AtomicBoolean(false);    // 模拟只能单线程操作的资源    public void use() throws InterruptedException {        if (!inUse.compareAndSet(false, true)) {            // 在正确使用锁的情况下，此异常不可能抛出            throw new IllegalStateException(&quot;Needs to be used by one client at a time&quot;);        }        try {            Thread.sleep((long) (100 * Math.random()));        } finally {            inUse.set(false);        }    }}</code></pre><p>下面的代码将创建 N 个线程来模拟分布式系统中的节点，系统将通过 InterProcessMutex 来控制对资源的同步使用；每个节点都将发起10次请求，完成 <code>请求锁--访问资源--再次请求锁--释放锁--释放锁</code> 的过程；客户端通过 <code>acquire</code> 请求锁，通过 <code>release</code> 释放锁，获得几把锁就要释放几把锁；这个共享资源一次只能被一个线程使用，如果控制同步失败，将抛异常。</p><pre><code class="java">public class SharedReentrantLockTest {    private static final String lockPath = &quot;/testZK/sharedreentrantlock&quot;;    private static final Integer clientNums = 5;    final static FakeLimitedResource resource = new FakeLimitedResource(); // 共享的资源    private static CountDownLatch countDownLatch = new CountDownLatch(clientNums);    public static void main(String[] args) throws InterruptedException {        for (int i = 0; i &lt; clientNums; i++) {            String clientName = &quot;client#&quot; + i;            new Thread(new Runnable() {                @Override                public void run() {                    CuratorFramework client = ZKUtils.getClient();                    client.start();                    Random random = new Random();                    try {                        final InterProcessMutex lock = new InterProcessMutex(client, lockPath);                        // 每个客户端请求10次共享资源                        for (int j = 0; j &lt; 10; j++) {                            if (!lock.acquire(10, TimeUnit.SECONDS)) {                                throw new IllegalStateException(j + &quot;. &quot; + clientName + &quot; 不能得到互斥锁&quot;);                            }                            try {                                System.out.println(j + &quot;. &quot; + clientName + &quot; 已获取到互斥锁&quot;);                                resource.use(); // 使用资源                                if (!lock.acquire(10, TimeUnit.SECONDS)) {                                    throw new IllegalStateException(j + &quot;. &quot; + clientName + &quot; 不能再次得到互斥锁&quot;);                                }                                System.out.println(j + &quot;. &quot; + clientName + &quot; 已再次获取到互斥锁&quot;);                                lock.release(); // 申请几次锁就要释放几次锁                            } finally {                                System.out.println(j + &quot;. &quot; + clientName + &quot; 释放互斥锁&quot;);                                lock.release(); // 总是在finally中释放                            }                            Thread.sleep(random.nextInt(100));                        }                    } catch (Throwable e) {                        System.out.println(e.getMessage());                    } finally {                        CloseableUtils.closeQuietly(client);                        System.out.println(clientName + &quot; 客户端关闭！&quot;);                        countDownLatch.countDown();                    }                }            }).start();        }        countDownLatch.await();        System.out.println(&quot;结束！&quot;);    }}</code></pre><p>控制台打印日志，可以看到对资源的同步访问控制成功，并且锁是可重入的</p><pre><code>0. client#3 已获取到互斥锁0. client#3 已再次获取到互斥锁0. client#3 释放互斥锁0. client#1 已获取到互斥锁0. client#1 已再次获取到互斥锁0. client#1 释放互斥锁0. client#2 已获取到互斥锁0. client#2 已再次获取到互斥锁0. client#2 释放互斥锁0. client#0 已获取到互斥锁0. client#0 已再次获取到互斥锁0. client#0 释放互斥锁0. client#4 已获取到互斥锁0. client#4 已再次获取到互斥锁0. client#4 释放互斥锁1. client#1 已获取到互斥锁1. client#1 已再次获取到互斥锁1. client#1 释放互斥锁2. client#1 已获取到互斥锁2. client#1 已再次获取到互斥锁2. client#1 释放互斥锁1. client#4 已获取到互斥锁1. client#4 已再次获取到互斥锁1. client#4 释放互斥锁1. client#3 已获取到互斥锁1. client#3 已再次获取到互斥锁1. client#3 释放互斥锁1. client#2 已获取到互斥锁1. client#2 已再次获取到互斥锁1. client#2 释放互斥锁2. client#4 已获取到互斥锁2. client#4 已再次获取到互斥锁2. client#4 释放互斥锁........client#2 客户端关闭！9. client#0 已获取到互斥锁9. client#0 已再次获取到互斥锁9. client#0 释放互斥锁9. client#3 已获取到互斥锁9. client#3 已再次获取到互斥锁9. client#3 释放互斥锁client#0 客户端关闭！8. client#4 已获取到互斥锁8. client#4 已再次获取到互斥锁8. client#4 释放互斥锁9. client#4 已获取到互斥锁9. client#4 已再次获取到互斥锁9. client#4 释放互斥锁client#3 客户端关闭！client#4 客户端关闭！结束！</code></pre><p>同时在程序运行期间查看Zookeeper节点树，可以发现每一次请求的锁实际上对应一个临时顺序节点</p><pre><code>[zk: localhost:2181(CONNECTED) 42] ls /testZK/sharedreentrantlock[leases, _c_208d461b-716d-43ea-ac94-1d2be1206db3-lock-0000001659, locks, _c_64b19dba-3efa-46a6-9344-19a52e9e424f-lock-0000001658, _c_cee02916-d7d5-4186-8867-f921210b8815-lock-0000001657]</code></pre><h4 id="不可重入锁"><a href="#不可重入锁" class="headerlink" title="不可重入锁"></a>不可重入锁</h4><p>Shared Lock 与 Shared Reentrant Lock 相似，但是<strong>不可重入</strong>。这个不可重入锁由类 InterProcessSemaphoreMutex 来实现，使用方法和上面的类类似。</p><p>将上面程序中的 InterProcessMutex 换成不可重入锁 InterProcessSemaphoreMutex，如果再运行上面的代码，结果就会发现线程被阻塞在第二个 <code>acquire</code> 上，直到超时，也就是此锁不是可重入的。</p><p>控制台输出日志</p><pre><code>0. client#2 已获取到互斥锁0. client#1 不能得到互斥锁0. client#4 不能得到互斥锁0. client#0 不能得到互斥锁0. client#3 不能得到互斥锁client#1 客户端关闭！client#4 客户端关闭！client#3 客户端关闭！client#0 客户端关闭！0. client#2 释放互斥锁0. client#2 不能再次得到互斥锁client#2 客户端关闭！结束！</code></pre><p>把第二个获取锁的代码注释，程序才能正常执行</p><pre><code>0. client#1 已获取到互斥锁0. client#1 释放互斥锁0. client#2 已获取到互斥锁0. client#2 释放互斥锁0. client#0 已获取到互斥锁0. client#0 释放互斥锁0. client#4 已获取到互斥锁0. client#4 释放互斥锁0. client#3 已获取到互斥锁0. client#3 释放互斥锁1. client#1 已获取到互斥锁1. client#1 释放互斥锁1. client#2 已获取到互斥锁1. client#2 释放互斥锁........9. client#4 已获取到互斥锁9. client#4 释放互斥锁9. client#0 已获取到互斥锁client#2 客户端关闭！9. client#0 释放互斥锁9. client#1 已获取到互斥锁client#0 客户端关闭！client#4 客户端关闭！9. client#1 释放互斥锁9. client#3 已获取到互斥锁client#1 客户端关闭！9. client#3 释放互斥锁client#3 客户端关闭！结束！</code></pre><h4 id="可重入读写锁"><a href="#可重入读写锁" class="headerlink" title="可重入读写锁"></a>可重入读写锁</h4><p>Shared Reentrant Read Write Lock，可重入读写锁，一个读写锁管理一对相关的锁，一个负责读操作，另外一个负责写操作；读操作在写锁没被使用时可同时由多个进程使用，而写锁在使用时不允许读(阻塞)；此锁是可重入的；一个拥有写锁的线程可重入读锁，但是读锁却不能进入写锁，这也意味着写锁可以降级成读锁， 比如 <code>请求写锁 ---&gt;读锁 ----&gt;释放写锁</code>；从读锁升级成写锁是不行的。</p><p>可重入读写锁主要由两个类实现：InterProcessReadWriteLock、InterProcessMutex，使用时首先创建一个 InterProcessReadWriteLock 实例，然后再根据你的需求得到读锁或者写锁，读写锁的类型是 InterProcessMutex。</p><pre><code class="java">    public static void main(String[] args) throws InterruptedException {        for (int i = 0; i &lt; clientNums; i++) {            final String clientName = &quot;client#&quot; + i;            new Thread(new Runnable() {                @Override                public void run() {                    CuratorFramework client = ZKUtils.getClient();                    client.start();                    final InterProcessReadWriteLock lock = new InterProcessReadWriteLock(client, lockPath);                    final InterProcessMutex readLock = lock.readLock();                    final InterProcessMutex writeLock = lock.writeLock();                    try {                        // 注意只能先得到写锁再得到读锁，不能反过来！！！                        if (!writeLock.acquire(10, TimeUnit.SECONDS)) {                            throw new IllegalStateException(clientName + &quot; 不能得到写锁&quot;);                        }                        System.out.println(clientName + &quot; 已得到写锁&quot;);                        if (!readLock.acquire(10, TimeUnit.SECONDS)) {                            throw new IllegalStateException(clientName + &quot; 不能得到读锁&quot;);                        }                        System.out.println(clientName + &quot; 已得到读锁&quot;);                        try {                            resource.use(); // 使用资源                        } finally {                            System.out.println(clientName + &quot; 释放读写锁&quot;);                            readLock.release();                            writeLock.release();                        }                    } catch (Exception e) {                        System.out.println(e.getMessage());                    } finally {                        CloseableUtils.closeQuietly(client);                        countDownLatch.countDown();                    }                }            }).start();        }        countDownLatch.await();        System.out.println(&quot;结束！&quot;);    }}</code></pre><p>控制台打印日志</p><pre><code>client#1 已得到写锁client#1 已得到读锁client#1 释放读写锁client#2 已得到写锁client#2 已得到读锁client#2 释放读写锁client#0 已得到写锁client#0 已得到读锁client#0 释放读写锁client#4 已得到写锁client#4 已得到读锁client#4 释放读写锁client#3 已得到写锁client#3 已得到读锁client#3 释放读写锁结束！</code></pre><h4 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h4><p>Shared Semaphore，一个计数的信号量类似JDK的 Semaphore，JDK中 Semaphore 维护的一组许可(permits)，而Cubator中称之为租约(Lease)。有两种方式可以决定 semaphore 的最大租约数，第一种方式是由用户给定的 path 决定，第二种方式使用 SharedCountReader 类。如果不使用 SharedCountReader，没有内部代码检查进程是否假定有10个租约而进程B假定有20个租约。 所以所有的实例必须使用相同的 numberOfLeases 值.</p><p>信号量主要实现类有：</p><pre><code>InterProcessSemaphoreV2 - 信号量实现类Lease - 租约(单个信号)SharedCountReader - 计数器，用于计算最大租约数量</code></pre><p>调用 <code>acquire</code> 会返回一个租约对象，客户端必须在 finally 中 close 这些租约对象，否则这些租约会丢失掉。但是，如果客户端session由于某种原因比如crash丢掉，那么这些客户端持有的租约会自动close，这样其它客户端可以继续使用这些租约。租约还可以通过下面的方式返还：</p><pre><code>public void returnLease(Lease lease)public void returnAll(Collection&lt;Lease&gt; leases) </code></pre><p>注意一次你可以请求多个租约，如果 Semaphore 当前的租约不够，则请求线程会被阻塞。同时还提供了超时的重载方法。</p><pre><code>public Lease acquire() throws Exceptionpublic Collection&lt;Lease&gt; acquire(int qty) throws Exceptionpublic Lease acquire(long time, TimeUnit unit) throws Exceptionpublic Collection&lt;Lease&gt; acquire(int qty, long time, TimeUnit unit) throws Exception</code></pre><p>一个Demo程序如下</p><pre><code class="java">public class SharedSemaphoreTest {    private static final int MAX_LEASE = 10;    private static final String PATH = &quot;/testZK/semaphore&quot;;    private static final FakeLimitedResource resource = new FakeLimitedResource();    public static void main(String[] args) throws Exception {        CuratorFramework client = ZKUtils.getClient();        client.start();        InterProcessSemaphoreV2 semaphore = new InterProcessSemaphoreV2(client, PATH, MAX_LEASE);        Collection&lt;Lease&gt; leases = semaphore.acquire(5);        System.out.println(&quot;获取租约数量：&quot; + leases.size());        Lease lease = semaphore.acquire();        System.out.println(&quot;获取单个租约&quot;);        resource.use(); // 使用资源        // 再次申请获取5个leases，此时leases数量只剩4个，不够，将超时        Collection&lt;Lease&gt; leases2 = semaphore.acquire(5, 10, TimeUnit.SECONDS);        System.out.println(&quot;获取租约，如果超时将为null： &quot; + leases2);        System.out.println(&quot;释放租约&quot;);        semaphore.returnLease(lease);        // 再次申请获取5个，这次刚好够        leases2 = semaphore.acquire(5, 10, TimeUnit.SECONDS);        System.out.println(&quot;获取租约，如果超时将为null： &quot; + leases2);        System.out.println(&quot;释放集合中的所有租约&quot;);        semaphore.returnAll(leases);        semaphore.returnAll(leases2);        client.close();        System.out.println(&quot;结束!&quot;);    }}</code></pre><p>控制台打印日志</p><pre><code>获取租约数量：5获取单个租约获取租约，如果超时将为null： null释放租约获取租约，如果超时将为null： [org.apache.curator.framework.recipes.locks.InterProcessSemaphoreV2$3@3108bc, org.apache.curator.framework.recipes.locks.InterProcessSemaphoreV2$3@370736d9, org.apache.curator.framework.recipes.locks.InterProcessSemaphoreV2$3@5f9d02cb, org.apache.curator.framework.recipes.locks.InterProcessSemaphoreV2$3@63753b6d, org.apache.curator.framework.recipes.locks.InterProcessSemaphoreV2$3@6b09bb57]释放集合中的所有租约结束!</code></pre><p>注意：上面所讲的4种锁都是公平锁(fair)。从ZooKeeper的角度看，每个客户端都按照请求的顺序获得锁，相当公平。</p><h4 id="多锁"><a href="#多锁" class="headerlink" title="多锁"></a>多锁</h4><p>Multi Shared Lock 是一个锁的容器。当调用 <code>acquire</code>，所有的锁都会被 <code>acquire</code>，如果请求失败，所有的锁都会被 <code>release</code>。同样调用 <code>release</code> 时所有的锁都被 <code>release</code>(失败被忽略)。基本上，它就是组锁的代表，在它上面的请求释放操作都会传递给它包含的所有的锁。</p><p>主要涉及两个类：</p><pre><code>InterProcessMultiLock - 对所对象实现类InterProcessLock - 分布式锁接口类</code></pre><p>它的构造函数需要包含的锁的集合，或者一组 ZooKeeper 的 path，用法和 Shared Lock 相同</p><pre><code>public InterProcessMultiLock(CuratorFramework client, List&lt;String&gt; paths)public InterProcessMultiLock(List&lt;InterProcessLock&gt; locks)</code></pre><p>一个Demo程序如下</p><pre><code class="java">public class MultiSharedLockTest {    private static final String lockPath1 = &quot;/testZK/MSLock1&quot;;    private static final String lockPath2 = &quot;/testZK/MSLock2&quot;;    private static final FakeLimitedResource resource = new FakeLimitedResource();    public static void main(String[] args) throws Exception {        CuratorFramework client = ZKUtils.getClient();        client.start();        InterProcessLock lock1 = new InterProcessMutex(client, lockPath1); // 可重入锁        InterProcessLock lock2 = new InterProcessSemaphoreMutex(client, lockPath2); // 不可重入锁        // 组锁，多锁        InterProcessMultiLock lock = new InterProcessMultiLock(Arrays.asList(lock1, lock2));        if (!lock.acquire(10, TimeUnit.SECONDS)) {            throw new IllegalStateException(&quot;不能获取多锁&quot;);        }        System.out.println(&quot;已获取多锁&quot;);        System.out.println(&quot;是否有第一个锁: &quot; + lock1.isAcquiredInThisProcess());        System.out.println(&quot;是否有第二个锁: &quot; + lock2.isAcquiredInThisProcess());        try {            resource.use(); // 资源操作        } finally {            System.out.println(&quot;释放多个锁&quot;);            lock.release(); // 释放多锁        }        System.out.println(&quot;是否有第一个锁: &quot; + lock1.isAcquiredInThisProcess());        System.out.println(&quot;是否有第二个锁: &quot; + lock2.isAcquiredInThisProcess());        client.close();        System.out.println(&quot;结束!&quot;);    }}</code></pre><blockquote><p><strong>代码下载地址</strong>：<a href="http://t.cn/EtVc1s4" target="_blank" rel="noopener">http://t.cn/EtVc1s4</a></p></blockquote><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p>1、 《从Paxos到Zookeeper分布式一致性原理与实践》<br>2、 <a href="http://curator.apache.org/curator-recipes/index.html" target="_blank" rel="noopener">Apache Curator Recipes Docs</a><br>3、 <a href="http://www.hollischuang.com/archives/1716" target="_blank" rel="noopener">分布式锁的几种实现方式~</a><br>4、 <a href="http://www.spring4all.com/question/158" target="_blank" rel="noopener">技术专题讨论第四期：漫谈分布式锁</a><br>5、 <a href="https://zhuanlan.zhihu.com/p/42056183" target="_blank" rel="noopener">分布式锁看这篇就够了</a><br>6、 <a href="https://www.cnblogs.com/LiZhiW/p/4931577.html" target="_blank" rel="noopener">Curator分布式锁</a></p><p><img src="http://image.laijianfeng.org/20190116_014816.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zookeeper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>利用Zookeeper实现 - 数据发布订阅</title>
      <link href="/2019/01/%E5%88%A9%E7%94%A8Zookeeper%E5%AE%9E%E7%8E%B0-%E6%95%B0%E6%8D%AE%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85/"/>
      <url>/2019/01/%E5%88%A9%E7%94%A8Zookeeper%E5%AE%9E%E7%8E%B0-%E6%95%B0%E6%8D%AE%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85/</url>
      <content type="html"><![CDATA[<h3 id="数据发布-订阅"><a href="#数据发布-订阅" class="headerlink" title="数据发布/订阅"></a>数据发布/订阅</h3><p>所谓的数据发布/订阅，意思是发布者将数据发布到Zookeeper上的一个或一系列节点上，通过watcher机制，客户端可以监听(订阅)这些数据节点，当这些节点发生变化时，Zookeeper及时地通知客户端，从而达到动态获取数据的目的。</p><p>一种常见的场景就是配置中心。随着应用越来越多，功能越来越复杂，机器也越来越多，对于一些公共的程序配置，譬如各种功能的开关、数据库的配置、服务器的地址等，如果每个应用每个机器仍然单独维护，当要修改配置时就得一个一个地修改，这样显然非常不方便。</p><p>这些公共的配置信息通常具备以下3个特性：</p><ul><li>数据量通常比较小</li><li>数据内容在运行时发生动态变化</li><li>集群中各机器共享、配置一致</li></ul><p>可以将这些配置抽取出来，交给配置中心统一管理起来。配置中心的架构一般是这样：</p><p><img src="http://image.laijianfeng.org/20190123_133414.jpg" alt="配置中心结构图"></p><h3 id="开源配置中心"><a href="#开源配置中心" class="headerlink" title="开源配置中心"></a>开源配置中心</h3><p>开源的配置中心有很多，各有特点，这里只列出几个进行简单地介绍。</p><h4 id="Ctrip-Apollo"><a href="#Ctrip-Apollo" class="headerlink" title="Ctrip Apollo"></a>Ctrip Apollo</h4><p>github地址：<a href="https://github.com/ctripcorp/apollo" target="_blank" rel="noopener">https://github.com/ctripcorp/apollo</a></p><p>介绍：Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。</p><h4 id="Disconf"><a href="#Disconf" class="headerlink" title="Disconf"></a>Disconf</h4><p>github地址：<a href="https://github.com/knightliao/disconf" target="_blank" rel="noopener">https://github.com/knightliao/disconf</a></p><p>介绍：专注于各种「分布式系统配置管理」的「通用组件」和「通用平台」, 提供统一的「配置管理服务」。主要目标是部署极其简单、部署动态化、统一管理、一个jar包，到处运行。</p><h4 id="Spring-Cloud-Config"><a href="#Spring-Cloud-Config" class="headerlink" title="Spring Cloud Config"></a>Spring Cloud Config</h4><p>github地址：<a href="https://github.com/spring-cloud/spring-cloud-config" target="_blank" rel="noopener">https://github.com/spring-cloud/spring-cloud-config</a></p><p>介绍：Spring Cloud Config是一个基于http协议的远程配置实现方式，通过统一的配置管理服务器进行配置管理，客户端通过https协议主动的拉取服务的的配置信息，完成配置获取。</p><h4 id="Nacos"><a href="#Nacos" class="headerlink" title="Nacos"></a>Nacos</h4><p>github地址：<a href="https://github.com/alibaba/nacos" target="_blank" rel="noopener">https://github.com/alibaba/nacos</a></p><p>介绍：Nacos是阿里最近才开源的一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。Nacos 致力于帮助您发现、配置和管理微服务。Nacos提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。</p><h4 id="利用Zookeeper实现一个配置中心"><a href="#利用Zookeeper实现一个配置中心" class="headerlink" title="利用Zookeeper实现一个配置中心"></a>利用Zookeeper实现一个配置中心</h4><p>开源的配置中心当然都很优秀，但是现在我们还是先利用Zookeeper来实现一个属于自己的配置中心。</p><p>我们的配置中心保存的配置信息十分简单，就是JDBC连接MySQL需要用的连接信息。这些连接信息将转化为JSON字符串，保存在Zookeeper上的一个节点中；应用程序(通过线程模拟的)从Zookeeper中读取这些配置信息，然后查询数据库；当修改数据库连接信息时(<strong>切换数据库</strong>)，应用程序能及时的拉取新的连接信息，使用新的连接查询数据库。</p><p>定义一个 MysqlConfig 类，方便使用 FastJSON 将配置信息在JSON字符串与对象之间做转换。</p><pre><code class="java">@AllArgsConstructor@Datapublic class MysqlConfig {    private String url;    private String driver;    private String username;    private String password;}</code></pre><p>最开始，将Zookeeper上节点的配置信息初始化为 test 数据库的连接信息，然后启动 N 个线程(模拟应用程序)，读取连接信息并查询数据，同时设置监听节点；等待 10 秒钟之后，将配置切换为 test2 数据库的连接信息，这时应用程序将受到配置变更的通知，然后获取信息连接信息，重新查询数据库。</p><pre><code class="java">// 工具类public class ZKUtils {    private static final String zkServerIps = &quot;master:2181,hadoop2:2181&quot;;    public static synchronized CuratorFramework getClient() {        CuratorFramework client = CuratorFrameworkFactory.builder().connectString(zkServerIps)                .sessionTimeoutMs(6000).connectionTimeoutMs(3000) //.namespace(&quot;LeaderLatchTest&quot;)                .retryPolicy(new ExponentialBackoffRetry(1000, 3)).build();        return client;    }}// 配置中心示例，模拟数据库切换public class ConfigCenterTest {    // test 数据库的 test1 表    private static final MysqlConfig mysqlConfig_1 = new MysqlConfig(&quot;jdbc:mysql://master:3306/test?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false&quot;, &quot;com.mysql.jdbc.Driver&quot;, &quot;root&quot;, &quot;123456&quot;);    // test2 数据库的 test1 表    private static final MysqlConfig mysqlConfig_2 = new MysqlConfig(&quot;jdbc:mysql://master:3306/test2?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false&quot;, &quot;com.mysql.jdbc.Driver&quot;, &quot;root&quot;, &quot;123456&quot;);    // 存储MySQL配置信息的节点路径    private static final String configPath = &quot;/testZK/jdbc/mysql&quot;;    private static final Integer clientNums = 3;    private static CountDownLatch countDownLatch = new CountDownLatch(clientNums);    public static void main(String[] args) throws Exception {        // 最开始时设置MySQL配置信息为 mysqlConfig_1        setMysqlConfig(mysqlConfig_1);        // 启动 clientNums 个线程，模拟分布式系统中的节点，        // 从Zookeeper中获取MySQL的配置信息，查询数据        for (int i = 0; i &lt; clientNums; i++) {            String clientName = &quot;client#&quot; + i;            new Thread(new Runnable() {                @Override                public void run() {                    CuratorFramework client = ZKUtils.getClient();                    client.start();                    try {                        Stat stat = new Stat();                        // 如果要监听多个子节点则应该使用 PathChildrenCache                        final NodeCache cacheNode = new NodeCache(client, configPath, false);                        cacheNode.start(true);  // true 表示启动时立即从Zookeeper上获取节点                        byte[] nodeData = cacheNode.getCurrentData().getData();                        MysqlConfig mysqlConfig = JSON.parseObject(new String(nodeData), MysqlConfig.class);                        queryMysql(clientName, mysqlConfig);    // 查询数据                        cacheNode.getListenable().addListener(new NodeCacheListener() {                            @Override                            public void nodeChanged() throws Exception {                                byte[] newData = cacheNode.getCurrentData().getData();                                MysqlConfig newMysqlConfig = JSON.parseObject(new String(newData), MysqlConfig.class);                                queryMysql(clientName, newMysqlConfig);    // 查询数据                            }                        });                        Thread.sleep(20 * 1000);                    } catch (Exception e) {                        e.printStackTrace();                    } finally {                        client.close();                        countDownLatch.countDown();                    }                }            }).start();        }        Thread.sleep(10 * 1000);        System.out.println(&quot;\n---------10秒钟后将MySQL配置信息修改为 mysqlConfig_2---------\n&quot;);        setMysqlConfig(mysqlConfig_2);        countDownLatch.await();    }    /**     * 初始化，最开始的时候的MySQL配置为 mysqlConfig_1     */    public static void setMysqlConfig(MysqlConfig config) throws Exception {        CuratorFramework client = ZKUtils.getClient();        client.start();        String mysqlConfigStr = JSON.toJSONString(config);        Stat s = client.checkExists().forPath(configPath);        if (s != null) {            Stat resultStat = client.setData().forPath(configPath, mysqlConfigStr.getBytes());            System.out.println(String.format(&quot;节点 %s 已存在，更新数据为：%s&quot;, configPath, mysqlConfigStr));        } else {            client.create().creatingParentsIfNeeded().withMode(CreateMode.PERSISTENT).forPath(configPath, mysqlConfigStr.getBytes());            System.out.println(String.format(&quot;创建节点：%s，初始化数据为：%s&quot;, configPath, mysqlConfigStr));        }        System.out.println();        client.close();    }    /**     * 通过配置信息，查询MySQL数据库     */    public static synchronized void queryMysql(String clientName, MysqlConfig mysqlConfig) throws ClassNotFoundException, SQLException {        System.out.println(clientName + &quot; 查询MySQL数据，使用的MySQL配置信息：&quot; + mysqlConfig);        Class.forName(mysqlConfig.getDriver());        Connection connection = DriverManager.getConnection(mysqlConfig.getUrl(), mysqlConfig.getUsername(), mysqlConfig.getPassword());        Statement statement = connection.createStatement();        ResultSet resultSet = statement.executeQuery(&quot;select * from test1&quot;);        while (resultSet.next()) {            System.out.println(String.format(&quot;id=%s, name=%s, age=%s&quot;, resultSet.getString(1), resultSet.getString(2), resultSet.getString(3)));        }        System.out.println();        resultSet.close();        statement.close();        connection.close();    }}</code></pre><p>控制台打印日志</p><pre><code>client#2 查询MySQL数据，使用的MySQL配置信息：MysqlConfig(url=jdbc:mysql://master:3306/test?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false, driver=com.mysql.jdbc.Driver, username=root, password=123456)id=2, name=赖键锋, age=25id=3, name=小旋锋, age=22000id=4, name=test, age=100client#1 查询MySQL数据，使用的MySQL配置信息：MysqlConfig(url=jdbc:mysql://master:3306/test?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false, driver=com.mysql.jdbc.Driver, username=root, password=123456)id=2, name=赖键锋, age=25id=3, name=小旋锋, age=22000id=4, name=test, age=100client#0 查询MySQL数据，使用的MySQL配置信息：MysqlConfig(url=jdbc:mysql://master:3306/test?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false, driver=com.mysql.jdbc.Driver, username=root, password=123456)id=2, name=赖键锋, age=25id=3, name=小旋锋, age=22000id=4, name=test, age=100---------10秒钟后将MySQL配置信息修改为 mysqlConfig_2---------节点 /testZK/jdbc/mysql 已存在，更新数据为：{&quot;driver&quot;:&quot;com.mysql.jdbc.Driver&quot;,&quot;password&quot;:&quot;123456&quot;,&quot;url&quot;:&quot;jdbc:mysql://master:3306/test2?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false&quot;,&quot;username&quot;:&quot;root&quot;}client#1 查询MySQL数据，使用的MySQL配置信息：MysqlConfig(url=jdbc:mysql://master:3306/test2?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false, driver=com.mysql.jdbc.Driver, username=root, password=123456)id=2, name=赖键锋, age=23id=3, name=小旋锋, age=22id=4, name=whirly, age=24client#2 查询MySQL数据，使用的MySQL配置信息：MysqlConfig(url=jdbc:mysql://master:3306/test2?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false, driver=com.mysql.jdbc.Driver, username=root, password=123456)id=2, name=赖键锋, age=23id=3, name=小旋锋, age=22id=4, name=whirly, age=24client#0 查询MySQL数据，使用的MySQL配置信息：MysqlConfig(url=jdbc:mysql://master:3306/test2?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false, driver=com.mysql.jdbc.Driver, username=root, password=123456)id=2, name=赖键锋, age=23id=3, name=小旋锋, age=22id=4, name=whirly, age=24</code></pre><p>上面采用的示例是通过 NodeCache 来监听单个节点，如果要监听多个子节点则须使用 PathChildrenCache，使用示例可以参考《<a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483840&amp;idx=1&amp;sn=615f280b8006333e3b943135e2156ce7&amp;chksm=e9c2edcddeb564dba4cfae6f1c7d125b374b3fb8caf36f0f5da3d48a7ca05d0190e7a98abff6&amp;scene=0&amp;xtrack=1#rd" target="_blank" rel="noopener">Zookeeper 分布式协调服务介绍</a>》</p><h4 id="相关文章"><a href="#相关文章" class="headerlink" title="相关文章"></a>相关文章</h4><ul><li><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483840&amp;idx=1&amp;sn=615f280b8006333e3b943135e2156ce7&amp;chksm=e9c2edcddeb564dba4cfae6f1c7d125b374b3fb8caf36f0f5da3d48a7ca05d0190e7a98abff6&amp;scene=0&amp;xtrack=1#rd" target="_blank" rel="noopener">Zookeeper 分布式协调服务介绍</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483848&amp;idx=1&amp;sn=dea24723c9e578cf1deaf540dc8f00ed&amp;chksm=e9c2edc5deb564d3f126329ce0940fadbdede07559c9d86a88a42b8038fcae8b1994ff6e45a9&amp;scene=0#rd" target="_blank" rel="noopener">利用Zookeeper实现 - Master选举</a></li></ul><h4 id="后序"><a href="#后序" class="headerlink" title="后序"></a>后序</h4><p>代码下载：<a href="http://t.cn/E5ncvDR" target="_blank" rel="noopener">http://t.cn/E5ncvDR</a></p><p>我的博客：laijianfeng.org</p><blockquote><p>参考：<br>《从Paxos到Zookeeper分布式一致性原理与实践》     </p></blockquote><p><img src="http://image.laijianfeng.org/20190116_014816.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zookeeper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>利用Zookeeper实现 - Master选举</title>
      <link href="/2019/01/%E5%88%A9%E7%94%A8Zookeeper%E5%AE%9E%E7%8E%B0-Master%E9%80%89%E4%B8%BE/"/>
      <url>/2019/01/%E5%88%A9%E7%94%A8Zookeeper%E5%AE%9E%E7%8E%B0-Master%E9%80%89%E4%B8%BE/</url>
      <content type="html"><![CDATA[<p>Zookeeper 是一个高可用的分布式数据管理与协调框架，基于ZAB协议算法的实现，该框架能够很好的保证分布式环境中数据的一致性。Zookeeper的典型应用场景主要有：数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、分布式锁和分布式队列等。</p><p>本文主要介绍如何利用Zookeeper实现Master选举。</p><h3 id="Master选举"><a href="#Master选举" class="headerlink" title="Master选举"></a>Master选举</h3><p>Master选举在分布式系统中是一个非常常见的场景。在分布式系统中，常常采用主从模式的方式避免单点故障，提高系统服务的可用性。正常情况下，Master节点用来协调集群中其他系统单元，维护系统状态信息，或者负责一些复杂的逻辑，再将处理结果同步给其他节点。当Master节点宕机，或者由于其他问题导致无法提供服务时，系统将发起一次Master选举，从候选节点中选出一个新的Master节点，以继续提供服务。</p><p>譬如在一些读写分离的应用中，Master节点负责客户端的写请求，处理完毕之后再将结果同步给从节点。</p><h4 id="选举算法？"><a href="#选举算法？" class="headerlink" title="选举算法？"></a>选举算法？</h4><p>著名的选举算法有 Paxos算法、Raft算法、Bully算法等，但在业务系统的开发中，实现选举算法并不是我们工作的重心。</p><p>Zookeeper有一个非常重要的特性即<strong>强一致性</strong>，能够很好地保证在分布式高并发情况下<strong>节点的创建一定能够保证全局唯一性</strong>，即Zookeeper将会保证客户端无法重复创建一个已经存在的数据节点。也就是说，如果同时有多个客户端请求创建同一个节点，那么最终一定只有一个客户端请求能够创建成功。利用这个特性，就能很容易地在分布式环境中进行Master选举了。</p><h3 id="利用Zookeeper实现Master选举"><a href="#利用Zookeeper实现Master选举" class="headerlink" title="利用Zookeeper实现Master选举"></a>利用Zookeeper实现Master选举</h3><p>Apache Curator是一个Zookeeper的开源客户端，它提供了Zookeeper各种应用场景（Recipe，如共享锁服务、master选举、分布式计数器等）的抽象封装，本文使用 Curator 提供的Recipe来实现Master选举。</p><p>Curator提供了两种选举方案：Leader Latch 和 Leader Election。下面分别介绍这两种选举方案。</p><h4 id="Leader-Latch"><a href="#Leader-Latch" class="headerlink" title="Leader Latch"></a>Leader Latch</h4><p>使用 Leader Latch 方案进行Master选举，系统将<strong>随机从候选者中选出一台作为 <code>leader</code>，直到调用 <code>close()</code> 释放leadship，此时再重新随机选举 <code>leader</code>，否则其他的候选者无法成为 <code>leader</code>。</strong></p><p>下面的程序将启动 N 个线程用来模拟分布式系统中的节点，每个线程将创建一个Zookeeper客户端和一个 LeaderLatch 对象用于选举；每个线程有一个名称，名称中有一个编号用于区分；每个线程的存活时间为 <code>number * 10秒</code> ，存活时间结束后将关闭 LeaderLatch 对象和客户端，表示该 ‘节点’ 宕机，如果该节点为 Master节点，这时系统将重新发起 Master选举。</p><pre><code class="java">public class LeaderLatchTest {    private static final String zkServerIps = &quot;master:2181,hadoop2:2181&quot;;    private static final String masterPath = &quot;/testZK/leader_latch&quot;;    public static void main(String[] args) {        final int clientNums = 5;  // 客户端数量，用于模拟        final CountDownLatch countDownLatch = new CountDownLatch(clientNums);        List&lt;LeaderLatch&gt; latchList = new CopyOnWriteArrayList();        List&lt;CuratorFramework&gt; clientList = new CopyOnWriteArrayList();        AtomicInteger atomicInteger = new AtomicInteger(1);        try {            for (int i = 0; i &lt; clientNums; i++) {                new Thread(new Runnable() {                    @Override                    public void run() {                        CuratorFramework client = getClient();  // 创建客户端                        clientList.add(client);                        int number = atomicInteger.getAndIncrement();                        final LeaderLatch latch = new LeaderLatch(client, masterPath, &quot;client#&quot; + number);                        System.out.println(&quot;创建客户端：&quot; + latch.getId());                        // LeaderLatch 添加监听事件                        latch.addListener(new LeaderLatchListener() {                            @Override                            public void isLeader() {                                System.out.println(latch.getId() + &quot;: 我现在被选举为Leader！我开始工作了....&quot;);                            }                            @Override                            public void notLeader() {                                System.out.println(latch.getId() + &quot;: 我遗憾地落选了，我到一旁休息去吧...&quot;);                            }                        });                        latchList.add(latch);                        try {                            latch.start();                            // 随机等待 number * 10秒，之后关闭客户端                            Thread.sleep(number * 10000);                        } catch (Exception e) {                            System.out.println(e.getMessage());                        } finally {                            System.out.println(&quot;客户端 &quot; + latch.getId() + &quot; 关闭&quot;);                            CloseableUtils.closeQuietly(latch);                            CloseableUtils.closeQuietly(client);                            countDownLatch.countDown();                        }                    }                }).start();            }            countDownLatch.await(); // 等待，只有所有线程都退出        } catch (Exception e) {            e.printStackTrace();        }    }    private static synchronized CuratorFramework getClient() {        CuratorFramework client = CuratorFrameworkFactory.builder().connectString(zkServerIps)                .sessionTimeoutMs(6000).connectionTimeoutMs(3000) //.namespace(&quot;LeaderLatchTest&quot;)                .retryPolicy(new ExponentialBackoffRetry(1000, 3)).build();        client.start();        return client;    }}</code></pre><p>控制台输出的日志</p><pre><code>创建客户端：client#1创建客户端：client#2创建客户端：client#3创建客户端：client#4创建客户端：client#5client#2: 我现在被选举为Leader！我开始工作了....客户端 client#1 关闭客户端 client#2 关闭client#4: 我现在被选举为Leader！我开始工作了....客户端 client#3 关闭客户端 client#4 关闭client#5: 我现在被选举为Leader！我开始工作了....客户端 client#5 关闭</code></pre><p>系统运行过程中查看 masterPath 可以看见客户端注册的临时节点，当客户端关闭时，临时节点也会被删除</p><p><img src="http://image.laijianfeng.org/20190122_233414.png" alt="LeaderLatch选举时的ZK节点"></p><h4 id="Leader-Election"><a href="#Leader-Election" class="headerlink" title="Leader Election"></a>Leader Election</h4><p>通过 Leader Election 选举方案进行 Master选举，需添加 LeaderSelectorListener 监听器对领导权进行控制，<strong>当节点被选为leader之后，将调用 <code>takeLeadership</code> 方法进行业务逻辑处理，处理完成会立即释放 leadship，重新进行Master选举</strong>，这样每个节点都有可能成为 leader。<code>autoRequeue()</code> 方法的调用确保此实例在释放领导权后还可能获得领导权。</p><pre><code class="java">public class LeaderSelectorTest {    private static final String zkServerIps = &quot;master:2181,hadoop2:2181&quot;;    private static final String masterPath = &quot;/testZK/leader_selector&quot;;    public static void main(String[] args) {        final int clientNums = 5;  // 客户端数量，用于模拟        final CountDownLatch countDownLatch = new CountDownLatch(clientNums);        List&lt;LeaderSelector&gt; selectorList = new CopyOnWriteArrayList();        List&lt;CuratorFramework&gt; clientList = new CopyOnWriteArrayList();        AtomicInteger atomicInteger = new AtomicInteger(1);        try {            for (int i = 0; i &lt; clientNums; i++) {                new Thread(new Runnable() {                    @Override                    public void run() {                        CuratorFramework client = getClient();  // 创建客户端                        clientList.add(client);                        int number = atomicInteger.getAndIncrement();                        final String name = &quot;client#&quot; + number;                        final LeaderSelector selector = new LeaderSelector(client, masterPath, new LeaderSelectorListener() {                            @Override                            public void takeLeadership(CuratorFramework client) throws Exception {                                System.out.println(name + &quot;: 我现在被选举为Leader！我开始工作了....&quot;);                                Thread.sleep(3000);                            }                            @Override                            public void stateChanged(CuratorFramework curatorFramework, ConnectionState connectionState) {                            }                        });                        System.out.println(&quot;创建客户端：&quot; + name);                        try {                            selector.autoRequeue();                            selector.start();                            selectorList.add(selector);                            // 随机等待 number * 10秒，之后关闭客户端                            Thread.sleep(number * 10000);                        } catch (Exception e) {                            System.out.println(e.getMessage());                        } finally {                            countDownLatch.countDown();                            System.out.println(&quot;客户端 &quot; + name + &quot; 关闭&quot;);                            CloseableUtils.closeQuietly(selector);                            if (!client.getState().equals(CuratorFrameworkState.STOPPED)) {                                CloseableUtils.closeQuietly(client);                            }                        }                    }                }).start();            }            countDownLatch.await(); // 等待，只有所有线程都退出        } catch (Exception e) {            e.printStackTrace();        }    }    private static synchronized CuratorFramework getClient() {        CuratorFramework client = CuratorFrameworkFactory.builder().connectString(zkServerIps)                .sessionTimeoutMs(6000).connectionTimeoutMs(3000) //.namespace(&quot;LeaderLatchTest&quot;)                .retryPolicy(new ExponentialBackoffRetry(1000, 3)).build();        client.start();        return client;    }}</code></pre><p>控制台输出的日志信息</p><pre><code>创建客户端：client#2创建客户端：client#1创建客户端：client#3创建客户端：client#5创建客户端：client#4client#5: 我现在被选举为Leader！我开始工作了....client#3: 我现在被选举为Leader！我开始工作了....client#2: 我现在被选举为Leader！我开始工作了....client#4: 我现在被选举为Leader！我开始工作了....客户端 client#1 关闭client#5: 我现在被选举为Leader！我开始工作了....client#3: 我现在被选举为Leader！我开始工作了....client#2: 我现在被选举为Leader！我开始工作了....客户端 client#2 关闭client#4: 我现在被选举为Leader！我开始工作了....client#5: 我现在被选举为Leader！我开始工作了....client#3: 我现在被选举为Leader！我开始工作了....client#4: 我现在被选举为Leader！我开始工作了....客户端 client#3 关闭client#5: 我现在被选举为Leader！我开始工作了....client#4: 我现在被选举为Leader！我开始工作了....client#5: 我现在被选举为Leader！我开始工作了....客户端 client#4 关闭client#5: 我现在被选举为Leader！我开始工作了....client#5: 我现在被选举为Leader！我开始工作了....client#5: 我现在被选举为Leader！我开始工作了....客户端 client#5 关闭</code></pre><p>LeaderSelectorListener类继承了ConnectionStateListener。一旦LeaderSelector启动，它会向curator客户端添加监听器。使用LeaderSelector必须时刻注意连接的变化。一旦出现连接问题如 <code>SUSPENDED</code>，curator实例必须确保它不再是leader，直至它重新收到 <code>RECONNECTED</code>。如果 <code>LOST</code> 出现，curator实例不再是 leader 并且其 <code>takeLeadership()</code> 应该直接退出。</p><p>推荐的做法是，如果发生 <code>SUSPENDED</code> 或者 <code>LOST</code> 连接问题，最好直接抛CancelLeadershipException，此时，leaderSelector实例会尝试中断并且取消正在执行 <code>takeLeadership()</code> 方法的线程。 建议扩展LeaderSelectorListenerAdapter，LeaderSelectorListenerAdapter中已经提供了推荐的处理方式 。</p><blockquote><p>参考：<br>《从Paxos到Zookeeper分布式一致性原理与实践》<br><a href="https://blog.csdn.net/wo541075754/article/details/70216046" target="_blank" rel="noopener">Zookeeper开源客户端Curator之Master/Leader选举</a></p></blockquote><p><img src="http://image.laijianfeng.org/20190116_014816.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zookeeper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Zookeeper 分布式协调服务介绍</title>
      <link href="/2019/01/Zookeeper-%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E6%9C%8D%E5%8A%A1%E4%BB%8B%E7%BB%8D/"/>
      <url>/2019/01/Zookeeper-%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E6%9C%8D%E5%8A%A1%E4%BB%8B%E7%BB%8D/</url>
      <content type="html"><![CDATA[<h4 id="分布式系统"><a href="#分布式系统" class="headerlink" title="分布式系统"></a>分布式系统</h4><p>分布式系统的简单定义：分布式系统是一个硬件或软件组件分布在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统。</p><p>分布式系统的特征：</p><ul><li>分布性：系统中的计算机在空间上随意分布和随时变动</li><li>对等性：系统中的计算机是对等的，没有主从之分</li><li>并发性：并发性操作是非常常见的行为</li><li>缺乏全局时钟：系统中的计算机具有明显的分布性，且缺乏一个全局的时钟序列控制，所以很难比较两个事件的先后</li><li>故障总是会发生：任何在设计阶段考虑到的异常情况，一定会在系统实际运行中发生，并且还会遇到很多在设计时未考虑到的异常故障</li></ul><p>随着分布式架构的出现，越来越多的分布式应用会面临数据一致性问题。</p><h4 id="选择Zookeeper"><a href="#选择Zookeeper" class="headerlink" title="选择Zookeeper"></a>选择Zookeeper</h4><p>Zookeeper是一个典型的分布式数据一致性解决方案，分布式应用程序可以基于它实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、master选举、分布式锁和分布式队列等功能。</p><p>Zookeeper致力于提供一个高性能、高可用，具有严格的顺序访问控制能力的分布式协调服务；其主要的设计目标是简单的数据模型、可以构建集群、顺序访问、高性能。Zookeeper已经成为很多大型分布式项目譬如Hadoop、HBase、Storm、Solr等中的核心组件，用于分布式协调。</p><p>Zookeeper可以保证如下<strong>分布式一致性特性</strong>：</p><ul><li>顺序一致性：从同一个客户端发起的事务请求，最终将会严格地按照其发起顺序被应用到Zookeeper中去</li><li>原子性：所有事务请求的处理结果在整个集群中所有的机器上的应用情况是一致的</li><li>单一视图：无论客户端连接的是哪个Zookeeper服务器，其看到的服务器数据模型都是一致的</li><li>可靠性：一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会被一直保留下来，除非有另一个事务又对其进行了变更</li><li>实时性：在一定的时间内，客户端最终一定能够从服务端上读取到最新的数据状态</li></ul><p><img src="http://image.laijianfeng.org/zkservice.jpg" alt="Zookeeper服务架构图"></p><h3 id="Zookeeper-基本概念"><a href="#Zookeeper-基本概念" class="headerlink" title="Zookeeper 基本概念"></a>Zookeeper 基本概念</h3><ul><li><p>集群角色</p><ul><li>Leader：客户端提供读和写服务</li><li>Follower：提供读服务，所有写服务都需要转交给Leader角色，参与选举</li><li>Observer：提供读服务，不参与选举过程，一般是为了增强Zookeeper集群的读请求并发能力</li></ul></li><li><p>会话 (session)</p><ul><li>Zk的客户端与zk的服务端之间的连接</li><li>通过心跳检测保持客户端连接的存活</li><li>接收来自服务端的watch事件通知</li><li>可以设置超时时间</li></ul></li></ul><h4 id="ZNode-节点"><a href="#ZNode-节点" class="headerlink" title="ZNode 节点"></a>ZNode 节点</h4><p>ZNode 是Zookeeper中数据的最小单元，每个ZNode上可以保存数据(byte[]类型)，同时可以挂在子节点，因此构成了一个层次化的命名空间，我们称之为树</p><p><img src="http://image.laijianfeng.org/20190121_141804.jpg" alt="Zookeeper数据模型"></p><ul><li><p>节点是有生命周期的，生命周期由<strong>节点类型</strong>决定：</p><ul><li>持久节点(PERSISTENT)：节点创建后就一直存在于Zookeeper服务器上，直到有删除操作主动将其删除</li><li>持久顺序节点(PERSISTENT_SEQUENTIAL)：基本特性与持久节点一致，额外的特性在于Zookeeper会记录其子节点创建的先后顺序</li><li>临时节点(EPHEMERAL)：声明周期与客户端的会话绑定，客户端会话失效时节点将被自动清除</li><li>临时顺序节点(EPHEMERAL_SEQUENTIAL)：基本特性与临时节点一致，但添加了顺序的特性</li></ul></li><li><p>每个节点都有<strong>状态信息</strong>，抽象为 Stat 对象，状态属性如下：</p><ul><li>czxid：节点被创建时的事务ID</li><li>mzxid：节点最后一个被更新时的事务ID</li><li>ctime：节点创建时间</li><li>mtime：节点最后一个被更新时间</li><li>version：节点版本号</li><li>cversion：子节点版本号</li><li>aversion：节点的ACL版本号</li><li>ephemeralOwner：创建该临时节点的会话的sessionID，若为持久节点则为0</li><li>dataLength：数据内容长度</li><li>numChildren：子节点数量</li></ul></li><li><p>权限控制ACL (Access Control Lists) </p><ul><li>CREATE：创建子节点的权限</li><li>READ：获取节点数据和子节点列表的权限</li><li>WRITE：更新节点数据的权限</li><li>DELETE：删除子节点的权限</li><li>ADMIN：设置节点ACL的权限</li></ul></li></ul><h4 id="watcher机制"><a href="#watcher机制" class="headerlink" title="watcher机制"></a>watcher机制</h4><p>Zookeeper 引入watcher机制来实现发布/订阅功能，能够让多个订阅者同时监听某一个节点对象，当这个节点对象状态发生变化时，会通知所有订阅者。</p><p>Zookeeper的watcher机制主要包括客户端线程、客户端WatchManager、Zookeeper服务器三个部分。其工作流程简单来说：客户端在向Zookeeper服务器注册Watcher的同时，会将Watcher对象存储在客户端的WatchManager中；当Zookeeper服务器端触发Watcher事件后，会向客户端发送通知，客户端线程从WatchManager中取出对应的Watcher对象来执行回调逻辑</p><p><img src="http://image.laijianfeng.org/20190121_174457.png" alt="Zookeeper Watcher机制概述"></p><p>可以设置的两种 Watcher</p><ul><li><p>NodeCache</p><ul><li>监听数据节点的内容变更</li><li>监听节点的创建，即如果指定的节点不存在，则节点创建后，会触发这个监听</li></ul></li><li><p>PathChildrenCache</p><ul><li>监听指定节点的子节点变化情况</li><li>包括新增子节点、子节点数据变更和子节点删除</li></ul></li></ul><h3 id="客户端命令"><a href="#客户端命令" class="headerlink" title="客户端命令"></a>客户端命令</h3><p>Zookeeper的安装可参考官方文档</p><pre><code class="shell"># 启动客户端，默认为 localhost:2181bin/zkCli.sh     # 启动客户端，指定连接的Zookeeper地址bin/zkCli.sh -server ip:port # create 创建一个节点，路径为 /test，内容为 some test data create /test &quot;some test data&quot;# ls 列出指定节点下的所有子节点 ls /# get 获取指定节点的数据内容和属性get /test# set 更新指定节点的数据内容set /test &quot;new test data&quot;# delete 删除节点delete /test# rmr 删除非空节点rmr /test# stat 输出节点的状态信息stat /test</code></pre><h4 id="四字命令"><a href="#四字命令" class="headerlink" title="四字命令"></a>四字命令</h4><p>四字命令可以查看Zookeeper服务器的一些信息，可以通过 telnet 和 nc 等方式执行四字命令，以执行 conf 命令为例</p><pre><code># telnet 方式 执行Zookeeper的 conf 命令telnet localhost 2181conf# nc 方式 执行Zookeeper的 conf 命令echo conf | nc localhost 2181</code></pre><p><strong>四字命令介绍</strong>：</p><ul><li>conf 命令用于输出Zookeeper服务器运行时的基本配置信息</li><li>cons 命令用于输出这台服务器上所有客户端连接的详细信息</li><li>crst 命令用于重置所有客户端的连接统计信息</li><li>dump 命令用于输出当前集群的所有会话信息</li><li>envi 命令用于输出Zookeeper所在服务器的运行时信息</li><li>ruok 命令用于输出当前Zookeeper服务器是否正在运行</li><li>stat 命令用于获取Zookeeper服务器的运行状态信息</li><li>srvr 命令与stat命令功能一致，但仅输出服务器自身的信息</li><li>srst 命令用于重置所有服务器的统计信息</li><li>wchs 命令用于输出当前服务器上管理的 watcher 的概要信息</li><li>wchc 命令用于输出当前服务器上管理的 watcher 的详细信息</li><li>wchp 命令与wchc功能非常相似，但输出信息以节点路径为单位进行归组</li><li>mntr 命令用于输出比stat命令更为详细的服务器统计信息</li></ul><h3 id="Curator-客户端代码实例"><a href="#Curator-客户端代码实例" class="headerlink" title="Curator 客户端代码实例"></a>Curator 客户端代码实例</h3><p>Curator 是 Apache 基金会的顶级项目之一，解决了很多Zookeeper客户端非常底层的细节开发工作，包括会话超时重连、反复注册Watcher、NodeExistsException异常等，提供了一套易用性和可读性更强的Fluent风格的客户端API框架，除此之外，curator还提供了Zookeeper各种应用场景（Recipe，如共享锁服务、master选举、分布式计数器等）的抽象封装。</p><p>Zookeeper 的核心提交者 Patrick Hunt 对 Curator 的高度评价：</p><blockquote><p>Guava is to Java what Curator is to Zookeeper</p></blockquote><h4 id="示例-增删查改"><a href="#示例-增删查改" class="headerlink" title="示例 - 增删查改"></a>示例 - 增删查改</h4><pre><code class="java">import org.apache.curator.RetryPolicy;import org.apache.curator.framework.CuratorFramework;import org.apache.curator.framework.CuratorFrameworkFactory;import org.apache.curator.framework.imps.CuratorFrameworkState;import org.apache.curator.retry.ExponentialBackoffRetry;import org.apache.zookeeper.CreateMode;import org.apache.zookeeper.ZooDefs;import org.apache.zookeeper.data.Stat;public class CuratorCrud {    // 集群模式则是多个ip    private static final String zkServerIps = &quot;master:2181,hadoop2:2181&quot;;    public static void main(String[] args) throws Exception {        // 创建节点        String nodePath = &quot;/testZK&quot;; // 节点路径        byte[] data = &quot;this is a test data&quot;.getBytes(); // 节点数据        byte[] newData = &quot;new test data&quot;.getBytes(); // 节点数据        // 设置重连策略ExponentialBackoffRetry, baseSleepTimeMs：初始sleep的时间,maxRetries：最大重试次数,maxSleepMs：最大重试时间        RetryPolicy retryPolicy = new ExponentialBackoffRetry(10000, 5);        //（推荐）curator链接zookeeper的策略:RetryNTimes n：重试的次数 sleepMsBetweenRetries：每次重试间隔的时间        // RetryPolicy retryPolicy = new RetryNTimes(3, 5000);        // （不推荐） curator链接zookeeper的策略:RetryOneTime sleepMsBetweenRetry:每次重试间隔的时间,这个策略只会重试一次        // RetryPolicy retryPolicy2 = new RetryOneTime(3000);        // 永远重试，不推荐使用        // RetryPolicy retryPolicy3 = new RetryForever(retryIntervalMs)        // curator链接zookeeper的策略:RetryUntilElapsed maxElapsedTimeMs:最大重试时间 sleepMsBetweenRetries:每次重试间隔 重试时间超过maxElapsedTimeMs后，就不再重试        // RetryPolicy retryPolicy4 = new RetryUntilElapsed(2000, 3000);        // Curator客户端        CuratorFramework client = null;        // 实例化Curator客户端，Curator的编程风格可以让我们使用方法链的形式完成客户端的实例化        client = CuratorFrameworkFactory.builder()  // 使用工厂类来建造客户端的实例对象                .connectString(zkServerIps) // 放入zookeeper服务器ip                .sessionTimeoutMs(10000).retryPolicy(retryPolicy)  // 设定会话时间以及重连策略                // .namespace(&quot;testApp&quot;)    // 隔离的命名空间                .build(); // 建立连接通道        // 启动Curator客户端        client.start();        boolean isZkCuratorStarted = client.getState().equals(CuratorFrameworkState.STARTED);        System.out.println(&quot;当前客户端的状态：&quot; + (isZkCuratorStarted ? &quot;连接中...&quot; : &quot;已关闭...&quot;));        try {            // 检查节点是否存在            Stat s = client.checkExists().forPath(nodePath);            if (s == null) {                System.out.println(&quot;节点不存在，创建节点&quot;);                // 创建节点                String result = client.create().creatingParentsIfNeeded()    // 创建父节点，也就是会递归创建                        .withMode(CreateMode.PERSISTENT) // 节点类型                        .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE) // 节点的ACL权限                        .forPath(nodePath, data);                System.out.println(result + &quot;节点，创建成功...&quot;);            } else {                System.out.println(&quot;节点已存在，&quot; + s);            }            getData(client, nodePath);  // 输出节点信息            // 更新指定节点的数据            int version = s == null ? 0 : s.getVersion();  // 版本不一致时的异常：KeeperErrorCode = BadVersion            Stat resultStat = client.setData().withVersion(version)   // 指定数据版本                    .forPath(nodePath, newData);    // 需要修改的节点路径以及新数据            System.out.println(&quot;更新节点数据成功&quot;);            getData(client, nodePath);  // 输出节点信息            // 删除节点            client.delete().guaranteed()    // 如果删除失败，那么在后端还是会继续删除，直到成功                    .deletingChildrenIfNeeded() // 子节点也一并删除，也就是会递归删除                    .withVersion(resultStat.getVersion())                    .forPath(nodePath);            System.out.println(&quot;删除节点：&quot; + nodePath);            Thread.sleep(1000);        } finally {            // 关闭客户端            if (!client.getState().equals(CuratorFrameworkState.STOPPED)) {                System.out.println(&quot;关闭客户端.....&quot;);                client.close();            }            isZkCuratorStarted = client.getState().equals(CuratorFrameworkState.STARTED);            System.out.println(&quot;当前客户端的状态：&quot; + (isZkCuratorStarted ? &quot;连接中...&quot; : &quot;已关闭...&quot;));        }    }    /**     * 读取节点的数据     */    private static byte[] getData(CuratorFramework client, String nodePath) throws Exception {        Stat stat = new Stat();        byte[] nodeData = client.getData().storingStatIn(stat).forPath(nodePath);        System.out.println(&quot;节点 &quot; + nodePath + &quot; 的数据为：&quot; + new String(nodeData));        System.out.println(&quot;该节点的数据版本号为：&quot; + stat.getVersion() + &quot;\n&quot;);        return nodeData;    }}// 输出当前客户端的状态：连接中...节点不存在，创建节点/testZK节点，创建成功...节点 /testZK 的数据为：this is a test data该节点的数据版本号为：0更新节点数据成功节点 /testZK 的数据为：new test data该节点的数据版本号为：1删除节点：/testZK关闭客户端.....当前客户端的状态：已关闭...</code></pre><h4 id="示例-异步接口"><a href="#示例-异步接口" class="headerlink" title="示例 - 异步接口"></a>示例 - 异步接口</h4><pre><code class="java">public class CuratorBackGround {    private static final String zkServerIps = &quot;master:2181,hadoop2:2181&quot;;    public static void main(String[] args) throws Exception {        CountDownLatch samphore = new CountDownLatch(2);        ExecutorService tp = Executors.newFixedThreadPool(2);   // 线程池        String nodePath = &quot;/testZK&quot;;        byte[] data = &quot;this is a test data&quot;.getBytes();        RetryPolicy retryPolicy = new ExponentialBackoffRetry(10000, 5);        CuratorFramework client = CuratorFrameworkFactory.builder().connectString(zkServerIps)                .sessionTimeoutMs(10000).retryPolicy(retryPolicy).build();        client.start();        // 异步创建节点，传入 ExecutorService，这样比较复杂的就会放到线程池中执行        client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL)                .inBackground(new BackgroundCallback() {                    @Override                    public void processResult(CuratorFramework curatorFramework, CuratorEvent curatorEvent) throws Exception {                        System.out.println(&quot;event[code: &quot; + curatorEvent.getResultCode() + &quot;, type: &quot; + curatorEvent.getType() + &quot;]&quot;);                        System.out.println(&quot;当前线程：&quot; + Thread.currentThread().getName());                        samphore.countDown();                    }                }, tp).forPath(nodePath, data); // 此处传入 ExecutorService tp        // 异步创建节点        client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL)                .inBackground(new BackgroundCallback() {                    @Override                    public void processResult(CuratorFramework curatorFramework, CuratorEvent curatorEvent) throws Exception {                        System.out.println(&quot;event[code: &quot; + curatorEvent.getResultCode() + &quot;, type: &quot; + curatorEvent.getType() + &quot;]&quot;);                        System.out.println(&quot;当前线程：&quot; + Thread.currentThread().getName());                        samphore.countDown();                    }                }).forPath(nodePath, data); // 此处没有传入 ExecutorService tp        samphore.await();        tp.shutdown();    }}// 输出event[code: -110, type: CREATE]当前线程：main-EventThreadevent[code: 0, type: CREATE]当前线程：pool-1-thread-1</code></pre><h4 id="示例-watcher-事件监听-NodeCache"><a href="#示例-watcher-事件监听-NodeCache" class="headerlink" title="示例 - watcher 事件监听 - NodeCache"></a>示例 - watcher 事件监听 - NodeCache</h4><pre><code class="java">public class CuratorWatcher {    private static final String zkServerIps = &quot;master:2181,hadoop2:2181&quot;;    public static void main(String[] args) throws Exception {        final String nodePath = &quot;/testZK&quot;;        RetryPolicy retryPolicy = new ExponentialBackoffRetry(10000, 5);        CuratorFramework client = CuratorFrameworkFactory.builder().connectString(zkServerIps)                .sessionTimeoutMs(10000).retryPolicy(retryPolicy).build();        try {            client.start();            client.create().creatingParentsIfNeeded().withMode(CreateMode.PERSISTENT).forPath(nodePath, &quot;this is a test data&quot;.getBytes());            final NodeCache cacheNode = new NodeCache(client, nodePath, false);            cacheNode.start(true);  // true 表示启动时立即从Zookeeper上获取节点            cacheNode.getListenable().addListener(new NodeCacheListener() {                @Override                public void nodeChanged() throws Exception {                    System.out.println(&quot;节点数据更新，新的内容是： &quot; + new String(cacheNode.getCurrentData().getData()));                }            });            for (int i = 0; i &lt; 5; i++) {                client.setData().forPath(nodePath, (&quot;new test data &quot; + i).getBytes());                Thread.sleep(1000);            }            Thread.sleep(10000); // 等待100秒，手动在 zkCli 客户端操作节点，触发事件        } finally {            client.delete().deletingChildrenIfNeeded().forPath(nodePath);            client.close();            System.out.println(&quot;客户端关闭......&quot;);        }    }}</code></pre><h4 id="示例-watcher-事件监听-PathChildrenCache"><a href="#示例-watcher-事件监听-PathChildrenCache" class="headerlink" title="示例 - watcher 事件监听 - PathChildrenCache"></a>示例 - watcher 事件监听 - PathChildrenCache</h4><pre><code>public class CuratorPCWatcher {    private static final String zkServerIps = &quot;master:2181,hadoop2:2181&quot;;    public static void main(String[] args) throws Exception {        final String nodePath = &quot;/testZK&quot;;        RetryPolicy retryPolicy = new ExponentialBackoffRetry(10000, 5);        CuratorFramework client = CuratorFrameworkFactory.builder().connectString(zkServerIps)                .sessionTimeoutMs(10000).retryPolicy(retryPolicy).build();        client.start();        try {            // 为子节点添加watcher，PathChildrenCache: 监听数据节点的增删改，可以设置触发的事件            final PathChildrenCache childrenCache = new PathChildrenCache(client, nodePath, true);            /**             * StartMode: 初始化方式             *  - POST_INITIALIZED_EVENT：异步初始化，初始化之后会触发事件             *  - NORMAL：异步初始化             *  - BUILD_INITIAL_CACHE：同步初始化             */            childrenCache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);            // 列出子节点数据列表，需要使用BUILD_INITIAL_CACHE同步初始化模式才能获得，异步是获取不到的            List&lt;ChildData&gt; childDataList = childrenCache.getCurrentData();            System.out.println(&quot;当前节点的子节点详细数据列表：&quot;);            for (ChildData childData : childDataList) {                System.out.println(&quot;\t* 子节点路径：&quot; + new String(childData.getPath()) + &quot;，该节点的数据为：&quot; + new String(childData.getData()));            }            // 添加事件监听器            childrenCache.getListenable().addListener(new PathChildrenCacheListener() {                @Override                public void childEvent(CuratorFramework curatorFramework, PathChildrenCacheEvent event) throws Exception {                    // 通过判断event type的方式来实现不同事件的触发                    if (event.getType().equals(PathChildrenCacheEvent.Type.INITIALIZED)) {  // 子节点初始化时触发                        System.out.println(&quot;子节点初始化成功&quot;);                    } else if (event.getType().equals(PathChildrenCacheEvent.Type.CHILD_ADDED)) {  // 添加子节点时触发                        System.out.print(&quot;子节点：&quot; + event.getData().getPath() + &quot; 添加成功，&quot;);                        System.out.println(&quot;该子节点的数据为：&quot; + new String(event.getData().getData()));                    } else if (event.getType().equals(PathChildrenCacheEvent.Type.CHILD_REMOVED)) {  // 删除子节点时触发                        System.out.println(&quot;子节点：&quot; + event.getData().getPath() + &quot; 删除成功&quot;);                    } else if (event.getType().equals(PathChildrenCacheEvent.Type.CHILD_UPDATED)) {  // 修改子节点数据时触发                        System.out.print(&quot;子节点：&quot; + event.getData().getPath() + &quot; 数据更新成功，&quot;);                        System.out.println(&quot;子节点：&quot; + event.getData().getPath() + &quot; 新的数据为：&quot; + new String(event.getData().getData()));                    }                }            });            Thread.sleep(100000); // sleep 100秒，在 zkCli.sh 操作子节点，注意查看控制台的输出        } finally {            client.close();        }    }}// 输出当前节点的子节点详细数据列表：    * 子节点路径：/testZK/node1，该节点的数据为：hello world子节点：/testZK/node2 添加成功，该子节点的数据为：hello node2子节点：/testZK/node2 数据更新成功，子节点：/testZK/node2 新的数据为：hello zookeeper子节点：/testZK/node2 删除成功</code></pre><h3 id="Zookeeper的典型应用场景"><a href="#Zookeeper的典型应用场景" class="headerlink" title="Zookeeper的典型应用场景"></a>Zookeeper的典型应用场景</h3><p>下一篇文章将使用 Curator 客户端来实现 Zookeeper 的典型应用场景的示例，这里简单概括一下Zookeeper的典型应用场景：</p><ul><li>数据发布/订阅，即所谓的配置中心</li><li>负载均衡</li><li>命名服务</li><li>分布式协调/通知</li><li>集群管理</li><li>master 选举</li><li>分布式锁</li><li>分布式队列</li></ul><blockquote><p>参考：<br>《从Paxos到Zookeeper分布式一致性原理与实践》</p></blockquote><p><img src="http://image.laijianfeng.org/20190116_014816.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zookeeper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统 | CAP 定理图解</title>
      <link href="/2019/01/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-CAP-%E5%AE%9A%E7%90%86%E5%9B%BE%E8%A7%A3/"/>
      <url>/2019/01/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-CAP-%E5%AE%9A%E7%90%86%E5%9B%BE%E8%A7%A3/</url>
      <content type="html"><![CDATA[<p>CAP定理是分布系统中的一个基本定理，它指出任何分布系统最多可以具有以下三个属性中的两个。</p><ul><li>一致性 (Consistency) </li><li>可用性 (Availability)  </li><li>分区容错性 (Partition tolerance)   </li></ul><p>本文将以图解的形式简明地对 <a href="https://www.comp.nus.edu.sg/~gilbert/pubs/BrewersConjecture-SigAct.pdf" target="_blank" rel="noopener">Gilbert and Lynch’s specification and proof of the CAP Theorem </a>(CAP定理的规范和证明) 进行概括总结</p><h3 id="什么是-CAP-定理？"><a href="#什么是-CAP-定理？" class="headerlink" title="什么是 CAP 定理？"></a>什么是 CAP 定理？</h3><p>CAP定理指出分布式系统不可能同时具有一致性、可用性和分区容错性。听起来很简单，但一致性、可用性、分区容错性到底是什么意思呢？确切地来说分布式系统又意味着什么呢？</p><p>在本文中，我们将介绍一个简单的分布式系统，并对分布式系统的可用性、一致性和分区容错性进行诠释。有关分布式系统和这三个属性的正式描述，请参阅 Gilbert 和 Lynch 的论文。</p><h4 id="分布式系统"><a href="#分布式系统" class="headerlink" title="分布式系统"></a>分布式系统</h4><p>让我们来考虑一个非常简单的分布式系统，它由两台服务器G1和G2组成；这两台服务器都存储了同一个变量<code>v</code>，<code>v</code>的初始值为<code>v0</code>；G1和G2互相之间能够通信，并且也能与外部的客户端通信；我们的分布式系统的架构图如下图所示：</p><p><img src="http://image.laijianfeng.org/cap1.svg" alt="一个简单的分布式系统"></p><p>客户端可以向任何服务器发出读写请求。服务器当接收到请求之后，将根据请求执行一些计算，然后把请求结果返回给客户端。譬如，下图是一个写请求的例子：</p><p><img src="http://image.laijianfeng.org/20190115_182005.png" alt="客户端发起写请求"></p><p>接着，下图是一个读请求的例子</p><p><img src="http://image.laijianfeng.org/20190115_182219.png" alt="客户端发起读请求"></p><p>现在我们的分布式系统建立起来了，下面我们就来回顾一下分布式系统的可用性、一致性以及分区容错性的含义。</p><h4 id="一致性-Consistency"><a href="#一致性-Consistency" class="headerlink" title="一致性 (Consistency)"></a>一致性 (Consistency)</h4><p>Gilbert 和 Lynch 在论文中的描述是：</p><blockquote><p>any read operation that begins after a write operation completes must return that value, or the result of a later write operation</p></blockquote><p>也就是说，在一个一致性的系统中，客户端向任何服务器发起一个写请求，将一个值写入服务器并得到响应，那么之后向任何服务器发起读请求，都必须读取到这个值（或者更加新的值）。</p><p>下图是一个不一致的分布式系统的例子:</p><p><img src="http://image.laijianfeng.org/20190115_223824.png" alt="不一致的分布式系统"></p><p>客户端向G1发起写请求，将v的值更新为v1且得到G1的确认响应；当向G2发起读<code>v</code>的请求时，读取到的却是旧的值<code>v0</code>，与期待的<code>v1</code>不一致。</p><p>下图一致的分布式系统的例子:</p><p><img src="http://image.laijianfeng.org/20190115_225536.png" alt="一致的分布式系统"></p><p>在这个系统中，G1在将确认响应返回给客户端之前，会先把<code>v</code>的新值复制给G2，这样，当客户端从G2读取<code>v</code>的值时就能读取到最新的值<code>v1</code></p><h4 id="可用性-Availability"><a href="#可用性-Availability" class="headerlink" title="可用性 (Availability)"></a>可用性 (Availability)</h4><p>Gilbert 和 Lynch 在论文中的描述是：</p><blockquote><p>every request received by a non-failing node in the system must result in a response</p></blockquote><p>也就是说，在一个可用的分布式系统中，客户端向其中一个服务器发起一个请求且该服务器未崩溃，那么这个服务器最终必须响应客户端的请求。</p><h4 id="分区容错性-Partition-tolerance"><a href="#分区容错性-Partition-tolerance" class="headerlink" title="分区容错性 (Partition tolerance)"></a>分区容错性 (Partition tolerance)</h4><p>Gilbert 和 Lynch 在论文中的描述是：</p><blockquote><p>the network will be allowed to lose arbitrarily many messages sent from one node to another</p></blockquote><p>也就是说服务器G1和G2之间互相发送的任意消息都可能丢失。如果所有的消息都丢失了，那么我们的系统就变成了下图这样：</p><p><img src="http://image.laijianfeng.org/20190115_225537.svg" alt="网络分区"></p><p>为了满足分区容错性，我们的系统在任意的网络分区情况下都必须正常的工作。</p><h3 id="CAP定理的证明"><a href="#CAP定理的证明" class="headerlink" title="CAP定理的证明"></a>CAP定理的证明</h3><p>现在我们已经了解了一致性、可用性和分区容错性的概念，我们可以来证明一个系统不能同时满足这三种属性了。</p><p>假设存在一个同时满足这三个属性的系统，我们第一件要做的就是让系统发生网络分区，就像下图的情况一样：</p><p><img src="http://image.laijianfeng.org/20190115_225537.svg" alt="网络分区"></p><p>客户端向G1发起写请求，将<code>v</code>的值更新为<code>v1</code>，因为系统是可用的，所以G1必须响应客户端的请求，但是由于网络是分区的，G1无法将其数据复制到G2</p><p><img src="http://image.laijianfeng.org/20190115_230826.png" alt="由于网络分区导致不一致"></p><p>接着，客户端向G2发起读<code>v</code>的请求，再一次因为系统是可用的，所以G2必须响应客户端的请求，又由于网络是分区的，G2无法从G1更新<code>v</code>的值，所以G2返回给客户端的是旧的值<code>v0</code></p><p><img src="http://image.laijianfeng.org/20190115_231317.png" alt="由于网络分区导致不一致"></p><p>客户端发起写请求将G1上<code>v</code>的值修改为<code>v1</code>之后，从G2上读取到的值仍然是<code>v0</code>，这违背了一致性。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>我们假设了存在一个满足一致性、可用性、分区容错性的分布式系统，但是我们展示了在一些情况下，系统表现出不一致的行为，因此证明不存在这样一个系统</p><p>对于一个分布式系统来说，P 是一个基本要求，CAP 三者中，只能根据系统要求在 C 和 A 两者之间做权衡，并且要想尽办法提升 P</p><blockquote><p>参考：<br>英文原文：<a href="https://www.iteblog.com/redirect.php?url=aHR0cHM6Ly9td2hpdHRha2VyLmdpdGh1Yi5pby9ibG9nL2FuX2lsbHVzdHJhdGVkX3Byb29mX29mX3RoZV9jYXBfdGhlb3JlbS8=&amp;article=true" target="_blank" rel="noopener">An Illustrated Proof of the CAP Theorem</a><br><a href="https://www.iteblog.com/archives/2390.html" target="_blank" rel="noopener">一篇文章搞清楚什么是分布式系统 CAP 定理</a></p></blockquote><h3 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h3><p>欢迎评论、转发、分享</p><p>更多内容可访问我的个人博客：<a href="http://laijianfeng.org">http://laijianfeng.org</a></p><p>关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式系统理论 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>设计模式 | 解释器模式及典型应用</title>
      <link href="/2019/01/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A7%A3%E9%87%8A%E5%99%A8%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2019/01/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A7%A3%E9%87%8A%E5%99%A8%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>本文主要介绍解释器模式，在日常开发中，解释器模式的使用频率比较低</p><h3 id="解释器模式"><a href="#解释器模式" class="headerlink" title="解释器模式"></a>解释器模式</h3><p><strong>解释器模式(Interpreter Pattern)</strong>：定义一个语言的文法，并且建立一个解释器来解释该语言中的句子，这里的 “语言” 是指使用规定格式和语法的代码。解释器模式是一种类行为型模式。</p><h4 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h4><p><strong>AbstractExpression（抽象表达式）</strong>：在抽象表达式中声明了抽象的解释操作，它是所有终结符表达式和非终结符表达式的公共父类。</p><p><strong>TerminalExpression（终结符表达式）</strong>：终结符表达式是抽象表达式的子类，它实现了与文法中的终结符相关联的解释操作，在句子中的每一个终结符都是该类的一个实例。通常在一个解释器模式中只有少数几个终结符表达式类，它们的实例可以通过非终结符表达式组成较为复杂的句子。</p><p><strong>NonterminalExpression（非终结符表达式）</strong>：非终结符表达式也是抽象表达式的子类，它实现了文法中非终结符的解释操作，由于在非终结符表达式中可以包含终结符表达式，也可以继续包含非终结符表达式，因此其解释操作一般通过递归的方式来完成。</p><p><strong>Context（环境类）</strong>：环境类又称为上下文类，它用于存储解释器之外的一些全局信息，通常它临时存储了需要解释的语句。</p><p><img src="http://image.laijianfeng.org/20190113_110631.jpg" alt="解释器模式结构图"></p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>使用解释器模式实现一个简单的后缀表达式解释器，仅支持对整数的加法和乘法即可</p><p>定义抽象表达式接口</p><pre><code class="java">public interface Interpreter {    int interpret();}</code></pre><p>非终结符表达式，对整数进行解释</p><pre><code class="java">public class NumberInterpreter implements Interpreter {    private int number;    public NumberInterpreter(int number) {        this.number = number;    }    public NumberInterpreter(String number) {        this.number = Integer.parseInt(number);    }    @Override    public int interpret() {        return this.number;    }}</code></pre><p>终结符表达式，对加法和乘法进行解释</p><pre><code class="java">// 加法public class AddInterpreter implements Interpreter {    private Interpreter firstExpression, secondExpression;    public AddInterpreter(Interpreter firstExpression, Interpreter secondExpression) {        this.firstExpression = firstExpression;        this.secondExpression = secondExpression;    }    @Override    public int interpret() {            return this.firstExpression.interpret() + this.secondExpression.interpret();    }    @Override    public String toString() {        return &quot;+&quot;;    }}// 乘法public class MultiInterpreter implements Interpreter {    private Interpreter firstExpression, secondExpression;    public MultiInterpreter(Interpreter firstExpression, Interpreter secondExpression) {        this.firstExpression = firstExpression;        this.secondExpression = secondExpression;    }    @Override    public int interpret() {        return this.firstExpression.interpret() * this.secondExpression.interpret();    }    @Override    public String toString() {        return &quot;*&quot;;    }}</code></pre><p>工具类</p><pre><code class="java">public class OperatorUtil {    public static boolean isOperator(String symbol) {        return (symbol.equals(&quot;+&quot;) || symbol.equals(&quot;*&quot;));    }    public static Interpreter getExpressionObject(Interpreter firstExpression, Interpreter secondExpression, String symbol) {        if (&quot;+&quot;.equals(symbol)) {  // 加法            return new AddInterpreter(firstExpression, secondExpression);        } else if (&quot;*&quot;.equals(symbol)) {    // 乘法            return new MultiInterpreter(firstExpression, secondExpression);        } else {            throw new RuntimeException(&quot;不支持的操作符：&quot; + symbol);        }    }}</code></pre><p>测试，对后缀表达式 <code>6 100 11 + *</code> 进行求值</p><pre><code class="java">public class Test {    public static void main(String[] args) {        String inputStr = &quot;6 100 11 + *&quot;;        MyExpressionParser expressionParser = new MyExpressionParser();        int result = expressionParser.parse(inputStr);        System.out.println(&quot;解释器计算结果: &quot; + result);    }}</code></pre><p>运行结果</p><pre><code>入栈: 6入栈: 100入栈: 11出栈: 11 和 100应用运算符: +阶段结果入栈: 111出栈: 111 和 6应用运算符: *阶段结果入栈: 666解释器计算结果: 666</code></pre><p><img src="http://image.laijianfeng.org/20190113_110632.png" alt="示例.类图"></p><h3 id="解释器模式总结"><a href="#解释器模式总结" class="headerlink" title="解释器模式总结"></a>解释器模式总结</h3><p>解释器模式为自定义语言的设计和实现提供了一种解决方案，它用于定义一组文法规则并通过这组文法规则来解释语言中的句子。虽然解释器模式的使用频率不是特别高，但是它在<strong>正则表达式</strong>、<strong>XML文档解释</strong>等领域还是得到了广泛使用。</p><h4 id="主要优点"><a href="#主要优点" class="headerlink" title="主要优点"></a>主要优点</h4><ul><li><strong>易于改变和扩展文法</strong>。由于在解释器模式中使用类来表示语言的文法规则，因此可以通过继承等机制来改变或扩展文法。</li><li>每一条文法规则都可以表示为一个类，因此可以<strong>方便地实现一个简单的语言</strong>。</li><li><strong>实现文法较为容易</strong>。在抽象语法树中每一个表达式节点类的实现方式都是相似的，这些类的代码编写都不会特别复杂，还可以通过一些工具自动生成节点类代码。</li><li><strong>增加新的解释表达式较为方便</strong>。如果用户需要增加新的解释表达式只需要对应增加一个新的终结符表达式或非终结符表达式类，原有表达式类代码无须修改，符合 “开闭原则”。</li></ul><h4 id="主要缺点"><a href="#主要缺点" class="headerlink" title="主要缺点"></a>主要缺点</h4><ul><li><strong>对于复杂文法难以维护</strong>。在解释器模式中，每一条规则至少需要定义一个类，因此如果一个语言包含太多文法规则，类的个数将会急剧增加，导致系统难以管理和维护，此时可以考虑使用语法分析程序等方式来取代解释器模式。</li><li><strong>执行效率较低</strong>。由于在解释器模式中使用了大量的循环和递归调用，因此在解释较为复杂的句子时其速度很慢，而且代码的调试过程也比较麻烦。</li></ul><h4 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h4><ul><li>可以将一个需要解释执行的语言中的句子表示为一个抽象语法树。</li><li>一些重复出现的问题可以用一种简单的语言来进行表达。</li><li>一个语言的文法较为简单。</li><li>对执行效率要求不高。</li></ul><h3 id="解释器模式的典型应用"><a href="#解释器模式的典型应用" class="headerlink" title="解释器模式的典型应用"></a>解释器模式的典型应用</h3><h4 id="Spring-EL表达式中的解释器模式"><a href="#Spring-EL表达式中的解释器模式" class="headerlink" title="Spring EL表达式中的解释器模式"></a>Spring EL表达式中的解释器模式</h4><p>Spring EL表达式相关的类在 <code>org.springframework.expression</code> 包下，类图如下</p><p><img src="http://image.laijianfeng.org/20190113_110633.png" alt="org.springframework.expression 包的类图"></p><p>涉及的类非常多，这里仅对此时我们最关心的几个类做介绍：</p><p><strong>SpelExpression</strong>，表示一个 EL 表达式，表达式在内部通过一个 AST抽象语法树 表示，EL表达式求值是通过 <code>this.ast.getValue(expressionState);</code> 求值</p><pre><code class="java">public class SpelExpression implements Expression {    private final String expression;    private final SpelNodeImpl ast;    private final SpelParserConfiguration configuration;    @Override    @Nullable    public Object getValue() throws EvaluationException {        if (this.compiledAst != null) {            try {                EvaluationContext context = getEvaluationContext();                return this.compiledAst.getValue(context.getRootObject().getValue(), context);            }            catch (Throwable ex) {                // If running in mixed mode, revert to interpreted                if (this.configuration.getCompilerMode() == SpelCompilerMode.MIXED) {                    this.interpretedCount = 0;                    this.compiledAst = null;                }                else {                    // Running in SpelCompilerMode.immediate mode - propagate exception to caller                    throw new SpelEvaluationException(ex, SpelMessage.EXCEPTION_RUNNING_COMPILED_EXPRESSION);                }            }        }        ExpressionState expressionState = new ExpressionState(getEvaluationContext(), this.configuration);        Object result = this.ast.getValue(expressionState);        checkCompile(expressionState);        return result;    }    //...省略...}</code></pre><p><strong>SpelNodeImpl</strong>：已解析的Spring表达式所代表的ast语法树的节点的通用父类型，语法树的节点在解释器模式中扮演的角色是终结符和非终结符。从类图中可以看到，SpelNodeImpl 的子类主要有 Literal，Operator，Indexer等，其中 Literal 是各种类型的值的父类，Operator 则是各种操作的父类</p><pre><code class="java">public abstract class SpelNodeImpl implements SpelNode, Opcodes {    protected int pos;  // start = top 16bits, end = bottom 16bits    protected SpelNodeImpl[] children = SpelNodeImpl.NO_CHILDREN;    @Nullable    private SpelNodeImpl parent;    public final Object getValue(ExpressionState expressionState) throws EvaluationException {        return getValueInternal(expressionState).getValue();    }    // 抽象方法，由子类实现，获取对象的值    public abstract TypedValue getValueInternal(ExpressionState expressionState) throws EvaluationException;    //...省略...}</code></pre><p><strong>IntLiteral</strong> 表示整型文字的表达式语言的ast结点</p><pre><code class="java">public class IntLiteral extends Literal {    private final TypedValue value;    public IntLiteral(String payload, int pos, int value) {        super(payload, pos);        this.value = new TypedValue(value); //         this.exitTypeDescriptor = &quot;I&quot;;    }    @Override    public TypedValue getLiteralValue() {        return this.value;    }    // ...}</code></pre><p><strong>OpPlus</strong> 表示加法的ast结点，在 getValueInternal 方法中对操作符两边进行相加操作</p><pre><code class="java">public class OpPlus extends Operator {    public OpPlus(int pos, SpelNodeImpl... operands) {        super(&quot;+&quot;, pos, operands);        Assert.notEmpty(operands, &quot;Operands must not be empty&quot;);    }    @Override    public TypedValue getValueInternal(ExpressionState state) throws EvaluationException {        SpelNodeImpl leftOp = getLeftOperand();        if (this.children.length &lt; 2) {  // if only one operand, then this is unary plus            Object operandOne = leftOp.getValueInternal(state).getValue();            if (operandOne instanceof Number) {                if (operandOne instanceof Double) {                    this.exitTypeDescriptor = &quot;D&quot;;                }                else if (operandOne instanceof Float) {                    this.exitTypeDescriptor = &quot;F&quot;;                }                else if (operandOne instanceof Long) {                    this.exitTypeDescriptor = &quot;J&quot;;                }                else if (operandOne instanceof Integer) {                    this.exitTypeDescriptor = &quot;I&quot;;                }                return new TypedValue(operandOne);            }            return state.operate(Operation.ADD, operandOne, null);        }        // 递归调用leftOp的 getValueInternal(state) ，获取操作符左边的值        TypedValue operandOneValue = leftOp.getValueInternal(state);        Object leftOperand = operandOneValue.getValue();        // 递归调用children[1]的 getValueInternal(state) ，获取操作符右边的值        TypedValue operandTwoValue = getRightOperand().getValueInternal(state);        Object rightOperand = operandTwoValue.getValue();        // 如果操作符左右都是数值类型，则将它们相加        if (leftOperand instanceof Number &amp;&amp; rightOperand instanceof Number) {            Number leftNumber = (Number) leftOperand;            Number rightNumber = (Number) rightOperand;            if (leftNumber instanceof BigDecimal || rightNumber instanceof BigDecimal) {                BigDecimal leftBigDecimal = NumberUtils.convertNumberToTargetClass(leftNumber, BigDecimal.class);                BigDecimal rightBigDecimal = NumberUtils.convertNumberToTargetClass(rightNumber, BigDecimal.class);                return new TypedValue(leftBigDecimal.add(rightBigDecimal));            }            else if (leftNumber instanceof Double || rightNumber instanceof Double) {                this.exitTypeDescriptor = &quot;D&quot;;                  return new TypedValue(leftNumber.doubleValue() + rightNumber.doubleValue());            }            //...省略 Float-&gt;F, BigInteger-&gt;add, Long-&gt;J,Integer-&gt;I            else {                // Unknown Number subtypes -&gt; best guess is double addition                return new TypedValue(leftNumber.doubleValue() + rightNumber.doubleValue());            }        }        //...        return state.operate(Operation.ADD, leftOperand, rightOperand);    }    //...}</code></pre><p>通过一个示例，调试查看程序中间经历的步骤</p><pre><code class="java">public class SpringELTest {    public static void main(String[] args) {        // 1. 构建解析器        org.springframework.expression.ExpressionParser parser = new SpelExpressionParser();        // 2. 解析表达式        Expression expression = parser.parseExpression(&quot;100 * 2 + 400 * 1 + 66&quot;);        // 3. 获取结果        int result = (Integer) expression.getValue();        System.out.println(result); // 结果：666    }}</code></pre><p>EL表达式解析后得到表达式 <code>(((100 * 2) + (400 * 1)) + 66)</code><br><img src="http://image.laijianfeng.org/20190113_161156.png" alt="EL表达式解析后得到的表达式"></p><p>如果用图形把其这棵AST抽象语法树简单地画出来，大概是这样</p><p><img src="http://image.laijianfeng.org/20190113_161157.jpg" alt="示例.AST抽象语法树"></p><p>调用 <code>expression.getValue()</code> 求值，此时的 ast 是语法树的头结点，也就是 <code>+</code> OpPlus，所以通过 <code>this.ast.getValue(expressionState)</code> 进入了 OpPlus 的 getValue 方法（是父类中的方法），接着进入 getValueInternal 方法，然后递归计算操作符左边的值，递归计算操作符右边的值，最后相加返回</p><p><img src="http://image.laijianfeng.org/20190113_163005.png" alt="示例.spring EL调试"></p><blockquote><p>参考：<br><a href="gof.quanke.name">刘伟.Java设计模式</a><br>Java设计模式精讲</p></blockquote><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ArrayList 源码分析</title>
      <link href="/2019/01/ArrayList-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2019/01/ArrayList-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      <content type="html"><![CDATA[<blockquote><p>以下源码分析使用的 Java 版本为 1.8 </p></blockquote><h4 id="1-概览"><a href="#1-概览" class="headerlink" title="1. 概览"></a>1. 概览</h4><p>ArrayList 是基于数组实现的，继承 AbstractList， 实现了 List、RandomAccess、Cloneable、Serializable 接口，支持随机访问。</p><pre><code>java.util public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;     implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable</code></pre><h4 id="2-Java-Doc-关键点："><a href="#2-Java-Doc-关键点：" class="headerlink" title="2. Java Doc 关键点："></a>2. Java Doc 关键点：</h4><ul><li>实现List接口的动态数组，容量大小为 capacity，默认的容量大小 10，会自动扩容</li><li>可包含空元素 null</li><li>size, isEmpty, get, set, iterator, and listIterator 等操作的复杂度为 O(1)，The add operation runs in amortized constant time, that is, adding n elements requires O(n) time，其它操作为线性时间</li><li>非线程安全，多线程环境下必须在外部增加同步限制，或者使用包装对象 <code>List list = Collections.synchronizedList(new ArrayList(...));</code></li><li>快速失败：在使用迭代器时，调用迭代器的添加、修改、删除方法，将抛出 <code>ConcurrentModificationException</code> 异常，但是快速失败行为不是硬保证的，只是尽最大努力</li></ul><h4 id="3-成员属性"><a href="#3-成员属性" class="headerlink" title="3. 成员属性"></a>3. 成员属性</h4><p>当添加第一个元素时，<code>elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA</code> 的任何空ArrayList都将扩展为默认的capacity</p><pre><code class="java">private static final int DEFAULT_CAPACITY = 10; // 默认容量大小private static final Object[] EMPTY_ELEMENTDATA = {}; // ArrayList空实例共享的一个空数组private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; // ArrayList空实例共享的一个空数组，用于默认大小的空实例。与 EMPTY_ELEMENTDATA 分开，这样就可以了解当添加第一个元素时需要创建多大的空间transient Object[] elementData; // 真正存储ArrayList中的元素的数组private int size;   // 存储ArrayList的大小，注意不是elementData的长度private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; // 数组的最大长度protected transient int modCount = 0; //AbstractList类的，表示 elementData在结构上被修改的次数,每次add或者remove它的值都会加1</code></pre><h4 id="4-构造方法"><a href="#4-构造方法" class="headerlink" title="4. 构造方法"></a>4. 构造方法</h4><pre><code class="java">// 无参构造方法，默认初始容量10public ArrayList() {    this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;}// 提供初始容量的构造方法public ArrayList(int initialCapacity) {    if (initialCapacity &gt; 0) {        this.elementData = new Object[initialCapacity];    } else if (initialCapacity == 0) {        this.elementData = EMPTY_ELEMENTDATA;    } else {        throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+                                           initialCapacity);    }}// 通过一个容器来初始化public ArrayList(Collection&lt;? extends E&gt; c) {    elementData = c.toArray();     if ((size = elementData.length) != 0) { // c.toArray 返回的可能不是  Object[]        if (elementData.getClass() != Object[].class)            elementData = Arrays.copyOf(elementData, size, Object[].class);    } else {        this.elementData = EMPTY_ELEMENTDATA; // replace with empty array.    }}</code></pre><h4 id="5-添加元素与扩容"><a href="#5-添加元素与扩容" class="headerlink" title="5. 添加元素与扩容"></a>5. 添加元素与扩容</h4><p><strong>添加元素</strong>时使用 ensureCapacityInternal() 方法来保证容量足够，<code>size + 1</code> 为最少需要的空间大小，如果elementData的长度不够时，需要使用 grow() 方法进行扩容</p><pre><code class="java">// 添加一个元素public boolean add(E e) {    ensureCapacityInternal(size + 1);  // Increments modCount!!    elementData[size++] = e;    return true;}// 计算最少需要的容量private static int calculateCapacity(Object[] elementData, int minCapacity) {    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {         // 默认的空实例第一次添加元素时，使用默认的容量大小与minCapacity的最大值        return Math.max(DEFAULT_CAPACITY, minCapacity);    }    return minCapacity;}private void ensureCapacityInternal(int minCapacity) {    ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));}private void ensureExplicitCapacity(int minCapacity) {    modCount++;     if (minCapacity - elementData.length &gt; 0) // 需要的容量大于elementData的长度        grow(minCapacity);  // 进行扩容}</code></pre><p>扩容：当新容量小于等于 <code>MAX_ARRAY_SIZE</code> 时，新容量的大小为 <code>oldCapacity + (oldCapacity &gt;&gt; 1)</code> 与 <code>minCapacity</code> 之间的较大值 ，也就是旧容量的 1.5 倍与 <code>minCapacity</code> 之间的较大值</p><pre><code>private void grow(int minCapacity) {    int oldCapacity = elementData.length; // 原本的容量    int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 新的容量    if (newCapacity - minCapacity &lt; 0)        newCapacity = minCapacity;    if (newCapacity - MAX_ARRAY_SIZE &gt; 0)        newCapacity = hugeCapacity(minCapacity);    elementData = Arrays.copyOf(elementData, newCapacity);}private static int hugeCapacity(int minCapacity) {    if (minCapacity &lt; 0) // overflow        throw new OutOfMemoryError();    return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;}</code></pre><p>最后调用 <code>Arrays.copyOf</code> 复制原数组，将 elementData 赋值为得到的新数组。由于数组复制代价较高，所以建议在创建 ArrayList 对象时就指定大概的容量大小，减少扩容操作的次数</p><pre><code>public class Arrays {    public static &lt;T&gt; T[] copyOf(T[] original, int newLength) {        return (T[]) copyOf(original, newLength, original.getClass());    }    public static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) {        @SuppressWarnings(&quot;unchecked&quot;)        T[] copy = ((Object)newType == (Object)Object[].class)            ? (T[]) new Object[newLength] : (T[]) Array.newInstance(newType.getComponentType(), newLength);        System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength));        return copy;    }    //...}</code></pre><p>通过 addAll <strong>添加一个集合中所有元素</strong>时的扩容：至少需要的容量为两个集合的长度之和，同样是通过 ensureCapacityInternal() 来保证容量是足够的，然后调用 <code>System.arraycopy</code> 将要添加的集合中的元素复制到原集合已有元素的后面</p><pre><code class="java">public boolean addAll(Collection&lt;? extends E&gt; c) {    Object[] a = c.toArray();    int numNew = a.length;    ensureCapacityInternal(size + numNew);  // Increments modCount    System.arraycopy(a, 0, elementData, size, numNew); // 复制元素到原数组尾部    size += numNew;    return numNew != 0;}</code></pre><h4 id="6-删除元素"><a href="#6-删除元素" class="headerlink" title="6. 删除元素"></a>6. 删除元素</h4><p><strong>删除指定下标的元素</strong>时，如果下标没有越界，则取出下标对应的值，然后将数组中该下标后面的元素都往前挪1位，需要挪的元素数量是 <code>size - index - 1</code>，时间复杂度为 O(n)，所以删除元素的代价挺高</p><pre><code class="java">public E remove(int index) {    rangeCheck(index); // 检查下标是否在数组的长度范围内    modCount++;    E oldValue = elementData(index); // 下标为index的值    int numMoved = size - index - 1; // 需要移动的元素数量    if (numMoved &gt; 0)        System.arraycopy(elementData, index+1, elementData, index, numMoved);    elementData[--size] = null; // clear to let GC do its work    return oldValue;}private void rangeCheck(int index) {    if (index &gt;= size)          throw new IndexOutOfBoundsException(outOfBoundsMsg(index));}</code></pre><p><strong>删除在指定集合中的所有元素</strong> removeAll，<strong>删除不在指定集合中的所有元素</strong> retainAll</p><p>这两者都是通过 <code>batchRemove</code> 来批量删除</p><pre><code>// 删除在指定集合中的所有元素public boolean removeAll(Collection&lt;?&gt; c) {    Objects.requireNonNull(c);  // c 不能为null    return batchRemove(c, false);}// 删除不在指定集合中的所有元素，也就是只保留指定集合中的元素，其它的都删除掉public boolean retainAll(Collection&lt;?&gt; c) {    Objects.requireNonNull(c);    return batchRemove(c, true);}// 批量删除private boolean batchRemove(Collection&lt;?&gt; c, boolean complement) {    final Object[] elementData = this.elementData;    int r = 0, w = 0;   // r为当前下标，w为当前需要保留的元素的数量（或者说是下一个需保留元素的下标）    boolean modified = false;    try {        for (; r &lt; size; r++)            if (c.contains(elementData[r]) == complement)   // 判断元素 elementData[r] 是否需要删除                elementData[w++] = elementData[r];    } finally {        // r != size 的情况可能是 c.contains() 抛出了异常，将 r 之后的元素复制到 w 之后        if (r != size) {             System.arraycopy(elementData, r, elementData, w, size - r);            w += size - r;        }        if (w != size) {            // w 之后的元素设置为 null 以让 GC 回收            for (int i = w; i &lt; size; i++)                 elementData[i] = null;              modCount += size - w;            size = w;            modified = true;        }    }    return modified;}</code></pre><p><strong>删除第一个值为指定值的元素</strong> <code>remove(Object o)</code>，参数 o 可以为 null</p><p><code>fastRemove(int index)</code> 与 <code>remove(int index)</code> 几乎一样，只不过不返回被删除的元素</p><pre><code>public boolean remove(Object o) {    if (o == null) {        for (int index = 0; index &lt; size; index++)            if (elementData[index] == null) {                fastRemove(index);                return true;            }    } else {        for (int index = 0; index &lt; size; index++)            if (o.equals(elementData[index])) {                fastRemove(index);                return true;            }    }    return false;}private void fastRemove(int index) {    modCount++;    int numMoved = size - index - 1;    if (numMoved &gt; 0)        System.arraycopy(elementData, index+1, elementData, index,                         numMoved);    elementData[--size] = null; // clear to let GC do its work}</code></pre><h4 id="7-遍历"><a href="#7-遍历" class="headerlink" title="7. 遍历"></a>7. 遍历</h4><p>ArrayList 支持三种方式：</p><ul><li>for循环下标遍历</li><li>迭代器(Iterator和ListIterator)</li><li>foreach 语句</li></ul><p><strong>迭代器 Iterator 和 ListIterator 的主要区别：</strong>：</p><blockquote><p>ArrayList 的迭代器 Iterator 和 ListIterator 在《<a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483752&amp;idx=1&amp;sn=7880679f18b5727ea64cd05c06817c35&amp;chksm=e9c2ed65deb56473da688784c4562995c24daf4b13425d0d4d080208728b86525f6600127925&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 迭代器模式及典型应用</a>》这篇文章中有过详细介绍，这里只做一个小结</p></blockquote><ul><li>ListIterator 有 add() 方法，可以向List中添加对象，而 Iterator 不能</li><li>ListIterator 和 Iterator 都有 hasNext() 和 next() 方法，可以实现顺序向后遍历，但是 ListIterator 有 hasPrevious() 和 previous() 方法，可以实现逆向（顺序向前）遍历。Iterator 就不可以。</li><li>ListIterator 可以定位当前的索引位置，nextIndex() 和 previousIndex() 可以实现。Iterator 没有此功能。</li><li>都可实现删除对象，但是 ListIterator 可以实现对象的修改，set() 方法可以实现。Iierator 仅能遍历，不能修改</li></ul><p><strong>foreach 循环：</strong></p><p>foreach 循环涉及到一个 Consumer 接口，接收一个泛型的参数T，当调用 accept 方法时，Stream流中将对 accept 的参数做一系列的操作</p><pre><code class="java">public void forEach(Consumer&lt;? super E&gt; action) {    Objects.requireNonNull(action);    final int expectedModCount = modCount;  // 记录当前的 modCount    @SuppressWarnings(&quot;unchecked&quot;)    final E[] elementData = (E[]) this.elementData;    final int size = this.size;    for (int i=0; modCount == expectedModCount &amp;&amp; i &lt; size; i++) {        action.accept(elementData[i]);    }    if (modCount != expectedModCount) {        throw new ConcurrentModificationException();    }}</code></pre><h4 id="8-序列化"><a href="#8-序列化" class="headerlink" title="8. 序列化"></a>8. 序列化</h4><p>ArrayList 有两个属性被 <code>transient 关键字</code> 修饰，<strong>transient 关键字</strong> 的作用：让某些被修饰的成员属性变量不被序列化   </p><pre><code class="java">transient Object[] elementData;protected transient int modCount = 0;</code></pre><p><strong>为什么最为重要的数组元素要用 transient 修饰呢？</strong> </p><p>跟Java的序列化机制有关，这里列出Java序列化机制的几个要点：</p><ul><li>需要序列化的类必须实现java.io.Serializable接口，否则会抛出NotSerializableException异常</li><li>若没有显示地声明一个serialVersionUID变量，Java序列化机制会根据编译时的class自动生成一个serialVersionUID作为序列化版本比较（验证一致性），如果检测到反序列化后的类的serialVersionUID和对象二进制流的serialVersionUID不同，则会抛出异常</li><li>Java的序列化会将一个类包含的引用中所有的成员变量保存下来（深度复制），所以里面的引用类型必须也要实现java.io.Serializable接口</li><li>当某个字段被声明为transient后，默认序列化机制就会忽略该字段，反序列化后自动获得0或者null值</li><li>静态成员不参与序列化</li><li>每个类可以实现readObject、writeObject方法实现自己的序列化策略，即使是transient修饰的成员变量也可以手动调用ObjectOutputStream的writeInt等方法将这个成员变量序列化。</li><li>任何一个readObject方法，不管是显式的还是默认的，它都会返回一个新建的实例，这个新建的实例不同于该类初始化时创建的实例</li><li>每个类可以实现private Object readResolve()方法，在调用readObject方法之后，如果存在readResolve方法则自动调用该方法，readResolve将对readObject的结果进行处理，而最终readResolve的处理结果将作为readObject的结果返回。readResolve的目的是保护性恢复对象，其最重要的应用就是保护性恢复单例、枚举类型的对象</li></ul><p>所以问题的答案是：ArrayList 不想用Java序列化机制的默认处理来序列化 elementData 数组，而是通过 readObject、writeObject 方法自定义序列化和反序列化策略。</p><p>问题又来了，<strong>为什么不用Java序列化机制的默认处理来序列化 elementData 数组呢</strong>？</p><p>答案是因为效率问题，如果用默认处理来序列化的话，如果 elementData 的长度有100，但是实际只用了50，其实剩余的50是可以不用序列化的，这样可以提高序列化和反序列化的效率，节省空间。</p><p>现在来看 ArrayList 中自定义的序列化和反序列化策略</p><pre><code class="java">private static final long serialVersionUID = 8683452581122892189L;private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException{    int expectedModCount = modCount;    s.defaultWriteObject(); // 默认的序列化策略，序列化其它的字段    s.writeInt(size);   // 实际用的长度，而不是容量    for (int i=0; i&lt;size; i++) {  // 只序列化数组的前 size 个对象        s.writeObject(elementData[i]);    }    if (modCount != expectedModCount) {        throw new ConcurrentModificationException();    }}private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException {    elementData = EMPTY_ELEMENTDATA;    // Read in size, and any hidden stuff    s.defaultReadObject();    s.readInt(); // ignored    if (size &gt; 0) {        int capacity = calculateCapacity(elementData, size);        SharedSecrets.getJavaOISAccess().checkArray(s, Object[].class, capacity);        ensureCapacityInternal(size);        Object[] a = elementData;        for (int i=0; i&lt;size; i++) {            a[i] = s.readObject();        }    }}</code></pre><h4 id="9-快速失败-fail-fast"><a href="#9-快速失败-fail-fast" class="headerlink" title="9. 快速失败(fail-fast)"></a>9. 快速失败(fail-fast)</h4><p>modCount 用来记录 ArrayList 结构发生变化的次数，如果一个动作前后 modCount 的值不相等，说明 ArrayList 被其它线程修改了</p><p>如果在创建迭代器之后的任何时候以任何方式修改了列表（增加、删除、修改），除了通过迭代器自己的remove 或 add方法，迭代器将抛出 <code>ConcurrentModificationException</code> 异常</p><p>需要注意的是：这里异常的抛出条件是检测到 <code>modCount != expectedmodCount</code>，如果并发场景下一个线程修改了modCount值时另一个线程又 “及时地” 修改了expectedmodCount值，则异常不会抛出。所以不能依赖于这个异常来检测程序的正确性。</p><pre><code>private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException{    int expectedModCount = modCount;    // 记录下当前的 modCount    // 一些操作之后....    if (modCount != expectedModCount) { // 比较现在与之前的 modCount，不相等表示在中间过程中被修改了        throw new ConcurrentModificationException();    }}private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException{    int expectedModCount = modCount;    // 一些操作之后....    if (modCount != expectedModCount) {        throw new ConcurrentModificationException();    }}public void forEach(Consumer&lt;? super E&gt; action) {    final int expectedModCount = modCount;    // 一些操作之后....    if (modCount != expectedModCount) {        throw new ConcurrentModificationException();    }}public boolean removeIf(Predicate&lt;? super E&gt; filter) {    final int expectedModCount = modCount;    // 一些操作之后....    if (modCount != expectedModCount) {        throw new ConcurrentModificationException();    }}public void replaceAll(UnaryOperator&lt;E&gt; operator) {    final int expectedModCount = modCount;    // 一些操作之后....    if (modCount != expectedModCount) {        throw new ConcurrentModificationException();    }    modCount++; // 修改了要加一}public void sort(Comparator&lt;? super E&gt; c) {    final int expectedModCount = modCount;    // 一些操作之后....    if (modCount != expectedModCount) {        throw new ConcurrentModificationException();    }    modCount++;}// 内部迭代器private class Itr implements Iterator&lt;E&gt; {    public void forEachRemaining(Consumer&lt;? super E&gt; consumer) {        checkForComodification();    }    final void checkForComodification() {        if (modCount != expectedModCount)            throw new ConcurrentModificationException();    }}</code></pre><h3 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h3><p>欢迎评论、转发、分享</p><p>更多内容可访问我的个人博客：<a href="http://laijianfeng.org">http://laijianfeng.org</a></p><p>关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java编程 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Elasticsearch源码分析 | 单节点的启动和关闭</title>
      <link href="/2019/01/Elasticsearch%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%8D%95%E8%8A%82%E7%82%B9%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E5%85%B3%E9%97%AD/"/>
      <url>/2019/01/Elasticsearch%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%8D%95%E8%8A%82%E7%82%B9%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E5%85%B3%E9%97%AD/</url>
      <content type="html"><![CDATA[<p>本文主要简要介绍Elasticsearch单节点的启动和关闭流程。Elasticsearch版本：6.3.2   </p><h4 id="相关文章"><a href="#相关文章" class="headerlink" title="相关文章"></a>相关文章</h4><p>1、<a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483683&amp;idx=1&amp;sn=0d77085a0234b2c5b7c679e62200e6f5&amp;chksm=e9c2ed2edeb56438010b5f5d487bcb7f0529c85d50ac7c858e1a8e3a9279c15007341170c5ac&amp;mpshare=1&amp;scene=1&amp;srcid=0107YiaAuX3EDzO9XLEBCDHq#rd" target="_blank" rel="noopener">Google Guice 快速入门</a><br>2、<a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483691&amp;idx=1&amp;sn=3c7175d318bce6728c2105d27ae6bafe&amp;chksm=e9c2ed26deb56430289edabd15cef1a0cf777c5dfe4f4ad5013655e9d3607958e0fe16ac5436&amp;mpshare=1&amp;scene=1&amp;srcid=01079MoANk2UViY4CftnPRVo#rd" target="_blank" rel="noopener">Elasticsearch 中的 Guice</a><br>3、<a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483676&amp;idx=1&amp;sn=1d88a883ce21d7dcacd073a8fa85dbfc&amp;chksm=e9c2ed11deb56407879ba0b22a4ef96916f8a9e7931e1efb99df57991966a3dc475eb3e23101&amp;mpshare=1&amp;scene=1&amp;srcid=0107L5Z1RW5tpECUU13Ymxwg#rd" target="_blank" rel="noopener">教你编译调试Elasticsearch 6.3.2源码</a><br>4、<a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483695&amp;idx=1&amp;sn=c434b83ca67cfd1e2e0cbf416b3ee28e&amp;chksm=e9c2ed22deb56434978446cd05c8b8235783a3f28ce940b601206fb76a8025e1a69a33e1c64a&amp;mpshare=1&amp;scene=1&amp;srcid=0107LgY2cJ3bNjMZFLX58mVz#rd" target="_blank" rel="noopener">Elasticsearch 6.3.2 启动过程</a></p><h4 id="创建节点"><a href="#创建节点" class="headerlink" title="创建节点"></a>创建节点</h4><p>Elasticsearch的启动引导类为 Bootstrap 类，在创建节点 Node 对象之前，Bootstrap 会解析配置和进行一些安全检查等</p><p><img src="http://image.laijianfeng.org/20190107_223512.png" alt="创建节点对象"></p><p>environment 对象主要是解析出来的配置信息</p><p><img src="http://image.laijianfeng.org/20190107_223749.png" alt="environment 对象"></p><p>创建节点过程的主要工作是创建各个模块对象和服务对象，<strong>完成 Guice 依赖绑定</strong>，获取并初始化探测器。</p><p>ModulesBuilder 用于统一管理 Module</p><pre><code>ModulesBuilder modules = new ModulesBuilder();ClusterModule clusterModule = new ClusterModule(settings, clusterService, clusterPlugins, clusterInfoService);modules.add(clusterModule);     // 将模块加入管理//....// 实例绑定modules.add(b -&gt; {        b.bind(Node.class).toInstance(this);        b.bind(NodeService.class).toInstance(nodeService);        b.bind(NamedXContentRegistry.class).toInstance(xContentRegistry);        b.bind(PluginsService.class).toInstance(pluginsService);        b.bind(Client.class).toInstance(client);        b.bind(NodeClient.class).toInstance(client);        b.bind(Environment.class).toInstance(this.environment);        b.bind(ThreadPool.class).toInstance(threadPool);        b.bind(NodeEnvironment.class).toInstance(nodeEnvironment);        // ....    });injector = modules.createInjector();    // 生成注入器</code></pre><p>主要的服务类简介如下：</p><table><thead><tr><th>服务</th><th>简介</th></tr></thead><tbody><tr><td>ResourceWatcherService</td><td>通用资源监视服务</td></tr><tr><td>HttpServerTransport</td><td>HTTP传输服务，提供Rest接口服务</td></tr><tr><td>SnapshotsService</td><td>快照服务</td></tr><tr><td>SnapshotShardsService</td><td>负责启动和停止shard级快照</td></tr><tr><td>IndicesClusterStateService</td><td>根据收到的集群状态信息，处理相关索引</td></tr><tr><td>Discovery</td><td>集群拓扑管理</td></tr><tr><td>RoutingService</td><td>处理路由（节点之间迁移shard）</td></tr><tr><td>ClusterService</td><td>集群管理服务，主要处理集群任务，发布集群状态</td></tr><tr><td>NodeConnectionsService</td><td>节点连接管理服务</td></tr><tr><td>MonitorService</td><td>提供进程级、系统级、文件系统和JVM的监控服务</td></tr><tr><td>GatewayService</td><td>负责集群元数据持久化与恢复</td></tr><tr><td>SearchService</td><td>处理搜索请求</td></tr><tr><td>TransportService</td><td>底层传输服务</td></tr><tr><td>plugins</td><td>插件</td></tr><tr><td>IndicesService</td><td>负责创建、删除索引等索引操作</td></tr></tbody></table><h4 id="启动节点"><a href="#启动节点" class="headerlink" title="启动节点"></a>启动节点</h4><p>启动节点的主要工作是启动各个模块的服务对象，服务对象从注入器 <code>injector</code> 中取出来，然后调用它们的 <code>start</code> 方法，服务对象的 <code>start</code> 方法的工作基本是初始化内部数据、创建线程池、启动线程池等，详细的流程留到后面的文章中再介绍。</p><pre><code class="java">injector.getInstance(MappingUpdatedAction.class).setClient(client);injector.getInstance(IndicesService.class).start();injector.getInstance(IndicesClusterStateService.class).start();</code></pre><p>在启动 Discovery 和 ClusterService 之前，还会调用 validateNodeBeforeAcceptingRequests 方法来检测环境外部，外部环境主要是JVM、操作系统相关参数，将一些影响性能的配置标记为错误以引起用户的重视。</p><h4 id="环境检测"><a href="#环境检测" class="headerlink" title="环境检测"></a>环境检测</h4><p>节点的环境检测代码都封装在 BootstrapChecks 类中，BootstrapChecks 类通过责任链模式对十几个检测项进行检测，关于责任链模式可以翻看这篇文章《<a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483778&amp;idx=1&amp;sn=aa816aec86370806ab9ee4b366760bcb&amp;scene=19#wechat_redirect" target="_blank" rel="noopener">设计模式之责任链模式及典型应用</a>》</p><p>这里的责任链模式中的抽象处理者由 BootstrapCheck 接口扮演，它定义了一个处理方法 <code>check</code>，而每个检查项则是具体处理者，都有对应的一个静态类，具体的检查则在 <code>check</code> 接口中完成</p><p>以第一个检查项 “堆大小检查” 为例，从 JvmInfo 类中获取配置的堆的初始值和最大值进行比较，不相等则格式化提示信息，最后返回检查结果</p><pre><code class="java">    static class HeapSizeCheck implements BootstrapCheck {        @Override        public BootstrapCheckResult check(BootstrapContext context) {            final long initialHeapSize = getInitialHeapSize();            final long maxHeapSize = getMaxHeapSize();            if (initialHeapSize != 0 &amp;&amp; maxHeapSize != 0 &amp;&amp; initialHeapSize != maxHeapSize) {                final String message = String.format(Locale.ROOT,                        &quot;initial heap size [%d] not equal to maximum heap size [%d]; &quot; +                                &quot;this can cause resize pauses and prevents mlockall from locking the entire heap&quot;,                        getInitialHeapSize(), getMaxHeapSize());                return BootstrapCheckResult.failure(message);            } else {                return BootstrapCheckResult.success();            }        }        long getInitialHeapSize() {             return JvmInfo.jvmInfo().getConfiguredInitialHeapSize();        }        long getMaxHeapSize() {            return JvmInfo.jvmInfo().getConfiguredMaxHeapSize();        }    }</code></pre><p>把所有检查项的对象添加到一个 List 链中</p><pre><code>    static List&lt;BootstrapCheck&gt; checks() {        final List&lt;BootstrapCheck&gt; checks = new ArrayList&lt;&gt;();        checks.add(new HeapSizeCheck());        final FileDescriptorCheck fileDescriptorCheck            = Constants.MAC_OS_X ? new OsXFileDescriptorCheck() : new FileDescriptorCheck();        checks.add(fileDescriptorCheck);        checks.add(new MlockallCheck());        if (Constants.LINUX) {            checks.add(new MaxNumberOfThreadsCheck());        }        if (Constants.LINUX || Constants.MAC_OS_X) {            checks.add(new MaxSizeVirtualMemoryCheck());        }        if (Constants.LINUX || Constants.MAC_OS_X) {            checks.add(new MaxFileSizeCheck());        }        if (Constants.LINUX) {            checks.add(new MaxMapCountCheck());        }        checks.add(new ClientJvmCheck());        checks.add(new UseSerialGCCheck());        checks.add(new SystemCallFilterCheck());        checks.add(new OnErrorCheck());        checks.add(new OnOutOfMemoryErrorCheck());        checks.add(new EarlyAccessCheck());        checks.add(new G1GCCheck());        checks.add(new AllPermissionCheck());        return Collections.unmodifiableList(checks);    }</code></pre><p>for 循环分别调用 check 方法进行检查，有些检查项检查不通过是可以忽略的，如果有不能忽略的错误则会抛出异常</p><pre><code>for (final BootstrapCheck check : checks) {    final BootstrapCheck.BootstrapCheckResult result = check.check(context);    if (result.isFailure()) {        if (!(enforceLimits || enforceBootstrapChecks) &amp;&amp; !check.alwaysEnforce()) {            ignoredErrors.add(result.getMessage());        } else {            errors.add(result.getMessage());        }    }}</code></pre><p><strong>那么检查项有哪些呢？</strong></p><ul><li><code>堆大小检查</code>：如果开启了<code>bootstrap.memory_lock</code>，则JVM在启动时将锁定堆的初始大小，若配置的初始值与最大值不等，堆变化后无法保证堆都锁定在内存中</li><li><code>文件描述符检查</code>：ES进程需要非常多的文件描述符，所以须配置系统的文件描述符的最大数量 <code>ulimit -n 65535</code></li><li><code>内存锁定检查</code>：ES允许进程只使用物理内存，若使用交换分区可能会带来很多问题，所以最好让ES锁定内存</li><li><code>最大线程数检查</code>：ES进程会创建很多线程，这个数最少需2048</li><li><code>最大虚拟内存检查</code></li><li><code>最大文件大小检查</code>：段文件和事务日志文件可能会非常大，建议这个数设置为无限</li><li><code>虚拟内存区域最大数量检查</code></li><li><code>JVM Client模式检查</code></li><li><code>串行收集检查</code>：ES默认使用 CMS 垃圾回收器，而不是 Serial 收集器</li><li><code>系统调用过滤器检查</code></li><li><code>OnError与OnOutOfMemoryError检查</code></li><li><code>Early-access检查</code>：ES最好运行在JVM的稳定版本上</li><li><code>G1GC检查</code></li></ul><p>顺便一提，JvmInfo 则是<strong>利用了 JavaSDK 自带的 ManagementFactory 类来获取JVM信息</strong>的，获取的 JVM 属性如下所示</p><pre><code>long pid;   // 进程IDString version; // Java版本String vmName;  // JVM名称String vmVersion;   // JVM版本String vmVendor;    // JVM开发商long startTime;     // 启动时间long configuredInitialHeapSize; // 配置的堆的初始值long configuredMaxHeapSize;     // 配置的堆的最大值Mem mem;            // 内存信息String[] inputArguments;    // JVM启动时输入的参数String bootClassPath;String classPath;   Map&lt;String, String&gt; systemProperties;   // 系统环境变量String[] gcCollectors;String[] memoryPools;String onError;String onOutOfMemoryError;String useCompressedOops;String useG1GC;     // 是否使用 G1 垃圾回收器String useSerialGC; // 是否使用 Serial 垃圾回收器</code></pre><h4 id="keepAlive-线程"><a href="#keepAlive-线程" class="headerlink" title="keepAlive 线程"></a>keepAlive 线程</h4><p>在启动引导类 Bootstrap 的 start 方法中，启动节点之后还会启动一个 keepAlive 线程</p><pre><code>private void start() throws NodeValidationException {    node.start();    keepAliveThread.start();}// CountDownLatch 初始值为 1private final CountDownLatch keepAliveLatch = new CountDownLatch(1);Bootstrap() {    keepAliveThread = new Thread(new Runnable() {        @Override        public void run() {            try {                keepAliveLatch.await(); // 一直等待直到 CountDownLatch 减为 0            } catch (InterruptedException e) {                // bail out            }        }    }, &quot;elasticsearch[keepAlive/&quot; + Version.CURRENT + &quot;]&quot;);    keepAliveThread.setDaemon(false);   // false 用户线程    // keep this thread alive (non daemon thread) until we shutdown    Runtime.getRuntime().addShutdownHook(new Thread() {        @Override        public void run() {            // 当进程收到关闭 SIGTERM 或 SIGINT 信号时，CountDownLatch 减1             keepAliveLatch.countDown();        }    });}if (addShutdownHook) {    Runtime.getRuntime().addShutdownHook(new Thread() {        @Override        public void run() {            try {                IOUtils.close(node, spawner);                LoggerContext context = (LoggerContext) LogManager.getContext(false);                Configurator.shutdown(context);            } catch (IOException ex) {                throw new ElasticsearchException(&quot;failed to stop node&quot;, ex);            }        }    });}</code></pre><p>keepAliveThread 线程本身不做具体的工作。主线程执行完启动流程后会退出，keepAliveThread 线程是唯一的用户线程，<strong>作用是保持进程运行</strong>。在Java程序中，一个进程至少需要有一个用户线程，当用户线程为零时将退出进程。</p><p>做个试验，将 <code>keepAliveThread.setDaemon(false);</code> 中的 <code>false</code> 改为 <code>true</code>，会发现Elasticsearch启动后马上就停止了</p><pre><code>[2019-01-08T01:28:47,522][INFO ][o.e.n.Node               ] [1yGidog] started[2019-01-08T01:28:47,525][INFO ][o.e.n.Node               ] [1yGidog] stopping ...</code></pre><h4 id="关闭节点"><a href="#关闭节点" class="headerlink" title="关闭节点"></a>关闭节点</h4><p>关闭的顺序大致为：</p><ul><li>关闭快照和HTTPServer，不再响应用户REST请求</li><li>关闭集群拓扑管理，不再响应ping请求</li><li>关闭网络模块，让节点离线</li><li>执行各个插件的关闭流程</li><li>关闭IndicesService，这期间需要等待释放的资源最多，时间最长</li></ul><pre><code class="java">public static void close(final Exception ex, final Iterable&lt;? extends Closeable&gt; objects) throws IOException {    Exception firstException = ex;    for (final Closeable object : objects) {        try {            if (object != null) {                object.close();            }        } catch (final IOException | RuntimeException e) {            if (firstException == null) {                firstException = e;            } else {                firstException.addSuppressed(e);            }        }    }    // ...}private Node stop() {    if (!lifecycle.moveToStopped()) {        return this;    }    Logger logger = Loggers.getLogger(Node.class, NODE_NAME_SETTING.get(settings));    logger.info(&quot;stopping ...&quot;);    injector.getInstance(ResourceWatcherService.class).stop();    if (NetworkModule.HTTP_ENABLED.get(settings)) {        injector.getInstance(HttpServerTransport.class).stop();    }    injector.getInstance(SnapshotsService.class).stop();    injector.getInstance(SnapshotShardsService.class).stop();    // stop any changes happening as a result of cluster state changes    injector.getInstance(IndicesClusterStateService.class).stop();    // close discovery early to not react to pings anymore.    // This can confuse other nodes and delay things - mostly if we&#39;re the master and we&#39;re running tests.    injector.getInstance(Discovery.class).stop();    // we close indices first, so operations won&#39;t be allowed on it    injector.getInstance(RoutingService.class).stop();    injector.getInstance(ClusterService.class).stop();    injector.getInstance(NodeConnectionsService.class).stop();    nodeService.getMonitorService().stop();    injector.getInstance(GatewayService.class).stop();    injector.getInstance(SearchService.class).stop();    injector.getInstance(TransportService.class).stop();    pluginLifecycleComponents.forEach(LifecycleComponent::stop);    // we should stop this last since it waits for resources to get released    // if we had scroll searchers etc or recovery going on we wait for to finish.    injector.getInstance(IndicesService.class).stop();    logger.info(&quot;stopped&quot;);    return this;}</code></pre><p>节点的关闭当然没那么简单。更多细节敬请期待。</p><blockquote><p>参考：<br>张超.Elasticsearch源码解析与优化实战</p></blockquote><h3 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h3><p>欢迎评论、转发、分享，您的支持是我最大的动力</p><p>更多内容可访问我的个人博客：<a href="http://laijianfeng.org">http://laijianfeng.org</a></p><p>关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>设计模式 | 单例模式及典型应用</title>
      <link href="/2019/01/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2019/01/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>单例是最常见的设计模式之一，实现的方式非常多，同时需要注意的问题也非常多。</p><p>本文主要内容：</p><ul><li>介绍单例模式</li><li>介绍单例模式的N中写法</li><li>单例模式的安全性<ul><li>序列化攻击</li><li>反射攻击</li></ul></li><li>单例模式总结</li><li>介绍单例模式的典型应用</li></ul><h3 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h3><p><strong>单例模式(Singleton Pattern)</strong>：确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例，这个类称为单例类，它提供全局访问的方法。单例模式是一种对象创建型模式。</p><p>单例模式有三个要点：</p><ol><li>构造方法私有化；</li><li>实例化的变量引用私有化；</li><li>获取实例的方法共有</li></ol><h4 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h4><p><strong>Singleton（单例）</strong>：在单例类的内部实现只生成一个实例，同时它提供一个静态的 <code>getInstance()</code> 工厂方法，让客户可以访问它的唯一实例；为了防止在外部对其实例化，将其构造函数设计为私有；在单例类内部定义了一个 <code>Singleton</code> 类型的静态对象，作为外部共享的唯一实例。</p><h3 id="单例模式的七种写法"><a href="#单例模式的七种写法" class="headerlink" title="单例模式的七种写法"></a>单例模式的七种写法</h3><h4 id="1、饿汉式"><a href="#1、饿汉式" class="headerlink" title="1、饿汉式"></a>1、饿汉式</h4><pre><code>// 线程安全public class Singleton {    private final static Singleton INSTANCE = new Singleton();    private Singleton(){}    public static Singleton getInstance(){        return INSTANCE;    }}</code></pre><p><strong>优点</strong>：简单，使用时没有延迟；在类装载时就完成实例化，天生的线程安全</p><p><strong>缺点</strong>：没有懒加载，启动较慢；如果从始至终都没使用过这个实例，则会造成内存的浪费。</p><h4 id="2、饿汉式变种"><a href="#2、饿汉式变种" class="headerlink" title="2、饿汉式变种"></a>2、饿汉式变种</h4><pre><code>// 线程安全public class Singleton {    private static Singleton instance;    static {        instance = new Singleton();    }    private Singleton() {}    public static Singleton getInstance() {        return instance;    }}</code></pre><p>将类实例化的过程放在了静态代码块中，在类装载的时执行静态代码块中的代码，初始化类的实例。优缺点同上。</p><h4 id="3、懒汉式"><a href="#3、懒汉式" class="headerlink" title="3、懒汉式"></a>3、懒汉式</h4><pre><code>// 线程不安全public class Singleton {    private static Singleton singleton;    private Singleton() {}    public static Singleton getInstance() {        if (singleton == null) {            singleton = new Singleton();        }        return singleton;    }}</code></pre><p><strong>优点</strong>：懒加载，启动速度快、如果从始至终都没使用过这个实例，则不会初始化该实力，可节约资源</p><p><strong>缺点</strong>：多线程环境下线程不安全。<code>if (singleton == null)</code> 存在竞态条件，可能会有多个线程同时进入 <code>if 语句</code>，导致产生多个实例</p><h4 id="4、懒汉式变种"><a href="#4、懒汉式变种" class="headerlink" title="4、懒汉式变种"></a>4、懒汉式变种</h4><pre><code>// 线程安全，效率低public class Singleton {    private static Singleton singleton;    private Singleton() {}    public static synchronized Singleton getInstance() {        if (singleton == null) {            singleton = new Singleton();        }        return singleton;    }}</code></pre><p><strong>优点</strong>：解决了上一种实现方式的线程不安全问题</p><p><strong>缺点</strong>：synchronized 对整个 <code>getInstance()</code> 方法都进行了同步，每次只有一个线程能够进入该方法，并发性能极差</p><h4 id="5、双重检查锁"><a href="#5、双重检查锁" class="headerlink" title="5、双重检查锁"></a>5、双重检查锁</h4><pre><code>// 线程安全public class Singleton {    // 注意：这里有 volatile 关键字修饰    private static volatile Singleton singleton;    private Singleton() {}    public static Singleton getInstance() {        if (singleton == null) {            synchronized (Singleton.class) {                if (singleton == null) {                    singleton = new Singleton();                }            }        }        return singleton;    }}</code></pre><p><strong>优点</strong>：线程安全；延迟加载；效率较高。</p><p>由于 JVM 具有指令重排的特性，在多线程环境下可能出现  singleton 已经赋值但还没初始化的情况，导致一个线程获得还没有初始化的实例。volatile 关键字的作用：</p><ul><li>保证了不同线程对这个变量进行操作时的可见性</li><li>禁止进行指令重排序</li></ul><h4 id="6、静态内部类"><a href="#6、静态内部类" class="headerlink" title="6、静态内部类"></a>6、静态内部类</h4><pre><code>// 线程安全public class Singleton {    private Singleton() {}    private static class SingletonInstance {        private static final Singleton INSTANCE = new Singleton();    }    public static Singleton getInstance() {        return SingletonInstance.INSTANCE;    }}</code></pre><p><strong>优点</strong>：避免了线程不安全，延迟加载，效率高。</p><p>静态内部类的方式利用了类装载机制来保证线程安全，只有在第一次调用getInstance方法时，才会装载SingletonInstance内部类，完成Singleton的实例化，所以也有懒加载的效果。</p><p><strong>加入参数 <code>-verbose:class</code> 可以查看类加载顺序</strong></p><pre><code>$ javac Singleton.java$ java -verbose:class Singleton</code></pre><h4 id="7、枚举"><a href="#7、枚举" class="headerlink" title="7、枚举"></a>7、枚举</h4><pre><code>// 线程安全public enum Singleton {    INSTANCE;    public void whateverMethod() {    }}</code></pre><p><strong>优点</strong>：通过JDK1.5中添加的枚举来实现单例模式，<strong>写法简单</strong>，且不仅能<strong>避免多线程同步问题</strong>，而且还能<strong>防止反序列化重新创建新的对象</strong>。</p><h3 id="单例模式的安全性"><a href="#单例模式的安全性" class="headerlink" title="单例模式的安全性"></a>单例模式的安全性</h3><p>单例模式的目标是，任何时候该类都只有唯一的一个对象。但是上面我们写的大部分单例模式都存在漏洞，被攻击时会产生多个对象，破坏了单例模式。</p><h4 id="序列化攻击"><a href="#序列化攻击" class="headerlink" title="序列化攻击"></a>序列化攻击</h4><p>通过Java的序列化机制来攻击单例模式</p><pre><code>public class HungrySingleton {    private static final HungrySingleton instance = new HungrySingleton();    private HungrySingleton() {    }    public static HungrySingleton getInstance() {        return instance;    }    public static void main(String[] args) throws IOException, ClassNotFoundException {        HungrySingleton singleton = HungrySingleton.getInstance();        ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(&quot;singleton_file&quot;));        oos.writeObject(singleton); // 序列化        ObjectInputStream ois = new ObjectInputStream(new FileInputStream(&quot;singleton_file&quot;));        HungrySingleton newSingleton = (HungrySingleton) ois.readObject(); // 反序列化        System.out.println(singleton);        System.out.println(newSingleton);        System.out.println(singleton == newSingleton);    }}</code></pre><p>结果</p><pre><code>com.singleton.HungrySingleton@ed17beecom.singleton.HungrySingleton@46f5f779false</code></pre><p>Java 序列化是如何攻击单例模式的呢？我们需要先复习一下Java的序列化机制</p><h5 id="Java-序列化机制"><a href="#Java-序列化机制" class="headerlink" title="Java 序列化机制"></a>Java 序列化机制</h5><p><code>java.io.ObjectOutputStream</code> 是Java实现序列化的关键类，它可以将一个对象转换成二进制流，然后可以通过 <code>ObjectInputStream</code> 将二进制流还原成对象。具体的序列化过程不是本文的重点，在此仅列出几个要点。</p><p><strong>Java 序列化机制的要点</strong>：</p><ul><li>需要序列化的类必须实现<code>java.io.Serializable</code>接口，否则会抛出<code>NotSerializableException</code>异常 </li><li>若没有显示地声明一个<code>serialVersionUID</code>变量，Java序列化机制会根据编译时的class自动生成一个<code>serialVersionUID</code>作为序列化版本比较（验证一致性），如果检测到反序列化后的类的<code>serialVersionUID</code>和对象二进制流的<code>serialVersionUID</code>不同，则会抛出异常</li><li>Java的序列化会将一个类包含的引用中所有的成员变量保存下来（深度复制），所以里面的引用类型必须也要实现<code>java.io.Serializable</code>接口</li><li>当某个字段被声明为<code>transient</code>后，默认序列化机制就会忽略该字段，反序列化后自动获得0或者null值</li><li>静态成员不参与序列化</li><li>每个类可以实现<code>readObject</code>、<code>writeObject</code>方法实现自己的序列化策略，即使是<code>transient</code>修饰的成员变量也可以手动调用<code>ObjectOutputStream</code>的<code>writeInt</code>等方法将这个成员变量序列化。</li><li>任何一个readObject方法，不管是显式的还是默认的，它都会返回一个新建的实例，这个新建的实例不同于该类初始化时创建的实例</li><li>每个类可以实现<code>private Object readResolve()</code>方法，在调用<code>readObject</code>方法之后，如果存在<code>readResolve</code>方法则自动调用该方法，<code>readResolve</code>将对<code>readObject</code>的结果进行处理，而最终<code>readResolve</code>的处理结果将作为<code>readObject</code>的结果返回。<code>readResolve</code>的目的是保护性恢复对象，其最重要的应用就是保护性恢复单例、枚举类型的对象</li><li><code>Serializable</code>接口是一个标记接口，可自动实现序列化，而<code>Externalizable</code>继承自<code>Serializable</code>，它强制必须手动实现序列化和反序列化算法，相对来说更加高效</li></ul><h5 id="序列化破坏单例模式的解决方案"><a href="#序列化破坏单例模式的解决方案" class="headerlink" title="序列化破坏单例模式的解决方案"></a>序列化破坏单例模式的解决方案</h5><p>根据上面对Java序列化机制的复习，我们可以自定义一个 <code>readResolve</code>，在其中返回类的单例对象，替换掉 <code>readObject</code> 方法反序列化生成的对象，让我们自己写的单例模式实现保护性恢复对象</p><pre><code>public class HungrySingleton implements Serializable {    private static final HungrySingleton instance = new HungrySingleton();    private HungrySingleton() {    }    public static HungrySingleton getInstance() {        return instance;    }    private Object readResolve() {        return instance;    }    public static void main(String[] args) throws IOException, ClassNotFoundException {        HungrySingleton singleton = HungrySingleton.getInstance();        ObjectInputStream ois = new ObjectInputStream(new FileInputStream(&quot;singleton_file&quot;));        HungrySingleton newSingleton = (HungrySingleton) ois.readObject();        System.out.println(singleton);        System.out.println(newSingleton);        System.out.println(singleton == newSingleton);    }}</code></pre><p>再次运行</p><pre><code>com.singleton.HungrySingleton@24273305com.singleton.HungrySingleton@24273305true</code></pre><p>注意：自己实现的单例模式都需要避免被序列化破坏</p><h4 id="反射攻击"><a href="#反射攻击" class="headerlink" title="反射攻击"></a>反射攻击</h4><p>在单例模式中，构造器都是私有的，而反射可以通过构造器对象调用 <code>setAccessible(true)</code> 来获得权限，这样就可以创建多个对象，来破坏单例模式了</p><pre><code>public class HungrySingleton {    private static final HungrySingleton instance = new HungrySingleton();    private HungrySingleton() {    }    public static HungrySingleton getInstance() {        return instance;    }    public static void main(String[] args) throws NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException {        HungrySingleton instance = HungrySingleton.getInstance();        Constructor constructor = HungrySingleton.class.getDeclaredConstructor();        constructor.setAccessible(true);    // 获得权限        HungrySingleton newInstance = (HungrySingleton) constructor.newInstance();        System.out.println(instance);        System.out.println(newInstance);        System.out.println(instance == newInstance);    }}</code></pre><p>输出结果</p><pre><code>com.singleton.HungrySingleton@3b192d32com.singleton.HungrySingleton@16f65612false</code></pre><h5 id="反射攻击解决方案"><a href="#反射攻击解决方案" class="headerlink" title="反射攻击解决方案"></a>反射攻击解决方案</h5><p>反射是通过它的Class对象来调用构造器创建新的对象，我们只需要在构造器中检测并抛出异常就可以达到目的了</p><pre><code>private HungrySingleton() {    // instance 不为空，说明单例对象已经存在    if (instance != null) {        throw new RuntimeException(&quot;单例模式禁止反射调用！&quot;);    }}</code></pre><p>运行结果</p><pre><code>Exception in thread &quot;main&quot; java.lang.reflect.InvocationTargetException    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)    at com.singleton.HungrySingleton.main(HungrySingleton.java:32)Caused by: java.lang.RuntimeException: 单例模式禁止反射调用！    at com.singleton.HungrySingleton.&lt;init&gt;(HungrySingleton.java:20)    ... 5 more</code></pre><p><strong>注意</strong>，上述方法针对饿汉式单例模式是有效的，但<strong>对懒汉式的单例模式是无效的，懒汉式的单例模式是无法避免反射攻击的！</strong></p><p>为什么对饿汉有效，对懒汉无效？因为饿汉的初始化是在类加载的时候，反射一定是在饿汉初始化之后才能使用；而懒汉是在第一次调用 <code>getInstance()</code> 方法的时候才初始化，我们无法控制反射和懒汉初始化的先后顺序，如果反射在前，不管反射创建了多少对象，instance都将一直为null，直到调用 <code>getInstance()</code>。</p><p><strong>事实上，实现单例模式的唯一推荐方法，是使用枚举类来实现。</strong></p><h4 id="为什么推荐使用枚举单例"><a href="#为什么推荐使用枚举单例" class="headerlink" title="为什么推荐使用枚举单例"></a>为什么推荐使用枚举单例</h4><p>写下我们的枚举单例模式</p><pre><code>package com.singleton;import java.io.*;import java.lang.reflect.Constructor;import java.lang.reflect.InvocationTargetException;public enum SerEnumSingleton implements Serializable {    INSTANCE;   // 单例对象    private String content;    public String getContent() {        return content;    }    public void setContent(String content) {        this.content = content;    }    private SerEnumSingleton() {    }    public static void main(String[] args) throws IOException, ClassNotFoundException, NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException {        SerEnumSingleton singleton1 = SerEnumSingleton.INSTANCE;        singleton1.setContent(&quot;枚举单例序列化&quot;);        System.out.println(&quot;枚举序列化前读取其中的内容：&quot; + singleton1.getContent());        ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(&quot;SerEnumSingleton.obj&quot;));        oos.writeObject(singleton1);        oos.flush();        oos.close();        FileInputStream fis = new FileInputStream(&quot;SerEnumSingleton.obj&quot;);        ObjectInputStream ois = new ObjectInputStream(fis);        SerEnumSingleton singleton2 = (SerEnumSingleton) ois.readObject();        ois.close();        System.out.println(singleton1 + &quot;\n&quot; + singleton2);        System.out.println(&quot;枚举序列化后读取其中的内容：&quot; + singleton2.getContent());        System.out.println(&quot;枚举序列化前后两个是否同一个：&quot; + (singleton1 == singleton2));        Constructor&lt;SerEnumSingleton&gt; constructor = SerEnumSingleton.class.getDeclaredConstructor();        constructor.setAccessible(true);        SerEnumSingleton singleton3 = constructor.newInstance(); // 通过反射创建对象        System.out.println(&quot;反射后读取其中的内容：&quot; + singleton3.getContent());        System.out.println(&quot;反射前后两个是否同一个：&quot; + (singleton1 == singleton3));    }}</code></pre><p>运行结果，序列化前后的对象是同一个对象，而反射的时候抛出了异常</p><pre><code>枚举序列化前读取其中的内容：枚举单例序列化INSTANCEINSTANCE枚举序列化后读取其中的内容：枚举单例序列化枚举序列化前后两个是否同一个：trueException in thread &quot;main&quot; java.lang.NoSuchMethodException: com.singleton.SerEnumSingleton.&lt;init&gt;()    at java.lang.Class.getConstructor0(Class.java:3082)    at java.lang.Class.getDeclaredConstructor(Class.java:2178)    at com.singleton.SerEnumSingleton.main(SerEnumSingleton.java:39)</code></pre><p>编译后，再通过 JAD 进行反编译得到下面的代码</p><pre><code>// Decompiled by Jad v1.5.8g. Copyright 2001 Pavel Kouznetsov.// Jad home page: http://www.kpdus.com/jad.html// Decompiler options: packimports(3) // Source File Name:   SerEnumSingleton.javapackage com.singleton;import java.io.*;import java.lang.reflect.Constructor;import java.lang.reflect.InvocationTargetException;public final class SerEnumSingleton extends Enum    implements Serializable{    public static SerEnumSingleton[] values()    {        return (SerEnumSingleton[])$VALUES.clone();    }    public static SerEnumSingleton valueOf(String name)    {        return (SerEnumSingleton)Enum.valueOf(com/singleton/SerEnumSingleton, name);    }    public String getContent()    {        return content;    }    public void setContent(String content)    {        this.content = content;    }    private SerEnumSingleton(String s, int i)    {        super(s, i);    }    public static void main(String args[])        throws IOException, ClassNotFoundException, NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException    {        SerEnumSingleton singleton1 = INSTANCE;        singleton1.setContent(&quot;\u679A\u4E3E\u5355\u4F8B\u5E8F\u5217\u5316&quot;);        System.out.println((new StringBuilder()).append(&quot;\u679A\u4E3E\u5E8F\u5217\u5316\u524D\u8BFB\u53D6\u5176\u4E2D\u7684\u5185\u5BB9\uFF1A&quot;).append(singleton1.getContent()).toString());        ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(&quot;SerEnumSingleton.obj&quot;));        oos.writeObject(singleton1);        oos.flush();        oos.close();        FileInputStream fis = new FileInputStream(&quot;SerEnumSingleton.obj&quot;);        ObjectInputStream ois = new ObjectInputStream(fis);        SerEnumSingleton singleton2 = (SerEnumSingleton)ois.readObject();        ois.close();        System.out.println((new StringBuilder()).append(singleton1).append(&quot;\n&quot;).append(singleton2).toString());        System.out.println((new StringBuilder()).append(&quot;\u679A\u4E3E\u5E8F\u5217\u5316\u540E\u8BFB\u53D6\u5176\u4E2D\u7684\u5185\u5BB9\uFF1A&quot;).append(singleton2.getContent()).toString());        System.out.println((new StringBuilder()).append(&quot;\u679A\u4E3E\u5E8F\u5217\u5316\u524D\u540E\u4E24\u4E2A\u662F\u5426\u540C\u4E00\u4E2A\uFF1A&quot;).append(singleton1 == singleton2).toString());        Constructor constructor = com/singleton/SerEnumSingleton.getDeclaredConstructor(new Class[0]);        constructor.setAccessible(true);        SerEnumSingleton singleton3 = (SerEnumSingleton)constructor.newInstance(new Object[0]);        System.out.println((new StringBuilder()).append(&quot;\u53CD\u5C04\u540E\u8BFB\u53D6\u5176\u4E2D\u7684\u5185\u5BB9\uFF1A&quot;).append(singleton3.getContent()).toString());        System.out.println((new StringBuilder()).append(&quot;\u53CD\u5C04\u524D\u540E\u4E24\u4E2A\u662F\u5426\u540C\u4E00\u4E2A\uFF1A&quot;).append(singleton1 == singleton3).toString());    }    public static final SerEnumSingleton INSTANCE;    private String content;    private static final SerEnumSingleton $VALUES[];    static     {        INSTANCE = new SerEnumSingleton(&quot;INSTANCE&quot;, 0);        $VALUES = (new SerEnumSingleton[] {            INSTANCE        });    }}</code></pre><p>通过反编译后代码我们可以看到，<code>ublic final class T extends Enum</code>，说明，当我们使用enmu来定义一个枚举类型的时候，编译器会自动帮我们创建一个final类型的类继承Enum类，所以枚举类型不能被继承。</p><h5 id="那么，为什么推荐使用枚举单例呢？"><a href="#那么，为什么推荐使用枚举单例呢？" class="headerlink" title="那么，为什么推荐使用枚举单例呢？"></a>那么，为什么推荐使用枚举单例呢？</h5><p><strong>1. 枚举单例写法简单</strong></p><p><strong>2. 线程安全&amp;懒加载</strong></p><p>代码中 INSTANCE 变量被 <code>public static final</code> 修饰，因为static类型的属性是在类加载之后初始化的，JVM可以保证线程安全；且Java类是在引用到的时候才进行类加载，所以枚举单例也有懒加载的效果。</p><p><strong>3. 枚举自己能避免序列化攻击</strong></p><p>为了保证枚举类型像Java规范中所说的那样，每一个枚举类型极其定义的枚举变量在JVM中都是唯一的，在枚举类型的序列化和反序列化上，Java做了特殊的规定。</p><p>在序列化的时候Java<strong>仅仅是将枚举对象的name属性输出到结果中</strong>，反序列化的时候则是通过java.lang.Enum的valueOf方法来<strong>根据名字查找枚举对象</strong>。同时，<strong>编译器是不允许任何对这种序列化机制的定制</strong>，因此禁用了writeObject、readObject、readObjectNoData、writeReplace和readResolve等方法。 我们看一下Enum类的valueOf方法：</p><pre><code>    public static &lt;T extends Enum&lt;T&gt;&gt; T valueOf(Class&lt;T&gt; enumType, String name) {        T result = enumType.enumConstantDirectory().get(name);        if (result != null)            return result;        if (name == null)            throw new NullPointerException(&quot;Name is null&quot;);        throw new IllegalArgumentException(            &quot;No enum constant &quot; + enumType.getCanonicalName() + &quot;.&quot; + name);    }</code></pre><p>从代码中可以看到，代码会尝试从调用enumType这个Class对象的<code>enumConstantDirectory()</code>方法返回的map中获取名字为name的枚举对象，如果不存在就会抛出异常。再进一步跟到<code>enumConstantDirectory()</code>方法，就会发现到最后会以反射的方式调用enumType这个类型的values()静态方法，也就是上面我们看到的编译器为我们创建的那个方法，然后用返回结果填充enumType这个Class对象中的<code>enumConstantDirectory</code>属性。所以，JVM对序列化有保证。</p><p><strong>4. 枚举能够避免反射攻击，因为反射不支持创建枚举对象</strong></p><p><code>Constructor</code>类的 <code>newInstance</code>方法中会判断是否为 enum，若是会抛出异常</p><pre><code>    @CallerSensitive    public T newInstance(Object ... initargs) throws InstantiationException, IllegalAccessException, IllegalArgumentException, InvocationTargetException {        if (!override) {            if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) {                Class&lt;?&gt; caller = Reflection.getCallerClass();                checkAccess(caller, clazz, null, modifiers);            }        }        // 不能为 ENUM，否则抛出异常：不能通过反射创建 enum 对象        if ((clazz.getModifiers() &amp; Modifier.ENUM) != 0)            throw new IllegalArgumentException(&quot;Cannot reflectively create enum objects&quot;);        ConstructorAccessor ca = constructorAccessor;   // read volatile        if (ca == null) {            ca = acquireConstructorAccessor();        }        @SuppressWarnings(&quot;unchecked&quot;)        T inst = (T) ca.newInstance(initargs);        return inst;    }</code></pre><h3 id="单例模式总结"><a href="#单例模式总结" class="headerlink" title="单例模式总结"></a>单例模式总结</h3><p>单例模式作为一种目标明确、结构简单、理解容易的设计模式，在软件开发中使用频率相当高，在很多应用软件和框架中都得以广泛应用。</p><h4 id="单例模式的主要优点"><a href="#单例模式的主要优点" class="headerlink" title="单例模式的主要优点"></a>单例模式的主要优点</h4><ul><li>单例模式提供了对唯一实例的受控访问。</li><li>由于在系统内存中只存在一个对象，因此可以节约系统资源，对于一些需要频繁创建和销毁的对象，单例模式可以提高系统的性能。</li><li>允许可变数目的实例。基于单例模式我们可以进行扩展，使用与单例控制相似的方法来获得指定个数的对象实例，既节省系统资源，又解决了单例单例对象共享过多有损性能的问题。</li></ul><h4 id="单例模式的主要缺点"><a href="#单例模式的主要缺点" class="headerlink" title="单例模式的主要缺点"></a>单例模式的主要缺点</h4><ul><li>由于单例模式中没有抽象层，因此单例类的扩展有很大的困难。</li><li>单例类的职责过重，在一定程度上违背了 “单一职责原则”。</li><li>如果实例化的共享对象长时间不被利用，系统可能会认为它是垃圾，会自动销毁并回收资源，下次利用时又将重新实例化，这将导致共享的单例对象状态的丢失。</li></ul><h4 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h4><ul><li>系统只需要一个实例对象，如系统要求提供一个唯一的序列号生成器或资源管理器，或者需要考虑资源消耗太大而只允许创建一个对象。</li><li>客户调用类的单个实例只允许使用一个公共访问点，除了该公共访问点，不能通过其他途径访问该实例。</li></ul><h3 id="单例模式的典型应用"><a href="#单例模式的典型应用" class="headerlink" title="单例模式的典型应用"></a>单例模式的典型应用</h3><h4 id="JDK-Runtime-饿汉单例"><a href="#JDK-Runtime-饿汉单例" class="headerlink" title="JDK Runtime 饿汉单例"></a>JDK Runtime 饿汉单例</h4><p>JDK Runtime类代表着Java程序的运行时环境，每个Java程序都有一个Runtime实例，该类会被自动创建，我们可以通过 Runtime.getRuntime() 方法来获取当前程序的Runtime实例。一旦得到了一个当前的Runtime对象的引用，就可以调用Runtime对象的方法去控制Java虚拟机的状态和行为。</p><p>Runtime 应用了饿汉式单例模式</p><pre><code>public class Runtime {    private static Runtime currentRuntime = new Runtime();    public static Runtime getRuntime() {        return currentRuntime;    }    private Runtime() {    }    //....}</code></pre><p>API 介绍</p><pre><code>addShutdownHook(Thread hook) 注册新的虚拟机来关闭挂钩。 availableProcessors() 向 Java 虚拟机返回可用处理器的数目。 exec(String command) 在单独的进程中执行指定的字符串命令。 exec(String[] cmdarray) 在单独的进程中执行指定命令和变量。 exec(String[] cmdarray, String[] envp) 在指定环境的独立进程中执行指定命令和变量。 exec(String[] cmdarray, String[] envp, File dir) 在指定环境和工作目录的独立进程中执行指定的命令和变量。 exec(String command, String[] envp) 在指定环境的单独进程中执行指定的字符串命令。 exec(String command, String[] envp, File dir) 在有指定环境和工作目录的独立进程中执行指定的字符串命令。 exit(int status) 通过启动虚拟机的关闭序列，终止当前正在运行的 Java 虚拟机。 freeMemory() 返回 Java 虚拟机中的空闲内存量。 gc() 运行垃圾回收器。  getRuntime() 返回与当前 Java 应用程序相关的运行时对象。 halt(int status) 强行终止目前正在运行的 Java 虚拟机。 load(String filename) 加载作为动态库的指定文件名。 loadLibrary(String libname) 加载具有指定库名的动态库。 maxMemory() 返回 Java 虚拟机试图使用的最大内存量。 removeShutdownHook(Thread hook) 取消注册某个先前已注册的虚拟机关闭挂钩。 runFinalization() 运行挂起 finalization 的所有对象的终止方法。 totalMemory() 返回 Java 虚拟机中的内存总量。 traceInstructions(on) 启用／禁用指令跟踪。 traceMethodCalls(on) 启用／禁用方法调用跟踪。</code></pre><h4 id="AWT-Desktop-容器单例"><a href="#AWT-Desktop-容器单例" class="headerlink" title="AWT Desktop 容器单例"></a>AWT Desktop 容器单例</h4><p>Desktop 类允许 Java 应用程序启动已在本机桌面上注册的关联应用程序，以处理 URI 或文件。支持的操作包括:</p><ul><li>打开浏览器: 启动用户默认浏览器来显示指定的 URI；</li><li>打开邮件客户端: 启动带有可选 mailto URI 的用户默认邮件客户端；</li><li>打开文件/文件夹: 启动已注册的应用程序，以打开、编辑 或 打印 指定的文件。</li></ul><p>Desktop 通过一个容器来管理单例对象</p><pre><code>public class Desktop {    // synchronized 同步方法    public static synchronized Desktop getDesktop(){        if (GraphicsEnvironment.isHeadless()) throw new HeadlessException();        if (!Desktop.isDesktopSupported()) {            throw new UnsupportedOperationException(&quot;Desktop API is not &quot; + &quot;supported on the current platform&quot;);        }        sun.awt.AppContext context = sun.awt.AppContext.getAppContext();        Desktop desktop = (Desktop)context.get(Desktop.class); // 获取单例对象        // 存在则返回，不存在则创建，创建后put进容器        if (desktop == null) {            desktop = new Desktop();             context.put(Desktop.class, desktop);        }        return desktop;    }</code></pre><p>AppContext 中有一个 HashMap 对象table，是实际的容器对象</p><pre><code>private final Map&lt;Object, Object&gt; table = new HashMap();</code></pre><h4 id="spring-AbstractFactoryBean"><a href="#spring-AbstractFactoryBean" class="headerlink" title="spring AbstractFactoryBean"></a>spring AbstractFactoryBean</h4><p>AbstractFactoryBean 类</p><pre><code>public final T getObject() throws Exception {    if (this.isSingleton()) {        return this.initialized ? this.singletonInstance : this.getEarlySingletonInstance();    } else {        return this.createInstance();    }}private T getEarlySingletonInstance() throws Exception {    Class&lt;?&gt;[] ifcs = this.getEarlySingletonInterfaces();    if (ifcs == null) {        throw new FactoryBeanNotInitializedException(this.getClass().getName() + &quot; does not support circular references&quot;);    } else {        if (this.earlySingletonInstance == null) {            // 通过代理创建对象            this.earlySingletonInstance = Proxy.newProxyInstance(this.beanClassLoader, ifcs, new AbstractFactoryBean.EarlySingletonInvocationHandler());        }        return this.earlySingletonInstance;    }}</code></pre><h4 id="Mybatis-ErrorContext-ThreadLocal"><a href="#Mybatis-ErrorContext-ThreadLocal" class="headerlink" title="Mybatis ErrorContext ThreadLocal"></a>Mybatis ErrorContext ThreadLocal</h4><p>ErrorContext 类，通过 ThreadLocal 管理单例对象，一个线程一个ErrorContext对象，ThreadLocal可以保证线程安全</p><pre><code>public class ErrorContext {    private static final ThreadLocal&lt;ErrorContext&gt; LOCAL = new ThreadLocal&lt;ErrorContext&gt;();    private ErrorContext() {    }    public static ErrorContext instance() {        ErrorContext context = LOCAL.get();        if (context == null) {          context = new ErrorContext();          LOCAL.set(context);        }        return context;    }    //...}</code></pre><blockquote><p>参考：<br><a href="http://www.hollischuang.com/archives/197" target="_blank" rel="noopener">http://www.hollischuang.com/archives/197</a><br><a href="https://www.cnblogs.com/chiclee/p/9097772.html" target="_blank" rel="noopener">https://www.cnblogs.com/chiclee/p/9097772.html</a><br><a href="https://blog.csdn.net/abc123lzf/article/details/82318148" target="_blank" rel="noopener">https://blog.csdn.net/abc123lzf/article/details/82318148</a></p></blockquote><h3 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h3><p>欢迎评论、转发、分享，您的支持是我最大的动力</p><p>更多内容可访问我的个人博客：<a href="http://laijianfeng.org">http://laijianfeng.org</a></p><p>关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java 动态代理详解</title>
      <link href="/2018/12/Java-%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E8%AF%A6%E8%A7%A3/"/>
      <url>/2018/12/Java-%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E8%AF%A6%E8%A7%A3/</url>
      <content type="html"><![CDATA[<p>动态代理在Java中有着广泛的应用，比如Spring AOP、Hibernate数据查询、测试框架的后端mock、RPC远程调用、Java注解对象获取、日志、用户鉴权、全局性异常处理、性能监控，甚至事务处理等。</p><p>本文主要介绍Java中两种常见的动态代理方式：JDK原生动态代理和CGLIB动态代理。</p><p>由于Java动态代理与java反射机制关系紧密，请读者确保已经了解了Java反射机制，可参考上一篇文章《<a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483785&amp;idx=1&amp;sn=f696c8c49cb7ecce9818247683482a1c&amp;chksm=e9c2ed84deb564925172b2dd78d307d4dc345fa313d3e44f01e84fa22ac5561b37aec5cbd5b4&amp;scene=0#rd" target="_blank" rel="noopener">Java反射机制详解</a>》</p><h3 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h3><p>本文将介绍的Java动态代理与设计模式中的代理模式有关，什么是代理模式呢？</p><p><strong>代理模式</strong>：给某一个对象提供一个代理，并由代理对象来控制对真实对象的访问。代理模式是一种结构型设计模式。</p><p>代理模式角色分为 3 种：</p><p><strong>Subject（抽象主题角色）</strong>：定义代理类和真实主题的公共对外方法，也是代理类代理真实主题的方法；</p><p><strong>RealSubject（真实主题角色</strong>）：真正实现业务逻辑的类；</p><p><strong>Proxy（代理主题角色）</strong>：用来代理和封装真实主题；</p><p>代理模式的结构比较简单，其核心是代理类，为了让客户端能够<strong>一致性地对待</strong>真实对象和代理对象，在代理模式中引入了抽象层</p><p><img src="http://image.laijianfeng.org/2018_12_20_proxyUML.jpg" alt="代理模式类图"></p><p>代理模式<strong>按照职责</strong>（使用场景）来分类，至少可以分为以下几类：1、远程代理。 2、虚拟代理。 3、Copy-on-Write 代理。 4、保护（Protect or Access）代理。 5、Cache代理。 6、防火墙（Firewall）代理。 7、同步化（Synchronization）代理。 8、智能引用（Smart Reference）代理等等。</p><p>如果<strong>根据字节码的创建时机</strong>来分类，可以分为静态代理和动态代理：</p><ul><li>所谓<strong>静态</strong>也就是在<strong>程序运行前</strong>就已经存在代理类的<strong>字节码文件</strong>，代理类和真实主题角色的关系在运行前就确定了。</li><li>而动态代理的源码是在程序运行期间由<strong>JVM</strong>根据反射等机制<strong>动态的生成</strong>，所以在运行前并不存在代理类的字节码文件</li></ul><h3 id="静态代理"><a href="#静态代理" class="headerlink" title="静态代理"></a>静态代理</h3><p>我们先通过实例来学习静态代理，然后理解静态代理的缺点，再来学习本文的主角：动态代理</p><p>编写一个接口 UserService ，以及该接口的一个实现类 UserServiceImpl</p><pre><code class="java">public interface UserService {    public void select();       public void update();}public class UserServiceImpl implements UserService {      public void select() {          System.out.println(&quot;查询 selectById&quot;);    }    public void update() {        System.out.println(&quot;更新 update&quot;);    }}</code></pre><p>我们将通过静态代理对 UserServiceImpl 进行功能增强，在调用 <code>select</code> 和 <code>update</code> 之前记录一些日志。写一个代理类 UserServiceProxy，代理类需要实现 UserService</p><pre><code class="java">public class UserServiceProxy implements UserService {    private UserService target; // 被代理的对象    public UserServiceProxy(UserService target) {        this.target = target;    }    public void select() {        before();        target.select();    // 这里才实际调用真实主题角色的方法        after();    }    public void update() {        before();        target.update();    // 这里才实际调用真实主题角色的方法        after();    }    private void before() {     // 在执行方法之前执行        System.out.println(String.format(&quot;log start time [%s] &quot;, new Date()));    }    private void after() {      // 在执行方法之后执行        System.out.println(String.format(&quot;log end time [%s] &quot;, new Date()));    }}</code></pre><p>客户端测试</p><pre><code class="java">public class Client1 {    public static void main(String[] args) {        UserService userServiceImpl = new UserServiceImpl();        UserService proxy = new UserServiceProxy(userServiceImpl);        proxy.select();        proxy.update();    }}</code></pre><p>输出</p><pre><code>log start time [Thu Dec 20 14:13:25 CST 2018] 查询 selectByIdlog end time [Thu Dec 20 14:13:25 CST 2018] log start time [Thu Dec 20 14:13:25 CST 2018] 更新 updatelog end time [Thu Dec 20 14:13:25 CST 2018] </code></pre><p>通过静态代理，我们达到了功能增强的目的，而且没有侵入原代码，这是静态代理的一个优点。</p><h4 id="静态代理的缺点"><a href="#静态代理的缺点" class="headerlink" title="静态代理的缺点"></a>静态代理的缺点</h4><p>虽然静态代理实现简单，且不侵入原代码，但是，当场景稍微复杂一些的时候，静态代理的缺点也会暴露出来。</p><p>1、 当需要代理多个类的时候，由于代理对象要实现与目标对象一致的接口，有两种方式：</p><ul><li>只维护一个代理类，由这个代理类实现多个接口，但是这样就导致<strong>代理类过于庞大</strong></li><li>新建多个代理类，每个目标对象对应一个代理类，但是这样会<strong>产生过多的代理类</strong></li></ul><p>2、 当接口需要增加、删除、修改方法的时候，目标对象与代理类都要同时修改，<strong>不易维护</strong>。</p><h4 id="如何改进？"><a href="#如何改进？" class="headerlink" title="如何改进？"></a>如何改进？</h4><p>当然是让代理类<strong>动态的生成</strong>啦，也就是动态代理。</p><p><strong>为什么类可以动态的生成？</strong></p><p>这就涉及到Java虚拟机的<strong>类加载机制</strong>了，推荐翻看《深入理解Java虚拟机》7.3节 类加载的过程。</p><p>Java虚拟机类加载过程主要分为五个阶段：加载、验证、准备、解析、初始化。其中加载阶段需要完成以下3件事情：</p><ol><li>通过一个类的全限定名来获取定义此类的二进制字节流</li><li>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构</li><li>在内存中生成一个代表这个类的 <code>java.lang.Class</code> 对象，作为方法区这个类的各种数据访问入口</li></ol><p>由于虚拟机规范对这3点要求并不具体，所以实际的实现是非常灵活的，关于第1点，<strong>获取类的二进制字节流</strong>（class字节码）就有很多途径：</p><ul><li>从ZIP包获取，这是JAR、EAR、WAR等格式的基础</li><li>从网络中获取，典型的应用是 Applet</li><li><strong>运行时计算生成</strong>，这种场景使用最多的是动态代理技术，在 java.lang.reflect.Proxy 类中，就是用了 ProxyGenerator.generateProxyClass 来为特定接口生成形式为 <code>*$Proxy</code> 的代理类的二进制字节流</li><li>由其它文件生成，典型应用是JSP，即由JSP文件生成对应的Class类</li><li>从数据库中获取等等</li></ul><p>所以，动态代理就是想办法，根据接口或目标对象，计算出代理类的字节码，然后再加载到JVM中使用。但是如何计算？如何生成？情况也许比想象的复杂得多，我们需要借助现有的方案。</p><h4 id="常见的字节码操作类库"><a href="#常见的字节码操作类库" class="headerlink" title="常见的字节码操作类库"></a>常见的字节码操作类库</h4><blockquote><p>这里有一些介绍：<a href="https://java-source.net/open-source/bytecode-libraries" target="_blank" rel="noopener">https://java-source.net/open-source/bytecode-libraries</a></p></blockquote><ul><li>Apache BCEL (Byte Code Engineering Library)：是Java classworking广泛使用的一种框架，它可以深入到JVM汇编语言进行类操作的细节。</li><li>ObjectWeb ASM：是一个Java字节码操作框架。它可以用于直接以二进制形式动态生成stub根类或其他代理类，或者在加载时动态修改类。</li><li>CGLIB(Code Generation Library)：是一个功能强大，高性能和高质量的代码生成库，用于扩展JAVA类并在运行时实现接口。</li><li>Javassist：是Java的加载时反射系统，它是一个用于在Java中编辑字节码的类库; 它使Java程序能够在运行时定义新类，并在JVM加载之前修改类文件。</li><li>…</li></ul><h4 id="实现动态代理的思考方向"><a href="#实现动态代理的思考方向" class="headerlink" title="实现动态代理的思考方向"></a>实现动态代理的思考方向</h4><p>为了让生成的代理类与目标对象（真实主题角色）保持一致性，从现在开始将介绍以下两种最常见的方式：</p><ol><li>通过实现接口的方式 -&gt; JDK动态代理</li><li>通过继承类的方式 -&gt; CGLIB动态代理</li></ol><p>注：使用ASM对使用者要求比较高，使用Javassist会比较麻烦</p><h3 id="JDK动态代理"><a href="#JDK动态代理" class="headerlink" title="JDK动态代理"></a>JDK动态代理</h3><p>JDK动态代理主要涉及两个类：<code>java.lang.reflect.Proxy</code> 和 <code>java.lang.reflect.InvocationHandler</code>，我们仍然通过案例来学习</p><p>编写一个调用逻辑处理器 LogHandler 类，提供日志增强功能，并实现 InvocationHandler 接口；在 LogHandler 中维护一个目标对象，这个对象是被代理的对象（真实主题角色）；在 <code>invoke</code> 方法中编写方法调用的逻辑处理</p><pre><code class="java">import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.util.Date;public class LogHandler implements InvocationHandler {    Object target;  // 被代理的对象，实际的方法执行者    public LogHandler(Object target) {        this.target = target;    }    @Override    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {        before();        Object result = method.invoke(target, args);  // 调用 target 的 method 方法        after();        return result;  // 返回方法的执行结果    }    // 调用invoke方法之前执行    private void before() {        System.out.println(String.format(&quot;log start time [%s] &quot;, new Date()));    }    // 调用invoke方法之后执行    private void after() {        System.out.println(String.format(&quot;log end time [%s] &quot;, new Date()));    }}</code></pre><p>编写客户端，获取动态生成的代理类的对象须借助 Proxy 类的 newProxyInstance 方法，具体步骤可见代码和注释</p><pre><code class="java">import proxy.UserService;import proxy.UserServiceImpl;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Proxy;public class Client2 {    public static void main(String[] args) throws IllegalAccessException, InstantiationException {        // 设置变量可以保存动态代理类，默认名称以 $Proxy0 格式命名        // System.getProperties().setProperty(&quot;sun.misc.ProxyGenerator.saveGeneratedFiles&quot;, &quot;true&quot;);        // 1. 创建被代理的对象，UserService接口的实现类        UserServiceImpl userServiceImpl = new UserServiceImpl();        // 2. 获取对应的 ClassLoader        ClassLoader classLoader = userServiceImpl.getClass().getClassLoader();        // 3. 获取所有接口的Class，这里的UserServiceImpl只实现了一个接口UserService，        Class[] interfaces = userServiceImpl.getClass().getInterfaces();        // 4. 创建一个将传给代理类的调用请求处理器，处理所有的代理对象上的方法调用        //     这里创建的是一个自定义的日志处理器，须传入实际的执行对象 userServiceImpl        InvocationHandler logHandler = new LogHandler(userServiceImpl);        /*           5.根据上面提供的信息，创建代理对象 在这个过程中，               a.JDK会通过根据传入的参数信息动态地在内存中创建和.class 文件等同的字节码               b.然后根据相应的字节码转换成对应的class，               c.然后调用newInstance()创建代理实例         */        UserService proxy = (UserService) Proxy.newProxyInstance(classLoader, interfaces, logHandler);        // 调用代理的方法        proxy.select();        proxy.update();        // 保存JDK动态代理生成的代理类，类名保存为 UserServiceProxy        // ProxyUtils.generateClassFile(userServiceImpl.getClass(), &quot;UserServiceProxy&quot;);    }}</code></pre><p>运行结果</p><pre><code>log start time [Thu Dec 20 16:55:19 CST 2018] 查询 selectByIdlog end time [Thu Dec 20 16:55:19 CST 2018] log start time [Thu Dec 20 16:55:19 CST 2018] 更新 updatelog end time [Thu Dec 20 16:55:19 CST 2018] </code></pre><p>InvocationHandler 和 Proxy 的主要方法介绍如下：</p><p><strong>java.lang.reflect.InvocationHandler</strong></p><p><code>Object invoke(Object proxy, Method method, Object[] args)</code> 定义了代理对象调用方法时希望执行的动作，用于集中处理在动态代理类对象上的方法调用</p><p><strong>java.lang.reflect.Proxy</strong></p><p><code>static InvocationHandler getInvocationHandler(Object proxy)</code>  用于获取指定代理对象所关联的调用处理器</p><p><code>static Class&lt;?&gt; getProxyClass(ClassLoader loader, Class&lt;?&gt;... interfaces)</code> 返回指定接口的代理类</p><p><code>static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h)</code> 构造实现指定接口的代理类的一个新实例，所有方法会调用给定处理器对象的 invoke 方法</p><p><code>static boolean isProxyClass(Class&lt;?&gt; cl)</code> 返回 cl 是否为一个代理类</p><h4 id="代理类的调用过程"><a href="#代理类的调用过程" class="headerlink" title="代理类的调用过程"></a>代理类的调用过程</h4><p>生成的代理类到底长什么样子呢？借助下面的工具类，把代理类保存下来再探个究竟<br>（通过设置环境变量sun.misc.ProxyGenerator.saveGeneratedFiles=true也可以保存代理类）</p><pre><code class="java">import sun.misc.ProxyGenerator;import java.io.FileOutputStream;import java.io.IOException;public class ProxyUtils {    /**     * 将根据类信息动态生成的二进制字节码保存到硬盘中，默认的是clazz目录下     * params: clazz 需要生成动态代理类的类     * proxyName: 为动态生成的代理类的名称     */    public static void generateClassFile(Class clazz, String proxyName) {        // 根据类信息和提供的代理类名称，生成字节码        byte[] classFile = ProxyGenerator.generateProxyClass(proxyName, clazz.getInterfaces());        String paths = clazz.getResource(&quot;.&quot;).getPath();        System.out.println(paths);        FileOutputStream out = null;        try {            //保留到硬盘中            out = new FileOutputStream(paths + proxyName + &quot;.class&quot;);            out.write(classFile);            out.flush();        } catch (Exception e) {            e.printStackTrace();        } finally {            try {                out.close();            } catch (IOException e) {                e.printStackTrace();            }        }    }}</code></pre><p>然后在 Client2 测试类的main的最后面加入一行代码</p><pre><code class="java">// 保存JDK动态代理生成的代理类，类名保存为 UserServiceProxyProxyUtils.generateClassFile(userServiceImpl.getClass(), &quot;UserServiceProxy&quot;);</code></pre><p>IDEA 再次运行之后就可以在 target 的类路径下找到 UserServiceProxy.class，双击后IDEA的反编译插件会将该二进制class文件</p><p><img src="http://image.laijianfeng.org/20181220_171031.png" alt="JDK 动态代理生成的代理类"></p><p>UserServiceProxy 的代码如下所示：</p><pre><code class="java">import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.lang.reflect.UndeclaredThrowableException;import proxy.UserService;public final class UserServiceProxy extends Proxy implements UserService {    private static Method m1;    private static Method m2;    private static Method m4;    private static Method m0;    private static Method m3;    public UserServiceProxy(InvocationHandler var1) throws  {        super(var1);    }    public final boolean equals(Object var1) throws  {        // 省略...    }    public final String toString() throws  {        // 省略...    }    public final void select() throws  {        try {            super.h.invoke(this, m4, (Object[])null);        } catch (RuntimeException | Error var2) {            throw var2;        } catch (Throwable var3) {            throw new UndeclaredThrowableException(var3);        }    }    public final int hashCode() throws  {        // 省略...    }    public final void update() throws  {        try {            super.h.invoke(this, m3, (Object[])null);        } catch (RuntimeException | Error var2) {            throw var2;        } catch (Throwable var3) {            throw new UndeclaredThrowableException(var3);        }    }    static {        try {            m1 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;equals&quot;, Class.forName(&quot;java.lang.Object&quot;));            m2 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;toString&quot;);            m4 = Class.forName(&quot;proxy.UserService&quot;).getMethod(&quot;select&quot;);            m0 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;hashCode&quot;);            m3 = Class.forName(&quot;proxy.UserService&quot;).getMethod(&quot;update&quot;);        } catch (NoSuchMethodException var2) {            throw new NoSuchMethodError(var2.getMessage());        } catch (ClassNotFoundException var3) {            throw new NoClassDefFoundError(var3.getMessage());        }    }}</code></pre><p>从 UserServiceProxy 的代码中我们可以发现：</p><ul><li>UserServiceProxy 继承了 Proxy 类，并且实现了被代理的所有接口，以及equals、hashCode、toString等方法</li><li>由于 UserServiceProxy 继承了 Proxy 类，所以每个代理类都会关联一个 InvocationHandler 方法调用处理器</li><li>类和所有方法都被 <code>public final</code> 修饰，所以代理类只可被使用，不可以再被继承</li><li>每个方法都有一个 Method 对象来描述，Method 对象在static静态代码块中创建，以 <code>m + 数字</code> 的格式命名</li><li>调用方法的时候通过 <code>super.h.invoke(this, m1, (Object[])null);</code> 调用，其中的 <code>super.h.invoke</code> 实际上是在创建代理的时候传递给 <code>Proxy.newProxyInstance</code> 的 LogHandler 对象，它继承 InvocationHandler 类，负责实际的调用处理逻辑</li></ul><p>而 LogHandler 的 invoke 方法接收到 method、args 等参数后，进行一些处理，然后通过反射让被代理的对象 target 执行方法</p><pre><code class="java">    @Override    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {        before();        Object result = method.invoke(target, args);       // 调用 target 的 method 方法        after();        return result;  // 返回方法的执行结果    }</code></pre><p>JDK动态代理执行方法调用的过程简图如下：</p><p><img src="http://image.laijianfeng.org/2018_12_20_JDKProxy.png" alt="JDK动态代理执行方法调用过程"></p><p>代理类的调用过程相信大家都明了了，而关于Proxy的源码解析，还请大家另外查阅其他文章或者直接看源码</p><h3 id="CGLIB动态代理"><a href="#CGLIB动态代理" class="headerlink" title="CGLIB动态代理"></a>CGLIB动态代理</h3><p>maven引入CGLIB包，然后编写一个UserDao类，它没有接口，只有两个方法，select() 和 update()</p><pre><code class="java">public class UserDao {    public void select() {        System.out.println(&quot;UserDao 查询 selectById&quot;);    }    public void update() {        System.out.println(&quot;UserDao 更新 update&quot;);    }}</code></pre><p>编写一个 LogInterceptor ，继承了 MethodInterceptor，用于方法的拦截回调</p><pre><code class="java">import java.lang.reflect.Method;import java.util.Date;public class LogInterceptor implements MethodInterceptor {    /**     * @param object 表示要进行增强的对象     * @param method 表示拦截的方法     * @param objects 数组表示参数列表，基本数据类型需要传入其包装类型，如int--&gt;Integer、long-Long、double--&gt;Double     * @param methodProxy 表示对方法的代理，invokeSuper方法表示对被代理对象方法的调用     * @return 执行结果     * @throws Throwable     */    @Override    public Object intercept(Object object, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {        before();        Object result = methodProxy.invokeSuper(object, objects);   // 注意这里是调用 invokeSuper 而不是 invoke，否则死循环，methodProxy.invokesuper执行的是原始类的方法，method.invoke执行的是子类的方法        after();        return result;    }    private void before() {        System.out.println(String.format(&quot;log start time [%s] &quot;, new Date()));    }    private void after() {        System.out.println(String.format(&quot;log end time [%s] &quot;, new Date()));    }}</code></pre><p>测试</p><pre><code class="java">import net.sf.cglib.proxy.Enhancer;public class CglibTest {    public static void main(String[] args) {        DaoProxy daoProxy = new DaoProxy();         Enhancer enhancer = new Enhancer();        enhancer.setSuperclass(Dao.class);  // 设置超类，cglib是通过继承来实现的        enhancer.setCallback(daoProxy);        Dao dao = (Dao)enhancer.create();   // 创建代理类        dao.update();        dao.select();    }}</code></pre><p>运行结果</p><pre><code>log start time [Fri Dec 21 00:06:40 CST 2018] UserDao 查询 selectByIdlog end time [Fri Dec 21 00:06:40 CST 2018] log start time [Fri Dec 21 00:06:40 CST 2018] UserDao 更新 updatelog end time [Fri Dec 21 00:06:40 CST 2018] </code></pre><p>还可以进一步多个 MethodInterceptor 进行过滤筛选</p><pre><code class="java">public class LogInterceptor2 implements MethodInterceptor {    @Override    public Object intercept(Object object, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {        before();        Object result = methodProxy.invokeSuper(object, objects);        after();        return result;    }    private void before() {        System.out.println(String.format(&quot;log2 start time [%s] &quot;, new Date()));    }    private void after() {        System.out.println(String.format(&quot;log2 end time [%s] &quot;, new Date()));    }}// 回调过滤器: 在CGLib回调时可以设置对不同方法执行不同的回调逻辑，或者根本不执行回调。public class DaoFilter implements CallbackFilter {    @Override    public int accept(Method method) {        if (&quot;select&quot;.equals(method.getName())) {            return 0;   // Callback 列表第1个拦截器        }        return 1;   // Callback 列表第2个拦截器，return 2 则为第3个，以此类推    }}</code></pre><p>再次测试</p><pre><code class="java">public class CglibTest2 {    public static void main(String[] args) {        LogInterceptor logInterceptor = new LogInterceptor();        LogInterceptor2 logInterceptor2 = new LogInterceptor2();        Enhancer enhancer = new Enhancer();        enhancer.setSuperclass(UserDao.class);   // 设置超类，cglib是通过继承来实现的        enhancer.setCallbacks(new Callback[]{logInterceptor, logInterceptor2, NoOp.INSTANCE});   // 设置多个拦截器，NoOp.INSTANCE是一个空拦截器，不做任何处理        enhancer.setCallbackFilter(new DaoFilter());        UserDao proxy = (UserDao) enhancer.create();   // 创建代理类        proxy.select();        proxy.update();    }}</code></pre><p>运行结果</p><pre><code class="java">log start time [Fri Dec 21 00:22:39 CST 2018] UserDao 查询 selectByIdlog end time [Fri Dec 21 00:22:39 CST 2018] log2 start time [Fri Dec 21 00:22:39 CST 2018] UserDao 更新 updatelog2 end time [Fri Dec 21 00:22:39 CST 2018] </code></pre><p>CGLIB 创建动态代理类的模式是：</p><ol><li>查找目标类上的所有非final 的public类型的方法定义；</li><li>将这些方法的定义转换成字节码；</li><li>将组成的字节码转换成相应的代理的class对象；</li><li>实现 MethodInterceptor接口，用来处理对代理类上所有方法的请求</li></ol><h3 id="JDK动态代理与CGLIB动态代理对比"><a href="#JDK动态代理与CGLIB动态代理对比" class="headerlink" title="JDK动态代理与CGLIB动态代理对比"></a>JDK动态代理与CGLIB动态代理对比</h3><p>JDK动态代理：基于Java反射机制实现，必须要实现了接口的业务类才能用这种办法生成代理对象。</p><p>cglib动态代理：基于ASM机制实现，通过生成业务类的子类作为代理类。</p><p>JDK Proxy 的优势：</p><ul><li>最小化依赖关系，减少依赖意味着简化开发和维护，JDK 本身的支持，可能比 cglib 更加可靠。</li><li>平滑进行 JDK 版本升级，而字节码类库通常需要进行更新以保证在新版 Java 上能够使用。</li><li>代码实现简单。</li></ul><p>基于类似 cglib 框架的优势：</p><ul><li>无需实现接口，达到代理类无侵入</li><li>只操作我们关心的类，而不必为其他相关类增加工作量。</li><li>高性能</li></ul><h3 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h3><blockquote><p>来源于网上，用于帮助理解和掌握，欢迎补充</p></blockquote><h4 id="描述动态代理的几种实现方式？分别说出相应的优缺点"><a href="#描述动态代理的几种实现方式？分别说出相应的优缺点" class="headerlink" title="描述动态代理的几种实现方式？分别说出相应的优缺点"></a>描述动态代理的几种实现方式？分别说出相应的优缺点</h4><p>代理可以分为 “静态代理” 和 “动态代理”，动态代理又分为 “JDK动态代理” 和 “CGLIB动态代理” 实现。</p><p><strong>静态代理</strong>：代理对象和实际对象都继承了同一个接口，在代理对象中指向的是实际对象的实例，这样对外暴露的是代理对象而真正调用的是 Real Object</p><ul><li><strong>优点</strong>：可以很好的保护实际对象的业务逻辑对外暴露，从而提高安全性。</li><li><strong>缺点</strong>：不同的接口要有不同的代理类实现，会很冗余</li></ul><p><strong>JDK 动态代理</strong>：</p><ul><li>为了解决静态代理中，生成大量的代理类造成的冗余；</li><li>JDK 动态代理只需要实现 InvocationHandler 接口，重写 invoke 方法便可以完成代理的实现， </li><li>jdk的代理是利用反射生成代理类 Proxyxx.class 代理类字节码，并生成对象</li><li>jdk动态代理之所以<strong>只能代理接口</strong>是因为<strong>代理类本身已经extends了Proxy，而java是不允许多重继承的</strong>，但是允许实现多个接口</li></ul><ul><li><strong>优点</strong>：解决了静态代理中冗余的代理实现类问题。</li><li><strong>缺点</strong>：JDK 动态代理是基于接口设计实现的，如果没有接口，会抛异常。</li></ul><p><strong>CGLIB 代理</strong>：</p><ul><li>由于 JDK 动态代理限制了只能基于接口设计，而对于没有接口的情况，JDK方式解决不了；</li><li>CGLib 采用了非常底层的字节码技术，其原理是通过字节码技术为一个类创建子类，并在子类中采用方法拦截的技术拦截所有父类方法的调用，顺势织入横切逻辑，来完成动态代理的实现。</li><li>实现方式实现 MethodInterceptor 接口，重写 intercept 方法，通过 Enhancer 类的回调方法来实现。</li><li>但是CGLib在创建代理对象时所花费的时间却比JDK多得多，所以对于单例的对象，因为无需频繁创建对象，用CGLib合适，反之，使用JDK方式要更为合适一些。</li><li>同时，由于CGLib由于是采用动态创建子类的方法，对于final方法，无法进行代理。</li></ul><ul><li><strong>优点</strong>：没有接口也能实现动态代理，而且采用字节码增强技术，性能也不错。</li><li><strong>缺点</strong>：技术实现相对难理解些。</li></ul><h4 id="CGlib-对接口实现代理？"><a href="#CGlib-对接口实现代理？" class="headerlink" title="CGlib 对接口实现代理？"></a>CGlib 对接口实现代理？</h4><pre><code class="java">import net.sf.cglib.proxy.Enhancer;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;import proxy.UserService;import java.lang.reflect.Method;/** * 创建代理类的工厂 该类要实现 MethodInterceptor 接口。 * 该类中完成三样工作： * （1）声明目标类的成员变量，并创建以目标类对象为参数的构造器。用于接收目标对象 * （2）定义代理的生成方法，用于创建代理对象。方法名是任意的。代理对象即目标类的子类 * （3）定义回调接口方法。对目标类的增强这在这里完成 */public class CGLibFactory implements MethodInterceptor {    // 声明目标类的成员变量    private UserService target;    public CGLibFactory(UserService target) {        this.target = target;    }    // 定义代理的生成方法,用于创建代理对象    public UserService myCGLibCreator() {        Enhancer enhancer = new Enhancer();        // 为代理对象设置父类，即指定目标类        enhancer.setSuperclass(UserService.class);        /**         * 设置回调接口对象 注意，只所以在setCallback()方法中可以写上this，         * 是因为MethodIntecepter接口继承自Callback，是其子接口         */        enhancer.setCallback(this);        return (UserService) enhancer.create();// create用以生成CGLib代理对象    }    @Override    public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {        System.out.println(&quot;start invoke &quot; + method.getName());        Object result = method.invoke(target, args);        System.out.println(&quot;end invoke &quot; + method.getName());        return result;    }}</code></pre><blockquote><p>参考：<br>《Java核心技术》卷1<br>《深入理解Java虚拟机》7.3<br>java docs: <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/reflect/Proxy.html" target="_blank" rel="noopener">https://docs.oracle.com/javase/8/docs/api/java/lang/reflect/Proxy.html</a><br><a href="https://segmentfault.com/a/1190000011291179" target="_blank" rel="noopener">Java三种代理模式：静态代理、动态代理和cglib代理</a><br><a href="http://xzc.fun/w/index.php?title=%E6%8F%8F%E8%BF%B0%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E7%9A%84%E5%87%A0%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F_%E5%88%86%E5%88%AB%E8%AF%B4%E5%87%BA%E7%9B%B8%E5%BA%94%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9" target="_blank" rel="noopener">描述动态代理的几种实现方式 分别说出相应的优缺点</a><br><a href="https://my.oschina.net/robinyao/blog/811193" target="_blank" rel="noopener">JDK动态代理详解</a><br><a href="https://blog.csdn.net/luanlouis/article/details/24589193" target="_blank" rel="noopener">Java动态代理机制详解（JDK 和CGLIB，Javassist，ASM）</a><br><a href="https://blog.csdn.net/WangQYoho/article/details/77584832" target="_blank" rel="noopener">静态代理和动态代理的理解</a></p></blockquote><h3 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h3><p>欢迎评论、转发、分享，您的支持是我最大的动力</p><p>更多内容可访问我的个人博客：<a href="http://laijianfeng.org">http://laijianfeng.org</a></p><p>关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java编程 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java反射机制详解</title>
      <link href="/2018/12/Java%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3/"/>
      <url>/2018/12/Java%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3/</url>
      <content type="html"><![CDATA[<p>对于一般的开发者，很少需要直接使用Java反射机制来完成功能开发，但是反射是很多框架譬如 Spring， Mybatis 实现的核心，反射虽小，能量却很大。</p><p>本文主要介绍反射相关的概念以及API的使用，关于反射的应用将在下一篇文章中介绍</p><h3 id="反射的介绍"><a href="#反射的介绍" class="headerlink" title="反射的介绍"></a>反射的介绍</h3><p><strong>反射(Reflection)</strong> 是 Java 在运行时（Run time）可以访问、检测和修改它本身状态或行为的一种能力，它允许运行中的 Java 程序获取自身的信息，并且可以操作类或对象的内部属性。</p><p><strong>Class 类介绍</strong>：Java虚拟机为每个类型管理一个Class对象，包含了与类有关的信息，当通过 javac 编译Java类文件时，生成的同名 .class 文件保存着该类的 Class 对象，JVM 加载一个类即是加载该 .class 文件。</p><p><code>Class</code> 和 <code>java.lang.reflect</code> 一起对反射提供了支持，java.lang.reflect 包中最常用的几个类的关系如下：</p><p><img src="http://image.laijianfeng.org/20181218_182511.png" alt="reflect package"></p><p>其中最主要的三个类 <code>Field</code>、<code>Method</code> 和 <code>Constructor</code> 分别用于描述类的域、方法和构造器，它们有一个共同的父类 <code>AccessibleObject</code>，它提供了访问控制检查的功能。</p><ul><li>Field ：描述类的域（属性），可以使用 get() 和 set() 方法读取和修改 Field 对象关联的字段；</li><li>Method ：描述类的方法，可以使用 invoke() 方法调用与 Method 对象关联的方法；</li><li>Constructor ：描述类的构造器，可以用 Constructor 创建新的对象。</li></ul><p>下面将通过几个程序来学习Java反射机制。</p><h3 id="准备两个类用于实验"><a href="#准备两个类用于实验" class="headerlink" title="准备两个类用于实验"></a>准备两个类用于实验</h3><p>我们特别定义两个类，Person和Employee，其中Employee继承自Person，且各自都有一个private，protected，public修饰的域（属性），Employee还有private，public修饰的方法</p><pre><code class="java">public class Person {    public String name; // 姓名 公有    protected String age;   // 年龄 保护    private String hobby;   // 爱好   私有    public Person(String name, String age, String hobby) {        this.name = name;        this.age = age;        this.hobby = hobby;    }    public String getHobby() {        return hobby;    }}public class Employee extends Person {    public static Integer totalNum = 0; // 员工数    public int empNo;   // 员工编号 公有    protected String position;  // 职位 保护    private int salary; // 工资   私有    public void sayHello() {        System.out.println(String.format(&quot;Hello, 我是 %s, 今年 %s 岁, 爱好是%s, 我目前的工作是%s, 月入%s元\n&quot;, name, age, getHobby(), position, salary));    }    private void work() {        System.out.println(String.format(&quot;My name is %s, 工作中勿扰.&quot;, name));    }    public Employee(String name, String age, String hobby, int empNo, String position, int salary) {        super(name, age, hobby);        this.empNo = empNo;        this.position = position;        this.salary = salary;        Employee.totalNum++;    }}</code></pre><h3 id="获取-Class-对象"><a href="#获取-Class-对象" class="headerlink" title="获取 Class 对象"></a>获取 Class 对象</h3><p>获取 Class 对象的方式有三种：使用 Class 类的 forName 静态方法；直接获取某一个对象的 class；调用某个对象的 getClass() 方法</p><pre><code>public class ClassTest {    public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException {        Class c1 = Class.forName(&quot;reflect.Employee&quot;);   // 第1种，forName 方式获取Class对象        Class c2 = Employee.class;      // 第2种，直接通过类获取Class对象        Employee employee = new Employee(&quot;小明&quot;, &quot;18&quot;, &quot;写代码&quot;, 1, &quot;Java攻城狮&quot;, 100000);        Class c3 = employee.getClass();    // 第3种，通过调用对象的getClass()方法获取Class对象        if (c1 == c2 &amp;&amp; c1 == c3) {     // 可以通过 == 比较Class对象是否为同一个对象            System.out.println(&quot;c1、c2、c3 为同一个对象&quot;);            System.out.println(c1);     // class reflect.Employee        }    }}</code></pre><h4 id="通过反射来创建实例"><a href="#通过反射来创建实例" class="headerlink" title="通过反射来创建实例"></a>通过反射来创建实例</h4><p>通过反射来生成对象主要有两种方式</p><ul><li>使用Class对象的newInstance()方法来创建Class对象对应类的实例</li><li>先通过Class对象获取指定的Constructor对象，再调用Constructor对象的newInstance()方法来创建实例</li></ul><pre><code class="java">public class NewInstanceTest {    public static void main(String[] args) throws IllegalAccessException, InstantiationException, NoSuchMethodException, InvocationTargetException {        Class c = Date.class;        Date date1 = (Date) c.newInstance();    // 第1种方式：使用Class对象的newInstance()方法来创建Class对象对应类的实例        System.out.println(date1);      // Wed Dec 19 22:57:16 CST 2018        long timestamp =date1.getTime();        Constructor constructor = c.getConstructor(long.class);         Date date2 = (Date)constructor.newInstance(timestamp);  // 第2种方式：先通过Class对象获取指定的Constructor对象，再调用Constructor对象的newInstance()方法来创建实例        System.out.println(date2);  // Wed Dec 19 22:57:16 CST 2018    }}</code></pre><h3 id="获取类的全部信息"><a href="#获取类的全部信息" class="headerlink" title="获取类的全部信息"></a>获取类的全部信息</h3><p>上面我们定义了两个类，现在有个需求：获取Employee的类名，构造器签名，所有的方法，所有的域（属性）和值，然后打印出来。该通过什么方式来实现呢？</p><p>没错，猜对了，就是通过反射来获取这些类的信息，在上面介绍中我们知道JVM虚拟机为每个类型管理一个Class对象，</p><p>为了完成我们的需求，我们需要知道一些API如下：</p><h4 id="获取类信息的部分API"><a href="#获取类信息的部分API" class="headerlink" title="获取类信息的部分API"></a>获取类信息的部分API</h4><p><code>String getName()</code> 获取这个Class的类名</p><p><code>Constructor[] getDeclaredConstructors()</code> 返回这个类的所有构造器的对象数组，包含保护和私有的构造器；相近的方法 getConstructors() 则返回这个类的所有<strong>公有</strong>构造器的对象数组，不包含保护和私有的构造器</p><p><code>Method[] getDeclaredMethods()</code> 返回这个类或接口的所有方法，包括保护和私有的方法，不包括超类的方法；相近的方法 getMethods() 则返回这个类及其超类的<strong>公有</strong>方法的对象数组，不含保护和私有的方法</p><p><code>Field[] getDeclaredFields()</code> 返回这个类的所有域的对象数组，包括保护域和私有域，不包括超类的域；还有一个相近的API <code>getFields()</code>，返回这个类及其超类的<strong>公有</strong>域的对象数组，不含保护域和私有域</p><p><code>int getModifiers()</code> 返回一个用于描述Field、Method和Constructor的<strong>修饰符</strong>的整形数值，该数值代表的含义可通过Modifier这个类分析</p><p><code>Modifier 类</code> 它提供了有关Field、Method和Constructor等的访问修饰符的信息，主要的方法有：toString(int modifiers)返回整形数值modifiers代表的修饰符的字符串；isAbstract是否被abstract修饰；isVolatile是否被volatile修饰；isPrivate是否为private；isProtected是否为protected；isPublic是否为public；isStatic是否为static修饰；等等，见名知义</p><h4 id="打印类信息程序"><a href="#打印类信息程序" class="headerlink" title="打印类信息程序"></a>打印类信息程序</h4><pre><code class="java">public class ReflectionTest {    public static void main(String[] args) throws ClassNotFoundException {        String name;        if (args.length &gt; 0) {            name = args[0];        } else {            Scanner in = new Scanner(System.in);            System.out.println(&quot;输入一个类名（e.g. java.util.Date）：&quot;); // reflect.Employee            name = in.next();        }        try {            Class cl = Class.forName(name);            Class superCl = cl.getSuperclass();            String modifiers = Modifier.toString(cl.getModifiers());            if (modifiers.length() &gt; 0) {                System.out.print(modifiers + &quot; &quot;);            }            System.out.print(&quot;class &quot; + name);            if (superCl != null &amp;&amp; superCl != Object.class) {                System.out.print(&quot; extends &quot; + superCl.getName());            }            System.out.println(&quot;\n{&quot;);            printConstructors(cl); // 打印构造方法            System.out.println();            printMethods(cl);   // 打印方法            System.out.println();            printFields(cl);    // 打印属性            System.out.println(&quot;}&quot;);        } catch (ClassNotFoundException e) {            e.printStackTrace();        }        System.exit(0);    }    /**     * 打印Class对象的所有构造方法     */    public static void printConstructors(Class cl) {        Constructor[] constructors = cl.getDeclaredConstructors();        for (Constructor c : constructors) {            String name = c.getName();            System.out.print(&quot;  &quot;);            String modifiers = Modifier.toString(c.getModifiers());            if (modifiers.length() &gt; 0) {                System.out.print(modifiers + &quot; &quot;);            }            System.out.print(name + &quot;(&quot;);            // 打印构造参数            Class[] paramTypes = c.getParameterTypes();            for (int i = 0; i &lt; paramTypes.length; i++) {                if (i &gt; 0) {                    System.out.print(&quot;, &quot;);                }                System.out.print(paramTypes[i].getName());            }            System.out.println(&quot;);&quot;);        }    }    /**     * 打印Class的所有方法     */    public static void printMethods(Class cl) {        Method[] methods = cl.getDeclaredMethods();        //Method[] methods = cl.getMethods();        for (Method m : methods) {            Class retType = m.getReturnType();  // 返回类型            System.out.print(&quot;  &quot;);            String modifiers = Modifier.toString(m.getModifiers());            if (modifiers.length() &gt; 0) {                System.out.print(modifiers + &quot; &quot;);            }            System.out.print(retType.getName() + &quot; &quot; + m.getName() + &quot;(&quot;);            Class[] paramTypes = m.getParameterTypes();            for (int i = 0; i &lt; paramTypes.length; i++) {                if (i &gt; 0) {                    System.out.print(&quot;, &quot;);                }                System.out.print(paramTypes[i].getName());            }            System.out.println(&quot;);&quot;);        }    }    /**     * 打印Class的所有属性     */    public static void printFields(Class cl) {        Field[] fields = cl.getDeclaredFields();        for (Field f: fields) {            Class type = f.getType();            System.out.print(&quot;  &quot;);            String modifiers = Modifier.toString(f.getModifiers());            if (modifiers.length()&gt; 0) {                System.out.print(modifiers + &quot; &quot;);            }            System.out.println(type.getName() + &quot; &quot; + f.getName() + &quot;;&quot;);        }    }}</code></pre><p>运行程序，然后在控制台输入一个我们想分析的类的全名，譬如 reflect.Employee，可得到下面的输出</p><pre><code>输入一个类名（e.g. java.util.Date）：reflect.Employeepublic class reflect.Employee extends reflect.Person{  private reflect.Employee(java.lang.String, java.lang.String, java.lang.String);  public reflect.Employee(java.lang.String, java.lang.String, java.lang.String, int, java.lang.String, int);  public static void main([Ljava.lang.String;);  public void sayHello();  private void work();  public static java.lang.Integer totalNum;  public int empNo;  protected java.lang.String position;  private int salary;}</code></pre><p>上面的输出中我们得到的类的构造器，所有方法和所有的域（属性），包括修饰符，名称和参数类型都是准确的，看来反射机制能完成我们的需求。</p><p>小结一下，我们通过 getDeclaredConstructors() 获取构造器信息，通过 getDeclaredMethods() 获得方法信息，通过 getDeclaredFields() 获得域信息，再通过 getModifiers() 和 Modifier类 获得修饰符信息，汇总起来就得到了整个类的类信息。</p><h3 id="运行时查看对象数据域的实际内容"><a href="#运行时查看对象数据域的实际内容" class="headerlink" title="运行时查看对象数据域的实际内容"></a>运行时查看对象数据域的实际内容</h3><p>上面我们已经获取到了类的信息，现在又有一个需求：在运行时查看对象的数据域的实际值。这个场景就像我们通过IDEA调试程序，设置断点拦截到程序后，查看某个对象的属性的值。</p><p>我们知道java反射机制提供了查看类信息的API，那么它应该也提供了查看Field域实际值和设置Field域实际值的API，没错，猜对了，确实有相关的API，但是有个疑问，有一些属性是private修饰的私有域，这种是否也能直接查看和设置呢？看完下面的API即可知道答案</p><h4 id="运行时查看对象数据域实际内容的相关API"><a href="#运行时查看对象数据域实际内容的相关API" class="headerlink" title="运行时查看对象数据域实际内容的相关API"></a>运行时查看对象数据域实际内容的相关API</h4><p><code>Class&lt;?&gt; getComponentType()</code> 返回数组类里组件类型的 Class，如果不是数组类则返回null</p><p><code>boolean isArray()</code> 返回这个类是否为数组，同类型的API还有 isAnnotation、isAsciiDigit、isEnum、isInstance、isInterface、isLocalClass、isPrimitive 等</p><p><code>int Array.getLength(obj)</code> 返回数组对象obj的长度</p><p><code>Object Array.get(obj, i)</code> 获取数组对象下标为i的元素</p><p><code>boolean isPrimitive()</code> 返回这个类是否为8种基本类型之一，即是否为boolean, byte, char, short, int, long, float, 和double 等原始类型</p><p><code>Field getField(String name)</code> 获取指定名称的域对象</p><p><code>AccessibleObject.setAccessible(fields, true)</code> 当访问 Field、Method 和 Constructor 的时候Java会执行访问检查，如果访问者没有权限将抛出SecurityException，譬如访问者是无法访问private修饰的域的。通过设置 setAccessible(true) 可以取消Java的执行访问检查，这样访问者就获得了指定 Field、Method 或 Constructor 访问权限</p><p><code>Class&lt;?&gt; Field.getType()</code> 返回一个Class 对象，它标识了此 Field 对象所表示字段的声明类型</p><p><code>Object Field.get(Object obj)</code> 获取obj对象上当前域对象表示的属性的实际值，获取到的是一个Object对象，实际使用中还需要转换成实际的类型，或者可以通过 getByte()、getChar、getInt() 等直接获取具体类型的值</p><p><code>void Field.set(Object obj, Object value)</code> 设置obj对象上当前域表示的属性的实际值</p><h4 id="查看对象数据域实际内容程序"><a href="#查看对象数据域实际内容程序" class="headerlink" title="查看对象数据域实际内容程序"></a>查看对象数据域实际内容程序</h4><p>了解完上述相关API之后，我们敲出下面的程序来验证</p><pre><code class="java">public class ObjectAnalyzer {    private ArrayList&lt;Object&gt; visited = new ArrayList&lt;&gt;();    public String toString(Object obj) {        if (obj == null) {            return &quot;null&quot;;        }        if (visited.contains(obj)) {    // 如果该对象已经处理过，则不再处理            return &quot;...&quot;;        }        visited.add(obj);        Class cl = obj.getClass(); // 获取Class对象        if (cl == String.class) {   // 如果是String类型则直接转为String            return (String) obj;        }        if (cl.isArray()) {        // 如果是数组            String r = cl.getComponentType() + &quot;[]{\n&quot;;     // 数组的元素的类型            for (int i = 0; i &lt; Array.getLength(obj); i++) {                if (i &gt; 0) {   // 不是数组的第一个元素加逗号和换行，显示更加美观                    r += &quot;,\n&quot;;                }                r += &quot;\t&quot;;                Object val = Array.get(obj, i);                if (cl.getComponentType().isPrimitive()) { // Class为8种基本类型的时候为 true，直接输出                    r += val;                } else {                    r += toString(val); // 不是8中基本类型时，说明是类，递归调用toString                }            }            return r + &quot;\n}&quot;;        }        // 既不是String，也不是数组时，输出该对象的类型和属性值        String r = cl.getName();        do {            r += &quot;[&quot;;            Field[] fields = cl.getDeclaredFields();    // 获取该类自己定义的所有域，包括私有的，不包括父类的            AccessibleObject.setAccessible(fields, true); // 访问私有的属性，需要打开这个设置，否则会报非法访问异常            for (Field f : fields) {                if (!Modifier.isStatic(f.getModifiers())) { // 通过 Modifier 可获取该域的修饰符，这里判断是否为 static                    if (!r.endsWith(&quot;[&quot;)) {                        r += &quot;,&quot;;                    }                    r += f.getName() + &quot;=&quot;;     // 域名称                    try {                        Class t = f.getType();  // 域（属性）的类型                        Object val = f.get(obj);   // 获取obj对象上该域的实际值                        if (t.isPrimitive()) {     // 如果类型为8种基本类型，则直接输出                            r += val;                        } else {                            r += toString(val);     // 不是8种基本类型，递归调用toString                        }                    } catch (IllegalAccessException e) {                        e.printStackTrace();                    }                }            }            r += &quot;]&quot;;            cl = cl.getSuperclass(); // 继续打印超类的类信息        } while (cl != null);        return r;    }}</code></pre><h4 id="测试验证结果"><a href="#测试验证结果" class="headerlink" title="测试验证结果"></a>测试验证结果</h4><p>接下来验证一下获取数据域实际值是否正确，分别打印数组、自定义类的对象的实际值</p><pre><code class="java">public class ObjectAnalyzerTest {    public static void main(String[] args) {        int size = 4;        ArrayList&lt;Integer&gt; squares = new ArrayList&lt;&gt;(size);        for (int i = 0; i &lt; size; i++) {            squares.add(i * i);        }        ObjectAnalyzer objectAnalyzer = new ObjectAnalyzer(); // 创建一个上面定义的分析类ObjectAnalyzer的对象        System.out.println(objectAnalyzer.toString(squares)); // 分析ArrayList&lt;Integer&gt;对象的实际值        Employee employee = new Employee(&quot;小明&quot;, &quot;18&quot;, &quot;爱好写代码&quot;, 1, &quot;Java攻城狮&quot;, 100); // 分析自定义类Employee的对象的实际值        System.out.println(objectAnalyzer.toString(employee));    }}</code></pre><p>输出如下</p><pre><code class="java">java.util.ArrayList[elementData=class java.lang.Object[]{    java.lang.Integer[value=0][][],    java.lang.Integer[value=1][][],    java.lang.Integer[value=4][][],    java.lang.Integer[value=9][][]},size=4][modCount=4][][]reflect.Employee[empNo=1,position=Java攻城狮,salary=100][name=小明,age=18,hobby=爱好写代码][]</code></pre><p>其中<code>ArrayList&lt;Integer&gt;</code>打印了类名和5个元素的类型和值，<code>Employee</code> 打印了类名，自己定义的3个基本类型的属性的实际值，和父类Person的3个基本类型的属性的实际值</p><p>需要注意的是，position，age 是 protected 保护域，salary，hobby 是 private 私有域，Java的安全机制只允许查看任意对象有哪些域，但是不允许读取它们的值</p><p>程序中是通过 <code>AccessibleObject.setAccessible(fields, true)</code> 将域设置为了可访问，取消了Java的执行访问检查，因此可以访问，如果不加会报异常 IllegalAccessException</p><p>小结一下，我们通过 setAccessible(true) 绕过了Java执行访问检查，因此能够访问私有域，通过 Field.getType() 获得了属性的声明类型，通过了 Field.get(Object obj) 获得了该域属性的实际值，还有一个没用上的 Field.set(Object obj, Object value) 设置域属性的实际值</p><h3 id="调用任意方法"><a href="#调用任意方法" class="headerlink" title="调用任意方法"></a>调用任意方法</h3><p>上面我们已经获取了类的构造器，方法，域，查看和设置了域的实际值，那么是不是还可以在调用对象的方法呢？嘿嘿，又猜对了，机智，类的方法信息，获取都获取了，当然就要调用一下，来都来了</p><p>上面查看Field的实际值是通过 Field 类的 get() 方法，与之类似，Method 调用方法是通过 Method 类的 invoke 方法 </p><h4 id="调用任意方法相关的API"><a href="#调用任意方法相关的API" class="headerlink" title="调用任意方法相关的API"></a>调用任意方法相关的API</h4><p><code>Method getMethod(String name, Class&lt;?&gt;... parameterTypes)</code> 获取指定的 Method，参数 name 为要获取的方法名，parameterTypes 为指定方法的参数的 Class，由于可能存在多个同名的重载方法，所以只有提供正确的 parameterTypes 才能准确的获取到指定的 Method</p><p><code>Object invoke(Object obj, Object... args)</code> 执行方法，第一个参数执行该方法的对象，如果是static修饰的类方法，则传null即可；后面是传给该方法执行的具体的参数值</p><h4 id="调用任意方法程序"><a href="#调用任意方法程序" class="headerlink" title="调用任意方法程序"></a>调用任意方法程序</h4><pre><code class="java">public class MethodTableTest {    public static void main(String[] args) throws NoSuchMethodException, InvocationTargetException, IllegalAccessException {        Employee employee = new Employee(&quot;小明&quot;, &quot;18&quot;, &quot;写代码&quot;, 1, &quot;Java攻城狮&quot;, 100000);        Method sayHello = employee.getClass().getMethod(&quot;sayHello&quot;);        System.out.println(sayHello);   // 打印 sayHello 的方法信息        sayHello.invoke(employee);      // 让 employee 执行 sayHello 方法        double x = 3.0;        Method square = MethodTableTest.class.getMethod(&quot;square&quot;, double.class);  // 获取 MethodTableTest 的square方法        double y1 = (double) square.invoke(null, x);    // 调用类方法 square 求平方，方法参数 x         System.out.printf(&quot;square    %-10.4f -&gt; %10.4f%n&quot;, x, y1);        Method sqrt = Math.class.getMethod(&quot;sqrt&quot;, double.class);   // 获取 Math 的 sqrt 方法        double y2 = (double) sqrt.invoke(null, x);  // 调用类方法 sqrt 求根，方法参数 x         System.out.printf(&quot;sqrt      %-10.4f -&gt; %10.4f%n&quot;, x, y2);    }    // static静态方法 计算乘方    public static double square(double x) {        return x * x;    }}</code></pre><p>执行结果</p><pre><code>public void reflect.Employee.sayHello()Hello, 我是 小明, 今年 18 岁, 爱好是写代码, 我目前的工作是Java攻城狮, 月入100000元square    3.0000     -&gt;     9.0000sqrt      3.0000     -&gt;     1.7321</code></pre><p>相信大家都看懂啦，通过 getMethod() 获取指定的 Method，再调用 Method.invoke() 执行该方法</p><h3 id="反射的优缺点"><a href="#反射的优缺点" class="headerlink" title="反射的优缺点"></a>反射的优缺点</h3><h4 id="反射的优点："><a href="#反射的优点：" class="headerlink" title="反射的优点："></a>反射的优点：</h4><ul><li><p><strong>可扩展性</strong> ：应用程序可以利用全限定名创建可扩展对象的实例，来使用来自外部的用户自定义类。</p></li><li><p><strong>类浏览器和可视化开发环境</strong> ：一个类浏览器需要可以枚举类的成员。可视化开发环境（如 IDE）可以从利用反射中可用的类型信息中受益，以帮助程序员编写正确的代码。</p></li><li><p><strong>调试器和测试工具</strong> ： 调试器需要能够检查一个类里的私有成员。测试工具可以利用反射来自动地调用类里定义的可被发现的 API 定义，以确保一组测试中有较高的代码覆盖率。</p></li></ul><h4 id="反射的缺点："><a href="#反射的缺点：" class="headerlink" title="反射的缺点："></a>反射的缺点：</h4><p>尽管反射非常强大，但也不能滥用。如果一个功能可以不用反射完成，那么最好就不用。在我们使用反射技术时，下面几条内容应该牢记于心。</p><ul><li><p><strong>性能开销</strong> ：反射涉及了动态类型的解析，所以 JVM 无法对这些代码进行优化。因此，反射操作的效率要比那些非反射操作低得多。我们应该避免在经常被执行的代码或对性能要求很高的程序中使用反射。</p></li><li><p><strong>安全限制</strong> ：使用反射技术要求程序必须在一个没有安全限制的环境中运行。如果一个程序必须在有安全限制的环境中运行，如 Applet，那么这就是个问题了。</p></li><li><p><strong>内部暴露</strong> ：由于反射允许代码执行一些在正常情况下不被允许的操作（比如访问私有的属性和方法），所以使用反射可能会导致意料之外的副作用，这可能导致代码功能失调并破坏可移植性。反射代码破坏了抽象性，因此当平台发生改变的时候，代码的行为就有可能也随着变化。</p></li></ul><blockquote><p>参考：<br>《Java核心技术》卷一<br><a href="https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/Java%20%E5%9F%BA%E7%A1%80.md#%E4%B8%83%E5%8F%8D%E5%B0%84" target="_blank" rel="noopener">https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/Java%20%E5%9F%BA%E7%A1%80.md#%E4%B8%83%E5%8F%8D%E5%B0%84</a>   </p></blockquote><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java编程 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spark SQL 分析 Nginx 访问日志</title>
      <link href="/2018/12/Spark-SQL-%E5%88%86%E6%9E%90-Imooc-%E8%AE%BF%E9%97%AE%E6%97%A5%E5%BF%97/"/>
      <url>/2018/12/Spark-SQL-%E5%88%86%E6%9E%90-Imooc-%E8%AE%BF%E9%97%AE%E6%97%A5%E5%BF%97/</url>
      <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="项目地址"><a href="#项目地址" class="headerlink" title="项目地址"></a>项目地址</h3><p><a href="https://github.com/whirlys/BigData-In-Practice/tree/master/ImoocLogAnalysis" target="_blank" rel="noopener">Spark SQL 分析 Imooc 访问日志</a></p><h3 id="环境说明"><a href="#环境说明" class="headerlink" title="环境说明"></a>环境说明</h3><ul><li>Java版本：1.8</li><li>Scala版本：2.11.12</li><li>Hadoop版本：hadoop-2.6.0-cdh5.14.0</li><li>spark版本：spark-2.3.1-bin-2.6.0-cdh5.14.0（自己编译）</li><li>MySQL版本：5.7.22</li><li>zeppelin版本：0.8</li></ul><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p><strong>Imooc 访问日志文件</strong>：access.20161111.log     </p><p><strong>数据量</strong>：一千多万条访问日志、5G多   </p><p><strong>日志格式</strong>：   </p><pre><code>60.165.39.1 - - [10/Nov/2016:00:01:53 +0800] &quot;POST /course/ajaxmediauser HTTP/1.1&quot; 200 54 &quot;www.imooc.com&quot; &quot;http://www.imooc.com/code/1431&quot; mid=1431&amp;time=60 &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.122 Safari/537.36 SE 2.X MetaSr 1.0&quot; &quot;-&quot; 10.100.136.64:80 200 0.014 0.01414.145.74.175 - - [10/Nov/2016:00:01:53 +0800] &quot;POST /course/ajaxmediauser/ HTTP/1.1&quot; 200 54 &quot;www.imooc.com&quot; &quot;http://www.imooc.com/video/678&quot; mid=678&amp;time=60&amp;learn_time=551.5 &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36&quot; &quot;-&quot; 10.100.136.64:80 200 0.014 0.014</code></pre><p><strong>百度云盘下载地址</strong>：链接：<a href="https://pan.baidu.com/s/1VfOG14mGW4P4kj20nzKx8g" target="_blank" rel="noopener">https://pan.baidu.com/s/1VfOG14mGW4P4kj20nzKx8g</a> 提取码：uwjg    </p><p><strong>开发测试数据</strong>：access.1w.log（10000条）   </p><h3 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h3><ul><li>统计某天最受欢迎的TopN课程</li><li>统计某天各个省市各自的 TopN 课程</li><li>按照流量进行统计 TopN 课程</li><li>某天最受欢迎的文章</li><li>某天进行code最多的课程</li><li>统计某天最勤奋的 IP</li><li>欢迎补充……</li></ul><h3 id="统计结果可视化-zeppelin展示"><a href="#统计结果可视化-zeppelin展示" class="headerlink" title="统计结果可视化(zeppelin展示)"></a>统计结果可视化(zeppelin展示)</h3><p><img src="https://user-gold-cdn.xitu.io/2018/12/16/167b6d3d71368a66?w=1861&amp;h=606&amp;f=png&amp;s=71269" alt=""></p><p><img src="https://user-gold-cdn.xitu.io/2018/12/16/167b6d42299204f6?w=1852&amp;h=603&amp;f=png&amp;s=57034" alt=""></p><p><img src="https://user-gold-cdn.xitu.io/2018/12/16/167b6d470fdc4e51?w=1856&amp;h=602&amp;f=png&amp;s=53017" alt=""></p><p><img src="https://user-gold-cdn.xitu.io/2018/12/16/167b6d4b68b1a130?w=1856&amp;h=613&amp;f=png&amp;s=38529" alt=""></p><h2 id="开发步骤"><a href="#开发步骤" class="headerlink" title="开发步骤"></a>开发步骤</h2><h3 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h3><p>根据需求，从日志中解析出我们需要的信息，譬如可能有：</p><ol><li>访问的系统属性： 操作系统、浏览器等等</li><li>访问特征：url、referer (从哪个url跳转过来的)、页面上的停留时间等</li><li>访问信息：session_id、访问ip(访问城市)等</li></ol><h4 id="主程序"><a href="#主程序" class="headerlink" title="主程序"></a>主程序</h4><ul><li><p>SparkStatFormatJob.scala  第一步，清洗出 ip, time, url, traffic</p></li><li><p>SparkStatCleanJob.scala 第二步，最终清洗转换得到  url、cmsType、cmsId、traffic、ip、city、time、day</p></li><li>AccessConvertUtil.scala 定义DataFrame schema，将日志信息转为对象，帮助RDD转为DataFrame</li><li>DateUtils.scala 时间格式转换</li></ul><h4 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h4><ol><li>使用 Spark SQL 解析访问日志</li><li>解析出课程编号类型</li><li>根据IP解析出城市名称</li><li>使用 Spark SQL 将访问时间按天进行分区输出</li></ol><h4 id="关键代码"><a href="#关键代码" class="headerlink" title="关键代码"></a>关键代码</h4><p>清洗第一步</p><pre><code class="scala">accessFile.map(line =&gt; {      val splits = line.split(&quot; &quot;) // 按空格分割      val ip = splits(0) // 第一个是IP      // 原始日志的第三个和第四个字段拼接起来就是完整的访问时间： [10/Nov/2016:00:01:02 +0800] ==&gt; yyyy-MM-dd HH:mm:ss      val time = splits(3) + &quot; &quot; + splits(4)      val url = splits(11).replaceAll(&quot;\&quot;&quot;, &quot;&quot;) // 第11个是 URL      val traffic = splits(9) // 第9个是流量      List(DateUtils.parse(time), url, traffic, ip)    })      // 过滤      .filter(item =&gt; !&quot;10.100.0.1&quot;.equals(item(3)))      .filter(item =&gt; !&quot;-&quot;.equals(item(1)))      // 拼成一个对象 (DateUtils.parse(time), url, traffic, ip)      .map(item =&gt; item(0) + &quot;\t&quot; + item(1) + &quot;\t&quot; + item(2) + &quot;\t&quot; + item(3))      // 保存      .saveAsTextFile(Constants.protocol + Constants.tempOut)</code></pre><p>清洗第二步</p><pre><code>val filterRDD = accessRDD.map(line =&gt; AccessConvertUtil.parseLog(line))val accessDF = spark.createDataFrame(filterRDD, AccessConvertUtil.struct)// 保存到 parquetaccessDF.coalesce(1).write.format(&quot;parquet&quot;).mode(SaveMode.Overwrite).partitionBy(&quot;day&quot;).save(Constants.protocol + Constants.cleanedOut)</code></pre><p>清洗结果样例</p><pre><code>+--------------------------------------------+-------+-----+-------+---------------+----+-------------------+--------+|url                                         |cmsType|cmsId|traffic|ip             |city|time               |day     |+--------------------------------------------+-------+-----+-------+---------------+----+-------------------+--------+|http://www.imooc.com/code/1852              |code   |1852 |2345   |117.35.88.11   |陕西省 |2016-11-10 00:01:02|20161110||http://www.imooc.com/learn/85/?src=360onebox|learn  |85   |14531  |115.34.187.133 |北京市 |2016-11-10 00:01:27|20161110||http://www.imooc.com/course/list?c=fetool   |course |0    |66     |120.198.231.151|广东省 |2016-11-10 00:01:27|20161110||http://www.imooc.com/code/10047             |code   |10047|54     |101.36.73.155  |北京市 |2016-11-10 00:01:27|20161110|+--------------------------------------------+-------+-----+-------+---------------+----+-------------------+--------+</code></pre><h3 id="Spark-SQL-统计-TopN"><a href="#Spark-SQL-统计-TopN" class="headerlink" title="Spark SQL 统计 TopN"></a>Spark SQL 统计 TopN</h3><h4 id="主程序-1"><a href="#主程序-1" class="headerlink" title="主程序"></a>主程序</h4><ul><li>TopNStatJob.scala Spark SQL 统计主类</li><li>StatDao.scala 将各个统计作业的统计结果写到数据库</li><li>MySQLUtils.scala 管理 MySQL JDBC 连接</li></ul><h4 id="关键代码-1"><a href="#关键代码-1" class="headerlink" title="关键代码"></a>关键代码</h4><pre><code class="scala">/**  * 统计某天各个省市各自的 TopN 课程  */def cityAccessTopNStat(spark: SparkSession, accessDF: DataFrame, day: String): Unit = {  import spark.implicits._  val cityAccessTopNDF = accessDF.filter($&quot;day&quot; === day &amp;&amp; $&quot;cmsType&quot; === &quot;video&quot; &amp;&amp; $&quot;cmsId&quot; =!= &quot;0&quot;)    .groupBy(&quot;city&quot;, &quot;day&quot;, &quot;cmsId&quot;)    .agg(count(&quot;cmsId&quot;).as(&quot;times&quot;))  // Window 函数在Spark SQL的使用: 窗口函数 row_number 的作用是根据表中字段进行分组，然后根据表中的字段排序，  //  给组中的每条记录添加一个序号；且每组的序号都是从1开始，可利用它的这个特性进行分组取top-n  val top3DF = cityAccessTopNDF.select(    cityAccessTopNDF(&quot;day&quot;), cityAccessTopNDF(&quot;city&quot;),    cityAccessTopNDF(&quot;cmsId&quot;), cityAccessTopNDF(&quot;times&quot;),    row_number().over(Window.partitionBy(cityAccessTopNDF(&quot;city&quot;)) // 根据 city 分组，根据 times 降序排序      .orderBy(cityAccessTopNDF(&quot;times&quot;).desc)).as(&quot;times_rank&quot;)  ).filter(&quot;times_rank &lt;= 3&quot;)  // 保存到 MySQL，需创建结果表 day_video_city_access_topn_stat  try {    top3DF.foreachPartition(partition =&gt; {      val list = new ListBuffer[DayCityVideoAccessStat]      partition.foreach(item =&gt; {        val day = item.getAs[String](&quot;day&quot;)        val cmsId = item.getAs[Long](&quot;cmsId&quot;)        val city = item.getAs[String](&quot;city&quot;)        val times = item.getAs[Long](&quot;times&quot;)        val timesRank = item.getAs[Int](&quot;times_rank&quot;)        list.append(DayCityVideoAccessStat(day, cmsId, city, times, timesRank))      })      StatDao.insertDayCityVideoAccessTopN(list)    })  } catch {    case e: Exception =&gt; e.printStackTrace()  }}</code></pre><h4 id="统计结果样例"><a href="#统计结果样例" class="headerlink" title="统计结果样例"></a>统计结果样例</h4><pre><code>+--------+-------+-----+-----+----------+|day     |city   |cmsId|times|times_rank|+--------+-------+-----+-----+----------+|20161110|北京市    |1309 |20   |1         ||20161110|北京市    |3369 |16   |2         ||20161110|北京市    |4018 |15   |3         ||20161110|辽宁省    |1336 |2    |1         ||20161110|辽宁省    |9028 |1    |2         ||20161110|辽宁省    |8141 |1    |3         ||20161110|浙江省    |3078 |19   |1         ||20161110|浙江省    |12552|16   |2         ||20161110|浙江省    |3237 |14   |3         |+--------+-------+-----+-----+----------+</code></pre><h2 id="项目开发说明"><a href="#项目开发说明" class="headerlink" title="项目开发说明"></a>项目开发说明</h2><p>1、 CDH相关的软件下载地址：<a href="http://archive.cloudera.com/cdh5/cdh/5/，spark自己编译的，看官方文档即可" target="_blank" rel="noopener">http://archive.cloudera.com/cdh5/cdh/5/，spark自己编译的，看官方文档即可</a></p><p>2、IDEA需要安装Scala插件</p><p>3、 Windows上开发需解压Hadoop和spark源码，然后在环境变量中配置HADOOP_HOME和SPARK_HOME</p><p>4、 windows上需下载相应版本的 <a href="https://github.com/steveloughran/winutils/tree/master/hadoop-2.6.0/bin" target="_blank" rel="noopener">winutils.exe </a> 文件放到 $HADOOP_HOME/bin</p><p>5、 解析IP地址使用  <a href="https://github.com/wzhe06/ipdatabase" target="_blank" rel="noopener">ipdatabase </a> ，三个步骤：</p><pre><code>1）git clone https://github.com/wzhe06/ipdatabase.git2）编译下载的项目：mvn clean package -DskipTests3）安装jar包到自己的maven仓库mvn install:install-file -Dfile=/home/whirly/source/ipdatabase/target/ipdatabase-1.0-SNAPSHOT.jar -DgroupId=com.ggstar -DartifactId=ipdatabase -Dversion=1.0 -Dpackaging=jar</code></pre><p>6、 需要创建相应的数据库和数据表，用于存储统计结果，具体的表结构见 imooc_log.sql ，Navicat 导入MySQL即可，创建库表完毕后须修改 MySQLUtils.scala 中的配置信息</p><p>7、 zeppelin 可导入 最受欢迎的TopN课程.json 文件查看结果，也可以使用可视化方案，譬如echarts、highcharts、D3.js、HUE等等…</p><hr><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>设计模式 | 责任链模式及典型应用</title>
      <link href="/2018/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2018/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>本文的主要内容：</p><ul><li>介绍责任链模式</li><li>请假流程示例</li><li>责任链模式总结</li><li>源码分析Tomcat Filter中的责任链模式</li></ul><h2 id="责任链模式"><a href="#责任链模式" class="headerlink" title="责任链模式"></a>责任链模式</h2><p>一个事件需要经过多个对象处理是一个挺常见的场景，譬如采购审批流程，请假流程，软件开发中的异常处理流程，web请求处理流程等各种各样的流程，可以考虑使用责任链模式来实现。</p><p>以请假流程为例，一般公司普通员工的请假流程简化如下：</p><p><img src="http://image.laijianfeng.org/20181030205552.jpg" alt="普通员工请假简化流程图"></p><p>普通员工发起一个请假申请，当请假天数小于3天时只需要得到主管批准即可；当请假天数大于3天时，主管批准后还需要提交给经理审批，经理审批通过，若请假天数大于7天还需要进一步提交给总经理审批。</p><p>使用 <code>if-else</code> 来实现这个请假流程的简化代码如下：</p><pre><code class="java">public class LeaveApproval {    public boolean process(String request, int number) {        boolean result = handleByDirector(request); // 主管处理        if (result == false) {  // 主管不批准            return false;        } else if (number &lt; 3) {    // 主管批准且天数小于 3            return true;        }        result = handleByManager(request); // 准管批准且天数大于等于 3，提交给经理处理        if (result == false) {   // 经理不批准            return false;        } else if (number &lt; 7) { // 经理批准且天数小于 7            return true;        }        result = handleByTopManager(request);   // 经理批准且天数大于等于 7，提交给总经理处理        if (result == false) { // 总经理不批准            return false;        }        return true;    // 总经理最后批准    }    public boolean handleByDirector(String request) {        // 主管处理该请假申请    }    public boolean handleByManager(String request) {        // 经理处理该请假申请    }    public boolean handleByTopManager(String request) {        // 总经理处理该请假申请    }}</code></pre><p>问题看起来很简单，三下五除二就搞定，但是<strong>该方案存在几个问题</strong>：</p><ol><li><p><code>LeaveApproval</code> 类比较庞大，各个上级的审批方法都集中在该类中，违反了 “单一职责原则”，测试和维护难度大</p></li><li><p>当需要修改该请假流程，譬如增加当天数大于30天时还需提交给董事长处理，必须修改该类源代码（并重新进行严格地测试），违反了 “开闭原则”</p></li><li><p>该流程缺乏灵活性，流程确定后不可再修改（除非修改源代码），客户端无法定制流程</p></li></ol><p>使用责任链模式可以解决上述问题。</p><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p><strong>责任链模式(Chain of Responsibility Pattern)</strong>：避免请求发送者与接收者耦合在一起，让多个对象都有可能接收请求，将这些对象连接成一条链，并且沿着这条链传递请求，直到有对象处理它为止。职责链模式是一种对象行为型模式。</p><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><p><strong>Handler（抽象处理者）</strong>：它定义了一个处理请求的接口，一般设计为抽象类，由于不同的具体处理者处理请求的方式不同，因此在其中定义了抽象请求处理方法。因为每一个处理者的下家还是一个处理者，因此在抽象处理者中定义了一个抽象处理者类型的对象，作为其对下家的引用。通过该引用，处理者可以连成一条链。</p><p><strong>ConcreteHandler（具体处理者）</strong>：它是抽象处理者的子类，可以处理用户请求，在具体处理者类中实现了抽象处理者中定义的抽象请求处理方法，在处理请求之前需要进行判断，看是否有相应的处理权限，如果可以处理请求就处理它，否则将请求转发给后继者；在具体处理者中可以访问链中下一个对象，以便请求的转发。</p><p>类图如下所示：</p><p><img src="http://image.laijianfeng.org/20181030205553.jpg" alt="责任链模式.类图"></p><h3 id="纯与不纯的责任链模式"><a href="#纯与不纯的责任链模式" class="headerlink" title="纯与不纯的责任链模式"></a>纯与不纯的责任链模式</h3><p><strong>纯的责任链模式</strong>：</p><ul><li>一个具体处理者对象只能在两个行为中选择一个：要么承担全部责任，要么将责任推给下家，不允许出现某一个具体处理者对象在承担了一部分或全部责任后<br>又将责任向下传递的情况</li><li>一个请求必须被某一个处理者对象所接收，不能出现某个请求未被任何一个处理者对象处理的情况</li></ul><p><strong>不纯的责任链模式</strong>：</p><ul><li>允许某个请求被一个具体处理者部分处理后再向下传递</li><li>或者一个具体处理者处理完某请求后其后继处理者可以继续处理该请求</li><li>而且一个请求可以最终不被任何处理者对象所接收</li></ul><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>使用责任链模式（不纯）重构请假流程</p><p>请假信息类，包含请假人姓名和请假天数</p><pre><code class="java">@Data@AllArgsConstructorpublic class LeaveRequest {    private String name;    // 请假人姓名    private int numOfDays;  // 请假天数}</code></pre><p>抽象处理者类 Handler，维护一个 <code>nextHandler</code> 属性，该属性为当前处理者的下一个处理者的引用；声明了抽象方法 <code>process</code></p><pre><code class="java">@Datapublic abstract class Handler {    protected String name; // 处理者姓名    protected Handler nextHandler;  // 下一个处理者    public Handler(String name) {        this.name = name;    }    public abstract boolean process(LeaveRequest leaveRequest); // 处理请假}</code></pre><p>三个具体处理类，分别实现了抽象处理类的 <code>process</code> 方法</p><pre><code class="java">// 主管处理者public class Director extends Handler {    public Director(String name) {        super(name);    }    @Override    public boolean process(LeaveRequest leaveRequest) {        boolean result = (new Random().nextInt(10)) &gt; 3; // 随机数大于3则为批准，否则不批准        String log = &quot;主管&lt;%s&gt; 审批 &lt;%s&gt; 的请假申请，请假天数： &lt;%d&gt; ，审批结果：&lt;%s&gt; &quot;;        System.out.println(String.format(log, this.name, leaveRequest.getName(), leaveRequest.getNumOfDays(), result == true ? &quot;批准&quot; : &quot;不批准&quot;));        if (result == false) {  // 不批准            return false;        } else if (leaveRequest.getNumOfDays() &lt; 3) { // 批准且天数小于3，返回true            return true;        }        return nextHandler.process(leaveRequest);   // 批准且天数大于等于3，提交给下一个处理者处理    }}// 经理public class Manager extends Handler {    public Manager(String name) {        super(name);    }    @Override    public boolean process(LeaveRequest leaveRequest) {        boolean result = (new Random().nextInt(10)) &gt; 3; // 随机数大于3则为批准，否则不批准        String log = &quot;经理&lt;%s&gt; 审批 &lt;%s&gt; 的请假申请，请假天数： &lt;%d&gt; ，审批结果：&lt;%s&gt; &quot;;        System.out.println(String.format(log, this.name, leaveRequest.getName(), leaveRequest.getNumOfDays(), result == true ? &quot;批准&quot; : &quot;不批准&quot;));        if (result == false) {  // 不批准            return false;        } else if (leaveRequest.getNumOfDays() &lt; 7) { // 批准且天数小于7            return true;        }        return nextHandler.process(leaveRequest);   // 批准且天数大于等于7，提交给下一个处理者处理    }}// 总经理public class TopManager extends Handler {    public TopManager(String name) {        super(name);    }    @Override    public boolean process(LeaveRequest leaveRequest) {        boolean result = (new Random().nextInt(10)) &gt; 3; // 随机数大于3则为批准，否则不批准        String log = &quot;总经理&lt;%s&gt; 审批 &lt;%s&gt; 的请假申请，请假天数： &lt;%d&gt; ，审批结果：&lt;%s&gt; &quot;;        System.out.println(String.format(log, this.name, leaveRequest.getName(), leaveRequest.getNumOfDays(), result == true ? &quot;批准&quot; : &quot;不批准&quot;));        if (result == false) { // 总经理不批准            return false;        }        return true;    // 总经理最后批准    }}</code></pre><p>客户端测试</p><pre><code class="java">public class Client {    public static void main(String[] args) {        Handler zhangsan = new Director(&quot;张三&quot;);        Handler lisi = new Manager(&quot;李四&quot;);        Handler wangwu = new TopManager(&quot;王五&quot;);        // 创建责任链        zhangsan.setNextHandler(lisi);        lisi.setNextHandler(wangwu);        // 发起请假申请        boolean result1 = zhangsan.process(new LeaveRequest(&quot;小旋锋&quot;, 1));        System.out.println(&quot;最终结果：&quot; + result1 + &quot;\n&quot;);        boolean result2 = zhangsan.process(new LeaveRequest(&quot;小旋锋&quot;, 4));        System.out.println(&quot;最终结果：&quot; + result2 + &quot;\n&quot;);        boolean result3 = zhangsan.process(new LeaveRequest(&quot;小旋锋&quot;, 8));        System.out.println(&quot;最终结果：&quot; + result3 + &quot;\n&quot;);    }}</code></pre><p>可能的结果如下：（由于是否批准是通过随机数模拟的，所以你的结果可能跟我不同）</p><pre><code>主管&lt;张三&gt; 审批 &lt;小旋锋&gt; 的请假申请，请假天数： &lt;1&gt; ，审批结果：&lt;批准&gt; 最终结果：true主管&lt;张三&gt; 审批 &lt;小旋锋&gt; 的请假申请，请假天数： &lt;4&gt; ，审批结果：&lt;不批准&gt; 最终结果：false主管&lt;张三&gt; 审批 &lt;小旋锋&gt; 的请假申请，请假天数： &lt;8&gt; ，审批结果：&lt;批准&gt; 经理&lt;李四&gt; 审批 &lt;小旋锋&gt; 的请假申请，请假天数： &lt;8&gt; ，审批结果：&lt;批准&gt; 总经理&lt;王五&gt; 审批 &lt;小旋锋&gt; 的请假申请，请假天数： &lt;8&gt; ，审批结果：&lt;批准&gt; 最终结果：true</code></pre><p>类图如下所示</p><p><img src="http://image.laijianfeng.org/20181030205554.png" alt="示例.责任链类图"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="职责链模式的主要优点"><a href="#职责链模式的主要优点" class="headerlink" title="职责链模式的主要优点"></a>职责链模式的主要优点</h3><ul><li><p>对象仅需知道该请求会被处理即可，且链中的对象不需要知道链的结构，由客户端负责链的创建，<strong>降低了系统的耦合度</strong></p></li><li><p>请求处理对象仅需维持一个指向其后继者的引用，而不需要维持它对所有的候选处理者的引用，<strong>可简化对象的相互连接</strong></p></li><li><p>在给对象分派职责时，职责链可以给我们更多的<strong>灵活性</strong>，可以在运行时对该链进行动态的增删改，改变处理一个请求的职责</p></li><li><p>新增一个新的具体请求处理者时无须修改原有代码，只需要在客户端重新建链即可，<strong>符合 “开闭原则”</strong></p></li></ul><h3 id="职责链模式的主要缺点"><a href="#职责链模式的主要缺点" class="headerlink" title="职责链模式的主要缺点"></a>职责链模式的主要缺点</h3><ul><li><p>一个请求可能因职责链没有被正确配置而<strong>得不到处理</strong></p></li><li><p>对于比较长的职责链，请求的处理可能涉及到多个处理对象，<strong>系统性能将受到一定影响</strong>，且不方便调试</p></li><li><p>可能因为职责链创建不当，造成循环调用，导致系统陷入<strong>死循环</strong></p></li></ul><h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><ul><li><p>有多个对象可以处理同一个请求，具体哪个对象处理该请求待运行时刻再确定，客户端只需将请求提交到链上，而无须关心请求的处理对象是谁以及它是如何处理的</p></li><li><p>在不明确指定接收者的情况下，向多个对象中的一个提交一个请求</p></li><li><p>可动态指定一组对象处理请求，客户端可以动态创建职责链来处理请求，还可以改变链中处理者之间的先后次序</p></li></ul><h2 id="责任链模式的典型应用"><a href="#责任链模式的典型应用" class="headerlink" title="责任链模式的典型应用"></a>责任链模式的典型应用</h2><h3 id="Tomcat-过滤器中的责任链模式"><a href="#Tomcat-过滤器中的责任链模式" class="headerlink" title="Tomcat 过滤器中的责任链模式"></a>Tomcat 过滤器中的责任链模式</h3><p><code>Servlet</code> 过滤器是可用于 <code>Servlet</code> 编程的 Java 类，可以实现以下目的：在客户端的请求访问后端资源之前，拦截这些请求；在服务器的响应发送回客户端之前，处理这些响应。</p><p><code>Servlet</code> 定义了过滤器接口 <code>Filter</code> 和过滤器链接口 <code>FilterChain</code> 的源码如下</p><pre><code class="java">public interface Filter {    public void init(FilterConfig filterConfig) throws ServletException;    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException;    public void destroy();}public interface FilterChain {    void doFilter(ServletRequest var1, ServletResponse var2) throws IOException, ServletException;}</code></pre><p>我们<strong>自定义一个过滤器的步骤</strong>是：</p><p>1）写一个过滤器类，实现 <code>javax.servlet.Filter</code> 接口，如下所示</p><pre><code class="java">public class MyFilter implements Filter {    @Override    public void doFilter(ServletRequest request, ServletResponse response,                         FilterChain chain) throws IOException, ServletException {        // 做一些自定义处理....        System.out.println(&quot;执行doFilter()方法之前...&quot;);        chain.doFilter(request, response);              // 传递请求给下一个过滤器        System.out.println(&quot;执行doFilter()方法之后...&quot;);    }    @Override    public void destroy() {    }    @Override    public void init(FilterConfig filterConfig) throws ServletException {    }}</code></pre><p>2）在 <code>web.xml</code> 文件中增加该过滤器的配置，譬如下面是拦截所有请求</p><pre><code class="xml">&lt;filter&gt;          &lt;filter-name&gt;MyFilter&lt;/filter-name&gt;          &lt;filter-class&gt;com.whirly.filter.MyFilter&lt;/filter-class&gt;  &lt;/filter&gt;&lt;filter-mapping&gt;          &lt;filter-name&gt;MyFilter&lt;/filter-name&gt;          &lt;url-pattern&gt;/*&lt;/url-pattern&gt;  &lt;/filter-mapping&gt;</code></pre><p>当启动 Tomcat 是我们的过滤器就可以发挥作用了。<strong>那么过滤器是怎样运行的呢？</strong></p><blockquote><p>Tomcat 有 <code>Pipeline Valve机制</code>，也是使用了责任链模式，一个请求会在 Pipeline 中流转，Pipeline 会调用相应的 Valve 完成具体的逻辑处理；<br>其中的一个基础Valve为 <code>StandardWrapperValve</code>，其中的一个作用是调用 <code>ApplicationFilterFactory</code> 生成 <code>Filter链</code>，具体代码在 <code>invoke</code> 方法中</p></blockquote><p>在运行过滤器之前需要<strong>完成过滤器的加载和初始化，以及根据配置信息生成过滤器链</strong>：</p><ol><li><p>过滤器的加载具体是在 <code>ContextConfig</code> 类的 <code>configureContext</code> 方法中，分别加载 <code>filter</code> 和 <code>filterMap</code> 的相关信息，并保存在上下文环境中</p></li><li><p>过滤器的初始化在 <code>StandardContext</code> 类的 <code>startInternal</code> 方法中完成，保存在 <code>filterConfigs</code> 中并存到上下文环境中</p></li><li><p>请求流转到 <code>StandardWrapperValve</code> 时，在 <code>invoke</code> 方法中，会根据过滤器映射配置信息，为每个请求创建对应的 <code>ApplicationFilterChain</code>，其中包含了目标 <code>Servlet</code> 以及对应的过滤器链，并调用过滤器链的 <code>doFilter</code> 方法执行过滤器</p></li></ol><p><code>StandardWrapperValve</code> 调用 <code>ApplicationFilterFactory</code> 为请求创建过滤器链并调用过滤器链的关键代码如下:</p><pre><code class="java">final class StandardWrapperValve extends ValveBase {    public final void invoke(Request request, Response response) throws IOException, ServletException {        // 省略其他的逻辑处理...        // 调用 ApplicationFilterChain.createFilterChain() 创建过滤器链        ApplicationFilterChain filterChain = ApplicationFilterFactory.createFilterChain(request, wrapper, servlet);        if (servlet != null &amp;&amp; filterChain != null) {            // 省略        } else if (request.isAsyncDispatching()) {            request.getAsyncContextInternal().doInternalDispatch();        } else if (comet) {            filterChain.doFilterEvent(request.getEvent());        } else {            // 调用过滤器链的 doFilter 方法开始过滤            filterChain.doFilter(request.getRequest(), response.getResponse());        }</code></pre><p>过滤器链 <code>ApplicationFilterChain</code> 的关键代码如下，过滤器链实际是一个 <code>ApplicationFilterConfig</code> 数组</p><pre><code class="java">final class ApplicationFilterChain implements FilterChain, CometFilterChain {    private ApplicationFilterConfig[] filters = new ApplicationFilterConfig[0]; // 过滤器链    private Servlet servlet = null; // 目标    // ...    @Override    public void doFilter(ServletRequest request, ServletResponse response) throws IOException, ServletException {        if( Globals.IS_SECURITY_ENABLED ) {            // ...        } else {            internalDoFilter(request,response); // 调用 internalDoFilter 方法        }    }    private void internalDoFilter(ServletRequest request, ServletResponse response) throws IOException, ServletException {        // Call the next filter if there is one        if (pos &lt; n) {            // 从过滤器数组中取出当前过滤器配置，然后下标自增1            ApplicationFilterConfig filterConfig = filters[pos++];            Filter filter = null;            try {                filter = filterConfig.getFilter();  // 从过滤器配置中取出该 过滤器对象                if( Globals.IS_SECURITY_ENABLED ) {                    final ServletRequest req = request;                    final ServletResponse res = response;                    Principal principal = ((HttpServletRequest) req).getUserPrincipal();                    Object[] args = new Object[]{req, res, this};                    SecurityUtil.doAsPrivilege(&quot;doFilter&quot;, filter, classType, args, principal);                } else {                    // 调用过滤器的 doFilter，完成一个过滤器的过滤功能                    filter.doFilter(request, response, this);                }            return;  // 这里很重要，不会重复执行后面的  servlet.service(request, response)        }        // 执行完过滤器链的所有过滤器之后，调用 Servlet 的 service 完成请求的处理        if ((request instanceof HttpServletRequest) &amp;&amp; (response instanceof HttpServletResponse)) {            if( Globals.IS_SECURITY_ENABLED ) {            } else {                servlet.service(request, response);            }        } else {            servlet.service(request, response);        }    }    // 省略...}</code></pre><p>过滤器</p><pre><code class="java">    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {        System.out.println(&quot;执行doFilter()方法之前...&quot;);        chain.doFilter(request, response);              // 传递请求给下一个过滤器        System.out.println(&quot;执行doFilter()方法之后...&quot;);    }</code></pre><p>当下标小于过滤器数组长度 n 时，说明过滤器链未执行完，所以从数组中取出当前过滤器，调用过滤器的 <code>doFilter</code> 方法完成过滤处理，在过滤器的 <code>doFilter</code> 中又调用 <code>FilterChain</code> 的 <code>doFilter</code>，回到 <code>ApplicationFilterChain</code>，又继续根据下标是否小于数组长度来判断过滤器链是否已执行完，未完则<strong>继续</strong>从数组取出过滤器并调用 <code>doFilter</code> 方法，所以这里的过滤链是通过<strong>嵌套递归</strong>的方式来串成一条链。</p><p>当全部过滤器都执行完毕，最后一次进入 <code>ApplicationFilterChain.doFilter</code> 方法的时候 <code>pos &lt; n</code> 为false，不进入 <code>if (pos &lt; n)</code> 中，而是执行后面的代码，判断 <code>(request instanceof HttpServletRequest) &amp;&amp; (response instanceof HttpServletResponse)</code>，若为 http 请求则调用 <code>servlet.service(request, response);</code> 来处理该请求。</p><p>处理完毕之后沿着调用过滤器的顺序反向退栈，分别执行过滤器中 <code>chain.doFilter()</code> 之后的处理逻辑，<strong>需要注意的是</strong>在 <code>if (pos &lt; n)</code> 方法体的最后有一个 <code>return;</code>，这样就保证了只有最后一次进入 <code>ApplicationFilterChain.doFilter</code> 方法的调用能够执行后面的 <code>servlet.service(request, response)</code> 方法</p><p>画一个简要的调用栈如下所示：</p><p><img src="http://image.laijianfeng.org/20181030205555.png" alt="Tomcat 过滤器链调用栈"></p><p><code>ApplicationFilterChain</code> 类扮演了抽象处理者角色，具体处理者角色由各个 <code>Filter</code> 扮演</p><h3 id="其他的责任链模式的典型应用"><a href="#其他的责任链模式的典型应用" class="headerlink" title="其他的责任链模式的典型应用"></a>其他的责任链模式的典型应用</h3><p>其他的责任链模式的应用基本都是大同小异</p><p><img src="http://image.laijianfeng.org/20181030_225050.png" alt="FilterChain 的实现类"></p><p>这里列举几个典型应用：</p><ol><li>Netty 中的 <code>Pipeline</code> 和 <code>ChannelHandler</code> 通过责任链设计模式来组织代码逻辑</li><li>Spring Security 使用责任链模式，可以动态地添加或删除责任（处理 request 请求）</li><li>Spring AOP 通过责任链模式来管理 Advisor</li><li>Dubbo Filter 过滤器链也是用了责任链模式（链表），可以对方法调用做一些过滤处理，譬如超时(TimeoutFilter)，异常(ExceptionFilter)，Token(TokenFilter)等</li><li>Mybatis 中的 Plugin 机制使用了责任链模式，配置各种官方或者自定义的 Plugin，与 Filter 类似，可以在执行 Sql 语句的时候做一些操作</li></ol><hr><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析<br><a href="https://blog.csdn.net/qq_36460189/article/details/83183448" target="_blank" rel="noopener">责任链设计模式（过滤器、拦截器）</a></p></blockquote><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>欢迎评论、转发、分享，您的支持是我最大的动力</p><p>更多内容可访问我的个人博客：<a href="http://laijianfeng.org">http://laijianfeng.org</a></p><p>关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="长按关注【小旋锋】微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>设计模式 | 中介者模式及典型应用</title>
      <link href="/2018/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E4%B8%AD%E4%BB%8B%E8%80%85%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2018/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E4%B8%AD%E4%BB%8B%E8%80%85%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>本文的主要内容：</p><ul><li>介绍中介者模式</li><li>数据同步示例</li><li>中介者模式总结</li><li>源码分析中介者模式的典型应用<ul><li>Java Timer 中的中介者模式</li></ul></li></ul><h2 id="中介者模式"><a href="#中介者模式" class="headerlink" title="中介者模式"></a>中介者模式</h2><p>世界上存在着各种各样的数据库，不同数据库有各自的应用场景，对于同一份数据，最开始可能使用关系型数据库（如MySQL）进行存储查询，使用Redis作为缓存数据库，当数据量较大时使用MySQL进行查询可能较慢，所以需要将数据同步到Elasticsearch或者列式数据库如Hbase中进行大数据查询。</p><p><strong>如何设计数据同步方案</strong>是一个重要的问题。数据源众多，目标端也众多，设计得不好可能 “牵一发而动全身”。</p><p>如果我们这样设计：每个数据源直接同步数据到目标端数据库的，如果数据库有 N 个，那么最多可能的同步作业将达到 <code>N * N</code> 个，当修改了其中一个数据库的某些配置，可能需要修改另外的 <code>N - 1</code> 个数据库的同步作业。</p><p>现在介绍另一种方案，DataX 是阿里巴巴集团内被广泛使用的离线数据同步工具/平台，实现包括 MySQL、Oracle、SqlServer、Postgre、HDFS、Hive、ADS、HBase、TableStore(OTS)、MaxCompute(ODPS)、DRDS 等各种异构数据源之间高效的数据同步功能。</p><p><img src="http://image.laijianfeng.org/datax-sync.png" alt="DataX"></p><p>DataX 其实相当于一个中介，从数据源读取数据，写入到目标端，数据源不再需要维护到目标端的同步作业，只需要与 DataX 通信即可。DataX 体现了中介者模式的思想。</p><p><strong>中介者模式(Mediator Pattern)</strong>：用一个中介对象（中介者）来封装一系列的对象交互，中介者使各对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地改变它们之间的交互。中介者模式又称为调停者模式，它是一种对象行为型模式。</p><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><p><strong>Mediator（抽象中介者）</strong>：它定义一个接口，该接口用于与各同事对象之间进行通信。</p><p><strong>ConcreteMediator（具体中介者）</strong>：它是抽象中介者的子类，通过协调各个同事对象来实现协作行为，它维持了对各个同事对象的引用。</p><p><strong>Colleague（抽象同事类）</strong>：它定义各个同事类公有的方法，并声明了一些抽象方法来供子类实现，同时它维持了一个对抽象中介者类的引用，其子类可以通过该引用来与中介者通信。</p><p><strong>ConcreteColleague（具体同事类）</strong>：它是抽象同事类的子类；每一个同事对象在需要和其他同事对象通信时，先与中介者通信，通过中介者来间接完成与其他同事类的通信；在具体同事类中实现了在抽象同事类中声明的抽象方法。</p><p>中介者模式的核心在于中介者类的引入，在中介者模式中，<strong>中介者类承担了两方面的职责</strong>：</p><ul><li><strong>中转作用（结构性）</strong>：通过中介者提供的中转作用，各个同事对象就不再需要显式引用其他同事，当需要和其他同事进行通信时，可通过中介者来实现间接调用。该中转作用属于中介者在结构上的支持。</li><li><strong>协调作用（行为性）</strong>：中介者可以更进一步的对同事之间的关系进行封装，同事可以一致的和中介者进行交互，而不需要指明中介者需要具体怎么做，中介者根据封装在自身内部的协调逻辑，对同事的请求进行进一步处理，将同事成员之间的关系行为进行分离和封装。</li></ul><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>我们来实现一个简化版的数据同步方案，有三种数据库 Mysql、Redis、Elasticsearch，其中的 Mysql 作为主数据库，当增加一条数据时<strong>需要</strong>同步到另外两个数据库中；Redis 作为缓存数据库，当增加一条数据时<strong>不需要</strong>同步到另外另个数据库；而 Elasticsearch 作为大数据查询数据库，有一个统计功能，当增加一条数据时<strong>只需要</strong>同步到 Mysql，所以它们之间的关系图如下所示。</p><p><img src="http://image.laijianfeng.org/20181025_193152.jpg" alt="简化的数据同步需求"></p><p>首先我们来实现第一种<strong>不使用</strong>中介者模式的数据同步方案，各数据源维护各自的同步作业。</p><p>抽象数据库</p><pre><code class="java">public abstract class AbstractDatabase {    public abstract void add(String data);    public abstract void addData(String data);}</code></pre><p>具体数据库 Mysql，维护同步到 Redis和Elasticsearch 的同步作业</p><pre><code class="java">public class MysqlDatabase extends AbstractDatabase {    private List&lt;String&gt; dataset = new ArrayList&lt;String&gt;();    @Setter    private RedisDatabase redisDatabase;    @Setter    private EsDatabase esDatabase;    @Override    public void addData(String data) {        System.out.println(&quot;Mysql 添加数据：&quot; + data);        this.dataset.add(data);    }    @Override    public void add(String data) {        addData(data);        this.redisDatabase.addData(data);   // 维护同步到Redis的同步作业        this.esDatabase.addData(data);  // 维护同步到Elasticsearch的同步作业    }    public void select() {        System.out.println(&quot;- Mysql 查询，数据：&quot; + this.dataset.toString());    }}</code></pre><p>具体数据库 Redis，不需要同步到其它数据库</p><pre><code class="java">public class RedisDatabase extends AbstractDatabase {    private List&lt;String&gt; dataset = new LinkedList&lt;String&gt;();    @Override    public void addData(String data) {        System.out.println(&quot;Redis 添加数据：&quot; + data);        this.dataset.add(data);    }    @Override    public void add(String data) {        addData(data); // 不同步到其它数据库    }    public void cache() {        System.out.println(&quot;- Redis 缓存的数据：&quot; + this.dataset.toString());    }}</code></pre><p>Elasticsearch ，只需要同步到Mysql</p><pre><code class="java">public class EsDatabase extends AbstractDatabase {    private List&lt;String&gt; dataset = new CopyOnWriteArrayList&lt;String&gt;();    @Setter    private MysqlDatabase mysqlDatabase;    @Override    public void addData(String data) {        System.out.println(&quot;ES 添加数据：&quot; + data);        this.dataset.add(data);    }    @Override    public void add(String data) {        addData(data);        this.mysqlDatabase.addData(data);   // 维护同步到MySQL的同步作业    }    public void count() {        int count = this.dataset.size();        System.out.println(&quot;- Elasticsearch 统计，目前有 &quot; + count + &quot; 条数据，数据：&quot; + this.dataset.toString());    }}</code></pre><p>测试客户端，分别往三个数据库中加入一些数据查看同步效果</p><pre><code class="java">public class Client {    public static void main(String[] args) {        MysqlDatabase mysqlDatabase = new MysqlDatabase();        RedisDatabase redisDatabase = new RedisDatabase();        EsDatabase esDatabase = new EsDatabase();        mysqlDatabase.setRedisDatabase(redisDatabase);        mysqlDatabase.setEsDatabase(esDatabase);        esDatabase.setMysqlDatabase(mysqlDatabase);        System.out.println(&quot;\n---------mysql 添加数据 1，将同步到Redis和ES中-----------&quot;);        mysqlDatabase.add(&quot;1&quot;);        mysqlDatabase.select();        redisDatabase.cache();        esDatabase.count();        System.out.println(&quot;\n---------Redis添加数据 2，将不同步到其它数据库-----------&quot;);        redisDatabase.add(&quot;2&quot;);        mysqlDatabase.select();        redisDatabase.cache();        esDatabase.count();        System.out.println(&quot;\n---------ES 添加数据 3，只同步到 Mysql-----------&quot;);        esDatabase.add(&quot;3&quot;);        mysqlDatabase.select();        redisDatabase.cache();        esDatabase.count();    }}</code></pre><p>输出结果</p><pre><code class="java">---------mysql 添加数据 1，将同步到Redis和ES中-----------Mysql 添加数据：1Redis 添加数据：1ES 添加数据：1- Mysql 查询，数据：[1]- Redis 缓存的数据：[1]- Elasticsearch 统计，目前有 1 条数据，数据：[1]---------Redis添加数据 2，将不同步到其它数据库-----------Redis 添加数据：2- Mysql 查询，数据：[1]- Redis 缓存的数据：[1, 2]- Elasticsearch 统计，目前有 1 条数据，数据：[1]---------ES 添加数据 3，只同步到 Mysql-----------ES 添加数据：3Mysql 添加数据：3- Mysql 查询，数据：[1, 3]- Redis 缓存的数据：[1, 2]- Elasticsearch 统计，目前有 2 条数据，数据：[1, 3]</code></pre><p>其实这样已经实现了我们的需求，但是<strong>存在一些问题</strong>：</p><ul><li><strong>系统结构复杂且耦合度高</strong>。数据源需要维护目标端数据库的引用，以便完成数据同步</li><li><strong>组件的可重用性差</strong>。由于每一个数据源和目标端之间具有很强的关联，若没有目标端的支持，这个组件很难被另一个系统或模块重用</li><li><strong>系统的可扩展性差</strong>：如果需要增加、修改或删除其中一个数据库、将导致多个类的源代码需要修改，这违反了 “开闭原则”，可扩展性和灵活性欠佳。</li></ul><p>我们<strong>使用中介者模式来重构</strong>，将数据同步的功能迁移到中介者中，由中介者来管理数据同步作业</p><p>首先还是抽象数据库类（抽象同事类），维护了一个中介者</p><pre><code class="java">public abstract class AbstractDatabase {    public static final String MYSQL = &quot;mysql&quot;;    public static final String REDIS = &quot;redis&quot;;    public static final String ELASTICSEARCH = &quot;elasticsearch&quot;;    protected AbstractMediator mediator;    // 中介者    public AbstractDatabase(AbstractMediator mediator) {        this.mediator = mediator;    }    public abstract void addData(String data);    public abstract void add(String data);}</code></pre><p>Mysql 数据库（具体同事类）</p><pre><code class="java">public class MysqlDatabase extends AbstractDatabase {    private List&lt;String&gt; dataset = new ArrayList&lt;String&gt;();    public MysqlDatabase(AbstractMediator mediator) {        super(mediator);    }    @Override    public void addData(String data) {        System.out.println(&quot;Mysql 添加数据：&quot; + data);        this.dataset.add(data);    }    @Override    public void add(String data) {        addData(data);        this.mediator.sync(AbstractDatabase.MYSQL, data); // 数据同步作业交给中介者管理    }    public void select() {        System.out.println(&quot;Mysql 查询，数据：&quot; + this.dataset.toString());    }}</code></pre><p>Redis 数据库（具体同事类）</p><pre><code class="java">public class RedisDatabase extends AbstractDatabase {    private List&lt;String&gt; dataset = new LinkedList&lt;String&gt;();    public RedisDatabase(AbstractMediator mediator) {        super(mediator);    }    @Override    public void addData(String data) {        System.out.println(&quot;Redis 添加数据：&quot; + data);        this.dataset.add(data);    }    @Override    public void add(String data) {        addData(data);        this.mediator.sync(AbstractDatabase.REDIS, data);    // 数据同步作业交给中介者管理    }    public void cache() {        System.out.println(&quot;Redis 缓存的数据：&quot; + this.dataset.toString());    }}</code></pre><p>Elasticsearch（具体同事类）</p><pre><code class="java">public class EsDatabase extends AbstractDatabase {    private List&lt;String&gt; dataset = new CopyOnWriteArrayList&lt;String&gt;();    public EsDatabase(AbstractMediator mediator) {        super(mediator);    }    @Override    public void addData(String data) {        System.out.println(&quot;ES 添加数据：&quot; + data);        this.dataset.add(data);    }    @Override    public void add(String data) {        addData(data);        this.mediator.sync(AbstractDatabase.ELASTICSEARCH, data);    // 数据同步作业交给中介者管理    }    public void count() {        int count = this.dataset.size();        System.out.println(&quot;Elasticsearch 统计，目前有 &quot; + count + &quot; 条数据，数据：&quot; + this.dataset.toString());    }}</code></pre><p>抽象中介者</p><pre><code class="java">@Datapublic abstract class AbstractMediator {    protected MysqlDatabase mysqlDatabase;    protected RedisDatabase redisDatabase;    protected EsDatabase esDatabase;    public abstract void sync(String databaseName, String data);}</code></pre><p>具体中介者</p><pre><code class="java">public class SyncMediator extends AbstractMediator {    @Override    public void sync(String databaseName, String data) {        if (AbstractDatabase.MYSQL.equals(databaseName)) {            // mysql 同步到 redis 和 Elasticsearch            this.redisDatabase.addData(data);            this.esDatabase.addData(data);        } else if (AbstractDatabase.REDIS.equals(databaseName)) {            // redis 缓存同步，不需要同步到其他数据库        } else if (AbstractDatabase.ELASTICSEARCH.equals(databaseName)) {            // Elasticsearch 同步到 Mysql            this.mysqlDatabase.addData(data);        }    }}</code></pre><p>测试客户端</p><pre><code class="java">public class Client {    public static void main(String[] args) {        AbstractMediator syncMediator = new SyncMediator();        MysqlDatabase mysqlDatabase = new MysqlDatabase(syncMediator);        RedisDatabase redisDatabase = new RedisDatabase(syncMediator);        EsDatabase esDatabase = new EsDatabase(syncMediator);        syncMediator.setMysqlDatabase(mysqlDatabase);        syncMediator.setRedisDatabase(redisDatabase);        syncMediator.setEsDatabase(esDatabase);        System.out.println(&quot;\n---------mysql 添加数据 1，将同步到Redis和ES中-----------&quot;);        mysqlDatabase.add(&quot;1&quot;);        mysqlDatabase.select();        redisDatabase.cache();        esDatabase.count();        System.out.println(&quot;\n---------Redis添加数据 2，将不同步到其它数据库-----------&quot;);        redisDatabase.add(&quot;2&quot;);        mysqlDatabase.select();        redisDatabase.cache();        esDatabase.count();        System.out.println(&quot;\n---------ES 添加数据 3，只同步到 Mysql-----------&quot;);        esDatabase.add(&quot;3&quot;);        mysqlDatabase.select();        redisDatabase.cache();        esDatabase.count();    }}</code></pre><p>输出结果，与预期一致</p><pre><code>---------mysql 添加数据 1，将同步到Redis和ES中-----------Mysql 添加数据：1Redis 添加数据：1ES 添加数据：1- Mysql 查询，数据：[1]- Redis 缓存的数据：[1]- Elasticsearch 统计，目前有 1 条数据，数据：[1]---------Redis添加数据 2，将不同步到其它数据库-----------Redis 添加数据：2- Mysql 查询，数据：[1]- Redis 缓存的数据：[1, 2]- Elasticsearch 统计，目前有 1 条数据，数据：[1]---------ES 添加数据 3，只同步到 Mysql-----------ES 添加数据：3Mysql 添加数据：3- Mysql 查询，数据：[1, 3]- Redis 缓存的数据：[1, 2]- Elasticsearch 统计，目前有 2 条数据，数据：[1, 3]</code></pre><p>画出类图如下</p><p><img src="http://image.laijianfeng.org/20181025_193153.png" alt="示例.中介者模式"></p><h2 id="中介者模式总结"><a href="#中介者模式总结" class="headerlink" title="中介者模式总结"></a>中介者模式总结</h2><h3 id="中介者模式的主要优点"><a href="#中介者模式的主要优点" class="headerlink" title="中介者模式的主要优点"></a>中介者模式的主要优点</h3><ul><li><p>中介者模式<strong>简化了对象之间的交互</strong>，它用中介者和同事的一对多交互代替了原来同事之间的多对多交互，一对多关系更容易理解、维护和扩展，将原本难以理解的网状结构转换成相对简单的星型结构。</p></li><li><p>中介者模式可<strong>将各同事对象解耦</strong>。中介者有利于各同事之间的松耦合，我们可以独立的改变和复用每一个同事和中介者，增加新的中介者和新的同事类都比较方便，更好地符合 “开闭原则”。</p></li><li><p>可以<strong>减少子类生成</strong>，中介者将原本分布于多个对象间的行为集中在一起，改变这些行为只需生成新的中介者子类即可，这使各个同事类可被重用，无须对同事类进行扩展。</p></li></ul><h3 id="中介者模式的主要缺点"><a href="#中介者模式的主要缺点" class="headerlink" title="中介者模式的主要缺点"></a>中介者模式的主要缺点</h3><ul><li>在<strong>具体中介者类中包含了大量同事之间的交互细节</strong>，可能会导致具体中介者类非常复杂，使得系统难以维护。（也就是把具体同事类之间的交互复杂性集中到了中介者类中，结果中介者成了最复杂的类）</li></ul><h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><ul><li><p>系统中对象之间存在复杂的引用关系，系统结构混乱且难以理解。</p></li><li><p>一个对象由于引用了其他很多对象并且直接和这些对象通信，导致难以复用该对象。</p></li><li><p>想通过一个中间类来封装多个类中的行为，而又不想生成太多的子类。可以通过引入中介者类来实现，在中介者中定义对象交互的公共行为，如果需要改变行为则可以增加新的具体中介者类。</p></li></ul><h2 id="中介者模式的典型应用"><a href="#中介者模式的典型应用" class="headerlink" title="中介者模式的典型应用"></a>中介者模式的典型应用</h2><h3 id="Java-Timer-中的中介者模式"><a href="#Java-Timer-中的中介者模式" class="headerlink" title="Java Timer 中的中介者模式"></a>Java Timer 中的中介者模式</h3><p>敲一个 <code>java.util.Timer</code> 的Demo</p><p>两个任务类</p><pre><code class="java">public class MyOneTask extends TimerTask {    private static int num = 0;    @Override    public void run() {        System.out.println(&quot;I&#39;m MyOneTask &quot; + ++num);    }}public class MyTwoTask extends TimerTask {    private static int num = 1000;    @Override    public void run() {        System.out.println(&quot;I&#39;m MyTwoTask &quot; + num--);    }}</code></pre><p>客户端测试，3秒后开始执行，循环周期为 1秒</p><pre><code class="java">public class TimerTest {    public static void main(String[] args) {        // 注意：多线程并行处理定时任务时，Timer运行多个TimeTask时，只要其中之一没有捕获抛出的异常，        // 其它任务便会自动终止运行，使用ScheduledExecutorService则没有这个问题        Timer timer = new Timer();        timer.schedule(new MyOneTask(), 3000, 1000); // 3秒后开始运行，循环周期为 1秒        timer.schedule(new MyTwoTask(), 3000, 1000);    }}</code></pre><p>输出</p><pre><code>I&#39;m MyOneTask 1I&#39;m MyTwoTask 1000I&#39;m MyTwoTask 999I&#39;m MyOneTask 2I&#39;m MyOneTask 3I&#39;m MyTwoTask 998I&#39;m MyTwoTask 997I&#39;m MyOneTask 4I&#39;m MyOneTask 5I&#39;m MyTwoTask 996I&#39;m MyTwoTask 995I&#39;m MyOneTask 6...</code></pre><p><code>Timer</code> 的部分关键源码如下</p><pre><code class="java">public class Timer {    private final TaskQueue queue = new TaskQueue();    private final TimerThread thread = new TimerThread(queue);    public void schedule(TimerTask task, long delay) {        if (delay &lt; 0)            throw new IllegalArgumentException(&quot;Negative delay.&quot;);        sched(task, System.currentTimeMillis()+delay, 0);    }    public void schedule(TimerTask task, Date time) {        sched(task, time.getTime(), 0);    }    private void sched(TimerTask task, long time, long period) {        if (time &lt; 0)            throw new IllegalArgumentException(&quot;Illegal execution time.&quot;);        if (Math.abs(period) &gt; (Long.MAX_VALUE &gt;&gt; 1))            period &gt;&gt;= 1;        // 获取任务队列的锁(同一个线程多次获取这个锁并不会被阻塞,不同线程获取时才可能被阻塞)        synchronized(queue) {            // 如果定时调度线程已经终止了,则抛出异常结束            if (!thread.newTasksMayBeScheduled)                throw new IllegalStateException(&quot;Timer already cancelled.&quot;);            // 再获取定时任务对象的锁(为什么还要再加这个锁呢?想不清)            synchronized(task.lock) {                // 判断线程的状态,防止多线程同时调度到一个任务时多次被加入任务队列                if (task.state != TimerTask.VIRGIN)                    throw new IllegalStateException(                        &quot;Task already scheduled or cancelled&quot;);                // 初始化定时任务的下次执行时间                task.nextExecutionTime = time;                // 重复执行的间隔时间                task.period = period;                // 将定时任务的状态由TimerTask.VIRGIN(一个定时任务的初始化状态)设置为TimerTask.SCHEDULED                task.state = TimerTask.SCHEDULED;            }            // 将任务加入任务队列            queue.add(task);            // 如果当前加入的任务是需要第一个被执行的(也就是他的下一次执行时间离现在最近)            // 则唤醒等待queue的线程(对应到上面提到的queue.wait())            if (queue.getMin() == task)                queue.notify();        }    }    // cancel会等到所有定时任务执行完后立刻终止定时线程    public void cancel() {        synchronized(queue) {            thread.newTasksMayBeScheduled = false;            queue.clear();            queue.notify();  // In case queue was already empty.        }    }    // ...}</code></pre><p><code>Timer</code> 中在 <code>schedulexxx</code> 方法中通过 <code>TaskQueue</code> 协调各种 <code>TimerTask</code> 定时任务，<code>Timer</code> 是中介者，<code>TimerTask</code> 是抽象同事类，而我们自己写的任务则是具体同事类</p><p><code>TimerThread</code> 是 <code>Timer</code> 中定时调度线程类的定义，这个类会做为一个线程一直运行来执行 <code>Timer</code> 中任务队列中的任务。</p><p><code>Timer</code> 这个中介者的功能就是<strong>定时调度我们写的各种任务</strong>，将任务添加到 <code>TaskQueue</code> 任务队列中，给 <code>TimerThread</code> 执行，让任务与执行线程解耦</p><h3 id="其他的中介者模式应用"><a href="#其他的中介者模式应用" class="headerlink" title="其他的中介者模式应用"></a>其他的中介者模式应用</h3><ul><li><p><code>java.util.concurrent.Executor#execute</code> 和 <code>java.util.concurrent.ExecutorService#submit</code> 与 <code>Timer#schedule</code> 类似</p></li><li><p>MVC模式中，Controller 是中介者，根据 View 层的请求来操作 Model 层</p></li></ul><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析<br><a href="https://www.jianshu.com/p/58a5b0853451" target="_blank" rel="noopener">java.util系列源码解读之Timer定时器</a></p></blockquote><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>欢迎评论、转发、分享，您的支持是我最大的动力</p><p>关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>设计模式 | 备忘录模式及典型应用</title>
      <link href="/2018/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2018/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>本文的主要内容：</p><ul><li>介绍备忘录模式</li><li>示例</li><li>备忘录模式总结</li></ul><h2 id="备忘录模式"><a href="#备忘录模式" class="headerlink" title="备忘录模式"></a>备忘录模式</h2><p>备忘录模式经常可以遇到，譬如下面这些场景：</p><ul><li><p><strong>浏览器回退</strong>：浏览器一般有浏览记录，当我们在一个网页上点击几次链接之后，可在左上角点击左箭头回退到上一次的页面，然后也可以点击右箭头重新回到当前页面</p></li><li><p><strong>数据库备份与还原</strong>：一般的数据库都支持备份与还原操作，备份即将当前已有的数据或者记录保留，还原即将已经保留的数据恢复到对应的表中</p></li><li><p><strong>编辑器撤销与重做</strong>：在编辑器上编辑文字，写错时可以按快捷键 <code>Ctrl + z</code> 撤销，撤销后可以按 <code>Ctrl + y</code> 重做</p></li><li><p><strong>虚拟机生成快照与恢复</strong>：虚拟机可以生成一个快照，当虚拟机发生错误时可以恢复到快照的样子</p></li><li><p><strong>Git版本管理</strong>：Git是最常见的版本管理软件，每提交一个新版本，实际上Git就会把它们自动串成一条时间线，每个版本都有一个版本号，使用 <code>git reset --hard 版本号</code> 即可回到指定的版本，让代码时空穿梭回到过去某个历史时刻</p></li><li><p><strong>棋牌游戏悔棋</strong>：在棋牌游戏中，有时下快了可以悔棋，回退到上一步重新下</p></li></ul><p><img src="http://image.laijianfeng.org/20181024_233428.png" alt="浏览器回退"></p><p><img src="http://image.laijianfeng.org/20181024_235908.png" alt="编辑器撤销"></p><p><strong>备忘录模式(Memento Pattern)</strong>：在不破坏封装的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，这样可以在以后将对象恢复到原先保存的状态。它是一种对象行为型模式，其别名为Token。</p><p><img src="http://image.laijianfeng.org/20181025_001332.png" alt="指针向左为撤销，向右为重做"></p><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><p><strong>Originator（原发器）</strong>：它是一个普通类，可以创建一个备忘录，并存储它的当前内部状态，也可以使用备忘录来恢复其内部状态，一般将需要保存内部状态的类设计为原发器。</p><p><strong>Memento（备忘录)</strong>：存储原发器的内部状态，根据原发器来决定保存哪些内部状态。备忘录的设计一般可以参考原发器的设计，根据实际需要确定备忘录类中的属性。需要注意的是，除了原发器本身与负责人类之外，备忘录对象不能直接供其他类使用，原发器的设计在不同的编程语言中实现机制会有所不同。</p><p><strong>Caretaker（负责人）</strong>：负责人又称为管理者，它负责保存备忘录，但是不能对备忘录的内容进行操作或检查。在负责人类中可以存储一个或多个备忘录对象，它只负责存储对象，而不能修改对象，也无须知道对象的实现细节。</p><p>备忘录模式的核心是备忘录类以及用于管理备忘录的负责人类的设计。</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>下棋例子，可以下棋，悔棋，撤销悔棋等</p><p>棋子类 <code>Chessman</code>，原发器角色</p><pre><code class="java">@Data@AllArgsConstructorclass Chessman {    private String label;    private int x;    private int y;    //保存状态    public ChessmanMemento save() {        return new ChessmanMemento(this.label, this.x, this.y);    }    //恢复状态    public void restore(ChessmanMemento memento) {        this.label = memento.getLabel();        this.x = memento.getX();        this.y = memento.getY();    }    public void show() {        System.out.println(String.format(&quot;棋子&lt;%s&gt;：当前位置为：&lt;%d, %d&gt;&quot;, this.getLabel(), this.getX(), this.getY()));    }}</code></pre><p>备忘录角色 <code>ChessmanMemento</code></p><pre><code class="java">@Data@AllArgsConstructorclass ChessmanMemento {    private String label;    private int x;    private int y;}</code></pre><p>负责人角色 <code>MementoCaretaker</code></p><pre><code class="java">class MementoCaretaker {    //定义一个集合来存储备忘录    private ArrayList mementolist = new ArrayList();    public ChessmanMemento getMemento(int i) {        return (ChessmanMemento) mementolist.get(i);    }    public void addMemento(ChessmanMemento memento) {        mementolist.add(memento);    }}</code></pre><p>棋子客户端，维护了一个 <code>MementoCaretaker</code> 对象</p><pre><code class="java">class Client {    private static int index = -1;    private static MementoCaretaker mc = new MementoCaretaker();    public static void main(String args[]) {        Chessman chess = new Chessman(&quot;车&quot;, 1, 1);        play(chess);        chess.setY(4);        play(chess);        chess.setX(5);        play(chess);        undo(chess, index);        undo(chess, index);        redo(chess, index);        redo(chess, index);    }    //下棋，同时保存备忘录    public static void play(Chessman chess) {        mc.addMemento(chess.save());        index++;        chess.show();    }    //悔棋，撤销到上一个备忘录    public static void undo(Chessman chess, int i) {        System.out.println(&quot;******悔棋******&quot;);        index--;        chess.restore(mc.getMemento(i - 1));        chess.show();    }    //撤销悔棋，恢复到下一个备忘录    public static void redo(Chessman chess, int i) {        System.out.println(&quot;******撤销悔棋******&quot;);        index++;        chess.restore(mc.getMemento(i + 1));        chess.show();    }}</code></pre><p>输出如下，悔棋成功，撤销悔棋成功</p><pre><code>棋子&lt;车&gt;：当前位置为：&lt;1, 1&gt;棋子&lt;车&gt;：当前位置为：&lt;1, 4&gt;棋子&lt;车&gt;：当前位置为：&lt;5, 4&gt;******悔棋******棋子&lt;车&gt;：当前位置为：&lt;1, 4&gt;******悔棋******棋子&lt;车&gt;：当前位置为：&lt;1, 1&gt;******撤销悔棋******棋子&lt;车&gt;：当前位置为：&lt;1, 4&gt;******撤销悔棋******棋子&lt;车&gt;：当前位置为：&lt;5, 4&gt;</code></pre><p>类图如下</p><p><img src="http://image.laijianfeng.org/20181024_113151.png" alt="示例.备忘录模式类图"></p><h2 id="备忘录模式总结"><a href="#备忘录模式总结" class="headerlink" title="备忘录模式总结"></a>备忘录模式总结</h2><p>备忘录模式的<strong>主要优点</strong>如下：</p><ul><li><p>它提供了一种状态恢复的实现机制，使得用户可以方便地回到一个特定的历史步骤，当新的状态无效或者存在问题时，可以使用暂时存储起来的备忘录将状态复原。</p></li><li><p>备忘录实现了对信息的封装，一个备忘录对象是一种原发器对象状态的表示，不会被其他代码所改动。备忘录保存了原发器的状态，采用列表、堆栈等集合来存储备忘录对象可以实现多次撤销操作。</p></li></ul><p>备忘录模式的<strong>主要缺点</strong>如下：</p><ul><li>资源消耗过大，如果需要保存的原发器类的成员变量太多，就不可避免需要占用大量的存储空间，每保存一次对象的状态都需要消耗一定的系统资源。</li></ul><p><strong>适用场景</strong>：</p><ul><li><p>保存一个对象在某一个时刻的全部状态或部分状态，这样以后需要时它能够恢复到先前的状态，实现撤销操作。</p></li><li><p>防止外界对象破坏一个对象历史状态的封装性，避免将对象历史状态的实现细节暴露给外界对象。</p></li></ul><blockquote><p>由于软件中JDK、Spring、Mybatis中很少有备忘录模式，也许 Spring webflow 中的 StateManageableMessageContext 接口算一个，但是真的很少见，所以这里不做典型应用源码分析</p></blockquote><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>设计模式 | 观察者模式及典型应用</title>
      <link href="/2018/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2018/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>本文主要内容：</p><ul><li>介绍观察者模式</li><li>微信公众号的发布/订阅示例</li><li>观察者模式总结</li><li>分析观察者模式的典型应用<ul><li>JDK 提供的观察者接口中的观察者模式</li><li>Guava EventBus 中的观察者模式</li><li>JDK 委托事件模型DEM中的观察者模式</li><li>Spring ApplicationContext 事件机制中的观察者模式</li></ul></li></ul><h2 id="观察者模式"><a href="#观察者模式" class="headerlink" title="观察者模式"></a>观察者模式</h2><p>观察者模式是设计模式中的 “超级模式”，其应用随处可见，我们以微信公众号为例。</p><p>微信公众号有服务号、订阅号和企业号之分。以我的公众号为例，我的公众号类型是订阅号，名称是 “小旋锋”，专注于大数据，Java后端类技术分享。目前主要是分享学习笔记为主，尽量做到 “原创”、”高质量”、”成体系”。每当我发布一篇博文推送，订阅的用户都能够在我发布推送之后及时接收到推送，即可方便地在手机端进行阅读。</p><p><img src="http://image.laijianfeng.org/20181023_193152.jpg" alt="微信公众号.发布/订阅"></p><p><strong>观察者模式(Observer Pattern)</strong>：定义对象之间的一种一对多依赖关系，使得每当一个对象状态发生改变时，其相关依赖对象皆得到通知并被自动更新。观察者模式是一种对象行为型模式。</p><p>观察者模式的别名包括发布-订阅（Publish/Subscribe）模式、模型-视图（Model/View）模式、源-监听器（Source/Listener）模式或从属者（Dependents）模式。</p><p>观察者模式包含观察目标和观察者两类对象，一个目标可以有任意数目的与之相依赖的观察者，一旦观察目标的状态发生改变，所有的观察者都将得到通知。</p><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><p><strong>Subject（目标）</strong>：目标又称为主题，它是指被观察的对象。在目标中定义了一个观察者集合，一个观察目标可以接受任意数量的观察者来观察，它提供一系列方法来增加和删除观察者对象，同时它定义了通知方法notify()。目标类可以是接口，也可以是抽象类或具体类。</p><p><strong>ConcreteSubject（具体目标）</strong>：具体目标是目标类的子类，通常它包含有经常发生改变的数据，当它的状态发生改变时，向它的各个观察者发出通知；同时它还实现了在目标类中定义的抽象业务逻辑方法（如果有的话）。如果无须扩展目标类，则具体目标类可以省略。</p><p><strong>Observer（观察者）</strong>：观察者将对观察目标的改变做出反应，观察者一般定义为接口，该接口声明了更新数据的方法update()，因此又称为抽象观察者。</p><p><strong>ConcreteObserver（具体观察者）</strong>：在具体观察者中维护一个指向具体目标对象的引用，它存储具体观察者的有关状态，这些状态需要和具体目标的状态保持一致；它实现了在抽象观察者Observer中定义的update()方法。通常在实现时，可以调用具体目标类的attach()方法将自己添加到目标类的集合中或通过detach()方法将自己从目标类的集合中删除。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>首先需要一个订阅者接口（观察者），该接口有一个 <code>receive</code> 方法，用于接收公众号推送通知</p><pre><code class="java">public interface Subscriber {    int receive(String publisher, String articleName);}</code></pre><p>然后是一个微信客户端（具体观察者），实现了 <code>receive</code> 方法</p><pre><code class="java">public class WeChatClient implements Subscriber {    private String username;    public WeChatClient(String username) {        this.username = username;    }    @Override    public int receive(String publisher, String articleName) {        // 接收到推送时的操作        System.out.println(String.format(&quot;用户&lt;%s&gt; 接收到 &lt;%s&gt;微信公众号 的推送，文章标题为 &lt;%s&gt;&quot;, username, publisher, articleName));        return 0;    }}</code></pre><p>发布者类（目标，被观察对象），该类维护了一个订阅者列表，实现了订阅、取消订阅、通知所有订阅者等功能</p><pre><code class="java">public class Publisher {    private List&lt;Subscriber&gt; subscribers;    private boolean pubStatus = false;    public Publisher() {        subscribers = new ArrayList&lt;Subscriber&gt;();    }    protected void subscribe(Subscriber subscriber) {        this.subscribers.add(subscriber);    }    protected void unsubscribe(Subscriber subscriber) {        if (this.subscribers.contains(subscriber)) {            this.subscribers.remove(subscriber);        }    }    protected void notifySubscribers(String publisher, String articleName) {        if (this.pubStatus == false) {            return;        }        for (Subscriber subscriber : this.subscribers) {            subscriber.receive(publisher, articleName);        }        this.clearPubStatus();    }    protected void setPubStatus() {        this.pubStatus = true;    }    protected void clearPubStatus() {        this.pubStatus = false;    }}</code></pre><p>微信公众号类（具体目标），该类提供了 <code>publishArticles</code> 方法，用于发布推送，当文章发布完毕时调用父类的通知所有订阅者方法</p><pre><code class="java">public class WeChatAccounts extends Publisher {    private String name;    public WeChatAccounts(String name) {        this.name = name;    }    public void publishArticles(String articleName, String content) {        System.out.println(String.format(&quot;\n&lt;%s&gt;微信公众号 发布了一篇推送，文章名称为 &lt;%s&gt;，内容为 &lt;%s&gt; &quot;, this.name, articleName, content));        setPubStatus();        notifySubscribers(this.name, articleName);    }}</code></pre><p>测试</p><pre><code class="java">public class Test {    public static void main(String[] args) {        WeChatAccounts accounts = new WeChatAccounts(&quot;小旋锋&quot;);        WeChatClient user1 = new WeChatClient(&quot;张三&quot;);        WeChatClient user2 = new WeChatClient(&quot;李四&quot;);        WeChatClient user3 = new WeChatClient(&quot;王五&quot;);        accounts.subscribe(user1);        accounts.subscribe(user2);        accounts.subscribe(user3);        accounts.publishArticles(&quot;设计模式 | 观察者模式及典型应用&quot;, &quot;观察者模式的内容...&quot;);        accounts.unsubscribe(user1);        accounts.publishArticles(&quot;设计模式 | 单例模式及典型应用&quot;, &quot;单例模式的内容....&quot;);    }}</code></pre><p>结果如下，符合预期，当公众号发布一篇推送时，订阅该公众号的用户可及时接收到推送的通知</p><pre><code>&lt;小旋锋&gt;微信公众号 发布了一篇推送，文章名称为 &lt;设计模式 | 观察者模式及典型应用&gt;，内容为 &lt;观察者模式的内容...&gt; 用户&lt;张三&gt; 接收到 &lt;小旋锋&gt;微信公众号 的推送，文章标题为 &lt;设计模式 | 观察者模式及典型应用&gt;用户&lt;李四&gt; 接收到 &lt;小旋锋&gt;微信公众号 的推送，文章标题为 &lt;设计模式 | 观察者模式及典型应用&gt;用户&lt;王五&gt; 接收到 &lt;小旋锋&gt;微信公众号 的推送，文章标题为 &lt;设计模式 | 观察者模式及典型应用&gt;&lt;小旋锋&gt;微信公众号 发布了一篇推送，文章名称为 &lt;设计模式 | 单例模式及典型应用&gt;，内容为 &lt;单例模式的内容....&gt; 用户&lt;李四&gt; 接收到 &lt;小旋锋&gt;微信公众号 的推送，文章标题为 &lt;设计模式 | 单例模式及典型应用&gt;用户&lt;王五&gt; 接收到 &lt;小旋锋&gt;微信公众号 的推送，文章标题为 &lt;设计模式 | 单例模式及典型应用&gt;</code></pre><p>可画出类图如下</p><p><img src="http://image.laijianfeng.org/20181023_171948.png" alt="示例.观察者模式类图"></p><p>借此机会做个小推广，欢迎大家关注我的微信公众号哦 \^_\^</p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注【小旋锋】微信公众号"></p><h2 id="观察者模式总结"><a href="#观察者模式总结" class="headerlink" title="观察者模式总结"></a>观察者模式总结</h2><p>观察者模式的<strong>主要优点</strong>如下：</p><ul><li><p>观察者模式可以实现表示层和数据逻辑层的分离，定义了稳定的消息更新传递机制，并抽象了更新接口，使得可以有各种各样不同的表示层充当具体观察者角色。</p></li><li><p>观察者模式在观察目标和观察者之间建立一个抽象的耦合。观察目标只需要维持一个抽象观察者的集合，无须了解其具体观察者。由于观察目标和观察者没有紧密地耦合在一起，因此它们可以属于不同的抽象化层次。</p></li><li><p>观察者模式支持广播通信，观察目标会向所有已注册的观察者对象发送通知，简化了一对多系统设计的难度。</p></li><li><p>观察者模式满足 “开闭原则” 的要求，增加新的具体观察者无须修改原有系统代码，在具体观察者与观察目标之间不存在关联关系的情况下，增加新的观察目标也很方便。</p></li></ul><p>观察者模式的<strong>主要缺点</strong>如下：</p><ul><li><p>如果一个观察目标对象有很多直接和间接观察者，将所有的观察者都通知到会花费很多时间。</p></li><li><p>如果在观察者和观察目标之间存在循环依赖，观察目标会触发它们之间进行循环调用，可能导致系统崩溃。</p></li><li><p>观察者模式没有相应的机制让观察者知道所观察的目标对象是怎么发生变化的，而仅仅只是知道观察目标发生了变化。</p></li></ul><p><strong>适用场景</strong>：</p><ul><li><p>一个抽象模型有两个方面，其中一个方面依赖于另一个方面，将这两个方面封装在独立的对象中使它们可以各自独立地改变和复用。</p></li><li><p>一个对象的改变将导致一个或多个其他对象也发生改变，而并不知道具体有多少对象将发生改变，也不知道这些对象是谁。</p></li><li><p>需要在系统中创建一个触发链，A对象的行为将影响B对象，B对象的行为将影响C对象……，可以使用观察者模式创建一种链式触发机制。</p></li></ul><h2 id="观察者模式的典型应用"><a href="#观察者模式的典型应用" class="headerlink" title="观察者模式的典型应用"></a>观察者模式的典型应用</h2><h3 id="JDK-提供的观察者接口"><a href="#JDK-提供的观察者接口" class="headerlink" title="JDK 提供的观察者接口"></a>JDK 提供的观察者接口</h3><p>观察者模式在Java语言中的地位非常重要。在JDK的 <code>java.util</code> 包中，提供了 <code>Observable</code> 类以及 <code>Observer</code> 接口，它们构成了JDK对观察者模式的支持。</p><p>其中的 <code>Observer</code> 接口为观察者，只有一个 <code>update</code> 方法，当观察目标发生变化时被调用，其代码如下：</p><pre><code class="java">public interface Observer {    void update(Observable o, Object arg);}</code></pre><p><code>Observable</code> 类则为目标类，相比我们的示例中的 <code>Publisher</code> 类多了并发和NPE方面的考虑</p><pre><code class="java">public class Observable {    private boolean changed = false;    private Vector&lt;Observer&gt; obs = new Vector();    public Observable() {    }    // 用于注册新的观察者对象到向量中    public synchronized void addObserver(Observer var1) {        if (var1 == null) {            throw new NullPointerException();        } else {            if (!this.obs.contains(var1)) {                this.obs.addElement(var1);            }        }    }    // 用于删除向量中的某一个观察者对象    public synchronized void deleteObserver(Observer var1) {        this.obs.removeElement(var1);    }    public void notifyObservers() {        this.notifyObservers((Object)null);    }    // 通知方法，用于在方法内部循环调用向量中每一个观察者的update()方法    public void notifyObservers(Object var1) {        Object[] var2;        synchronized(this) {            if (!this.changed) {                return;            }            var2 = this.obs.toArray();            this.clearChanged();        }        for(int var3 = var2.length - 1; var3 &gt;= 0; --var3) {            ((Observer)var2[var3]).update(this, var1);        }    }    // 用于清空向量，即删除向量中所有观察者对象    public synchronized void deleteObservers() {        this.obs.removeAllElements();    }    // 该方法被调用后会设置一个boolean类型的内部标记变量changed的值为true，表示观察目标对象的状态发生了变化    protected synchronized void setChanged() {        this.changed = true;    }    // 用于将changed变量的值设为false，表示对象状态不再发生改变或者已经通知了所有的观察者对象，调用了它们的update()方法    protected synchronized void clearChanged() {        this.changed = false;    }    // 返回对象状态是否改变    public synchronized boolean hasChanged() {        return this.changed;    }    // 返回向量中观察者的数量    public synchronized int countObservers() {        return this.obs.size();    }}</code></pre><p>我们可以使用 <code>Observable</code> 类以及 <code>Observer</code> 接口来重新实现微信公众号示例。</p><p>增加一个通知类 <code>WechatNotice</code>，用于推送通知的传递</p><pre><code class="java">@Data@AllArgsConstructorpublic class WechatNotice {    private String publisher;    private String articleName;}</code></pre><p>然后改写 <code>WeChatClient</code> 和 <code>WeChatAccounts</code>，分别实现JDK的 <code>Observer</code> 接口和继承 <code>Observable</code> 类</p><pre><code class="java">public class WeChatClient implements Observer {    private String username;    public WeChatClient(String username) {        this.username = username;    }    @Override    public void update(Observable o, Object arg) {        //WeChatAccounts weChatAccounts = (WeChatAccounts) o;        WechatNotice notice = (WechatNotice) arg;        System.out.println(String.format(&quot;用户&lt;%s&gt; 接收到 &lt;%s&gt;微信公众号 的推送，文章标题为 &lt;%s&gt;&quot;, username, notice.getPublisher(), notice.getArticleName()));    }}public class WeChatAccounts extends Observable {    private String name;    public WeChatAccounts(String name) {        this.name = name;    }    public void publishArticles(String articleName, String content) {        System.out.println(String.format(&quot;\n&lt;%s&gt;微信公众号 发布了一篇推送，文章名称为 &lt;%s&gt;，内容为 &lt;%s&gt; &quot;, this.name, articleName, content));        setChanged();        notifyObservers(new WechatNotice(this.name, articleName));    }}</code></pre><p>测试，与示例中的测试代码的区别在于调用的方法不同</p><pre><code class="java">public class Test {    public static void main(String[] args) {        WeChatAccounts accounts = new WeChatAccounts(&quot;小旋锋&quot;);        WeChatClient user1 = new WeChatClient(&quot;张三&quot;);        WeChatClient user2 = new WeChatClient(&quot;李四&quot;);        WeChatClient user3 = new WeChatClient(&quot;王五&quot;);        accounts.addObserver(user1);        accounts.addObserver(user2);        accounts.addObserver(user3);        accounts.publishArticles(&quot;设计模式 | 观察者模式及典型应用&quot;, &quot;观察者模式的内容...&quot;);        accounts.deleteObserver(user1);        accounts.publishArticles(&quot;设计模式 | 单例模式及典型应用&quot;, &quot;单例模式的内容....&quot;);    }}</code></pre><p>测试结果如下，可以发现结果如示例一致</p><pre><code class="java">&lt;小旋锋&gt;微信公众号 发布了一篇推送，文章名称为 &lt;设计模式 | 观察者模式及典型应用&gt;，内容为 &lt;观察者模式的内容...&gt; 用户&lt;王五&gt; 接收到 &lt;小旋锋&gt;微信公众号 的推送，文章标题为 &lt;设计模式 | 观察者模式及典型应用&gt;用户&lt;李四&gt; 接收到 &lt;小旋锋&gt;微信公众号 的推送，文章标题为 &lt;设计模式 | 观察者模式及典型应用&gt;用户&lt;张三&gt; 接收到 &lt;小旋锋&gt;微信公众号 的推送，文章标题为 &lt;设计模式 | 观察者模式及典型应用&gt;&lt;小旋锋&gt;微信公众号 发布了一篇推送，文章名称为 &lt;设计模式 | 单例模式及典型应用&gt;，内容为 &lt;单例模式的内容....&gt; 用户&lt;王五&gt; 接收到 &lt;小旋锋&gt;微信公众号 的推送，文章标题为 &lt;设计模式 | 单例模式及典型应用&gt;用户&lt;李四&gt; 接收到 &lt;小旋锋&gt;微信公众号 的推送，文章标题为 &lt;设计模式 | 单例模式及典型应用&gt;</code></pre><h3 id="Guava-EventBus-中的观察者模式"><a href="#Guava-EventBus-中的观察者模式" class="headerlink" title="Guava EventBus 中的观察者模式"></a>Guava EventBus 中的观察者模式</h3><p>Guava 中的 <code>EventBus</code> 封装了友好的 “生产/消费模型”，通过非常简单的方式，实现了观察者模式中的监听注册，事件分发。</p><p>使用了 Guava <code>EventBus</code> 之后，如果需要订阅消息，不需要实现任何接口，只需在监听方法上加上 <code>@Subscribe</code> 注解即可，<code>EventBus</code> 提供了 <code>register</code> 和 <code>unregister</code> 方法用于注册与取消注册事件，当 <code>EventBus</code> 调用 <code>post</code> 方法时将把事件分发给注册的对象</p><p>使用 Guava 重新实现示例</p><pre><code class="java">@Data@AllArgsConstructorpublic class WechatNotice {    private String publisher;    private String articleName;}public class WeChatClient  {    private String username;    public WeChatClient(String username) {        this.username = username;    }    @Subscribe    public void listen(WechatNotice notice) {        System.out.println(String.format(&quot;用户&lt;%s&gt; 接收到 &lt;%s&gt;微信公众号 的推送，文章标题为 &lt;%s&gt;&quot;, username, notice.getPublisher(), notice.getArticleName()));    }}public class WeChatAccounts {    private String name;    private EventBus eventBus;    public WeChatAccounts(String name) {        this.name = name;        this.eventBus = new EventBus();    }    public void publishArticles(String articleName, String content) {        System.out.println(String.format(&quot;\n&lt;%s&gt;微信公众号 发布了一篇推送，文章名称为 &lt;%s&gt;，内容为 &lt;%s&gt; &quot;, this.name, articleName, content));        this.eventBus.post(new WechatNotice(this.name, articleName));    }    public void register(WeChatClient weChatClient) {        this.eventBus.register(weChatClient);    }    public void unregister(WeChatClient weChatClient) {        this.eventBus.unregister(weChatClient);    }}</code></pre><p>测试 </p><pre><code class="java">public class Test {    public static void main(String[] args) {        WeChatAccounts accounts = new WeChatAccounts(&quot;小旋锋&quot;);        WeChatClient user1 = new WeChatClient(&quot;张三&quot;);        WeChatClient user2 = new WeChatClient(&quot;李四&quot;);        WeChatClient user3 = new WeChatClient(&quot;王五&quot;);        accounts.register(user1);        accounts.register(user2);        accounts.register(user3);        accounts.publishArticles(&quot;设计模式 | 观察者模式及典型应用&quot;, &quot;观察者模式的内容...&quot;);        accounts.unregister(user1);        accounts.publishArticles(&quot;设计模式 | 单例模式及典型应用&quot;, &quot;单例模式的内容....&quot;);    }}</code></pre><p>不出意料，输出的内容与上面两个示例一样</p><pre><code>&lt;小旋锋&gt;微信公众号 发布了一篇推送，文章名称为 &lt;设计模式 | 观察者模式及典型应用&gt;，内容为 &lt;观察者模式的内容...&gt; 用户&lt;张三&gt; 接收到 &lt;小旋锋&gt;微信公众号 的推送，文章标题为 &lt;设计模式 | 观察者模式及典型应用&gt;用户&lt;李四&gt; 接收到 &lt;小旋锋&gt;微信公众号 的推送，文章标题为 &lt;设计模式 | 观察者模式及典型应用&gt;用户&lt;王五&gt; 接收到 &lt;小旋锋&gt;微信公众号 的推送，文章标题为 &lt;设计模式 | 观察者模式及典型应用&gt;&lt;小旋锋&gt;微信公众号 发布了一篇推送，文章名称为 &lt;设计模式 | 单例模式及典型应用&gt;，内容为 &lt;单例模式的内容....&gt; 用户&lt;李四&gt; 接收到 &lt;小旋锋&gt;微信公众号 的推送，文章标题为 &lt;设计模式 | 单例模式及典型应用&gt;用户&lt;王五&gt; 接收到 &lt;小旋锋&gt;微信公众号 的推送，文章标题为 &lt;设计模式 | 单例模式及典型应用&gt;</code></pre><blockquote><p>Guava EventBus 的更多用法可自行查看相关文档<br>Guava EventBus 源码分析可看这篇 <a href="http://t.cn/EZzC35B" target="_blank" rel="noopener">http://t.cn/EZzC35B</a></p></blockquote><h3 id="JDK-委托事件模型DEM中的观察者模式"><a href="#JDK-委托事件模型DEM中的观察者模式" class="headerlink" title="JDK 委托事件模型DEM中的观察者模式"></a>JDK 委托事件模型DEM中的观察者模式</h3><p>首先来敲一个AWT按钮监听事件的Demo</p><pre><code class="java">import java.awt.*;import java.awt.event.MouseAdapter;import java.awt.event.MouseEvent;import java.awt.event.WindowAdapter;import java.awt.event.WindowEvent;public class MouseEvents {    private Frame frame;    private Button button;    MouseEvents() {        frame = new Frame(&quot;点击按钮触发点击事件，控制台将打印日志&quot;);        frame.setBounds(300, 200, 600, 300);        frame.setLayout(new FlowLayout());        button = new Button(&quot;this is a button&quot;);        button.setFont(new Font(&quot;Default&quot;, 0, 30));        frame.add(button);        dealwithEvent();        frame.setVisible(true);    }    //事件监听器以及处理事件    private void dealwithEvent() {        // 监听窗体关闭事件        frame.addWindowListener(new WindowAdapter() {            @Override            public void windowClosing(WindowEvent e) {                System.exit(0);            }        });        button.addActionListener(new ActionListener() {            private int eventCount = 1;            @Override            public void actionPerformed(ActionEvent e) {                System.out.println(String.format(&quot;动作事件发生 %d 次&quot;, eventCount++));            }        });    }    public static void main(String[] args) {        new MouseEvents();    }}</code></pre><p>运行 main 方法桌面将弹出下面的面板和按钮</p><p><img src="http://image.laijianfeng.org/20181023_193151.png" alt="按钮监听鼠标事件"></p><p>按钮的 <code>addActionListener</code> 添加指定的动作侦听器，以接收发自此按钮的动作事件，当用户在按钮上按下或释放鼠标时，JVM将产生一个相应的 <code>ActionEvent</code> 类型的事件对象，并在触发事件时将调用按钮的 <code>fireXXX()</code> 方法（继承自 Component），在该方法内部，将调用注册到按钮中的 <code>ActionListener</code> 对象的 <code>actionPerformed()</code> 方法（也就是我们实现的匿名事件处理类），实现对事件的处理</p><pre><code>动作事件发生 1 次动作事件发生 2 次动作事件发生 3 次动作事件发生 4 次</code></pre><h3 id="Spring-ApplicationContext-事件机制中的观察者模式"><a href="#Spring-ApplicationContext-事件机制中的观察者模式" class="headerlink" title="Spring ApplicationContext 事件机制中的观察者模式"></a>Spring ApplicationContext 事件机制中的观察者模式</h3><p>spring的事件机制是从java的事件机制拓展而来，<code>ApplicationContext</code> 中事件处理是由 <code>ApplicationEvent</code> 类和 <code>ApplicationListener</code> 接口来提供的。如果一个Bean实现了 <code>ApplicationListener</code> 接口，并且已经发布到容器中去，每次 <code>ApplicationContext</code> 发布一个 <code>ApplicationEvent</code> 事件，这个Bean就会接到通知</p><ul><li>ApplicationContext：事件源，其中的 publishEvent()方法用于触发容器事件</li><li>ApplicationEvent：事件本身，自定义事件需要继承该类，可以用来传递数据</li><li>ApplicationListener：事件监听器接口，事件的业务逻辑封装在监听器里面</li></ul><p>使用 spring 事件机制重新实现示例</p><pre><code class="java">@Datapublic class WechatNotice extends ApplicationEvent {    private String publisher;    private String articleName;    public WechatNotice(Object source, String publisher, String articleName) {        super(source);        this.publisher = publisher;        this.articleName = articleName;    }}public class WeChatClient implements ApplicationListener {    private String username;    public WeChatClient(String username) {        this.username = username;    }    @Override    public void onApplicationEvent(ApplicationEvent event) {        if (event instanceof WechatNotice) {            WechatNotice notice = (WechatNotice) event;            System.out.println(String.format(&quot;用户&lt;%s&gt; 接收到 &lt;%s&gt;微信公众号 的推送，文章标题为 &lt;%s&gt;&quot;, username, notice.getPublisher(), notice.getArticleName()));        }    }    public void setUsername(String username) {        this.username = username;    }}public class WeChatAccounts implements ApplicationContextAware {    private ApplicationContext ctx;    private String name;    public WeChatAccounts(String name) {        this.name = name;    }    public void setName(String name) {        this.name = name;    }    @Override    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {        this.ctx = applicationContext;    }    public void publishArticles(String articleName, String content) {        System.out.println(String.format(&quot;\n&lt;%s&gt;微信公众号 发布了一篇推送，文章名称为 &lt;%s&gt;，内容为 &lt;%s&gt; &quot;, this.name, articleName, content));        ctx.publishEvent(new WechatNotice(this.name, this.name, articleName));    }}</code></pre><p>在 resources 目录下创建 <code>spring.xml</code> 文件，填入下面的内容</p><pre><code class="xml">&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;    &lt;bean id=&quot;WeChatAccounts&quot; class=&quot;com.observer.sprintevent.WeChatAccounts&quot; scope=&quot;prototype&quot;&gt;        &lt;constructor-arg name=&quot;name&quot; value=&quot;&quot;&gt;&lt;/constructor-arg&gt;    &lt;/bean&gt;    &lt;bean id=&quot;WeChatClient1&quot; class=&quot;com.observer.sprintevent.WeChatClient&quot;&gt;        &lt;constructor-arg name=&quot;username&quot; value=&quot;张三&quot;&gt;&lt;/constructor-arg&gt;    &lt;/bean&gt;    &lt;bean id=&quot;WeChatClient2&quot; class=&quot;com.observer.sprintevent.WeChatClient&quot;&gt;        &lt;constructor-arg name=&quot;username&quot; value=&quot;李四&quot;&gt;&lt;/constructor-arg&gt;    &lt;/bean&gt;    &lt;bean id=&quot;WeChatClient3&quot; class=&quot;com.observer.sprintevent.WeChatClient&quot;&gt;        &lt;constructor-arg name=&quot;username&quot; value=&quot;王五&quot;&gt;&lt;/constructor-arg&gt;    &lt;/bean&gt;&lt;/beans&gt;</code></pre><p>测试</p><pre><code class="java">public class Test {    public static void main(String[] args) {        ApplicationContext context = new ClassPathXmlApplicationContext(&quot;spring.xml&quot;);        WeChatAccounts accounts = (WeChatAccounts) context.getBean(&quot;WeChatAccounts&quot;);        accounts.setName(&quot;小旋锋&quot;);        accounts.setApplicationContext(context);        accounts.publishArticles(&quot;设计模式 | 观察者模式及典型应用&quot;, &quot;观察者模式的内容...&quot;);    }}</code></pre><p>输出如下</p><pre><code>&lt;小旋锋&gt;微信公众号 发布了一篇推送，文章名称为 &lt;设计模式 | 观察者模式及典型应用&gt;，内容为 &lt;观察者模式的内容...&gt; 用户&lt;张三&gt; 接收到 &lt;小旋锋&gt;微信公众号 的推送，文章标题为 &lt;设计模式 | 观察者模式及典型应用&gt;用户&lt;李四&gt; 接收到 &lt;小旋锋&gt;微信公众号 的推送，文章标题为 &lt;设计模式 | 观察者模式及典型应用&gt;用户&lt;王五&gt; 接收到 &lt;小旋锋&gt;微信公众号 的推送，文章标题为 &lt;设计模式 | 观察者模式及典型应用&gt;</code></pre><p>在此示例中 <code>ApplicationContext</code> 对象的实际类型为 <code>ClassPathXmlApplicationContext</code>，其中的与 <code>publishEvent</code> 方法相关的主要代码如下：</p><pre><code class="java">private ApplicationEventMulticaster applicationEventMulticaster;public void publishEvent(ApplicationEvent event) {    this.getApplicationEventMulticaster().multicastEvent(event);    if (this.parent != null) {        this.parent.publishEvent(event);    }}ApplicationEventMulticaster getApplicationEventMulticaster() throws IllegalStateException {    return this.applicationEventMulticaster;}protected void initApplicationEventMulticaster() {        ConfigurableListableBeanFactory beanFactory = this.getBeanFactory();        if (beanFactory.containsLocalBean(&quot;applicationEventMulticaster&quot;)) {            this.applicationEventMulticaster = (ApplicationEventMulticaster)beanFactory.getBean(&quot;applicationEventMulticaster&quot;, ApplicationEventMulticaster.class);        } else {            this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory);            beanFactory.registerSingleton(&quot;applicationEventMulticaster&quot;, this.applicationEventMulticaster);        }    }</code></pre><p>其中的 <code>SimpleApplicationEventMulticaster</code> 如下，<code>multicastEvent</code> 方法主要是通过遍历 <code>ApplicationListener</code>（注册由 AbstractApplicationEventMulticaster 实现），使用线程池框架 <code>Executor</code> 来并发执行 <code>ApplicationListener</code> 的 <code>onApplicationEvent</code> 方法，与示例本质上是一致的</p><pre><code class="java">public class SimpleApplicationEventMulticaster extends AbstractApplicationEventMulticaster {    private Executor taskExecutor;    public void multicastEvent(final ApplicationEvent event) {        Iterator var2 = this.getApplicationListeners(event).iterator();        while(var2.hasNext()) {            final ApplicationListener listener = (ApplicationListener)var2.next();            Executor executor = this.getTaskExecutor();            if (executor != null) {                executor.execute(new Runnable() {                    public void run() {                        listener.onApplicationEvent(event);                    }                });            } else {                listener.onApplicationEvent(event);            }        }    }}</code></pre><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析<br><a href="http://uule.iteye.com/blog/2096279" target="_blank" rel="noopener">用guava实现简单的事件驱动</a><br><a href="http://www.cnblogs.com/youzhibing/p/9593788.html" target="_blank" rel="noopener">springboot 事件机制</a></p></blockquote><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>设计模式 | 策略模式及典型应用</title>
      <link href="/2018/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2018/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>本文的主要内容：</p><ul><li>介绍策略模式</li><li>示例<ul><li>商场购物打折策略的实现</li></ul></li><li>策略模式总结</li><li>源码分析策略模式的典型应用<ul><li>Java Comparator 中的策略模式</li><li>Spring Resource 中的策略模式</li><li>Spring Bean 实例化中的策略模式</li></ul></li></ul><h2 id="策略模式"><a href="#策略模式" class="headerlink" title="策略模式"></a>策略模式</h2><p>在软件开发中，我们也常常会遇到类似的情况，实现某一个功能有多条途径，每一条途径对应一种算法，此时我们可以使用一种设计模式来实现灵活地选择解决途径，也能够方便地增加新的解决途径。</p><p>譬如商场购物场景中，有些商品按原价卖，商场可能为了促销而推出优惠活动，有些商品打九折，有些打八折，有些则是返现10元等。</p><p>而优惠活动并不影响结算之外的其他过程，只是在结算的时候需要根据优惠方案结算</p><p><img src="http://image.laijianfeng.org/20181018_171948.jpg" alt="商场促销场景"></p><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><p><strong>Context（环境类）</strong>：环境类是使用算法的角色，它在解决某个问题（即实现某个方法）时可以采用多种策略。在环境类中维持一个对抽象策略类的引用实例，用于定义所采用的策略。</p><p><strong>Strategy（抽象策略类）</strong>：它为所支持的算法声明了抽象方法，是所有策略类的父类，它可以是抽象类或具体类，也可以是接口。环境类通过抽象策略类中声明的方法在运行时调用具体策略类中实现的算法。</p><p><strong>ConcreteStrategy（具体策略类）</strong>：它实现了在抽象策略类中声明的算法，在运行时，具体策略类将覆盖在环境类中定义的抽象策略类对象，使用一种具体的算法实现某个业务处理。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>如果要写出一个商场优惠场景的Demo可以很快的写出来，譬如</p><pre><code class="java">import java.text.MessageFormat;public class Shopping {    private String goods;    private double price;    private double finalPrice;    private String desc;    public Shopping(String goods, double price) {        this.goods = goods;        this.price = price;    }    public double calculate(String discountType) {        if (&quot;dis9&quot;.equals(discountType)) {            finalPrice = price * 0.9;            desc = &quot;打九折&quot;;        } else if (&quot;dis8&quot;.equals(discountType)) {            finalPrice = price * 0.8;            desc = &quot;打八折&quot;;        } else if (&quot;cash10&quot;.equals(discountType)) {            finalPrice = price &gt;= 10 ? price - 10 : 0;            desc = &quot;返现10元&quot;;        } else {            finalPrice = price;            desc = &quot;不参与优惠活动&quot;;        }        System.out.println(MessageFormat.format(&quot;购买的物品：{0}，原始价格：{1}，{2}，最终价格为：{3}&quot;, goods, price, desc, finalPrice));        return finalPrice;    }}</code></pre><p>测试</p><pre><code class="java">public class Test {    public static void main(String[] args) {        Shopping shopping1 = new Shopping(&quot;书籍-深入理解Java虚拟机&quot;, 54.00);        shopping1.calculate(&quot;dis9&quot;); // 九折        Shopping shopping2 = new Shopping(&quot;Apple 妙控鼠标&quot;, 588.00 );        shopping2.calculate(&quot;dis8&quot;);        Shopping shopping3 = new Shopping(&quot;戴尔U2417H显示器&quot;, 1479.00);        shopping3.calculate(&quot;cash10&quot;);        Shopping shopping4 = new Shopping(&quot;索尼ILCE-6000L相机&quot;, 3599.00);        shopping4.calculate(null);    }}</code></pre><p>以上代码当然完成了我们的需求，但是存在以下问题：</p><ul><li><p>Shopping 类的 calculate() 方法非常庞大，它包含各种优惠算法的实现代码，在代码中出现了较长的 <code>if…else…</code> 语句，不利于测试和维护。</p></li><li><p>增加新的优惠算法或者对原有打折算法进行修改时必须修改 Shopping 类的源代码，违反了 “开闭原则”，系统的灵活性和可扩展性较差。</p></li><li><p>算法的复用性差，如果在另一个系统中需要重用某些优惠算法，只能通过对源代码进行复制粘贴来重用，无法单独重用其中的某个或某些算法。</p></li></ul><p>所以我们需要使用策略模式对 Shopping 类进行重构，将原本庞大的 Shopping 类的职责进行分解，将算法的定义和使用分离。</p><p>抽象策略类  <code>Discount</code>，它是所有具体优惠算法的父类，定义了一个 <code>discount</code> 抽象方法</p><pre><code class="java">import lombok.Data;@Datapublic abstract class Discount {    protected double finalPrice;    protected String desc;    public Discount(String desc) {        this.desc = desc;    }    abstract double discount(double price);}</code></pre><p>四种具体策略类，继承自抽象策略类 <code>Discount</code>，并在 <code>discount</code> 方法中实现具体的优惠算法</p><pre><code class="java">public class Dis9Discount extends Discount {    public Dis9Discount() {        super(&quot;打九折&quot;);    }    @Override    double discount(double price) {        finalPrice = price * 0.9;        return finalPrice;    }}public class Dis8Discount extends Discount{    public Dis8Discount() {        super(&quot;打八折&quot;);    }    @Override    double discount(double price) {        finalPrice = price * 0.8;        return finalPrice;    }}public class Cash10Discount extends Discount {    public Cash10Discount() {        super(&quot;返现10元&quot;);    }    @Override    public double discount(double price) {        this.finalPrice = price &gt;= 10 ? price - 10 : 0;        return finalPrice;    }}public class NoneDiscount extends Discount {    public NoneDiscount() {        super(&quot;不参与优惠活动&quot;);    }    @Override    double discount(double price) {        finalPrice = price;        return finalPrice;    }}</code></pre><p>环境类 <code>Shopping</code>，维护了一个 <code>Discount</code> 引用</p><pre><code class="java">public class Shopping {    private String goods;    private double price;    private Discount discount;    public Shopping(String goods, double price, Discount discount) {        this.goods = goods;        this.price = price;        this.discount = discount;    }    public double calculate() {        double finalPrice = discount.discount(this.price);        String desc = discount.getDesc();        System.out.println(MessageFormat.format(&quot;购买的物品：{0}，原始价格：{1}，{2}，最终价格为：{3}&quot;, goods, price, desc, finalPrice));        return finalPrice;    }}</code></pre><p>测试</p><pre><code class="java">public class Test {    public static void main(String[] args) {        Shopping shopping1 = new Shopping(&quot;书籍-深入理解Java虚拟机&quot;, 54.00, new Dis9Discount());        shopping1.calculate();        Shopping shopping2 = new Shopping(&quot;Apple 妙控鼠标&quot;, 588.00, new Dis8Discount());        shopping2.calculate();        Shopping shopping3 = new Shopping(&quot;戴尔U2417H显示器&quot;, 1479.00, new Cash10Discount());        shopping3.calculate();        Shopping shopping4 = new Shopping(&quot;索尼ILCE-6000L相机&quot;, 3599.00, new NoneDiscount());        shopping4.calculate();    }}</code></pre><p>结果</p><pre><code class="java">购买的物品：书籍-深入理解Java虚拟机，原始价格：54，打九折，最终价格为：48.6购买的物品：Apple 妙控鼠标，原始价格：588，打八折，最终价格为：470.4购买的物品：戴尔U2417H显示器，原始价格：1,479，返现10元，最终价格为：1,469购买的物品：索尼ILCE-6000L相机，原始价格：3,599，不参与优惠活动，最终价格为：3,599</code></pre><p>可以看到，使用策略模式重构后，<code>Shopping</code> 类的 <code>calculate</code> 方法简洁了很多，当需要更改优惠算法的时候不需要再修改 <code>Shopping</code> 类的源代码；要扩展出新的优惠算法很方便，只需要继承抽象策略类 <code>Discount</code> 并实现 <code>calculate</code> 方法即可；优惠算法很容易重用。</p><p>画出类图如下</p><p><img src="http://image.laijianfeng.org/20181017_114704.png" alt="示例.策略模式类图"></p><h2 id="策略模式总结"><a href="#策略模式总结" class="headerlink" title="策略模式总结"></a>策略模式总结</h2><p>策略模式的<strong>主要优点</strong>如下： </p><ul><li><p>策略模式提供了对 “开闭原则” 的完美支持，用户可以在不修改原有系统的基础上选择算法或行为，也可以灵活地增加新的算法或行为。</p></li><li><p>策略模式提供了管理相关的算法族的办法。策略类的等级结构定义了一个算法或行为族，恰当使用继承可以把公共的代码移到抽象策略类中，从而避免重复的代码。</p></li><li><p>策略模式提供了一种可以替换继承关系的办法。如果不使用策略模式而是通过继承，这样算法的使用就<br>和算法本身混在一起，不符合 “单一职责原则”，而且使用继承无法实现算法或行为在程序运行时的动态切<br>换。</p></li><li><p>使用策略模式可以避免多重条件选择语句。多重条件选择语句是硬编码，不易维护。</p></li><li><p>策略模式提供了一种算法的复用机制，由于将算法单独提取出来封装在策略类中，因此不同的环境类可以方便地复用这些策略类。</p></li></ul><p>策略模式的<strong>主要缺点</strong>如下：</p><ul><li><p>客户端必须知道所有的策略类，并自行决定使用哪一个策略类。这就意味着客户端必须理解这些算法的区别，以便适时选择恰当的算法。换言之，策略模式只适用于客户端知道所有的算法或行为的情况。</p></li><li><p>策略模式将造成系统产生很多具体策略类，任何细小的变化都将导致系统要增加一个新的具体策略类。</p></li><li><p>无法同时在客户端使用多个策略类，也就是说，在使用策略模式时，客户端每次只能使用一个策略类，不支持使用一个策略类完成部分功能后再使用另一个策略类来完成剩余功能的情况。</p></li></ul><p><strong>适用场景</strong></p><ul><li><p>一个系统需要动态地在几种算法中选择一种，那么可以将这些算法封装到一个个的具体算法类中，而这些具体算法类都是一个抽象算法类的子类。换言之，这些具体算法类均有统一的接口，根据 “里氏代换原则” 和面向对象的多态性，客户端可以选择使用任何一个具体算法类，并只需要维持一个数据类型是抽象算法类的对象。</p></li><li><p>一个对象有很多的行为，如果不用恰当的模式，这些行为就只好使用多重条件选择语句来实现。此时，使用策略模式，把这些行为转移到相应的具体策略类里面，就可以避免使用难以维护的多重条件选择语句。</p></li><li><p>不希望客户端知道复杂的、与算法相关的数据结构，在具体策略类中封装算法与相关的数据结构，可以提高算法的保密性与安全性。</p></li></ul><h2 id="源码分析策略模式的典型应用"><a href="#源码分析策略模式的典型应用" class="headerlink" title="源码分析策略模式的典型应用"></a>源码分析策略模式的典型应用</h2><h3 id="Java-Comparator-中的策略模式"><a href="#Java-Comparator-中的策略模式" class="headerlink" title="Java Comparator 中的策略模式"></a>Java Comparator 中的策略模式</h3><p><code>java.util.Comparator</code> 接口是比较器接口，可以通过 <code>Collections.sort(List,Comparator)</code> 和 <code>Arrays.sort(Object[],Comparator)</code> 对集合和数据进行排序，下面为示例程序</p><p>一个学生类，有两个属性 <code>id</code> 和 <code>name</code></p><pre><code class="java">@Data@AllArgsConstructorpublic class Student {    private Integer id;    private String name;    @Override    public String toString() {        return &quot;{id=&quot; + id + &quot;, name=&#39;&quot; + name + &quot;&#39;}&quot;;    }}</code></pre><p>实现两个比较器，比较器实现了 <code>Comparator</code> 接口，一个升序，一个降序</p><pre><code class="java">// 降序public class DescSortor implements Comparator&lt;Student&gt; {    @Override    public int compare(Student o1, Student o2) {        return o2.getId() - o1.getId();    }}// 升序public class AscSortor implements Comparator&lt;Student&gt; {    @Override    public int compare(Student o1, Student o2) {        return o1.getId() - o2.getId();    }}</code></pre><p>通过 <code>Arrays.sort()</code> 对数组进行排序</p><pre><code class="java">public class Test1 {    public static void main(String[] args) {        Student[] students = {                new Student(3, &quot;张三&quot;),                new Student(1, &quot;李四&quot;),                new Student(4, &quot;王五&quot;),                new Student(2, &quot;赵六&quot;)        };        toString(students, &quot;排序前&quot;);        Arrays.sort(students, new AscSortor());        toString(students, &quot;升序后&quot;);        Arrays.sort(students, new DescSortor());        toString(students, &quot;降序后&quot;);    }    public static void toString(Student[] students, String desc){        for (int i = 0; i &lt; students.length; i++) {            System.out.print(desc + &quot;: &quot; +students[i].toString() + &quot;, &quot;);        }        System.out.println();    }}</code></pre><p>输出</p><pre><code>排序前: {id=3, name=&#39;张三&#39;}, 排序前: {id=1, name=&#39;李四&#39;}, 排序前: {id=4, name=&#39;王五&#39;}, 排序前: {id=2, name=&#39;赵六&#39;}, 升序后: {id=1, name=&#39;李四&#39;}, 升序后: {id=2, name=&#39;赵六&#39;}, 升序后: {id=3, name=&#39;张三&#39;}, 升序后: {id=4, name=&#39;王五&#39;}, 降序后: {id=4, name=&#39;王五&#39;}, 降序后: {id=3, name=&#39;张三&#39;}, 降序后: {id=2, name=&#39;赵六&#39;}, 降序后: {id=1, name=&#39;李四&#39;}, </code></pre><p>通过 <code>Collections.sort()</code> 对集合List进行排序</p><pre><code class="java">public class Test2 {    public static void main(String[] args) {        List&lt;Student&gt; students = Arrays.asList(                new Student(3, &quot;张三&quot;),                new Student(1, &quot;李四&quot;),                new Student(4, &quot;王五&quot;),                new Student(2, &quot;赵六&quot;)        );        toString(students, &quot;排序前&quot;);        Collections.sort(students, new AscSortor());        toString(students, &quot;升序后&quot;);        Collections.sort(students, new DescSortor());        toString(students, &quot;降序后&quot;);    }    public static void toString(List&lt;Student&gt; students, String desc) {        for (Student student : students) {            System.out.print(desc + &quot;: &quot; + student.toString() + &quot;, &quot;);        }        System.out.println();    }}</code></pre><p>输出</p><pre><code>排序前: {id=3, name=&#39;张三&#39;}, 排序前: {id=1, name=&#39;李四&#39;}, 排序前: {id=4, name=&#39;王五&#39;}, 排序前: {id=2, name=&#39;赵六&#39;}, 升序后: {id=1, name=&#39;李四&#39;}, 升序后: {id=2, name=&#39;赵六&#39;}, 升序后: {id=3, name=&#39;张三&#39;}, 升序后: {id=4, name=&#39;王五&#39;}, 降序后: {id=4, name=&#39;王五&#39;}, 降序后: {id=3, name=&#39;张三&#39;}, 降序后: {id=2, name=&#39;赵六&#39;}, 降序后: {id=1, name=&#39;李四&#39;}, </code></pre><p>我们向 <code>Collections.sort()</code> 和 <code>Arrays.sort()</code> 分别传入不同的比较器即可实现不同的排序效果（升序或降序）</p><p>这里 <code>Comparator</code> 接口充当了抽象策略角色，两个比较器 <code>DescSortor</code> 和 <code>AscSortor</code> 则充当了具体策略角色，<code>Collections</code> 和 <code>Arrays</code> 则是环境角色</p><h3 id="Spring-Resource-中的策略模式"><a href="#Spring-Resource-中的策略模式" class="headerlink" title="Spring Resource 中的策略模式"></a>Spring Resource 中的策略模式</h3><p>Spring 把所有能记录信息的载体，如各种类型的文件、二进制流等都称为资源，譬如最常用的Spring配置文件。</p><p>在 Sun 所提供的标准 API 里，资源访问通常由 <code>java.NET.URL</code> 和文件 IO 来完成，尤其是当我们需要访问来自网络的资源时，通常会选择 URL 类。</p><p>URL 类可以处理一些常规的资源访问问题，但依然不能很好地满足所有底层资源访问的需要，比如，暂时还无法从类加载路径、或相对于 <code>ServletContext</code> 的路径来访问资源，虽然 Java 允许使用特定的 URL 前缀注册新的处理类（例如已有的 http: 前缀的处理类），但是这样做通常比较复杂，而且 URL 接口还缺少一些有用的功能，比如检查所指向的资源是否存在等。</p><p>Spring 改进了 Java 资源访问的策略，Spring 为资源访问提供了一个 Resource 接口，该接口提供了更强的资源访问能力，Spring 框架本身大量使用了 Resource 接口来访问底层资源。</p><pre><code class="java">public interface Resource extends InputStreamSource {    boolean exists();    // 返回 Resource 所指向的资源是否存在    boolean isReadable();   // 资源内容是否可读    boolean isOpen();   // 返回资源文件是否打开    URL getURL() throws IOException;    URI getURI() throws IOException;    File getFile() throws IOException;  // 返回资源对应的 File 对象    long contentLength() throws IOException;    long lastModified() throws IOException;    Resource createRelative(String var1) throws IOException;    String getFilename();    String getDescription();    // 返回资源的描述信息}</code></pre><p><code>Resource</code> 接口是 Spring 资源访问策略的抽象，它本身并不提供任何资源访问实现，具体的资源访问由该接口的实现类完成——<strong>每个实现类代表一种资源访问策略</strong>。</p><p><img src="http://image.laijianfeng.org/20181018_171944.png" alt="Spring资源访问接口Resource的实现类"></p><p>Spring 为 Resource 接口提供的部分实现类如下：</p><ul><li><code>UrlResource</code>：访问网络资源的实现类。</li><li><code>ClassPathResource</code>：访问类加载路径里资源的实现类。</li><li><code>FileSystemResource</code>：访问文件系统里资源的实现类。</li><li><code>ServletContextResource</code>：访问相对于 <code>ServletContext</code> 路径里的资源的实现类：</li><li><code>InputStreamResource</code>：访问输入流资源的实现类。</li><li><code>ByteArrayResource</code>：访问字节数组资源的实现类。</li><li><code>WritableResource</code>：写资源文件</li></ul><p>这些 <code>Resource</code> 实现类，针对不同的的底层资源，提供了相应的资源访问逻辑，并提供便捷的包装，以利于客户端程序的资源访问。</p><p>它们之间的类关系如下所示：</p><p><img src="http://image.laijianfeng.org/20181018_171945.png" alt="Spring Resource 类图"></p><p>可以看到 <code>AbstractResource</code> 资源抽象类实现了 <code>Resource</code> 接口，为子类通用的操作提供了具体实现，非通用的操作留给子类实现，所以这里也应用了模板方法模式。（只不过缺少了模板方法）</p><p><code>Resource</code> 不仅可在 Spring 的项目中使用，也可直接作为资源访问的工具类使用。意思是说：即使不使用 Spring 框架，也可以使用 <code>Resource</code> 作为工具类，用来代替 <code>URL</code>。</p><p>譬如我们可以使用 <code>UrlResource</code> 访问网络资源。</p><blockquote><p>也可以通过其它协议访问资源，file: 用于访问文件系统；http: 用于通过 HTTP 协议访问资源；ftp: 用于通过 FTP 协议访问资源等</p></blockquote><pre><code class="java">public class Test {    public static void main(String[] args) throws IOException {        UrlResource ur = new UrlResource(&quot;http://image.laijianfeng.org/hello.txt&quot;);        System.out.println(&quot;文件名：&quot; + ur.getFilename());        System.out.println(&quot;网络文件URL：&quot; + ur.getURL());        System.out.println(&quot;是否存在：&quot; + ur.exists());        System.out.println(&quot;是否可读：&quot; + ur.isReadable());        System.out.println(&quot;文件长度：&quot; + ur.contentLength());        System.out.println(&quot;\n--------文件内容----------\n&quot;);        byte[] bytes = new byte[47];        ur.getInputStream().read(bytes);        System.out.println(new String(bytes));    }}</code></pre><p>输出的内容如下，符合预期</p><pre><code>文件名：hello.txt网络文件URL：http://image.laijianfeng.org/hello.txt是否存在：true是否可读：true文件长度：47--------文件内容----------hello world!welcome to http://laijianfeng.org</code></pre><blockquote><p>更多的示例可以参考：<a href="https://www.ibm.com/developerworks/cn/java/j-lo-spring-resource/index.html" target="_blank" rel="noopener">Spring 资源访问剖析和策略模式应用</a></p></blockquote><h3 id="Spring-Bean-实例化中的策略模式"><a href="#Spring-Bean-实例化中的策略模式" class="headerlink" title="Spring Bean 实例化中的策略模式"></a>Spring Bean 实例化中的策略模式</h3><p>Spring实例化Bean有三种方式：构造器实例化、静态工厂实例化、实例工厂实例化</p><p>譬如通过构造器实例化bean的XML示例如下：</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;    xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;    &lt;bean id=&quot;person&quot; class=&quot;com.demo.Person&quot;&gt;&lt;/bean&gt;    &lt;bean id=&quot;personWithParam&quot; class=&quot;com.demo.Person&quot;&gt;        &lt;constructor-arg name=&quot;name&quot; value=&quot;小旋锋&quot;/&gt;    &lt;/bean&gt;    &lt;bean id=&quot;personWirhParams&quot; class=&quot;com.demo.Person&quot;&gt;            &lt;constructor-arg name=&quot;name&quot; value=&quot;小旋锋&quot;/&gt;            &lt;constructor-arg name=&quot;age&quot; value=&quot;22&quot;/&gt;    &lt;/bean&gt;&lt;/beans&gt;</code></pre><p>具体实例化Bean的过程中，Spring中角色分工很明确，创建对象的时候先通过 <code>ConstructorResolver</code> 找到对应的实例化方法和参数，再通过实例化策略 <code>InstantiationStrategy</code> 进行实例化，根据创建对象的三个分支( 工厂方法、有参构造方法、无参构造方法 ), <code>InstantiationStrategy</code> 提供了三个接口方法：</p><pre><code class="java">public interface InstantiationStrategy {    // 默认构造方法    Object instantiate(RootBeanDefinition beanDefinition, String beanName, BeanFactory owner) throws BeansException;    // 指定构造方法    Object instantiate(RootBeanDefinition beanDefinition, String beanName, BeanFactory owner, Constructor&lt;?&gt; ctor,            Object[] args) throws BeansException;    // 指定工厂方法    Object instantiate(RootBeanDefinition beanDefinition, String beanName, BeanFactory owner, Object factoryBean,            Method factoryMethod, Object[] args) throws BeansException;}</code></pre><p><code>InstantiationStrategy</code> 为实例化策略接口，扮演抽象策略角色，有两种具体策略类，分别为 <code>SimpleInstantiationStrategy</code> 和 <code>CglibSubclassingInstantiationStrategy</code> </p><p><img src="http://image.laijianfeng.org/20181018_171946.png" alt="Spring 实例化策略类图"></p><p>在 <code>SimpleInstantiationStrategy</code> 中对这三个方法做了简单实现，如果工厂方法实例化直接用反射创建对象，如果是构造方法实例化的则判断是否有 <code>MethodOverrides</code>，如果有无 <code>MethodOverrides</code> 也是直接用反射，如果有 <code>MethodOverrides</code> 就需要用 <code>cglib</code> 实例化对象，<code>SimpleInstantiationStrategy</code> 把通过 <code>cglib</code> 实例化的任务交给了它的子类 <code>CglibSubclassingInstantiationStrategy</code>。</p><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析<br><a href="https://www.ibm.com/developerworks/cn/java/j-lo-spring-resource/index.html" target="_blank" rel="noopener">Spring 资源访问剖析和策略模式应用</a><br><a href="https://my.oschina.net/chengxiaoyuan/blog/823655" target="_blank" rel="noopener">Spring源码阅读-实例化策略InstantiationStrategy</a><br><a href="https://blog.csdn.net/u011726984/article/details/45290871" target="_blank" rel="noopener">Spring学习之实例化bean的三种方式</a>   </p></blockquote><h3 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h3><p><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483700&amp;idx=1&amp;sn=dd4d23f9400c8be248f5d125465ba941&amp;chksm=e9c2ed39deb5642fb809eca1351f00995f06c9a4875f09986cc5005059eff74d6c20fc1118a3&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 简单工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483704&amp;idx=1&amp;sn=fa3ae947cebf22da35e6ac0a37f566f8&amp;chksm=e9c2ed35deb564230a69e43d93a3b74618287c6ddd402a6f1dc6a5b14a896e99584985e7cf92&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 工厂方法模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483708&amp;idx=1&amp;sn=9b8c155b86511ea6ec323dc6a72c52df&amp;chksm=e9c2ed31deb56427b2a6bbcbad5bdd3a4ef68b52eb88cc47b5bcfc76773d3d983d8aaf57761c&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 抽象工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483712&amp;idx=1&amp;sn=1ffd9837eb9413dde74ff509bf69ecc5&amp;chksm=e9c2ed4ddeb5645b8cbf64c83d103a859ae49921c60e17fe8bebe63c26b04966be101d598848&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 建造者模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483716&amp;idx=1&amp;sn=df00c297c8f32e10e277db8941839c14&amp;chksm=e9c2ed49deb5645fa2586da358a8f0a00dd926f883637adebc59435f846c67c040ef759ba034&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 原型模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483721&amp;idx=1&amp;sn=721d0bce3bd516c10d4b6addbf3eced6&amp;chksm=e9c2ed44deb56452395c94a0b150994b94aa26cae71149e6c030d0ac32f9c3c37e2bfe9685b6&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 外观模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483726&amp;idx=1&amp;sn=df583e5b297ddaff5e1ab822df762274&amp;chksm=e9c2ed43deb56455d2a099f3c3e8622031027d6da00202e6a7d731eac691e4d87d673ca103b5&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 装饰者模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483730&amp;idx=1&amp;sn=859feab7f4632b7ba3d1b5a614d57bbe&amp;chksm=e9c2ed5fdeb56449575995778573fa05a3730ac72792d70fc91e38e2d2f5238899f620481d16&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 适配器模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483737&amp;idx=1&amp;sn=ed27a42a80b87ff74f1e1266d918ad5b&amp;chksm=e9c2ed54deb56442aba5c95fbddd4c774eb39ebe7ab8c03471a62e3cf3979e303cef43417bac&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 享元模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483742&amp;idx=1&amp;sn=436670dc4793c6c9e7207ca6222e062c&amp;chksm=e9c2ed53deb56445c7fb1aef89ab80b23bab96e6f9993618c98e1746209eec05f36b231cfaa8&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 组合模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483747&amp;idx=1&amp;sn=aa494215a2933e2424a6daa03587e478&amp;chksm=e9c2ed6edeb564783b9acd9f5372a08d53d04b001ca362c9213c4379bc7e1bff363e4ad01e3c&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 模板方法模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483752&amp;idx=1&amp;sn=7880679f18b5727ea64cd05c06817c35&amp;chksm=e9c2ed65deb56473da688784c4562995c24daf4b13425d0d4d080208728b86525f6600127925&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 迭代器模式及典型应用</a>   </p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>20181013-燃烧吧，破铜烂铁！</title>
      <link href="/2018/10/20181013-%E7%87%83%E7%83%A7%E5%90%A7%EF%BC%8C%E7%A0%B4%E9%93%9C%E7%83%82%E9%93%81%EF%BC%81/"/>
      <url>/2018/10/20181013-%E7%87%83%E7%83%A7%E5%90%A7%EF%BC%8C%E7%A0%B4%E9%93%9C%E7%83%82%E9%93%81%EF%BC%81/</url>
      <content type="html"><![CDATA[<p>燃烧吧，破铜烂铁！</p><p><img src="http://image.laijianfeng.org/20181013220016.jpg" alt="英国Junnk乐队极限音乐会"></p><p>燃烧吧，青春！</p><video src="http://image.laijianfeng.org/WeChat_20181013215718.mp4" controls="controls"><br>英国Junnk乐队极限音乐会<br></video>]]></content>
      
      <categories>
          
          <category> 生活杂记 </category>
          
      </categories>
      
      
    </entry>
    
    <entry>
      <title>设计模式 | 迭代器模式及典型应用</title>
      <link href="/2018/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2018/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>本文的主要内容：</p><ul><li>介绍迭代器模式</li><li>源码分析迭代器模式的典型应用<ul><li>Java集合中的迭代器模式</li><li>Mybatis中的迭代器模式</li></ul></li></ul><h2 id="迭代器模式"><a href="#迭代器模式" class="headerlink" title="迭代器模式"></a>迭代器模式</h2><p><strong>迭代器模式(Iterator Pattern)</strong>：提供一种方法来访问聚合对象，而不用暴露这个对象的内部表示，其别名为游标(Cursor)。迭代器模式是一种对象行为型模式。</p><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><p><strong>Iterator（抽象迭代器）</strong>：它定义了访问和遍历元素的接口，声明了用于遍历数据元素的方法，例如：用于获取第一个元素的first()方法，用于访问下一个元素的next()方法，用于判断是否还有下一个元素的hasNext()方法，用于获取当前元素的currentItem()方法等，在具体迭代器中将实现这些方法。</p><p><strong>ConcreteIterator（具体迭代器）</strong>：它实现了抽象迭代器接口，完成对聚合对象的遍历，同时在具体迭代器中通过游标来记录在聚合对象中所处的当前位置，在具体实现时，游标通常是一个表示位置的非负整数。</p><p><strong>Aggregate（抽象聚合类）</strong>：它用于存储和管理元素对象，声明一个createIterator()方法用于创建一个迭代器对象，充当抽象迭代器工厂角色。</p><p><strong>ConcreteAggregate（具体聚合类）</strong>：它实现了在抽象聚合类中声明的createIterator()方法，该方法返回一个与该具体聚合类对应的具体迭代器ConcreteIterator实例。</p><p>在迭代器模式中，提供了一个外部的迭代器来对聚合对象进行访问和遍历，迭代器定义了一个访问该聚合元素的接口，并且可以跟踪当前遍历的元素，了解哪些元素已经遍历过而哪些没有。迭代器的引入，将使得对一个复杂聚合对象的操作变得简单。</p><p>在迭代器模式中应用了工厂方法模式，抽象迭代器对应于抽象产品角色，具体迭代器对应于具体产品角色，抽象聚合类对应于抽象工厂角色，具体聚合类对应于具体工厂角色。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>我们来实现一个学生报数的示例</p><p>定义一个学生类，有一个报数方法 <code>count()</code></p><pre><code class="java">@Getter@Setter@ToStringpublic class Student {    private String name;    private Integer number;    public Student(String name, Integer number) {        this.name = name;        this.number = number;    }    public void count() {        System.out.println(String.format(&quot;我是 %d 号 %s&quot;, this.number, this.name));    }}</code></pre><p>定义班级接口和班级类</p><pre><code class="java">public interface StudentAggregate {    void addStudent(Student student);    void removeStudent(Student student);    StudentIterator getStudentIterator();}public class StudentAggregateImpl implements StudentAggregate {    private List&lt;Student&gt; list;  // 学生列表    public StudentAggregateImpl() {        this.list = new ArrayList&lt;Student&gt;();    }    @Override    public void addStudent(Student student) {        this.list.add(student);    }    @Override    public void removeStudent(Student student) {        this.list.remove(student);    }    @Override    public StudentIterator getStudentIterator() {        return new StudentIteratorImpl(list);    }}</code></pre><p>定义迭代器接口并实现迭代器</p><pre><code class="java">public interface StudentIterator {    boolean hashNext();    Student next();}public class StudentIteratorImpl implements StudentIterator{    private List&lt;Student&gt; list;    private int position = 0;    private Student currentStudent;    public StudentIteratorImpl(List&lt;Student&gt; list) {        this.list = list;    }    @Override    public boolean hashNext() {        return position &lt; list.size();    }    @Override    public Student next() {        currentStudent = list.get(position);        position ++;        return currentStudent;    }}</code></pre><p>测试，进行报数</p><pre><code class="java">public class Test {    public static void main(String[] args) {        StudentAggregate classOne = new StudentAggregateImpl();        classOne.addStudent(new Student(&quot;张三&quot;, 1));        classOne.addStudent(new Student(&quot;李四&quot;, 2));        classOne.addStudent(new Student(&quot;王五&quot;, 3));        classOne.addStudent(new Student(&quot;赵六&quot;, 4));        // 遍历，报数        StudentIterator iterator = classOne.getStudentIterator();        while (iterator.hashNext()){            Student student = iterator.next();            student.count();        }    }}</code></pre><p>输出</p><pre><code>我是 1 号 张三我是 2 号 李四我是 3 号 王五我是 4 号 赵六</code></pre><p>迭代器模式类图如下</p><p><img src="http://image.laijianfeng.org/20181011_214704.jpg" alt="示例.迭代器类图"></p><h2 id="迭代器模式总结"><a href="#迭代器模式总结" class="headerlink" title="迭代器模式总结"></a>迭代器模式总结</h2><p>迭代器模式的<strong>主要优点</strong>如下：</p><ul><li>它支持以不同的方式遍历一个聚合对象，在同一个聚合对象上可以定义多种遍历方式。在迭代器模式中只需要用一个不同的迭代器来替换原有迭代器即可改变遍历算法，我们也可以自己定义迭代器的子类以支持新的遍历方式。</li><li>迭代器简化了聚合类。由于引入了迭代器，在原有的聚合对象中不需要再自行提供数据遍历等方法，这样可以简化聚合类的设计。</li><li>在迭代器模式中，由于引入了抽象层，增加新的聚合类和迭代器类都很方便，无须修改原有代码，满足 “开闭原则” 的要求。</li></ul><p>迭代器模式的<strong>主要缺点</strong>如下：</p><ul><li>由于迭代器模式将存储数据和遍历数据的职责分离，增加新的聚合类需要对应增加新的迭代器类，类的个数成对增加，这在一定程度上增加了系统的复杂性。</li><li>抽象迭代器的设计难度较大，需要充分考虑到系统将来的扩展，例如JDK内置迭代器Iterator就无法实现逆向遍历，如果需要实现逆向遍历，只能通过其子类ListIterator等来实现，而ListIterator迭代器无法用于操作Set类型的聚合对象。在自定义迭代器时，创建一个考虑全面的抽象迭代器并不是件很容易的事情。</li></ul><p><strong>适用场景</strong>:</p><ul><li>访问一个聚合对象的内容而无须暴露它的内部表示。将聚合对象的访问与内部数据的存储分离，使得访问聚合对象时无须了解其内部实现细节。</li><li>需要为一个聚合对象提供多种遍历方式。</li><li>为遍历不同的聚合结构提供一个统一的接口，在该接口的实现类中为不同的聚合结构提供不同的遍历方式，而客户端可以一致性地操作该接口。</li></ul><h2 id="源码分析迭代器模式的典型应用"><a href="#源码分析迭代器模式的典型应用" class="headerlink" title="源码分析迭代器模式的典型应用"></a>源码分析迭代器模式的典型应用</h2><h3 id="Java集合中的迭代器模式"><a href="#Java集合中的迭代器模式" class="headerlink" title="Java集合中的迭代器模式"></a>Java集合中的迭代器模式</h3><p>看 <code>java.util.ArrayList</code> 类</p><pre><code class="java">public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable {    transient Object[] elementData; // non-private to simplify nested class access    private int size;    public E get(int index) {        rangeCheck(index);        return elementData(index);    }    public boolean add(E e) {        ensureCapacityInternal(size + 1);  // Increments modCount!!        elementData[size++] = e;        return true;    }    public ListIterator&lt;E&gt; listIterator() {        return new ListItr(0);    }    public ListIterator&lt;E&gt; listIterator(int index) {        if (index &lt; 0 || index &gt; size)            throw new IndexOutOfBoundsException(&quot;Index: &quot;+index);        return new ListItr(index);    }    public Iterator&lt;E&gt; iterator() {        return new Itr();    }    private class Itr implements Iterator&lt;E&gt; {        int cursor;       // index of next element to return        int lastRet = -1; // index of last element returned; -1 if no such        int expectedModCount = modCount;        public boolean hasNext() {            return cursor != size;        }        public E next() {            //...        }        public E next() {            //...        }        public void remove() {            //...        }        //...    }      private class ListItr extends Itr implements ListIterator&lt;E&gt; {        public boolean hasPrevious() {            return cursor != 0;        }        public int nextIndex() {            return cursor;        }        public int previousIndex() {            return cursor - 1;        }        public E previous() {            //...        }        public void set(E e) {            //...        }        public void add(E e) {            //...        }    //...}</code></pre><p>从 <code>ArrayList</code> 源码中看到了有两个迭代器 <code>Itr</code> 和 <code>ListItr</code>，分别实现 <code>Iterator</code> 和 <code>ListIterator</code> 接口；</p><p>第一个当然很容易看明白，它跟我们示例的迭代器的区别是这里是一个内部类，可以直接使用 <code>ArrayList</code> 的数据列表；第二个迭代器是第一次见到， <code>ListIterator</code> 跟 <code>Iterator</code> 有什么区别呢？</p><p>先看 <code>ListIterator</code> 源码</p><pre><code class="java">public interface ListIterator&lt;E&gt; extends Iterator&lt;E&gt; {    boolean hasNext();    E next();    boolean hasPrevious();  // 返回该迭代器关联的集合是否还有上一个元素    E previous();           // 返回该迭代器的上一个元素    int nextIndex();        // 返回列表中ListIterator所需位置后面元素的索引    int previousIndex();    // 返回列表中ListIterator所需位置前面元素的索引    void remove();    void set(E var1);       // 从列表中将next()或previous()返回的最后一个元素更改为指定元素e    void add(E var1);   }</code></pre><p>接着是 <code>Iterator</code> 的源码</p><pre><code class="java">public interface Iterator&lt;E&gt; {    boolean hasNext();    E next();    default void remove() {        throw new UnsupportedOperationException(&quot;remove&quot;);    }    // 备注：JAVA8允许接口方法定义默认实现    default void forEachRemaining(Consumer&lt;? super E&gt; action) {        Objects.requireNonNull(action);        while (hasNext())            action.accept(next());    }}</code></pre><p>通过源码我们看出：<code>ListIterator</code> 是一个功能更加强大的迭代器，它继承于 <code>Iterator</code> 接口，只能用于各种List类型的访问。可以通过调用 <code>listIterator()</code> 方法产生一个指向List开始处的 <code>ListIterator</code>, 还可以调用 <code>listIterator(n)</code> 方法创建一个一开始就指向列表索引为n的元素处的 <code>ListIterator</code>。</p><p><code>Iterator</code> 和 <code>ListIterator</code> 主要区别概括如下:</p><ul><li><code>ListIterator</code> 有 <code>add()</code> 方法，可以向List中添加对象，而 <code>Iterator</code> 不能</li><li><code>ListIterator</code> 和 <code>Iterator</code> 都有 <code>hasNext()</code> 和 <code>next()</code> 方法，可以实现顺序向后遍历，但是 <code>ListIterator</code> 有 <code>hasPrevious()</code> 和 <code>previous()</code> 方法，可以实现逆向（顺序向前）遍历。<code>Iterator</code> 就不可以。</li><li><code>ListIterator</code> 可以定位当前的索引位置，<code>nextIndex()</code> 和 <code>previousIndex()</code> 可以实现。<code>Iterator</code> 没有此功能。</li><li>都可实现删除对象，但是 <code>ListIterator</code> 可以实现对象的修改，<code>set()</code> 方法可以实现。<code>Iierator</code> 仅能遍历，不能修改。</li></ul><p>敲一个 Iterator 的 Demo 探究一下</p><pre><code class="java">public class Test3 {    public static void main(String[] args) {        List&lt;String&gt; list = new ArrayList&lt;String&gt;();        list.add(&quot;张三&quot;);        list.add(&quot;李四&quot;);        list.add(&quot;王五&quot;);        list.add(&quot;赵六&quot;);        Iterator&lt;String&gt; iterator = list.iterator();        String first = iterator.next();        System.out.println(&quot;first: &quot; + first);        System.out.println(&quot;-----------next-------------&quot;);        while (iterator.hasNext()){            System.out.println(iterator.next());        }        iterator.remove();        System.out.println(&quot;-----------list-------------&quot;);        for (String name: list){            System.out.println(name);        }    }}</code></pre><p>输出结果</p><pre><code>first: 张三-----------next-------------李四王五赵六-----------list-------------张三李四王五</code></pre><p>可以看到 <code>Iterator.remove()</code> 会删除原来的 List 对象的数据</p><p>再敲一个 ListIterator 的 Demo 探究一下</p><pre><code class="java">public class Test2 {    public static void main(String[] args) {        List&lt;String&gt; list = new ArrayList&lt;String&gt;();        list.add(&quot;张三&quot;);        list.add(&quot;李四&quot;);        list.add(&quot;王五&quot;);        list.add(&quot;赵六&quot;);        ListIterator&lt;String&gt; listIterator = list.listIterator();        String first = listIterator.next();        listIterator.set(&quot;小明&quot;);        System.out.println(&quot;first: &quot; + first);        System.out.println(&quot;-----------next-------------&quot;);        listIterator.add(&quot;大明&quot;);        while (listIterator.hasNext()){            System.out.println(listIterator.nextIndex() + &quot;: &quot; + listIterator.next());        }        listIterator.remove();        System.out.println(&quot;------------previous------------&quot;);        while (listIterator.hasPrevious()){            System.out.println(listIterator.previousIndex() + &quot;: &quot; + listIterator.previous());        }        System.out.println(&quot;-----------list-------------&quot;);        for (String name: list){            System.out.println(name);        }    }}</code></pre><p>结果如下</p><pre><code class="java">first: 张三-----------next-------------2: 李四3: 王五4: 赵六------------previous------------3: 王五2: 李四1: 大明0: 小明-----------list-------------小明大明李四王五</code></pre><p>可以看出 <code>ListIterator</code> 的 <code>add</code>、<code>set</code>、<code>remove</code> 方法会直接改变原来的 List 对象，而且可以通过 <code>previous</code> 反向遍历</p><h3 id="Mybatis中的迭代器模式"><a href="#Mybatis中的迭代器模式" class="headerlink" title="Mybatis中的迭代器模式"></a>Mybatis中的迭代器模式</h3><p>当查询数据库返回大量的数据项时可以使用游标 <code>Cursor</code>，利用其中的迭代器可以懒加载数据，避免因为一次性加载所有数据导致内存奔溃，Mybatis 为 <code>Cursor</code> 接口提供了一个默认实现类 <code>DefaultCursor</code>，代码如下</p><pre><code class="java">public interface Cursor&lt;T&gt; extends Closeable, Iterable&lt;T&gt; {    boolean isOpen();    boolean isConsumed();    int getCurrentIndex();}public class DefaultCursor&lt;T&gt; implements Cursor&lt;T&gt; {    private final DefaultResultSetHandler resultSetHandler;    private final ResultMap resultMap;    private final ResultSetWrapper rsw;    private final RowBounds rowBounds;    private final ObjectWrapperResultHandler&lt;T&gt; objectWrapperResultHandler = new ObjectWrapperResultHandler&lt;T&gt;();    // 游标迭代器    private final CursorIterator cursorIterator = new CursorIterator();     protected T fetchNextUsingRowBound() {        T result = fetchNextObjectFromDatabase();        while (result != null &amp;&amp; indexWithRowBound &lt; rowBounds.getOffset()) {            result = fetchNextObjectFromDatabase();        }        return result;    }    @Override    public Iterator&lt;T&gt; iterator() {        if (iteratorRetrieved) {            throw new IllegalStateException(&quot;Cannot open more than one iterator on a Cursor&quot;);        }        iteratorRetrieved = true;        return cursorIterator;    }    private class CursorIterator implements Iterator&lt;T&gt; {        T object;        int iteratorIndex = -1;        @Override        public boolean hasNext() {            if (object == null) {                object = fetchNextUsingRowBound();            }            return object != null;        }        @Override        public T next() {            T next = object;            if (next == null) {                next = fetchNextUsingRowBound();            }            if (next != null) {                object = null;                iteratorIndex++;                return next;            }            throw new NoSuchElementException();        }        @Override        public void remove() {            throw new UnsupportedOperationException(&quot;Cannot remove element from Cursor&quot;);        }    }    // ...}</code></pre><p>游标迭代器 <code>CursorIterator</code> 实现了 <code>java.util.Iterator</code> 迭代器接口，这里的迭代器模式跟 <code>ArrayList</code> 中的迭代器几乎一样</p><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析<br><a href="https://blog.csdn.net/weixin_39241397/article/details/79687789" target="_blank" rel="noopener">Java 集合中关于Iterator 和ListIterator的详解</a>   </p></blockquote><h3 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h3><p><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483700&amp;idx=1&amp;sn=dd4d23f9400c8be248f5d125465ba941&amp;chksm=e9c2ed39deb5642fb809eca1351f00995f06c9a4875f09986cc5005059eff74d6c20fc1118a3&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 简单工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483704&amp;idx=1&amp;sn=fa3ae947cebf22da35e6ac0a37f566f8&amp;chksm=e9c2ed35deb564230a69e43d93a3b74618287c6ddd402a6f1dc6a5b14a896e99584985e7cf92&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 工厂方法模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483708&amp;idx=1&amp;sn=9b8c155b86511ea6ec323dc6a72c52df&amp;chksm=e9c2ed31deb56427b2a6bbcbad5bdd3a4ef68b52eb88cc47b5bcfc76773d3d983d8aaf57761c&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 抽象工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483712&amp;idx=1&amp;sn=1ffd9837eb9413dde74ff509bf69ecc5&amp;chksm=e9c2ed4ddeb5645b8cbf64c83d103a859ae49921c60e17fe8bebe63c26b04966be101d598848&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 建造者模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483716&amp;idx=1&amp;sn=df00c297c8f32e10e277db8941839c14&amp;chksm=e9c2ed49deb5645fa2586da358a8f0a00dd926f883637adebc59435f846c67c040ef759ba034&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 原型模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483721&amp;idx=1&amp;sn=721d0bce3bd516c10d4b6addbf3eced6&amp;chksm=e9c2ed44deb56452395c94a0b150994b94aa26cae71149e6c030d0ac32f9c3c37e2bfe9685b6&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 外观模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483726&amp;idx=1&amp;sn=df583e5b297ddaff5e1ab822df762274&amp;chksm=e9c2ed43deb56455d2a099f3c3e8622031027d6da00202e6a7d731eac691e4d87d673ca103b5&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 装饰者模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483730&amp;idx=1&amp;sn=859feab7f4632b7ba3d1b5a614d57bbe&amp;chksm=e9c2ed5fdeb56449575995778573fa05a3730ac72792d70fc91e38e2d2f5238899f620481d16&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 适配器模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483737&amp;idx=1&amp;sn=ed27a42a80b87ff74f1e1266d918ad5b&amp;chksm=e9c2ed54deb56442aba5c95fbddd4c774eb39ebe7ab8c03471a62e3cf3979e303cef43417bac&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 享元模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483742&amp;idx=1&amp;sn=436670dc4793c6c9e7207ca6222e062c&amp;chksm=e9c2ed53deb56445c7fb1aef89ab80b23bab96e6f9993618c98e1746209eec05f36b231cfaa8&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 组合模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483747&amp;idx=1&amp;sn=aa494215a2933e2424a6daa03587e478&amp;chksm=e9c2ed6edeb564783b9acd9f5372a08d53d04b001ca362c9213c4379bc7e1bff363e4ad01e3c&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 模板方法模式及典型应用</a>   </p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>设计模式 | 模板方法模式及典型应用</title>
      <link href="/2018/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2018/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>本文的主要内容：</p><ul><li>介绍模板方法模式</li><li>源码分析模板方法模式的典型应用<ul><li>Servlet 中的模板方法模式</li><li>Mybatis BaseExecutor接口中的模板方法模式</li></ul></li></ul><h2 id="模板方法模式"><a href="#模板方法模式" class="headerlink" title="模板方法模式"></a>模板方法模式</h2><p>在程序开发中，经常会遇到这种情况：某个方法要实现的算法需要多个步骤，但其中有一些步骤是固定不变的，而另一些步骤则是不固定的。为了提高代码的可扩展性和可维护性，模板方法模式在这种场景下就派上了用场。</p><p>譬如制作一节网课的步骤可以简化为4个步骤：</p><ol><li>制作PPT</li><li>录制视频</li><li>编写笔记</li><li>提供课程资料</li></ol><p>其中1、2、3的动作在所有课程中的固定不变的，步骤3可有可无，步骤4在每个课程都不同（有些课程需要提供源代码，有些需要提供图片文件等）</p><p>我们可以在父类中确定整个流程的循序，并实现固定不变的步骤，而把不固定的步骤留给子类实现。甚至可以通过一个钩子方法，让子类来决定流程中某个方法的执行与否</p><p><img src="http://image.laijianfeng.org/20181010_214705.jpg" alt="示例.模板方法模式"></p><p><strong>模板方法模式</strong>：定义一个操作中算法的框架，而将一些步骤延迟到子类中。模板方法模式使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。模板方法模式是一种基于继承的代码复用技术，它是一种类行为型模式。</p><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><p><strong>AbstractClass（抽象类）</strong>：在抽象类中定义了一系列基本操作(PrimitiveOperations)，这些基本操作可以是具体的，也可以是抽象的，每一个基本操作对应算法的一个步骤，在其子类中可以重定义或实现这些步骤。同时，在抽象类中实现了一个模板方法(Template Method)，用于定义一个算法的框架，模板方法不仅可以调用在抽象类中实现的基本方法，也可以调用在抽象类的子类中实现的基本方法，还可以调用其他对象中的方法。</p><p><strong>ConcreteClass（具体子类）</strong>：它是抽象类的子类，用于实现在父类中声明的抽象基本操作以完成子类特定算法的步骤，也可以覆盖在父类中已经实现的具体基本操作。</p><p>一个模板方法是定义在抽象类中的、把基本操作方法组合在一起形成一个总算法或一个总行为的方法。这个模板方法定义在抽象类中，并由子类不加以修改地完全继承下来。模板方法是一个具体方法，它给出了一个顶层逻辑框架，而逻辑的组成步骤在抽象类中可以是具体方法，也可以是抽象方法。</p><p>基本方法是实现算法各个步骤的方法，是模板方法的组成部分。基本方法又可以分为三种：抽象方法(Abstract Method)、具体方法(Concrete Method)和钩子方法(Hook Method)。</p><ul><li>抽象方法：一个抽象方法由抽象类声明、由其具体子类实现。</li><li>具体方法：一个具体方法由一个抽象类或具体类声明并实现，其子类可以进行覆盖也可以直接继承。</li><li>钩子方法：可以与一些具体步骤 “挂钩” ，以实现在不同条件下执行模板方法中的不同步骤</li></ul><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>所以我们通过模板方法模式，在抽象类中把整个流程固定下来，其中1、2、3的实现在抽象类中完成，3的执行与否则由子类通过钩子方法来控制，4则由子类来实现</p><p>抽象类定义如下：</p><pre><code class="java">public abstract class ACourse {    protected final void makeCourse() {        this.makePPT();        this.makeVideo();        if (needWriteArticle()) {            this.writeArticle();        }        this.packageCourse();    }    final void makePPT() {        System.out.println(&quot;1. 制作PPT&quot;);    }    final void makeVideo() {        System.out.println(&quot;2. 制作视频&quot;);    }    final void writeArticle() {        System.out.println(&quot;3. 编写课程笔记&quot;);    }    //钩子方法    protected boolean needWriteArticle() {        return false;    }    abstract void packageCourse();}</code></pre><p>其中的 <code>makeCourse</code> 方法是模板方法，它定义了制作网课的基本流程，<code>makePPT</code>、<code>makeVideo</code>、<code>writeArticle</code> 这三个步骤在所有课程中都是固定的，所以用 <code>final</code> 关键字修饰；<code>packageCourse</code> 方法在所有课程中都可能不一样，所以声明为抽象方法，由子类自行实现；钩子方法 <code>needWriteArticle</code> 返回一个 <code>boolean</code> 类型的值，控制是否编写课程笔记</p><p>子类 JavaCourse，实现了抽象方法 <code>packageCourse</code>，重写了钩子方法 <code>needWriteArticle</code></p><pre><code class="java">public class JavaCourse extends ACourse {    @Override    void packageCourse() {        System.out.println(&quot;4. 提供Java课程源代码&quot;);    }    @Override    protected boolean needWriteArticle() {        return true;    }}</code></pre><p>子类 FECourse，实现了抽象方法 <code>packageCourse</code>，重写了钩子方法 <code>needWriteArticle</code>，其中把钩子方法的结果交给客户端确定</p><pre><code class="java">public class FECourse extends ACourse {    private boolean needWriteArticleFlag = false;    @Override    void packageCourse() {        System.out.println(&quot;4.1 提供课程的前端代码&quot;);        System.out.println(&quot;4.2 提供课程的图片等多媒体素材&quot;);    }    public FECourse(boolean needWriteArticleFlag) {        this.needWriteArticleFlag = needWriteArticleFlag;    }    @Override    protected boolean needWriteArticle() {        return this.needWriteArticleFlag;    }}</code></pre><p>客户端测试</p><pre><code class="java">public class Test {    public static void main(String[] args) {        System.out.println(&quot;Java课程start---&quot;);        ACourse javaCourse = new JavaCourse();        javaCourse.makeCourse();        System.out.println(&quot;Java课程end---\n&quot;);        System.out.println(&quot;前端课程start---&quot;);        ACourse feCourse = new FECourse(false);        feCourse.makeCourse();        System.out.println(&quot;前端课程end---&quot;);    }}</code></pre><p>输出结果</p><pre><code>Java课程start---1. 制作PPT2. 制作视频3. 编写笔记4. 提供Java课程源代码Java课程end---前端课程start---1. 制作PPT2. 制作视频4.1 提供课程的前端代码4.2 提供课程的图片等多媒体素材前端课程end---</code></pre><p>它们的类图如下</p><p><img src="http://image.laijianfeng.org/20181010_213837.png" alt="示例.模板方法模式"></p><h2 id="模板方法模式总结"><a href="#模板方法模式总结" class="headerlink" title="模板方法模式总结"></a>模板方法模式总结</h2><p>模板方法模式的<strong>主要优点</strong>如下：</p><ul><li>在父类中形式化地定义一个算法，而由它的子类来实现细节的处理，在子类实现详细的处理算法时并不会改变算法中步骤的执行次序。</li><li>模板方法模式是一种代码复用技术，它在类库设计中尤为重要，它提取了类库中的公共行为，将公共行为放在父类中，而通过其子类来实现不同的行为，它鼓励我们恰当使用继承来实现代码复用。</li><li>可实现一种反向控制结构，通过子类覆盖父类的钩子方法来决定某一特定步骤是否需要执行。</li><li>在模板方法模式中可以通过子类来覆盖父类的基本方法，不同的子类可以提供基本方法的不同实现，更换和增加新的子类很方便，符合单一职责原则和开闭原则。</li></ul><p>模板方法模式的<strong>主要缺点</strong>如下：</p><ul><li>需要为每一个基本方法的不同实现提供一个子类，如果父类中可变的基本方法太多，将会导致类的个数增加，系统更加庞大，设计也更加抽象，此时，可结合桥接模式来进行设计。</li></ul><p><strong>适用场景</strong>：</p><ul><li>对一些复杂的算法进行分割，将其算法中固定不变的部分设计为模板方法和父类具体方法，而一些可以改变的细节由其子类来实现。即：一次性实现一个算法的不变部分，并将可变的行为留给子类来实现。</li><li>各子类中公共的行为应被提取出来并集中到一个公共父类中以避免代码重复。</li><li>需要通过子类来决定父类算法中某个步骤是否执行，实现子类对父类的反向控制。</li></ul><h2 id="源码分析模板方法模式的典型应用"><a href="#源码分析模板方法模式的典型应用" class="headerlink" title="源码分析模板方法模式的典型应用"></a>源码分析模板方法模式的典型应用</h2><h3 id="Servlet-中的模板方法模式"><a href="#Servlet-中的模板方法模式" class="headerlink" title="Servlet 中的模板方法模式"></a>Servlet 中的模板方法模式</h3><p><code>Servlet</code>（Server Applet）是Java Servlet的简称，用Java编写的服务器端程序，主要功能在于交互式地浏览和修改数据，生成动态Web内容。在每一个 <code>Servlet</code> 都必须要实现 <code>Servlet</code> 接口，<code>GenericServlet</code> 是个通用的、不特定于任何协议的Servlet，它实现了 <code>Servlet</code> 接口，而 <code>HttpServlet</code> 继承于 <code>GenericServlet</code>，实现了 <code>Servlet</code> 接口，为 <code>Servlet</code> 接口提供了处理HTTP协议的通用实现，所以我们定义的 <code>Servlet</code> 只需要继承 <code>HttpServlet</code> 即可。</p><p><img src="http://image.laijianfeng.org/20181010_214703.png" alt="HttpServlet的继承关系"></p><p><code>HttpServlet</code> 的简要代码如下所示</p><pre><code class="java">public abstract class HttpServlet extends GenericServlet {    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {        // ...    }    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {        // ...    }    protected void doHead(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {        // ...    }    protected void doPut(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {        // ...    }    protected void doDelete(HttpServletRequest req,  HttpServletResponse resp) throws ServletException, IOException {        // ...    }    protected void doOptions(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {        // ...    }    protected void doTrace(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {        // ...    }    protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {        String method = req.getMethod();        if (method.equals(METHOD_GET)) {            long lastModified = getLastModified(req);            if (lastModified == -1) {                // servlet doesn&#39;t support if-modified-since, no reason                // to go through further expensive logic                doGet(req, resp);            } else {                long ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE);                if (ifModifiedSince &lt; lastModified) {                    // If the servlet mod time is later, call doGet()                    // Round down to the nearest second for a proper compare                    // A ifModifiedSince of -1 will always be less                    maybeSetLastModified(resp, lastModified);                    doGet(req, resp);                } else {                    resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED);                }            }        } else if (method.equals(METHOD_HEAD)) {            long lastModified = getLastModified(req);            maybeSetLastModified(resp, lastModified);            doHead(req, resp);        } else if (method.equals(METHOD_POST)) {            doPost(req, resp);        } else if (method.equals(METHOD_PUT)) {            doPut(req, resp);        } else if (method.equals(METHOD_DELETE)) {            doDelete(req, resp);        } else if (method.equals(METHOD_OPTIONS)) {            doOptions(req,resp);        } else if (method.equals(METHOD_TRACE)) {            doTrace(req,resp);        } else {            //            // Note that this means NO servlet supports whatever            // method was requested, anywhere on this server.            //            String errMsg = lStrings.getString(&quot;http.method_not_implemented&quot;);            Object[] errArgs = new Object[1];            errArgs[0] = method;            errMsg = MessageFormat.format(errMsg, errArgs);            resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg);        }    }    // ...省略...}</code></pre><p>在 <code>HttpServlet</code> 的 <code>service</code> 方法中，首先获得到请求的方法名，然后根据方法名调用对应的 <code>doXXX</code> 方法，比如说请求方法为GET，那么就去调用 <code>doGet</code> 方法；请求方法为POST，那么就去调用 <code>doPost</code> 方法</p><p><code>HttpServlet</code> 相当于定义了一套处理 HTTP 请求的模板；<code>service</code> 方法为模板方法，定义了处理HTTP请求的基本流程；<code>doXXX</code> 等方法为基本方法，根据请求方法做相应的处理，子类可重写这些方法；<code>HttpServletRequest</code> 中的Method则起到钩子方法的作用.</p><p>在开发javaWeb应用时，自定义的Servlet类一般都扩展 <code>HttpServlet</code> 类，譬如我们实现一个输出 <code>Hello World!</code> 的 <code>Servlet</code> 如下</p><pre><code class="java">import java.io.*;import javax.servlet.*;import javax.servlet.http.*;// 扩展 HttpServlet 类public class HelloWorld extends HttpServlet {  public void init() throws ServletException {    // ...  }  public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {      response.setContentType(&quot;text/html&quot;);      PrintWriter out = response.getWriter();      out.println(&quot;&lt;h1&gt;Hello World!&lt;/h1&gt;&quot;);  }  public void destroy() {      // ...  }}</code></pre><p>该自定义的 <code>Servlet</code> 重写了 <code>doGet</code> 方法，当客户端发起 GET 请求时将得到 <code>&lt;h1&gt;Hello World!&lt;/h1&gt;</code>。</p><h3 id="Mybatis-BaseExecutor接口中的模板方法模式"><a href="#Mybatis-BaseExecutor接口中的模板方法模式" class="headerlink" title="Mybatis BaseExecutor接口中的模板方法模式"></a>Mybatis BaseExecutor接口中的模板方法模式</h3><p><code>Executor</code> 是 Mybatis 的核心接口之一，其中定义了数据库操作的基本方法，该接口的代码如下：</p><pre><code>public interface Executor {  ResultHandler NO_RESULT_HANDLER = null;  // 执行 update、insert、delete 三种类型的SQL语句  int update(MappedStatement ms, Object parameter) throws SQLException;  // 执行selete类型的SQL语句，返回值分为结果对象列表或游标对象  &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey cacheKey, BoundSql boundSql) throws SQLException;  /  &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException;  &lt;E&gt; Cursor&lt;E&gt; queryCursor(MappedStatement ms, Object parameter, RowBounds rowBounds) throws SQLException;   // 批量执行SQL语句  List&lt;BatchResult&gt; flushStatements() throws SQLException;  // 提交事务  void commit(boolean required) throws SQLException;  // 回滚事务  void rollback(boolean required) throws SQLException;  // 创建缓存中用到的CacheKey对象  CacheKey createCacheKey(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql);  // 根据CacheKey对象查找缓存  boolean isCached(MappedStatement ms, CacheKey key);  // 清空一级缓存  void clearLocalCache();  // 延迟加载一级缓存中的数据  void deferLoad(MappedStatement ms, MetaObject resultObject, String property, CacheKey key, Class&lt;?&gt; targetType);  // 获取事务对象  Transaction getTransaction();  // 关闭Executor对象  void close(boolean forceRollback);  // 检测Executor是否已关闭  boolean isClosed();  void setExecutorWrapper(Executor executor);}</code></pre><p><code>Executor</code> 类的类图如下</p><p><img src="http://image.laijianfeng.org/20181010_214704.png" alt="Executor与其子类的类图"></p><p><code>BaseExecutor</code> 中主要提供了缓存管理和事务管理的基本功能，继承 <code>BaseExecutor</code> 的子类只需要实现四个基本方法来完成数据库的相关操作即可，这四个方法分别是：<code>doUpdate()</code> 方法、<code>doQuery()</code> 方法、<code>doQueryCursor()</code> 方法、<code>doFlushStatement()</code> 方法，其余功能都在 <code>BaseExecutor</code> 中实现。</p><p><code>BaseExecutor</code>的部分代码如下，其中的 <code>query()</code> 方法首先会创建 <code>CacheKey</code> 对象，并根据 <code>CacheKey</code> 对象查找一级缓存，如果缓存命中则返回缓存中记录的结果对象，如果未命中则查询数据库得到结果集，之后将结果集映射成结果对象并保存到一级缓存中，同时返回结果对象。</p><pre><code class="java">public abstract class BaseExecutor implements Executor {  protected Transaction transaction;  protected Executor wrapper;  protected ConcurrentLinkedQueue&lt;DeferredLoad&gt; deferredLoads;  protected PerpetualCache localCache;  protected PerpetualCache localOutputParameterCache;  protected Configuration configuration;  protected int queryStack = 0;  private boolean closed;  @Override  public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {    ErrorContext.instance().resource(ms.getResource()).activity(&quot;executing a query&quot;).object(ms.getId());    if (closed) {      throw new ExecutorException(&quot;Executor was closed.&quot;);    }    if (queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) {      clearLocalCache();    }    List&lt;E&gt; list;    try {      queryStack++;      list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null;      if (list != null) {        handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);      } else {        list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);      }    } finally {      queryStack--;    }    if (queryStack == 0) {      for (DeferredLoad deferredLoad : deferredLoads) {        deferredLoad.load();      }      // issue #601      deferredLoads.clear();      if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) {        // issue #482        clearLocalCache();      }    }    return list;  }  protected abstract int doUpdate(MappedStatement ms, Object parameter)      throws SQLException;  protected abstract List&lt;BatchResult&gt; doFlushStatements(boolean isRollback)      throws SQLException;  protected abstract &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql)      throws SQLException;  protected abstract &lt;E&gt; Cursor&lt;E&gt; doQueryCursor(MappedStatement ms, Object parameter, RowBounds rowBounds, BoundSql boundSql)      throws SQLException;  // 省略....}</code></pre><p><code>BaseExecutor</code> 的子类有四个分别是 <code>SimpleExecotor</code>、<code>ReuseExecutor</code>、<code>BatchExecutor</code>、<code>ClosedExecutor</code>，由于这里使用了模板方法模式，一级缓存等固定不变的操作都封装到了 <code>BaseExecutor</code> 中，因此子类就不必再关心一级缓存等操作，只需要专注实现4个基本方法的实现即可。</p><p>这里对这四个子类的功能做一个简要的介绍：</p><ul><li><code>SimpleExecutor</code> 是Mybatis执行Mapper语句时默认使用的 <code>Executor</code>，提供最基本的Mapper语句执行功能，没有过多的封装的</li><li><code>ReuseExecutor</code> 提供了 <code>Statement</code> 重用的功能，通过 <code>statementMap</code> 字段缓存使用过的 <code>Statement</code> 对象进行重用，可以减少SQL预编译以及创建和销毁 <code>Statement</code> 对象的开销，从而提高性能</li><li><code>BatchExecutor</code> 实现了批处理多条SQL语句的功能，在客户端缓存多条SQL并在合适的时机将多条SQL打包发送给数据库执行，从而减少网络方面的开销，提升系统的性能</li><li><code>ClosedExecutor</code> 只是某个类的一个内部类</li></ul><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析<br>徐郡明：Mybatis技术内幕 3.6 Executor</p></blockquote><h3 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h3><p><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483700&amp;idx=1&amp;sn=dd4d23f9400c8be248f5d125465ba941&amp;chksm=e9c2ed39deb5642fb809eca1351f00995f06c9a4875f09986cc5005059eff74d6c20fc1118a3&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 简单工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483704&amp;idx=1&amp;sn=fa3ae947cebf22da35e6ac0a37f566f8&amp;chksm=e9c2ed35deb564230a69e43d93a3b74618287c6ddd402a6f1dc6a5b14a896e99584985e7cf92&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 工厂方法模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483708&amp;idx=1&amp;sn=9b8c155b86511ea6ec323dc6a72c52df&amp;chksm=e9c2ed31deb56427b2a6bbcbad5bdd3a4ef68b52eb88cc47b5bcfc76773d3d983d8aaf57761c&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 抽象工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483712&amp;idx=1&amp;sn=1ffd9837eb9413dde74ff509bf69ecc5&amp;chksm=e9c2ed4ddeb5645b8cbf64c83d103a859ae49921c60e17fe8bebe63c26b04966be101d598848&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 建造者模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483716&amp;idx=1&amp;sn=df00c297c8f32e10e277db8941839c14&amp;chksm=e9c2ed49deb5645fa2586da358a8f0a00dd926f883637adebc59435f846c67c040ef759ba034&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 原型模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483721&amp;idx=1&amp;sn=721d0bce3bd516c10d4b6addbf3eced6&amp;chksm=e9c2ed44deb56452395c94a0b150994b94aa26cae71149e6c030d0ac32f9c3c37e2bfe9685b6&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 外观模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483726&amp;idx=1&amp;sn=df583e5b297ddaff5e1ab822df762274&amp;chksm=e9c2ed43deb56455d2a099f3c3e8622031027d6da00202e6a7d731eac691e4d87d673ca103b5&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 装饰者模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483730&amp;idx=1&amp;sn=859feab7f4632b7ba3d1b5a614d57bbe&amp;chksm=e9c2ed5fdeb56449575995778573fa05a3730ac72792d70fc91e38e2d2f5238899f620481d16&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 适配器模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483737&amp;idx=1&amp;sn=ed27a42a80b87ff74f1e1266d918ad5b&amp;chksm=e9c2ed54deb56442aba5c95fbddd4c774eb39ebe7ab8c03471a62e3cf3979e303cef43417bac&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 享元模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483742&amp;idx=1&amp;sn=436670dc4793c6c9e7207ca6222e062c&amp;chksm=e9c2ed53deb56445c7fb1aef89ab80b23bab96e6f9993618c98e1746209eec05f36b231cfaa8&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 组合模式及典型应用</a></p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>设计模式 | 组合模式及典型应用</title>
      <link href="/2018/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2018/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>本文的主要内容：</p><ul><li>介绍组合模式</li><li>示例</li><li>组合模式总结</li><li>源码分析组合模式的典型应用<ul><li>java.awt中的组合模式</li><li>Java集合中的组合模式</li><li>Mybatis SqlNode中的组合模式</li></ul></li></ul><h2 id="组合模式"><a href="#组合模式" class="headerlink" title="组合模式"></a>组合模式</h2><p>树形结构不论在生活中或者是开发中都是一种非常常见的结构，一个容器对象（如文件夹）下可以存放多种不同的叶子对象或者容器对象，容器对象与叶子对象之间属性差别可能非常大。</p><p>由于容器对象和叶子对象在功能上的区别，在使用这些对象的代码中必须有区别地对待容器对象和叶子对象，而实际上<strong>大多数情况下我们希望一致地处理它们</strong>，因为对于这些对象的区别对待将会使得程序非常复杂。</p><p><img src="http://image.laijianfeng.org/20181005_123836.jpg" alt="一个简化的Linux目录树"></p><p>组合模式为解决此类问题而诞生，<strong>它可以让叶子对象和容器对象的使用具有一致性</strong>。</p><p><strong>组合模式(Composite Pattern)</strong>：组合多个对象形成树形结构以表示具有 “整体—部分” 关系的层次结构。组合模式对单个对象（即叶子对象）和组合对象（即容器对象）的使用具有一致性，组合模式又可以称为 “整体—部分”(Part-Whole) 模式，它是一种对象结构型模式。</p><p>由于在软件开发中存在大量的树形结构，因此组合模式是一种使用频率较高的结构型设计模式，Java SE中的AWT和Swing包的设计就基于组合模式。</p><p>除此以外，在XML解析、组织结构树处理、文件系统设计等领域，组合模式都得到了广泛应用。</p><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><p><strong>Component（抽象构件）</strong>：它可以是接口或抽象类，为叶子构件和容器构件对象声明接口，在该角色中可以包含所有子类共有行为的声明和实现。在抽象构件中定义了访问及管理它的子构件的方法，如增加子构件、删除子构件、获取子构件等。</p><p><strong>Leaf（叶子构件）</strong>：它在组合结构中表示叶子节点对象，叶子节点没有子节点，它实现了在抽象构件中定义的行为。对于那些访问及管理子构件的方法，可以通过异常等方式进行处理。</p><p><strong>Composite（容器构件）</strong>：它在组合结构中表示容器节点对象，容器节点包含子节点，其子节点可以是叶子节点，也可以是容器节点，它提供一个集合用于存储子节点，实现了在抽象构件中定义的行为，包括那些访问及管理子构件的方法，在其业务方法中可以递归调用其子节点的业务方法。</p><p>组合模式的<strong>关键是定义了一个抽象构件类，它既可以代表叶子，又可以代表容器</strong>，而客户端针对该抽象构件类进行编程，无须知道它到底表示的是叶子还是容器，可以对其进行统一处理。<strong>同时容器对象与抽象构件类之间还建立一个聚合关联关系</strong>，在容器对象中既可以包含叶子，也可以包含容器，以此实现递归组合，形成一个树形结构。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>我们来实现一个简单的目录树，有文件夹和文件两种类型，首先需要一个抽象构件类，声明了文件夹类和文件类需要的方法</p><pre><code class="java">public abstract class Component {    public String getName() {        throw new UnsupportedOperationException(&quot;不支持获取名称操作&quot;);    }    public void add(Component component) {        throw new UnsupportedOperationException(&quot;不支持添加操作&quot;);    }    public void remove(Component component) {        throw new UnsupportedOperationException(&quot;不支持删除操作&quot;);    }    public void print() {        throw new UnsupportedOperationException(&quot;不支持打印操作&quot;);    }    public String getContent() {        throw new UnsupportedOperationException(&quot;不支持获取内容操作&quot;);    }}</code></pre><p>实现一个文件夹类 Folder，继承 Component，定义一个 <code>List&lt;Component&gt;</code> 类型的componentList属性，用来存储该文件夹下的文件和子文件夹，并实现 getName、add、remove、print等方法</p><pre><code class="java">public class Folder extends Component {    private String name;    private List&lt;Component&gt; componentList = new ArrayList&lt;Component&gt;();    public Folder(String name) {        this.name = name;    }    @Override    public String getName() {        return this.name;    }    @Override    public void add(Component component) {        this.componentList.add(component);    }    @Override    public void remove(Component component) {        this.componentList.remove(component);    }    @Override    public void print() {        System.out.println(this.getName());        for (Component component : this.componentList) {            component.print();        }    }}</code></pre><p>文件类 File，继承Component父类，实现 getName、print、getContent等方法</p><pre><code class="java">public class File extends Component {    private String name;    private String content;    public File(String name, String content) {        this.name = name;        this.content = content;    }    @Override    public String getName() {        return this.name;    }    @Override    public void print() {        System.out.println(this.getName());    }    @Override    public String getContent() {        return this.content;    }}</code></pre><p>我们来测试一下</p><pre><code class="java">public class Test {    public static void main(String[] args) {        Folder DSFolder = new Folder(&quot;设计模式资料&quot;);        File note1 = new File(&quot;组合模式笔记.md&quot;, &quot;组合模式组合多个对象形成树形结构以表示具有 \&quot;整体—部分\&quot; 关系的层次结构&quot;);        File note2 = new File(&quot;工厂方法模式.md&quot;, &quot;工厂方法模式定义一个用于创建对象的接口，让子类决定将哪一个类实例化。&quot;);        DSFolder.add(note1);        DSFolder.add(note2);        Folder codeFolder = new Folder(&quot;样例代码&quot;);        File readme = new File(&quot;README.md&quot;, &quot;# 设计模式示例代码项目&quot;);        Folder srcFolder = new Folder(&quot;src&quot;);        File code1 = new File(&quot;组合模式示例.java&quot;, &quot;这是组合模式的示例代码&quot;);        srcFolder.add(code1);        codeFolder.add(readme);        codeFolder.add(srcFolder);        DSFolder.add(codeFolder);        DSFolder.print();    }}</code></pre><p>输出结果</p><pre><code>设计模式资料组合模式笔记.md工厂方法模式.md样例代码README.mdsrc组合模式示例.java</code></pre><p>输出正常，不过有个小问题，<strong>从输出看不出它们的层级结构</strong>，为了体现出它们之间的层级关系，我们需要改造一下 Folder 类，增加一个 level 属性，并修改 print 方法</p><pre><code class="java">public class Folder extends Component {    private String name;    private List&lt;Component&gt; componentList = new ArrayList&lt;Component&gt;();    public Integer level;    public Folder(String name) {        this.name = name;    }    @Override    public String getName() {        return this.name;    }    @Override    public void add(Component component) {        this.componentList.add(component);    }    @Override    public void remove(Component component) {        this.componentList.remove(component);    }    @Override    public void print() {        System.out.println(this.getName());        if (this.level == null) {            this.level = 1;        }        String prefix = &quot;&quot;;        for (int i = 0; i &lt; this.level; i++) {            prefix += &quot;\t- &quot;;        }        for (Component component : this.componentList) {            if (component instanceof Folder){                ((Folder)component).level = this.level + 1;            }            System.out.print(prefix);            component.print();        }        this.level = null;    }}</code></pre><p>现在的输出就有相应的层级结构了</p><pre><code>设计模式资料    - 组合模式笔记.md    - 工厂方法模式.md    - 样例代码    -     - README.md    -     - src    -     -     - 组合模式示例.java</code></pre><p>我们可以画出它们之间的类图</p><p><img src="http://image.laijianfeng.org/20181004_164219.png" alt="示例.组合模式类图"></p><p>在这里父类 <code>Component</code> 是一个抽象构件类，<code>Folder</code> 类是一个容器构件类，<code>File</code> 是一个叶子构件类，Folder 和 File 继承了 Component，Folder 与 Component 又是聚合关系</p><h2 id="透明与安全"><a href="#透明与安全" class="headerlink" title="透明与安全"></a>透明与安全</h2><p>在使用组合模式时，根据抽象构件类的定义形式，我们可将组合模式分为透明组合模式和安<br>全组合模式两种形式。</p><p><strong>透明组合模式</strong></p><p>透明组合模式中，抽象构件角色中声明了所有用于管理成员对象的方法，譬如在示例中 <code>Component</code> 声明了 <code>add</code>、<code>remove</code> 方法，这样做的好处是确保所有的构件类都有相同的接口。透明组合模式也是组合模式的标准形式。</p><p>透明组合模式的缺点是不够安全，因为叶子对象和容器对象在本质上是有区别的，叶子对象不可能有下一个层次的对象，即不可能包含成员对象，因此为其提供 <code>add()</code>、<code>remove()</code> 等方法是没有意义的，这在编译阶段不会出错，但在运行阶段如果调用这些方法可能会出错（如果没有提供相应的错误处理代码）</p><p><strong>安全组合模式</strong> </p><p>在安全组合模式中，在抽象构件角色中没有声明任何用于管理成员对象的方法，而是在容器构件 <code>Composite</code> 类中声明并实现这些方法。</p><p><img src="http://image.laijianfeng.org/20181005_123837.jpg" alt="安全组合模式模式图"></p><p>安全组合模式的缺点是不够透明，因为叶子构件和容器构件具有不同的方法，且容器构件中那些用于管理成员对象的方法没有在抽象构件类中定义，因此客户端不能完全针对抽象编程，必须有区别地对待叶子构件和容器构件。</p><p>在实际应用中 <code>java.awt</code> 和 <code>swing</code> 中的组合模式即为安全组合模式。</p><h2 id="组合模式总结"><a href="#组合模式总结" class="headerlink" title="组合模式总结"></a>组合模式总结</h2><p>组合模式的<strong>主要优点</strong>如下：</p><ul><li>组合模式可以清楚地定义分层次的复杂对象，表示对象的全部或部分层次，它让客户端忽略了层次的差异，方便对整个层次结构进行控制。</li><li>客户端可以一致地使用一个组合结构或其中单个对象，不必关心处理的是单个对象还是整个组合结构，简化了客户端代码。</li><li>在组合模式中增加新的容器构件和叶子构件都很方便，无须对现有类库进行任何修改，符合“开闭原则”。</li><li>组合模式为树形结构的面向对象实现提供了一种灵活的解决方案，通过叶子对象和容器对象的递归组合，可以形成复杂的树形结构，但对树形结构的控制却非常简单。</li></ul><p>组合模式的<strong>主要缺点</strong>如下：</p><ul><li>使得设计更加复杂，客户端需要花更多时间理清类之间的层次关系。</li><li>在增加新构件时很难对容器中的构件类型进行限制。</li></ul><p><strong>适用场景</strong>：</p><ul><li>在具有整体和部分的层次结构中，希望通过一种方式忽略整体与部分的差异，客户端可以一致地对待它们。</li><li>在一个使用面向对象语言开发的系统中需要处理一个树形结构。</li><li>在一个系统中能够分离出叶子对象和容器对象，而且它们的类型不固定，需要增加一些新的类型。</li></ul><h2 id="源码分析组合模式的典型应用"><a href="#源码分析组合模式的典型应用" class="headerlink" title="源码分析组合模式的典型应用"></a>源码分析组合模式的典型应用</h2><h3 id="java-awt中的组合模式"><a href="#java-awt中的组合模式" class="headerlink" title="java.awt中的组合模式"></a>java.awt中的组合模式</h3><p>Java GUI分两种：</p><ul><li><p>AWT(Abstract Window Toolkit)：抽象窗口工具集，是第一代的Java GUI组件。绘制依赖于底层的操作系统。基本的AWT库处理用户界面元素的方法是把这些元素的创建和行为委托给每个目标平台上（Windows、 Unix、 Macintosh等）的本地GUI工具进行处理。</p></li><li><p>Swing，不依赖于底层细节，是轻量级的组件。现在多是基于Swing来开发。</p></li></ul><p>我们来看一个AWT的简单示例：</p><blockquote><p>注意：为了正常显示中文，需要在IDEA中的 <code>Edit Configurations -&gt; VM Options</code> 中设置参数 <code>-Dfile.encoding=GB18030</code></p></blockquote><pre><code class="java">import java.awt.*;import java.awt.event.WindowAdapter;import java.awt.event.WindowEvent;public class MyFrame extends Frame {    public MyFrame(String title) {        super(title);    }    public static void main(String[] args) {        MyFrame frame = new MyFrame(&quot;这是一个 Frame&quot;);        // 定义三个构件，添加到Frame中去        Button button = new Button(&quot;按钮 A&quot;);        Label label = new Label(&quot;这是一个 AWT Label!&quot;);        TextField textField = new TextField(&quot;这是一个 AWT TextField!&quot;);        frame.add(button, BorderLayout.EAST);        frame.add(label, BorderLayout.SOUTH);        frame.add(textField, BorderLayout.NORTH);        // 定义一个 Panel，在Panel中添加三个构件，然后再把Panel添加到Frame中去        Panel panel = new Panel();        panel.setBackground(Color.pink);        Label lable1 = new Label(&quot;用户名&quot;);        TextField textField1 = new TextField(&quot;请输入用户名：&quot;, 20);        Button button1 = new Button(&quot;确定&quot;);        panel.add(lable1);        panel.add(textField1);        panel.add(button1);        frame.add(panel, BorderLayout.CENTER);        // 设置Frame的属性        frame.setSize(500, 300);        frame.setBackground(Color.orange);        // 设置点击关闭事件        frame.addWindowListener(new WindowAdapter() {            @Override            public void windowClosing(WindowEvent e) {                System.exit(0);            }        });        frame.setVisible(true);    }}</code></pre><p>运行后窗体显示如下</p><p><img src="http://image.laijianfeng.org/20181005_123833.png" alt="示例.AWT绘制窗体"></p><p>我们在Frame容器中添加了三个不同的构件 <code>Button</code>、<code>Label</code>、<code>TextField</code>，还添加了一个 <code>Panel</code> 容器，<code>Panel</code> 容器中又添加了 <code>Button</code>、<code>Label</code>、<code>TextField</code> 三个构件，为什么容器 <code>Frame</code> 和 <code>Panel</code> 可以添加类型不同的构件和容器呢？</p><p>我们先来看下AWT Component的类图</p><p><img src="http://image.laijianfeng.org/20181004_164221.png" alt="AWT Component类图"></p><p>GUI组件根据作用可以分为两种：基本组件和容器组件。</p><ul><li>基本组件又称构件，诸如按钮、文本框之类的图形界面元素。</li><li>容器是一种比较特殊的组件，可以容纳其他组件，容器如窗口、对话框等。所有的容器类都是 <code>java.awt.Container</code> 的直接或间接子类</li></ul><p>容器父类 <code>Container</code> 的部分代码如下</p><pre><code>public class Container extends Component {    /**     * The components in this container.     * @see #add     * @see #getComponents     */    private java.util.List&lt;Component&gt; component = new ArrayList&lt;&gt;();    public Component add(Component comp) {        addImpl(comp, null, -1);        return comp;    }    // 省略...}</code></pre><p>容器父类 <code>Container</code> 内部定义了一个集合用于存储 <code>Component</code> 对象，而容器组件 <code>Container</code> 和 基本组件如 <code>Button</code>、<code>Label</code>、<code>TextField</code> 等都是 <code>Component</code> 的子类，所以可以很清楚的看到这里应用了组合模式</p><p><code>Component</code> 类中封装了组件通用的方法和属性，如图形的组件对象、大小、显示位置、前景色和背景色、边界、可见性等，因此许多组件类也就继承了 <code>Component</code> 类的成员方法和成员变量，相应的成员方法包括：</p><pre><code class="java">　　　getComponentAt(int x, int y)　　　getFont()　　　getForeground()　　　getName()　　　getSize()　　　paint(Graphics g)　　　repaint()　　　update()　　　setVisible(boolean b)　　　setSize(Dimension d)　　　setName(String name)</code></pre><h3 id="Java集合中的组合模式"><a href="#Java集合中的组合模式" class="headerlink" title="Java集合中的组合模式"></a>Java集合中的组合模式</h3><p><code>HashMap</code> 提供 <code>putAll</code> 的方法，可以将另一个 <code>Map</code> 对象放入自己的存储空间中，如果有相同的 key 值则会覆盖之前的 key 值所对应的 value 值</p><pre><code class="java">public class Test {    public static void main(String[] args) {        Map&lt;String, Integer&gt; map1 = new HashMap&lt;String, Integer&gt;();        map1.put(&quot;aa&quot;, 1);        map1.put(&quot;bb&quot;, 2);        map1.put(&quot;cc&quot;, 3);        System.out.println(&quot;map1: &quot; + map1);        Map&lt;String, Integer&gt; map2 = new LinkedMap();        map2.put(&quot;cc&quot;, 4);        map2.put(&quot;dd&quot;, 5);        System.out.println(&quot;map2: &quot; + map2);        map1.putAll(map2);        System.out.println(&quot;map1.putAll(map2): &quot; + map1);    }}</code></pre><p>输出结果</p><pre><code>map1: {aa=1, bb=2, cc=3}map2: {cc=4, dd=5}map1.putAll(map2): {aa=1, bb=2, cc=4, dd=5}</code></pre><p>查看 <code>putAll</code> 源码</p><pre><code>    public void putAll(Map&lt;? extends K, ? extends V&gt; m) {        putMapEntries(m, true);    }</code></pre><p><code>putAll</code> 接收的参数为父类 <code>Map</code> 类型，所以 <code>HashMap</code> 是一个容器类，<code>Map</code> 的子类为叶子类，当然如果 <code>Map</code> 的其他子类也实现了 <code>putAll</code> 方法，那么它们都既是容器类，又都是叶子类</p><p>同理，<code>ArrayList</code> 中的 <code>addAll(Collection&lt;? extends E&gt; c)</code> 方法也是一个组合模式的应用，在此不做探讨</p><h2 id="Mybatis-SqlNode中的组合模式"><a href="#Mybatis-SqlNode中的组合模式" class="headerlink" title="Mybatis SqlNode中的组合模式"></a>Mybatis SqlNode中的组合模式</h2><p>MyBatis 的强大特性之一便是它的动态SQL，其通过 <code>if</code>, <code>choose</code>, <code>when</code>, <code>otherwise</code>, <code>trim</code>, <code>where</code>, <code>set</code>, <code>foreach</code> 标签，可组合成非常灵活的SQL语句，从而提高开发人员的效率。</p><p>来几个官方示例：</p><p>动态SQL – IF</p><pre><code class="sql">&lt;select id=&quot;findActiveBlogLike&quot;  resultType=&quot;Blog&quot;&gt;  SELECT * FROM BLOG WHERE state = ‘ACTIVE’   &lt;if test=&quot;title != null&quot;&gt;    AND title like #{title}  &lt;/if&gt;  &lt;if test=&quot;author != null and author.name != null&quot;&gt;    AND author_name like #{author.name}  &lt;/if&gt;&lt;/select&gt;</code></pre><p>动态SQL – choose, when, otherwise</p><pre><code class="sql">&lt;select id=&quot;findActiveBlogLike&quot;  resultType=&quot;Blog&quot;&gt;  SELECT * FROM BLOG WHERE state = ‘ACTIVE’  &lt;choose&gt;    &lt;when test=&quot;title != null&quot;&gt;      AND title like #{title}    &lt;/when&gt;    &lt;when test=&quot;author != null and author.name != null&quot;&gt;      AND author_name like #{author.name}    &lt;/when&gt;    &lt;otherwise&gt;      AND featured = 1    &lt;/otherwise&gt;  &lt;/choose&gt;&lt;/select&gt;</code></pre><p>动态SQL – where</p><pre><code class="sql">&lt;select id=&quot;findActiveBlogLike&quot;  resultType=&quot;Blog&quot;&gt;  SELECT * FROM BLOG   &lt;where&gt;     &lt;if test=&quot;state != null&quot;&gt;         state = #{state}    &lt;/if&gt;     &lt;if test=&quot;title != null&quot;&gt;        AND title like #{title}    &lt;/if&gt;    &lt;if test=&quot;author != null and author.name != null&quot;&gt;        AND author_name like #{author.name}    &lt;/if&gt;  &lt;/where&gt;&lt;/select&gt;</code></pre><p>动态SQL – foreach</p><pre><code class="sql">&lt;select id=&quot;selectPostIn&quot; resultType=&quot;domain.blog.Post&quot;&gt;  SELECT * FROM POST P WHERE ID in  &lt;foreach item=&quot;item&quot; index=&quot;index&quot; collection=&quot;list&quot;      open=&quot;(&quot; separator=&quot;,&quot; close=&quot;)&quot;&gt;        #{item}  &lt;/foreach&gt;&lt;/select&gt;</code></pre><p>Mybatis在处理动态SQL节点时，应用到了组合设计模式，Mybatis会将映射配置文件中定义的动态SQL节点、文本节点等解析成对应的 SqlNode 实现，并形成树形结构。</p><p><code>SQLNode</code> 的类图如下所示</p><p><img src="http://image.laijianfeng.org/20181005_123835.png" alt="Mybatis SqlNode 类图"></p><p>需要先了解 <code>DynamicContext</code> 类的作用：主要用于记录解析动态SQL语句之后产生的SQL语句片段，可以认为它是一个用于记录动态SQL语句解析结果的容器</p><p>抽象构件为 <code>SqlNode</code> 接口，源码如下</p><pre><code class="java">public interface SqlNode {  boolean apply(DynamicContext context);}</code></pre><p><code>apply</code> 是 <code>SQLNode</code> 接口中定义的唯一方法，该方法会根据用户传入的实参，参数解析该SQLNode所记录的动态SQL节点，并调用 <code>DynamicContext.appendSql()</code> 方法将解析后的SQL片段追加到 <code>DynamicContext.sqlBuilder</code> 中保存，当SQL节点下所有的 <code>SqlNode</code> 完成解析后，我们就可以从 <code>DynamicContext</code> 中获取一条动态生产的、完整的SQL语句</p><p>然后来看 <code>MixedSqlNode</code> 类的源码</p><pre><code>public class MixedSqlNode implements SqlNode {  private List&lt;SqlNode&gt; contents;  public MixedSqlNode(List&lt;SqlNode&gt; contents) {    this.contents = contents;  }  @Override  public boolean apply(DynamicContext context) {    for (SqlNode sqlNode : contents) {      sqlNode.apply(context);    }    return true;  }}</code></pre><p><code>MixedSqlNode</code> 维护了一个 <code>List&lt;SqlNode&gt;</code> 类型的列表，用于存储 <code>SqlNode</code> 对象，<code>apply</code> 方法通过 <code>for循环</code> 遍历 contents 并调用其中对象的 <code>apply</code> 方法，这里跟我们的示例中的 <code>Folder</code> 类中的 <code>print</code> 方法非常类似，很明显 <code>MixedSqlNode</code> 扮演了容器构件角色</p><p>对于其他SqlNode子类的功能，稍微概括如下：</p><ul><li><code>TextSqlNode</code>：表示包含 <code>${}</code> 占位符的动态SQL节点，其 apply 方法会使用 <code>GenericTokenParser</code> 解析 <code>${}</code> 占位符，并直接替换成用户给定的实际参数值</li><li><code>IfSqlNode</code>：对应的是动态SQL节点 <code>&lt;If&gt;</code> 节点，其 apply 方法首先通过 <code>ExpressionEvaluator.evaluateBoolean()</code> 方法检测其 test 表达式是否为 true，然后根据 test 表达式的结果，决定是否执行其子节点的 apply() 方法</li><li><code>TrimSqlNode</code> ：会根据子节点的解析结果，添加或删除相应的前缀或后缀。</li><li><code>WhereSqlNode</code> 和 <code>SetSqlNode</code> 都继承了 <code>TrimSqlNode</code></li><li><code>ForeachSqlNode</code>：对应 <code>&lt;foreach&gt;</code> 标签，对集合进行迭代</li><li>动态SQL中的 <code>&lt;choose&gt;</code>、<code>&lt;when&gt;</code>、<code>&lt;otherwise&gt;</code> 分别解析成 <code>ChooseSqlNode</code>、<code>IfSqlNode</code>、<code>MixedSqlNode</code></li></ul><p>综上，<code>SqlNode</code> 接口有多个实现类，每个实现类对应一个动态SQL节点，其中 <code>SqlNode</code> 扮演抽象构件角色，<code>MixedSqlNode</code> 扮演容器构件角色，其它一般是叶子构件角色</p><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析<br><a href="https://www.cnblogs.com/mengdd/archive/2013/02/06/2906959.html" target="_blank" rel="noopener">Java AWT基础及布局管理</a><br><a href="https://segmentfault.com/a/1190000009324403" target="_blank" rel="noopener">【java源码一带一路系列】之HashMap.putAll()</a><br>徐郡明：Mybatis技术内幕 3.2 SqlNode&amp;SqlSource<br><a href="http://www.mybatis.org/mybatis-3/zh/dynamic-sql.html" target="_blank" rel="noopener">Mybatis 3.4.7 文档：动态 SQL</a>   </p></blockquote><h3 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h3><p><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483700&amp;idx=1&amp;sn=dd4d23f9400c8be248f5d125465ba941&amp;chksm=e9c2ed39deb5642fb809eca1351f00995f06c9a4875f09986cc5005059eff74d6c20fc1118a3&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 简单工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483704&amp;idx=1&amp;sn=fa3ae947cebf22da35e6ac0a37f566f8&amp;chksm=e9c2ed35deb564230a69e43d93a3b74618287c6ddd402a6f1dc6a5b14a896e99584985e7cf92&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 工厂方法模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483708&amp;idx=1&amp;sn=9b8c155b86511ea6ec323dc6a72c52df&amp;chksm=e9c2ed31deb56427b2a6bbcbad5bdd3a4ef68b52eb88cc47b5bcfc76773d3d983d8aaf57761c&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 抽象工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483712&amp;idx=1&amp;sn=1ffd9837eb9413dde74ff509bf69ecc5&amp;chksm=e9c2ed4ddeb5645b8cbf64c83d103a859ae49921c60e17fe8bebe63c26b04966be101d598848&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 建造者模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483716&amp;idx=1&amp;sn=df00c297c8f32e10e277db8941839c14&amp;chksm=e9c2ed49deb5645fa2586da358a8f0a00dd926f883637adebc59435f846c67c040ef759ba034&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 原型模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483721&amp;idx=1&amp;sn=721d0bce3bd516c10d4b6addbf3eced6&amp;chksm=e9c2ed44deb56452395c94a0b150994b94aa26cae71149e6c030d0ac32f9c3c37e2bfe9685b6&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 外观模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483726&amp;idx=1&amp;sn=df583e5b297ddaff5e1ab822df762274&amp;chksm=e9c2ed43deb56455d2a099f3c3e8622031027d6da00202e6a7d731eac691e4d87d673ca103b5&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 装饰者模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483730&amp;idx=1&amp;sn=859feab7f4632b7ba3d1b5a614d57bbe&amp;chksm=e9c2ed5fdeb56449575995778573fa05a3730ac72792d70fc91e38e2d2f5238899f620481d16&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 适配器模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483737&amp;idx=1&amp;sn=ed27a42a80b87ff74f1e1266d918ad5b&amp;chksm=e9c2ed54deb56442aba5c95fbddd4c774eb39ebe7ab8c03471a62e3cf3979e303cef43417bac&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 享元模式及典型应用</a>   </p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>设计模式 | 享元模式及典型应用</title>
      <link href="/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文的主要内容：</p><ul><li>介绍享元模式</li><li>示例-云盘</li><li>总结</li><li>源码分析享元模式的典型应用<ul><li>String中的享元模式</li><li>Integer中的享元模式</li><li>Long中的享元模式</li><li>Apache Common Pool2中的享元模式</li></ul></li></ul><h2 id="享元模式"><a href="#享元模式" class="headerlink" title="享元模式"></a>享元模式</h2><p><strong>享元模式(Flyweight Pattern)</strong>：运用共享技术有效地支持大量细粒度对象的复用。系统只使用少量的对象，而这些对象都很相似，状态变化很小，可以实现对象的多次复用。由于享元模式要求能够共享的对象必须是细粒度对象，因此它又称为轻量级模式，它是一种对象结构型模式。享元模式结构较为复杂，一般结合工厂模式一起使用。</p><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><p><strong>Flyweight（抽象享元类）</strong>：通常是一个接口或抽象类，在抽象享元类中声明了具体享元类公共的方法，这些方法可以向外界提供享元对象的内部数据（内部状态），同时也可以通过这些方法来设置外部数据（外部状态）。</p><p><strong>ConcreteFlyweight（具体享元类）</strong>：它实现了抽象享元类，其实例称为享元对象；在具体享元类中为内部状态提供了存储空间。通常我们可以结合单例模式来设计具体享元类，为每一个具体享元类提供唯一的享元对象。</p><p><strong>UnsharedConcreteFlyweight（非共享具体享元类）</strong>：并不是所有的抽象享元类的子类都需要被共享，不能被共享的子类可设计为非共享具体享元类；当需要一个非共享具体享元类的对象时可以直接通过实例化创建。</p><p><strong>FlyweightFactory（享元工厂类）</strong>：享元工厂类用于创建并管理享元对象，它针对抽象享元类编程，将各种类型的具体享元对象存储在一个享元池中，享元池一般设计为一个存储“键值对”的集合（也可以是其他类型的集合），可以结合工厂模式进行设计；当用户请求一个具体享元对象时，享元工厂提供一个存储在享元池中已创建的实例或者创建一个新的实例（如果不存在的话），返回新创建的实例并将其存储在享元池中。</p><blockquote><p>单纯享元模式：在单纯享元模式中，所有的具体享元类都是可以共享的，不存在非共享具体享元类。<br>复合享元模式：将一些单纯享元对象使用组合模式加以组合，还可以形成复合享元对象，这样的复合享元对象本身不能共享，但是它们可以分解成单纯享元对象，而后者则可以共享</p></blockquote><p>在享元模式中引入了享元工厂类，享元工厂类的作用在于提供一个用于存储享元对象的享元池，当用户需要对象时，首先从享元池中获取，如果享元池中不存在，则创建一个新的享元对象返回给用户，并在享元池中保存该新增对象。</p><p>典型的享元工厂类的代码如下：</p><pre><code>class FlyweightFactory {    //定义一个HashMap用于存储享元对象，实现享元池    private HashMap flyweights = newHashMap();    public Flyweight getFlyweight(String key){        //如果对象存在，则直接从享元池获取        if(flyweights.containsKey(key)){            return(Flyweight)flyweights.get(key);        }        //如果对象不存在，先创建一个新的对象添加到享元池中，然后返回        else {            Flyweight fw = newConcreteFlyweight();            flyweights.put(key,fw);            return fw;        }    }}</code></pre><p>享元类的设计是享元模式的要点之一，在享元类中要将内部状态和外部状态分开处理，通常将内部状态作为享元类的成员变量，而外部状态通过注入的方式添加到享元类中。</p><p>典型的享元类代码如下所示：</p><pre><code>class Flyweight {    //内部状态intrinsicState作为成员变量，同一个享元对象其内部状态是一致的    private String intrinsicState;    public Flyweight(String intrinsicState) {        this.intrinsicState=intrinsicState;    }    //外部状态extrinsicState在使用时由外部设置，不保存在享元对象中，即使是同一个对象    public void operation(String extrinsicState) {        //......    }}</code></pre><p>享元模式一般的类图如下</p><p><img src="http://image.laijianfeng.org/20180925_002554.png" alt="享元模式类图"></p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>一般网盘对于相同的文件只保留一份，譬如有一个场景：当我们上传一部别人上传过的电影，会发现很快就上传完成了，实际上不是真的上传，而是引用别人曾经上传过的那部电影，这样一可以提高我们的用户体验，二可以节约存储空间避免资源浪费</p><blockquote><p>注意：这个场景是小编想的，与一般见到的例子不太一样，小编其实不确定是不是享元模式，请大家多多指教</p></blockquote><p>首先定义一个工具类 HashUtil，计算内容的hash值（注：计算hash是从 <a href="https://www.cnblogs.com/oxgen/p/3962085.html" target="_blank" rel="noopener">https://www.cnblogs.com/oxgen/p/3962085.html</a> 处复制的）</p><pre><code>public class HashUtil {    public static String computeHashId(String key) {        String cacheKey;        try {            final MessageDigest mDigest = MessageDigest.getInstance(&quot;MD5&quot;);            mDigest.update(key.getBytes());            cacheKey = bytesToHexString(mDigest.digest());        } catch (NoSuchAlgorithmException e) {            cacheKey = String.valueOf(key.hashCode());        }        return cacheKey;    }    private static String bytesToHexString(byte[] bytes) {        // http://stackoverflow.com/questions/332079        StringBuilder sb = new StringBuilder();        for (int i = 0; i &lt; bytes.length; i++) {            String hex = Integer.toHexString(0xFF &amp; bytes[i]);            if (hex.length() == 1) {                sb.append(&#39;0&#39;);            }            sb.append(hex);        }        return sb.toString();    }}</code></pre><p>资源类 Resource，相当于享元类的内部状态</p><pre><code>public class Resource {    private String hashId;    private int byteSize;    private String content;    public Resource(String content) {        this.content = content;        this.hashId = HashUtil.computeHashId(content);   // 文件的hash值        this.byteSize = content.length();    }    // ....getter、setter、toString...}</code></pre><p>用户的文件类 File，其中的 resource 为内部状态，owner和filename为外部状态</p><pre><code>public  class File {    protected String owner;    protected String filename;    protected Resource resource;    public File(String owner, String filename) {        this.owner = owner;        this.filename = filename;    }    public String fileMeta() {// 文件存储到文件系统中需要的key        if (this.owner == null || filename == null || resource == null) {            return &quot;未知文件&quot;;        }        return owner + &quot;-&quot; + filename + resource.getHashId();    }    public String display() {        return fileMeta() + &quot;, 资源内容：&quot; + getResource().toString();    }    // ....getter、setter、toString...}</code></pre><p>网盘类 PanServer，该类使用单例模式（在其他例子中该类还使用工厂方法模式），在upload方法中根据所上传的文件的hashId判断是否已经有相同内容的文件存在，存在则引用，不存在才上传该文件</p><pre><code>public class PanServer {    private static PanServer panServer = new PanServer(); // 单例模式    private Map&lt;String, Resource&gt; resourceSystem; // 资源系统，相当于享元池    private Map&lt;String, File&gt; fileSystem;   // 文件系统    public PanServer() {        resourceSystem = new HashMap&lt;String, Resource&gt;();        fileSystem = new HashMap&lt;String, File&gt;();    }    public static PanServer getInstance() {        return panServer;    }    public String upload(String username, LocalFile localFile) {        long startTime = System.currentTimeMillis();        File file = new File(username, localFile.getFilename());        String hashId = HashUtil.computeHashId(localFile.getContent());     // 计算文件hash值        System.out.println(username + &quot; 上传文件&quot;);        try {            if (resourceSystem.containsKey(hashId)) {                System.out.println(String.format(&quot;检测到内容相同的文件《%s》，为了节约空间，重用文件&quot;, localFile.getFilename()));                file.setResource(this.resourceSystem.get(hashId));                Thread.sleep(100);            } else {                System.out.println(String.format(&quot;文件《%s》上传中....&quot;, localFile.getFilename()));                Resource newResource = new Resource(localFile.getContent());                file.setResource(newResource);                this.resourceSystem.put(newResource.getHashId(), newResource); // 将资源对象存储到资源池中                Thread.sleep(3000);     // 上传文件需要耗费一定时间            }        } catch (Exception e) {            e.printStackTrace();        }        fileSystem.put(file.fileMeta(), file);        long endTime = System.currentTimeMillis();        System.out.println(String.format(&quot;文件上传完成，共耗费 %s 毫秒\n&quot;, endTime - startTime));        return file.fileMeta();    }    public void download(String fileKey) {        File file = this.fileSystem.get(fileKey);        if (file == null) {            System.out.println(&quot;文件不存在&quot;);        } else {            System.out.println(&quot;下载文件：&quot; + file.display());        }        // 转为 LocalFile 返回    }}</code></pre><p>客户端和本地文件类</p><pre><code>public class LocalFile {    private String filename;    private String content;    public LocalFile(String filename, String content) {        this.filename = filename;        this.content = content;    }    //...省略...}public class Test {    public static void main(String[] args) {        PanServer panServer = PanServer.getInstance();        String fileContent = &quot;这是一个pdf文件《设计模式：从入门到放弃》&quot;;        LocalFile localFile1 = new LocalFile(&quot;小明的设计模式.pdf&quot;, fileContent);        String fikeKey1 = panServer.upload(&quot;小明&quot;, localFile1);        LocalFile localFile2 = new LocalFile(&quot;大明的设计模式.pdf&quot;, fileContent);        String fikeKey2 = panServer.upload(&quot;大明&quot;, localFile2);        panServer.download(fikeKey1);        panServer.download(fikeKey2);    }}</code></pre><p>输出</p><pre><code>小明 上传文件文件《小明的设计模式.pdf》上传中....文件上传完成，共耗费 3077 毫秒大明 上传文件检测到内容相同的文件《大明的设计模式.pdf》，为了节约空间，重用文件文件上传完成，共耗费 100 毫秒下载文件：小明-小明的设计模式.pdf-f73ea50f00f87b42d1f2e4eb6b71d383, 资源内容：Resource {hashId=&#39;f73ea50f00f87b42d1f2e4eb6b71d383&#39;, byteSize=22, content=&#39;这是一个pdf文件《设计模式：从入门到放弃》&#39;}下载文件：大明-大明的设计模式.pdf-f73ea50f00f87b42d1f2e4eb6b71d383, 资源内容：Resource {hashId=&#39;f73ea50f00f87b42d1f2e4eb6b71d383&#39;, byteSize=22, content=&#39;这是一个pdf文件《设计模式：从入门到放弃》&#39;}</code></pre><p>小明和大明各自上传了一份文件，文件的内容（内部状态）是相同的，但是名称（外部状态）不同，由于内部状态相同没有必要重复存储，所以内部状态之拷贝了一份</p><h2 id="享元模式总结"><a href="#享元模式总结" class="headerlink" title="享元模式总结"></a>享元模式总结</h2><p>享元模式的<strong>主要优点</strong>如下：</p><ul><li>可以极大减少内存中对象的数量，使得相同或相似对象在内存中只保存一份，从而可以节约系统资源，提高系统性能。</li><li>享元模式的外部状态相对独立，而且不会影响其内部状态，从而使得享元对象可以在不同的环境中被共享。</li></ul><p>享元模式的<strong>主要缺点</strong>如下：</p><ul><li>享元模式使得系统变得复杂，需要分离出内部状态和外部状态，这使得程序的逻辑复杂化。</li><li>为了使对象可以共享，享元模式需要将享元对象的部分状态外部化，而读取外部状态将使得运行时间变长。</li></ul><p><strong>适用场景</strong>：</p><ul><li>一个系统有大量相同或者相似的对象，造成内存的大量耗费。</li><li>对象的大部分状态都可以外部化，可以将这些外部状态传入对象中。</li><li>在使用享元模式时需要维护一个存储享元对象的享元池，而这需要耗费一定的系统资源，因此，应当在需要多次重复使用享元对象时才值得使用享元模式。</li></ul><h2 id="源码分析享元模式的典型应用"><a href="#源码分析享元模式的典型应用" class="headerlink" title="源码分析享元模式的典型应用"></a>源码分析享元模式的典型应用</h2><h3 id="String中的享元模式"><a href="#String中的享元模式" class="headerlink" title="String中的享元模式"></a>String中的享元模式</h3><p>Java中将String类定义为final（不可改变的），JVM中字符串一般保存在字符串常量池中，java会确保一个字符串在常量池中只有一个拷贝，这个字符串常量池在JDK6.0以前是位于常量池中，位于永久代，而在JDK7.0中，JVM将其从永久代拿出来放置于堆中。</p><p>我们做一个测试：</p><pre><code>public class Main {    public static void main(String[] args) {        String s1 = &quot;hello&quot;;        String s2 = &quot;hello&quot;;        String s3 = &quot;he&quot; + &quot;llo&quot;;        String s4 = &quot;hel&quot; + new String(&quot;lo&quot;);        String s5 = new String(&quot;hello&quot;);        String s6 = s5.intern();        String s7 = &quot;h&quot;;        String s8 = &quot;ello&quot;;        String s9 = s7 + s8;        System.out.println(s1==s2);//true        System.out.println(s1==s3);//true        System.out.println(s1==s4);//false        System.out.println(s1==s9);//false        System.out.println(s4==s5);//false        System.out.println(s1==s6);//true    }}</code></pre><p>String类的<code>final</code>修饰的，以字面量的形式创建String变量时，jvm会在编译期间就把该字面量<code>hello</code>放到字符串常量池中，由Java程序启动的时候就已经加载到内存中了。这个字符串常量池的特点就是有且只有一份相同的字面量，如果有其它相同的字面量，jvm则返回这个字面量的引用，如果没有相同的字面量，则在字符串常量池创建这个字面量并返回它的引用。</p><p>由于s2指向的字面量<code>hello</code>在常量池中已经存在了（s1先于s2），于是jvm就返回这个字面量绑定的引用，所以<code>s1==s2</code>。</p><p>s3中字面量的拼接其实就是<code>hello</code>，jvm在编译期间就已经对它进行优化，所以s1和s3也是相等的。</p><p>s4中的<code>new String(&quot;lo&quot;)</code>生成了两个对象，<code>lo</code>，<code>new String(&quot;lo&quot;)</code>，<code>lo</code>存在字符串常量池，<code>new String(&quot;lo&quot;)</code>存在堆中，<code>String s4 = &quot;hel&quot; + new String(&quot;lo&quot;)</code>实质上是两个对象的相加，编译器不会进行优化，相加的结果存在堆中，而s1存在字符串常量池中，当然不相等。<code>s1==s9</code>的原理一样。</p><p><code>s4==s5</code>两个相加的结果都在堆中，不用说，肯定不相等。</p><p><code>s1==s6</code>中，<code>s5.intern()</code>方法能使一个位于堆中的字符串在运行期间动态地加入到字符串常量池中（字符串常量池的内容是程序启动的时候就已经加载好了），如果字符串常量池中有该对象对应的字面量，则返回该字面量在字符串常量池中的引用，否则，创建复制一份该字面量到字符串常量池并返回它的引用。因此<code>s1==s6</code>输出true。</p><h3 id="Integer-中的享元模式"><a href="#Integer-中的享元模式" class="headerlink" title="Integer 中的享元模式"></a>Integer 中的享元模式</h3><p>使用例子如下：</p><pre><code class="java">    public static void main(String[] args) {        Integer i1 = 12 ;        Integer i2 = 12 ;        System.out.println(i1 == i2);        Integer b1 = 128 ;        Integer b2 = 128 ;        System.out.println(b1 == b2);    }</code></pre><p>输出是</p><pre><code>truefalse</code></pre><p>为什么第一个是true，第二个是false？<br>反编译后可以发现 <code>Integer b1 = 128;</code> 实际变成了 <code>Integer b1 = Integer.valueOf(128);</code>，所以我们来看 <code>Integer</code> 中的 <code>valueOf</code> 方法的实现</p><pre><code class="java">public final class Integer extends Number implements Comparable&lt;Integer&gt; {    public static Integer valueOf(int var0) {        return var0 &gt;= -128 &amp;&amp; var0 &lt;= Integer.IntegerCache.high ? Integer.IntegerCache.cache[var0 + 128] : new Integer(var0);    }    //...省略...}</code></pre><p>IntegerCache 缓存类</p><pre><code>    //是Integer内部的私有静态类,里面的cache[]就是jdk事先缓存的Integer。    private static class IntegerCache {        static final int low = -128;//区间的最低值        static final int high;//区间的最高值，后面默认赋值为127，也可以用户手动设置虚拟机参数        static final Integer cache[]; //缓存数组        static {            // high value may be configured by property            int h = 127;            //这里可以在运行时设置虚拟机参数来确定h  :-Djava.lang.Integer.IntegerCache.high=250            String integerCacheHighPropValue =                sun.misc.VM.getSavedProperty(&quot;java.lang.Integer.IntegerCache.high&quot;);            if (integerCacheHighPropValue != null) {//用户设置了                int i = parseInt(integerCacheHighPropValue);                i = Math.max(i, 127);//虽然设置了但是还是不能小于127                // 也不能超过最大值                h = Math.min(i, Integer.MAX_VALUE - (-low) -1);            }            high = h;            cache = new Integer[(high - low) + 1];            int j = low;            //循环将区间的数赋值给cache[]数组            for(int k = 0; k &lt; cache.length; k++)                cache[k] = new Integer(j++);        }        private IntegerCache() {}    }</code></pre><p>可以看到 <code>Integer</code> 默认先创建并缓存 <code>-128 ~ 127</code> 之间数的 <code>Integer</code> 对象，当调用 <code>valueOf</code> 时如果参数在 <code>-128 ~ 127</code> 之间则计算下标并从缓存中返回，否则创建一个新的 <code>Integer</code> 对象</p><h3 id="Long中的享元模式"><a href="#Long中的享元模式" class="headerlink" title="Long中的享元模式"></a>Long中的享元模式</h3><pre><code>public final class Long extends Number implements Comparable&lt;Long&gt; {    public static Long valueOf(long var0) {        return var0 &gt;= -128L &amp;&amp; var0 &lt;= 127L ? Long.LongCache.cache[(int)var0 + 128] : new Long(var0);    }       private static class LongCache {        private LongCache(){}        static final Long cache[] = new Long[-(-128) + 127 + 1];        static {            for(int i = 0; i &lt; cache.length; i++)                cache[i] = new Long(i - 128);        }    }    //...}</code></pre><p>同理，<code>Long</code> 中也有缓存，不过不能指定缓存最大值</p><h3 id="Apache-Commons-Pool2中的享元模式"><a href="#Apache-Commons-Pool2中的享元模式" class="headerlink" title="Apache Commons Pool2中的享元模式"></a>Apache Commons Pool2中的享元模式</h3><p>对象池化的基本思路是：将用过的对象保存起来，等下一次需要这种对象的时候，再拿出来重复使用，从而在一定程度上减少频繁创建对象所造成的开销。用于充当保存对象的“容器”的对象，被称为“对象池”（Object Pool，或简称Pool）</p><p>Apache Commons Pool实现了对象池的功能。定义了对象的生成、销毁、激活、钝化等操作及其状态转换，并提供几个默认的对象池实现。</p><p>有几个重要的对象：</p><p><strong>PooledObject（池对象）</strong>：用于封装对象（如：线程、数据库连接、TCP连接），将其包裹成可被池管理的对象。<br><strong>PooledObjectFactory（池对象工厂）</strong>：定义了操作PooledObject实例生命周期的一些方法，PooledObjectFactory必须实现线程安全。<br><strong>Object Pool （对象池）</strong>：Object Pool负责管理PooledObject，如：借出对象，返回对象，校验对象，有多少激活对象，有多少空闲对象。</p><pre><code> // 对象池 private final Map&lt;S, PooledObject&lt;S&gt;&gt; allObjects = new ConcurrentHashMap&lt;S, PooledObject&lt;S&gt;&gt;();</code></pre><p>重要方法：</p><p>borrowObject：从池中借出一个对象。<br>returnObject：将一个对象返还给池。</p><p>由于篇幅较长，后面会专门出一篇介绍并使用 <code>Apache Commons Pool2</code> 的文章，敬请期待</p><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析<br><a href="https://www.cnblogs.com/tongkey/p/8587060.html" target="_blank" rel="noopener">Java中String字符串常量池</a><br><a href="https://blog.csdn.net/LuoZheng4698729/article/details/53995925" target="_blank" rel="noopener">Integer的享元模式解析</a><br><a href="https://blog.csdn.net/qq_22075041/article/details/69802378?locationNum=7&amp;fps=1" target="_blank" rel="noopener">7种结构型模式之：享元模式（Flyweight）与数据库连接池的原理</a><br><a href="https://blog.csdn.net/zilong_zilong/article/details/78556281" target="_blank" rel="noopener">Apache commons-pool2-2.4.2源码学习笔记</a><br><a href="https://blog.csdn.net/amon1991/article/details/77110657" target="_blank" rel="noopener">Apache Commons Pool2 源码分析</a> </p></blockquote><h3 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h3><p><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483700&amp;idx=1&amp;sn=dd4d23f9400c8be248f5d125465ba941&amp;chksm=e9c2ed39deb5642fb809eca1351f00995f06c9a4875f09986cc5005059eff74d6c20fc1118a3&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 简单工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483704&amp;idx=1&amp;sn=fa3ae947cebf22da35e6ac0a37f566f8&amp;chksm=e9c2ed35deb564230a69e43d93a3b74618287c6ddd402a6f1dc6a5b14a896e99584985e7cf92&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 工厂方法模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483708&amp;idx=1&amp;sn=9b8c155b86511ea6ec323dc6a72c52df&amp;chksm=e9c2ed31deb56427b2a6bbcbad5bdd3a4ef68b52eb88cc47b5bcfc76773d3d983d8aaf57761c&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 抽象工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483712&amp;idx=1&amp;sn=1ffd9837eb9413dde74ff509bf69ecc5&amp;chksm=e9c2ed4ddeb5645b8cbf64c83d103a859ae49921c60e17fe8bebe63c26b04966be101d598848&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 建造者模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483716&amp;idx=1&amp;sn=df00c297c8f32e10e277db8941839c14&amp;chksm=e9c2ed49deb5645fa2586da358a8f0a00dd926f883637adebc59435f846c67c040ef759ba034&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 原型模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483721&amp;idx=1&amp;sn=721d0bce3bd516c10d4b6addbf3eced6&amp;chksm=e9c2ed44deb56452395c94a0b150994b94aa26cae71149e6c030d0ac32f9c3c37e2bfe9685b6&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 外观模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483726&amp;idx=1&amp;sn=df583e5b297ddaff5e1ab822df762274&amp;chksm=e9c2ed43deb56455d2a099f3c3e8622031027d6da00202e6a7d731eac691e4d87d673ca103b5&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 装饰者模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483730&amp;idx=1&amp;sn=859feab7f4632b7ba3d1b5a614d57bbe&amp;chksm=e9c2ed5fdeb56449575995778573fa05a3730ac72792d70fc91e38e2d2f5238899f620481d16&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 适配器模式及典型应用</a></p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>设计模式 | 适配器模式及典型应用</title>
      <link href="/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<h2 id="适配器模式"><a href="#适配器模式" class="headerlink" title="适配器模式"></a>适配器模式</h2><p><strong>适配器模式(Adapter Pattern)</strong>：将一个接口转换成客户希望的另一个接口，使接口不兼容的那些类可以一起工作，其别名为包装器(Wrapper)。适配器模式既可以作为类结构型模式，也可以作为对象结构型模式。</p><p>在适配器模式中，我们通过增加一个新的适配器类来解决接口不兼容的问题，使得原本没有任何关系的类可以协同工作。</p><p>根据适配器类与适配者类的关系不同，适配器模式可分为对象适配器和类适配器两种，在<strong>对象适配器模式</strong>中，适配器与适配者之间是<strong>关联</strong>关系；在<strong>类适配器模式</strong>中，适配器与适配者之间是<strong>继承</strong>（或实现）关系。</p><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><p><strong>Target（目标抽象类）</strong>：目标抽象类定义客户所需接口，可以是一个抽象类或接口，也可以是具体类。</p><p><strong>Adapter（适配器类）</strong>：适配器可以调用另一个接口，作为一个转换器，对Adaptee和Target进行适配，适配器类是适配器模式的核心，在对象适配器中，它通过继承Target并关联一个Adaptee对象使二者产生联系。</p><p><strong>Adaptee（适配者类）</strong>：适配者即被适配的角色，它定义了一个已经存在的接口，这个接口需要适配，适配者类一般是一个具体类，包含了客户希望使用的业务方法，在某些情况下可能没有适配者类的源代码。</p><blockquote><p>缺省适配器模式(Default Adapter Pattern)：当不需要实现一个接口所提供的所有方法时，可先设计一个抽象类实现该接口，并为接口中每个方法提供一个默认实现（空方法），那么该抽象类的子类可以选择性地覆盖父类的某些方法来实现需求，它适用于不想使用一个接口中的所有方法的情况，又称为单接口适配器模式。缺省适配器模式是适配器模式的一种变体，其应用也较为广泛。在JDK类库的事件处理包java.awt.event中广泛使用了缺省适配器模式，如WindowAdapter、KeyAdapter、MouseAdapter等。</p></blockquote><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><h3 id="类适配器"><a href="#类适配器" class="headerlink" title="类适配器"></a>类适配器</h3><p>首先有一个已存在的将被适配的类</p><pre><code>public class Adaptee {    public void adapteeRequest() {        System.out.println(&quot;被适配者的方法&quot;);    }}</code></pre><p>定义一个目标接口</p><pre><code>public interface Target {    void request();}</code></pre><p>怎么才可以在目标接口中的 <code>request()</code> 调用 <code>Adaptee</code> 的 <code>adapteeRequest()</code> 方法呢？</p><p>如果直接实现 <code>Target</code> 是不行的</p><pre><code>public class ConcreteTarget implements Target {    @Override    public void request() {        System.out.println(&quot;concreteTarget目标方法&quot;);    }}</code></pre><p>如果通过一个适配器类，实现 <code>Target</code> 接口，同时继承了 <code>Adaptee</code> 类，然后在实现的 <code>request()</code> 方法中调用父类的 <code>adapteeRequest()</code> 即可实现</p><pre><code>public class Adapter extends Adaptee implements Target{    @Override    public void request() {        //...一些操作...        super.adapteeRequest();        //...一些操作...    }}</code></pre><p>我们来测试一下</p><pre><code>public class Test {    public static void main(String[] args) {        Target target = new ConcreteTarget();        target.request();        Target adapterTarget = new Adapter();        adapterTarget.request();    }}</code></pre><p>输出</p><pre><code>concreteTarget目标方法被适配者的方法</code></pre><p><img src="http://image.laijianfeng.org/Package%20classadapter.png" alt="类适配器模式类图"></p><p>这样我们即可在新接口 <code>Target</code> 中适配旧的接口或类</p><h3 id="对象适配器"><a href="#对象适配器" class="headerlink" title="对象适配器"></a>对象适配器</h3><p>对象适配器与类适配器不同之处在于，类适配器通过继承来完成适配，对象适配器则是通过关联来完成，这里稍微修改一下 <code>Adapter</code> 类即可将转变为对象适配器</p><pre><code>public class Adapter implements Target{    // 适配者是对象适配器的一个属性    private Adaptee adaptee = new Adaptee();    @Override    public void request() {        //...        adaptee.adapteeRequest();        //...    }}</code></pre><p><img src="http://image.laijianfeng.org/20180919Package_objectadapter.png" alt="对象适配器模式类图"></p><p>注意这里的 <code>Adapter</code> 是将 <code>Adaptee</code> 作为一个成员属性，而不是继承它</p><h3 id="电压适配器"><a href="#电压适配器" class="headerlink" title="电压适配器"></a>电压适配器</h3><p>再来一个好理解的例子，我们国家的民用电都是 220V，日本是 110V，而我们的手机充电一般需要 5V，这时候要充电，就需要一个电压适配器，将 220V 或者 100V 的输入电压变换为 5V 输出</p><p>定义输出交流电接口，输出220V交流电类和输出110V交流电类</p><pre><code>public interface AC {    int outputAC();}public class AC110 implements AC {    public final int output = 110;    @Override    public int outputAC() {        return output;    }}public class AC220 implements AC {    public final int output = 220;    @Override    public int outputAC() {        return output;    }}</code></pre><p>适配器接口，其中 <code>support()</code> 方法用于检查输入的电压是否与适配器匹配，<code>outputDC5V()</code> 方法则用于将输入的电压变换为 5V 后输出 </p><pre><code>public interface DC5Adapter {    boolean support(AC ac);    int outputDC5V(AC ac);}</code></pre><p>实现中国变压适配器和日本变压适配器</p><pre><code>public class ChinaPowerAdapter implements DC5Adapter {    public static final int voltage = 220;    @Override    public boolean support(AC ac) {        return (voltage == ac.outputAC());    }    @Override    public int outputDC5V(AC ac) {        int adapterInput = ac.outputAC();        //变压器...        int adapterOutput = adapterInput / 44;        System.out.println(&quot;使用ChinaPowerAdapter变压适配器，输入AC:&quot; + adapterInput + &quot;V&quot; + &quot;，输出DC:&quot; + adapterOutput + &quot;V&quot;);        return adapterOutput;    }}public class JapanPowerAdapter implements DC5Adapter {    public static final int voltage = 110;    @Override    public boolean support(AC ac) {        return (voltage == ac.outputAC());    }    @Override    public int outputDC5V(AC ac) {        int adapterInput = ac.outputAC();        //变压器...        int adapterOutput = adapterInput / 22;        System.out.println(&quot;使用JapanPowerAdapter变压适配器，输入AC:&quot; + adapterInput + &quot;V&quot; + &quot;，输出DC:&quot; + adapterOutput + &quot;V&quot;);        return adapterOutput;    }}</code></pre><p>测试，准备中国变压适配器和日本变压适配器各一个，定义一个方法可以根据电压找到合适的变压器，然后进行测试</p><pre><code>public class Test {    private List&lt;DC5Adapter&gt; adapters = new LinkedList&lt;DC5Adapter&gt;();    public Test() {        this.adapters.add(new ChinaPowerAdapter());        this.adapters.add(new JapanPowerAdapter());    }    // 根据电压找合适的变压器    public DC5Adapter getPowerAdapter(AC ac) {        DC5Adapter adapter = null;        for (DC5Adapter ad : this.adapters) {            if (ad.support(ac)) {                adapter = ad;                break;            }        }        if (adapter == null){            throw new  IllegalArgumentException(&quot;没有找到合适的变压适配器&quot;);        }        return adapter;    }    public static void main(String[] args) {        Test test = new Test();        AC chinaAC = new AC220();        DC5Adapter adapter = test.getPowerAdapter(chinaAC);        adapter.outputDC5V(chinaAC);        // 去日本旅游，电压是 110V        AC japanAC = new AC110();        adapter = test.getPowerAdapter(japanAC);        adapter.outputDC5V(japanAC);    }}</code></pre><p>输出</p><pre><code>使用ChinaPowerAdapter变压适配器，输入AC:220V，输出DC:5V使用JapanPowerAdapter变压适配器，输入AC:110V，输出DC:5V</code></pre><h2 id="适配器模式总结"><a href="#适配器模式总结" class="headerlink" title="适配器模式总结"></a>适配器模式总结</h2><p><strong>主要优点</strong>：</p><ol><li>将目标类和适配者类解耦，通过引入一个适配器类来重用现有的适配者类，无须修改原有结构。</li><li>增加了类的透明性和复用性，将具体的业务实现过程封装在适配者类中，对于客户端类而言是透明的，而且提高了适配者的复用性，同一个适配者类可以在多个不同的系统中复用。</li><li>灵活性和扩展性都非常好，通过使用配置文件，可以很方便地更换适配器，也可以在不修改原有代码的基础上增加新的适配器类，完全符合“开闭原则”。</li></ol><p>具体来说，类适配器模式还有如下优点：</p><ul><li>由于适配器类是适配者类的子类，因此可以在适配器类中置换一些适配者的方法，使得适配器的灵活性更强。</li></ul><p>对象适配器模式还有如下优点：</p><ul><li>一个对象适配器可以把多个不同的适配者适配到同一个目标；</li><li>可以适配一个适配者的子类，由于适配器和适配者之间是关联关系，根据“里氏代换原则”，适配者的子类也可通过该适配器进行适配。</li></ul><p>类适配器模式的缺点如下：</p><ol><li>对于Java、C#等不支持多重类继承的语言，一次最多只能适配一个适配者类，不能同时适配多个适配者；</li><li>适配者类不能为最终类，如在Java中不能为final类，C#中不能为sealed类；</li><li>在Java、C#等语言中，类适配器模式中的目标抽象类只能为接口，不能为类，其使用有一定的局限性。</li></ol><p>对象适配器模式的缺点如下：</p><p>与类适配器模式相比，要在适配器中置换适配者类的某些方法比较麻烦。如果一定要置换掉适配者类的一个或多个方法，可以先做一个适配者类的子类，将适配者类的方法置换掉，然后再把适配者类的子类当做真正的适配者进行适配，实现过程较为复杂。</p><p><strong>适用场景</strong>：</p><ul><li>系统需要使用一些现有的类，而这些类的接口（如方法名）不符合系统的需要，甚至没有这些类的源代码。</li><li>想创建一个可以重复使用的类，用于与一些彼此之间没有太大关联的一些类，包括一些可能在将来引进的类一起工作。</li></ul><h2 id="源码分析适配器模式的典型应用"><a href="#源码分析适配器模式的典型应用" class="headerlink" title="源码分析适配器模式的典型应用"></a>源码分析适配器模式的典型应用</h2><h3 id="spring-AOP中的适配器模式"><a href="#spring-AOP中的适配器模式" class="headerlink" title="spring AOP中的适配器模式"></a>spring AOP中的适配器模式</h3><p>在Spring的Aop中，使用的 <code>Advice（通知）</code> 来增强被代理类的功能。<code>Advice</code>的类型有：<code>MethodBeforeAdvice</code>、<code>AfterReturningAdvice</code>、<code>ThrowsAdvice</code> ，在每个类型 <code>Advice</code> 都有对应的拦截器，<code>MethodBeforeAdviceInterceptor</code>、<code>AfterReturningAdviceInterceptor</code>、<code>ThrowsAdviceInterceptor</code>。Spring需要将每个 <code>Advice</code> <strong>都封装成对应的拦截器类型</strong>，返回给容器，所以需要使用适配器模式对 <code>Advice</code> 进行转换。</p><p>三个适配者类 Adaptee 如下：</p><pre><code>public interface MethodBeforeAdvice extends BeforeAdvice {    void before(Method var1, Object[] var2, @Nullable Object var3) throws Throwable;}public interface AfterReturningAdvice extends AfterAdvice {    void afterReturning(@Nullable Object var1, Method var2, Object[] var3, @Nullable Object var4) throws Throwable;}public interface ThrowsAdvice extends AfterAdvice {}</code></pre><p>目标接口 Target，有两个方法，一个判断 <code>Advice</code> 类型是否匹配，一个是工厂方法，创建对应类型的 <code>Advice</code> 对应的拦截器</p><pre><code>public interface AdvisorAdapter {    boolean supportsAdvice(Advice var1);    MethodInterceptor getInterceptor(Advisor var1);}</code></pre><p>三个适配器类 Adapter 分别如下，注意其中的 Advice、Adapter、Interceptor之间的对应关系</p><pre><code>class MethodBeforeAdviceAdapter implements AdvisorAdapter, Serializable {    @Override    public boolean supportsAdvice(Advice advice) {        return (advice instanceof MethodBeforeAdvice);    }    @Override    public MethodInterceptor getInterceptor(Advisor advisor) {        MethodBeforeAdvice advice = (MethodBeforeAdvice) advisor.getAdvice();        return new MethodBeforeAdviceInterceptor(advice);    }}@SuppressWarnings(&quot;serial&quot;)class AfterReturningAdviceAdapter implements AdvisorAdapter, Serializable {    @Override    public boolean supportsAdvice(Advice advice) {        return (advice instanceof AfterReturningAdvice);    }    @Override    public MethodInterceptor getInterceptor(Advisor advisor) {        AfterReturningAdvice advice = (AfterReturningAdvice) advisor.getAdvice();        return new AfterReturningAdviceInterceptor(advice);    }}class ThrowsAdviceAdapter implements AdvisorAdapter, Serializable {    @Override    public boolean supportsAdvice(Advice advice) {        return (advice instanceof ThrowsAdvice);    }    @Override    public MethodInterceptor getInterceptor(Advisor advisor) {        return new ThrowsAdviceInterceptor(advisor.getAdvice());    }}</code></pre><p>客户端 DefaultAdvisorAdapterRegistry</p><pre><code>public class DefaultAdvisorAdapterRegistry implements AdvisorAdapterRegistry, Serializable {    private final List&lt;AdvisorAdapter&gt; adapters = new ArrayList(3);    public DefaultAdvisorAdapterRegistry() {        // 这里注册了适配器        this.registerAdvisorAdapter(new MethodBeforeAdviceAdapter());        this.registerAdvisorAdapter(new AfterReturningAdviceAdapter());        this.registerAdvisorAdapter(new ThrowsAdviceAdapter());    }    public MethodInterceptor[] getInterceptors(Advisor advisor) throws UnknownAdviceTypeException {        List&lt;MethodInterceptor&gt; interceptors = new ArrayList(3);        Advice advice = advisor.getAdvice();        if (advice instanceof MethodInterceptor) {            interceptors.add((MethodInterceptor)advice);        }        Iterator var4 = this.adapters.iterator();        while(var4.hasNext()) {            AdvisorAdapter adapter = (AdvisorAdapter)var4.next();            if (adapter.supportsAdvice(advice)) {   // 这里调用适配器方法                interceptors.add(adapter.getInterceptor(advisor));  // 这里调用适配器方法            }        }        if (interceptors.isEmpty()) {            throw new UnknownAdviceTypeException(advisor.getAdvice());        } else {            return (MethodInterceptor[])interceptors.toArray(new MethodInterceptor[0]);        }    }    // ...省略...}    </code></pre><p>这里看 while 循环里，逐个取出注册的适配器，调用 <code>supportsAdvice()</code> 方法来判断 <code>Advice</code> 对应的类型，然后调用 <code>getInterceptor()</code> 创建对应类型的拦截器</p><p><img src="http://image.laijianfeng.org/20180919_2217.jpg" alt="spring aop 适配器模式"></p><p>这里应该属于对象适配器模式，关键字 <code>instanceof</code> 可看成是 <code>Advice</code> 的方法，不过这里的 <code>Advice</code> 对象是从外部传进来，而不是成员属性</p><h3 id="spring-JPA中的适配器模式"><a href="#spring-JPA中的适配器模式" class="headerlink" title="spring JPA中的适配器模式"></a>spring JPA中的适配器模式</h3><p>在Spring的ORM包中，对于JPA的支持也是采用了适配器模式，首先定义了一个接口的 <code>JpaVendorAdapter</code>，然后不同的持久层框架都实现此接口。</p><p>jpaVendorAdapter：用于设置实现厂商JPA实现的特定属性，如设置Hibernate的是否自动生成DDL的属性generateDdl；这些属性是厂商特定的，因此最好在这里设置；目前Spring提供 <code>HibernateJpaVendorAdapter</code>、<code>OpenJpaVendorAdapter</code>、<code>EclipseLinkJpaVendorAdapter</code>、<code>TopLinkJpaVendorAdapter</code> 四个实现。其中最重要的属性是 database，用来指定使用的数据库类型，从而能<strong>根据数据库类型来决定比如如何将数据库特定异常转换为Spring的一致性异常</strong>，目前支持如下数据库（DB2、DERBY、H2、HSQL、INFORMIX、MYSQL、ORACLE、POSTGRESQL、SQL_SERVER、SYBASE）</p><pre><code>public interface JpaVendorAdapter{  // 返回一个具体的持久层提供者  public abstract PersistenceProvider getPersistenceProvider();  // 返回持久层提供者的包名  public abstract String getPersistenceProviderRootPackage();  // 返回持久层提供者的属性  public abstract Map&lt;String, ?&gt; getJpaPropertyMap();  // 返回JpaDialect  public abstract JpaDialect getJpaDialect();  // 返回持久层管理器工厂  public abstract Class&lt;? extends EntityManagerFactory&gt; getEntityManagerFactoryInterface();  // 返回持久层管理器  public abstract Class&lt;? extends EntityManager&gt; getEntityManagerInterface();  // 自定义回调方法  public abstract void postProcessEntityManagerFactory(EntityManagerFactory paramEntityManagerFactory);}</code></pre><p>我们来看其中一个适配器实现类 HibernateJpaVendorAdapter</p><pre><code>public class HibernateJpaVendorAdapter extends AbstractJpaVendorAdapter {    //设定持久层提供者    private final PersistenceProvider persistenceProvider;    //设定持久层方言    private final JpaDialect jpaDialect;    public HibernateJpaVendorAdapter() {        this.persistenceProvider = new HibernatePersistence();        this.jpaDialect = new HibernateJpaDialect();    }    //返回持久层方言    public PersistenceProvider getPersistenceProvider() {        return this.persistenceProvider;    }    //返回持久层提供者    public String getPersistenceProviderRootPackage() {        return &quot;org.hibernate&quot;;    }    //返回JPA的属性    public Map&lt;String, Object&gt; getJpaPropertyMap() {        Map jpaProperties = new HashMap();        if (getDatabasePlatform() != null) {            jpaProperties.put(&quot;hibernate.dialect&quot;, getDatabasePlatform());        } else if (getDatabase() != null) {            Class databaseDialectClass = determineDatabaseDialectClass(getDatabase());            if (databaseDialectClass != null) {                jpaProperties.put(&quot;hibernate.dialect&quot;,                        databaseDialectClass.getName());            }        }        if (isGenerateDdl()) {            jpaProperties.put(&quot;hibernate.hbm2ddl.auto&quot;, &quot;update&quot;);        }        if (isShowSql()) {            jpaProperties.put(&quot;hibernate.show_sql&quot;, &quot;true&quot;);        }        return jpaProperties;    }    //设定数据库    protected Class determineDatabaseDialectClass(Database database)         {                                                                                               switch (1.$SwitchMap$org$springframework$orm$jpa$vendor$Database[database.ordinal()])         {                                                                                             case 1:                                                                                       return DB2Dialect.class;                                                                    case 2:                                                                                         return DerbyDialect.class;                                                                  case 3:                                                                                         return H2Dialect.class;                                                                     case 4:                                                                                         return HSQLDialect.class;                                                                   case 5:                                                                                         return InformixDialect.class;                                                               case 6:                                                                                         return MySQLDialect.class;                                                                  case 7:                                                                                         return Oracle9iDialect.class;                                                               case 8:                                                                                         return PostgreSQLDialect.class;                                                             case 9:                                                                                         return SQLServerDialect.class;                                                              case 10:                                                                                        return SybaseDialect.class; }                                                               return null;                  }    //返回JPA方言    public JpaDialect getJpaDialect() {        return this.jpaDialect;    }    //返回JPA实体管理器工厂    public Class&lt;? extends EntityManagerFactory&gt; getEntityManagerFactoryInterface() {        return HibernateEntityManagerFactory.class;    }    //返回JPA实体管理器    public Class&lt;? extends EntityManager&gt; getEntityManagerInterface() {        return HibernateEntityManager.class;    }}</code></pre><p>配置文件中可以这样指定</p><pre><code>&lt;bean id=&quot;jpaVendorAdapter&quot; class=&quot;org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter&quot;&gt;    &lt;property name=&quot;generateDdl&quot; value=&quot;false&quot; /&gt;     &lt;property name=&quot;database&quot; value=&quot;HSQL&quot;/&gt;  &lt;/bean&gt;  &lt;bean id=&quot;jpaDialect&quot; class=&quot;org.springframework.orm.jpa.vendor.HibernateJpaDialect&quot;/&gt;  </code></pre><h3 id="spring-MVC中的适配器模式"><a href="#spring-MVC中的适配器模式" class="headerlink" title="spring MVC中的适配器模式"></a>spring MVC中的适配器模式</h3><p>Spring MVC中的适配器模式主要用于执行目标 <code>Controller</code> 中的请求处理方法。</p><p>在Spring MVC中，<code>DispatcherServlet</code> 作为用户，<code>HandlerAdapter</code> 作为期望接口，具体的适配器实现类用于对目标类进行适配，<code>Controller</code> 作为需要适配的类。</p><p>为什么要在 Spring MVC 中使用适配器模式？Spring MVC 中的 <code>Controller</code> 种类众多，不同类型的 <code>Controller</code> 通过不同的方法来对请求进行处理。如果不利用适配器模式的话，<code>DispatcherServlet</code> 直接获取对应类型的 <code>Controller</code>，需要的自行来判断，像下面这段代码一样：</p><pre><code>if(mappedHandler.getHandler() instanceof MultiActionController){     ((MultiActionController)mappedHandler.getHandler()).xxx  }else if(mappedHandler.getHandler() instanceof XXX){      ...  }else if(...){     ...  }  </code></pre><p>这样假设如果我们增加一个 <code>HardController</code>,就要在代码中加入一行 <code>if(mappedHandler.getHandler() instanceof HardController)</code>，这种形式就使得程序难以维护，也违反了设计模式中的开闭原则 – 对扩展开放，对修改关闭。</p><p>我们来看看源码，首先是适配器接口 <code>HandlerAdapter</code></p><pre><code>public interface HandlerAdapter {    boolean supports(Object var1);    ModelAndView handle(HttpServletRequest var1, HttpServletResponse var2, Object var3) throws Exception;    long getLastModified(HttpServletRequest var1, Object var2);}</code></pre><p>现该接口的适配器每一个 <code>Controller</code> 都有一个适配器与之对应，这样的话，每自定义一个 <code>Controller</code> 需要定义一个实现 <code>HandlerAdapter</code> 的适配器。</p><p>springmvc 中提供的 <code>Controller</code> 实现类有如下</p><p><img src="http://image.laijianfeng.org/20180919_233327.png" alt="spring mvc Controller 提供的实现类"></p><p>springmvc 中提供的 <code>HandlerAdapter</code> 实现类如下</p><p><img src="http://image.laijianfeng.org/20180919_234325.png" alt="spring mvc HandlerAdapter 提供的实现类"></p><p><code>HttpRequestHandlerAdapter</code> 这个适配器代码如下</p><pre><code>public class HttpRequestHandlerAdapter implements HandlerAdapter {    public HttpRequestHandlerAdapter() {    }    public boolean supports(Object handler) {        return handler instanceof HttpRequestHandler;    }    public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {        ((HttpRequestHandler)handler).handleRequest(request, response);        return null;    }    public long getLastModified(HttpServletRequest request, Object handler) {        return handler instanceof LastModified ? ((LastModified)handler).getLastModified(request) : -1L;    }}</code></pre><p>当Spring容器启动后，会将所有定义好的适配器对象存放在一个List集合中，当一个请求来临时，<code>DispatcherServlet</code> 会通过 <code>handler</code> 的类型找到对应适配器，并将该适配器对象返回给用户，然后就可以统一通过适配器的 <code>hanle()</code> 方法来调用 <code>Controller</code> 中的用于处理请求的方法。</p><pre><code>public class DispatcherServlet extends FrameworkServlet {    private List&lt;HandlerAdapter&gt; handlerAdapters;    //初始化handlerAdapters    private void initHandlerAdapters(ApplicationContext context) {        //..省略...    }    // 遍历所有的 HandlerAdapters，通过 supports 判断找到匹配的适配器    protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException {        for (HandlerAdapter ha : this.handlerAdapters) {            if (logger.isTraceEnabled()) {                logger.trace(&quot;Testing handler adapter [&quot; + ha + &quot;]&quot;);            }            if (ha.supports(handler)) {                return ha;            }        }    }    // 分发请求，请求需要找到匹配的适配器来处理    protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception {        HttpServletRequest processedRequest = request;        HandlerExecutionChain mappedHandler = null;        // Determine handler for the current request.        mappedHandler = getHandler(processedRequest);        // 确定当前请求的匹配的适配器.        HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler());        ha.getLastModified(request, mappedHandler.getHandler());        mv = ha.handle(processedRequest, response, mappedHandler.getHandler());    }    // ...省略...}    </code></pre><p>通过适配器模式我们将所有的 <code>controller</code> 统一交给 <code>HandlerAdapter</code> 处理，免去了写大量的 <code>if-else</code> 语句对 <code>Controller</code> 进行判断，也更利于扩展新的 <code>Controller</code> 类型。</p><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析<br>孤落:<a href="https://blog.csdn.net/lu__peng/article/details/79117894" target="_blank" rel="noopener">Spring MVC中的适配器模式</a><br>ToughMind_：<a href="https://blog.csdn.net/liuquan0071/article/details/50506121" target="_blank" rel="noopener">深入浅出设计模式（五）：7.适配器模式</a>   </p></blockquote><h3 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h3><p><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483700&amp;idx=1&amp;sn=dd4d23f9400c8be248f5d125465ba941&amp;chksm=e9c2ed39deb5642fb809eca1351f00995f06c9a4875f09986cc5005059eff74d6c20fc1118a3&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 简单工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483704&amp;idx=1&amp;sn=fa3ae947cebf22da35e6ac0a37f566f8&amp;chksm=e9c2ed35deb564230a69e43d93a3b74618287c6ddd402a6f1dc6a5b14a896e99584985e7cf92&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 工厂方法模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483708&amp;idx=1&amp;sn=9b8c155b86511ea6ec323dc6a72c52df&amp;chksm=e9c2ed31deb56427b2a6bbcbad5bdd3a4ef68b52eb88cc47b5bcfc76773d3d983d8aaf57761c&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 抽象工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483712&amp;idx=1&amp;sn=1ffd9837eb9413dde74ff509bf69ecc5&amp;chksm=e9c2ed4ddeb5645b8cbf64c83d103a859ae49921c60e17fe8bebe63c26b04966be101d598848&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 建造者模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483716&amp;idx=1&amp;sn=df00c297c8f32e10e277db8941839c14&amp;chksm=e9c2ed49deb5645fa2586da358a8f0a00dd926f883637adebc59435f846c67c040ef759ba034&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 原型模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483721&amp;idx=1&amp;sn=721d0bce3bd516c10d4b6addbf3eced6&amp;chksm=e9c2ed44deb56452395c94a0b150994b94aa26cae71149e6c030d0ac32f9c3c37e2bfe9685b6&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 外观模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483726&amp;idx=1&amp;sn=df583e5b297ddaff5e1ab822df762274&amp;chksm=e9c2ed43deb56455d2a099f3c3e8622031027d6da00202e6a7d731eac691e4d87d673ca103b5&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 装饰者模式及典型应用</a>  </p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>设计模式 | 装饰者模式及典型应用</title>
      <link href="/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文的主要内容：</p><ul><li>介绍装饰者模式</li><li>示例</li><li>源码分析装饰者模式的典型应用<ul><li>Java I/O 中的装饰者模式</li><li>spring session 中的装饰者模式</li><li>Mybatis 缓存中的装饰者模式</li></ul></li><li>总结</li></ul><h2 id="装饰者模式"><a href="#装饰者模式" class="headerlink" title="装饰者模式"></a>装饰者模式</h2><p><strong>装饰者模式(Decorator Pattern)</strong>：动态地给一个对象增加一些额外的职责，增加对象功能来说，装饰模式比生成子类实现更为灵活。装饰模式是一种对象结构型模式。</p><p>在装饰者模式中，为了让系统具有更好的灵活性和可扩展性，我们通常会定义一个抽象装饰类，而将具体的装饰类作为它的子类</p><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><p><strong>Component（抽象构件）</strong>：它是具体构件和抽象装饰类的共同父类，声明了在具体构件中实现的业务方法，它的引入可以使客户端以一致的方式处理未被装饰的对象以及装饰之后的对象，实现客户端的透明操作。</p><p><strong>ConcreteComponent（具体构件）</strong>：它是抽象构件类的子类，用于定义具体的构件对象，实现了在抽象构件中声明的方法，装饰器可以给它增加额外的职责（方法）。</p><p><strong>Decorator（抽象装饰类）</strong>：它也是抽象构件类的子类，用于给具体构件增加职责，但是具体职责在其子类中实现。它维护一个指向抽象构件对象的引用，通过该引用可以调用装饰之前构件对象的方法，并通过其子类扩展该方法，以达到装饰的目的。</p><p><strong>ConcreteDecorator（具体装饰类）</strong>：它是抽象装饰类的子类，负责向构件添加新的职责。每一个具体装饰类都定义了一些新的行为，它可以调用在抽象装饰类中定义的方法，并可以增加新的方法用以扩充对象的行为。</p><p>由于具体构件类和装饰类都实现了相同的抽象构件接口，因此装饰模式以对客户透明的方式动态地给一个对象附加上更多的责任，换言之，客户端并不会觉得对象在装饰前和装饰后有什么不同。装饰模式可以在不需要创造更多子类的情况下，将对象的功能加以扩展。</p><p>装饰模式的<strong>核心在于抽象装饰类的设计</strong>。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>煎饼抽象类</p><pre><code>public abstract class ABattercake {    protected abstract String getDesc();    protected abstract int cost();}</code></pre><p>煎饼类，继承了煎饼抽象类，一个煎饼 8 块钱</p><pre><code>public class Battercake extends ABattercake {    @Override    protected String getDesc() {        return &quot;煎饼&quot;;    }    @Override    protected int cost() {        return 8;    }}</code></pre><p>抽象装饰类，需要注意的是，<strong>抽象装饰类通过成员属性的方式将 煎饼抽象类组合进来，同时也继承了煎饼抽象类</strong>，且这里定义了新的业务方法 <code>doSomething()</code></p><pre><code>public abstract class AbstractDecorator extends ABattercake {    private ABattercake aBattercake;    public AbstractDecorator(ABattercake aBattercake) {        this.aBattercake = aBattercake;    }    protected abstract void doSomething();    @Override    protected String getDesc() {        return this.aBattercake.getDesc();    }    @Override    protected int cost() {        return this.aBattercake.cost();    }}</code></pre><p>鸡蛋装饰器，继承了抽象装饰类，鸡蛋装饰器在父类的基础上增加了一个鸡蛋，同时价格加上 1 块钱</p><pre><code>public class EggDecorator extends AbstractDecorator {    public EggDecorator(ABattercake aBattercake) {        super(aBattercake);    }    @Override    protected void doSomething() {    }    @Override    protected String getDesc() {        return super.getDesc() + &quot; 加一个鸡蛋&quot;;    }    @Override    protected int cost() {        return super.cost() + 1;    }    public void egg() {        System.out.println(&quot;增加了一个鸡蛋&quot;);    }}</code></pre><p>香肠装饰器，与鸡蛋装饰器类似，继承了抽象装饰类，给在父类的基础上加上一根香肠，同时价格增加 2 块钱</p><pre><code>public class SausageDecorator extends AbstractDecorator{    public SausageDecorator(ABattercake aBattercake) {        super(aBattercake);    }    @Override    protected void doSomething() {    }    @Override    protected String getDesc() {        return super.getDesc() + &quot; 加一根香肠&quot;;    }    @Override    protected int cost() {        return super.cost() + 2;    }}</code></pre><h3 id="测试，购买煎饼"><a href="#测试，购买煎饼" class="headerlink" title="测试，购买煎饼"></a>测试，购买煎饼</h3><p><strong>1、购买一个煎饼</strong></p><pre><code>public class Test {    public static void main(String[] args) {        ABattercake aBattercake = new Battercake();        System.out.println(aBattercake.getDesc() + &quot;, 销售价格: &quot; + aBattercake.cost());    }}</code></pre><p>输出</p><pre><code>煎饼, 销售价格: 8</code></pre><p><strong>2、购买一个加鸡蛋的煎饼</strong></p><pre><code>public class Test {    public static void main(String[] args) {        ABattercake aBattercake = new Battercake();        aBattercake = new EggDecorator(aBattercake);        System.out.println(aBattercake.getDesc() + &quot;, 销售价格: &quot; + aBattercake.cost());    }}</code></pre><p>输出</p><pre><code>煎饼 加一个鸡蛋, 销售价格: 9</code></pre><p><strong>3、购买一个加两个鸡蛋的煎饼</strong></p><pre><code>public class Test {    public static void main(String[] args) {        ABattercake aBattercake = new Battercake();        aBattercake = new EggDecorator(aBattercake);        aBattercake = new EggDecorator(aBattercake);        System.out.println(aBattercake.getDesc() + &quot;, 销售价格: &quot; + aBattercake.cost());    }}</code></pre><p>输出</p><pre><code>煎饼 加一个鸡蛋 加一个鸡蛋, 销售价格: 10</code></pre><p><strong>4、购买一个加两个鸡蛋和一根香肠的煎饼</strong></p><pre><code>public class Test {    public static void main(String[] args) {        ABattercake aBattercake = new Battercake();        aBattercake = new EggDecorator(aBattercake);        aBattercake = new EggDecorator(aBattercake);        aBattercake = new SausageDecorator(aBattercake);        System.out.println(aBattercake.getDesc() + &quot;, 销售价格: &quot; + aBattercake.cost());    }}</code></pre><p>输出</p><pre><code>煎饼 加一个鸡蛋 加一个鸡蛋 加一根香肠, 销售价格: 12</code></pre><p>画出UML类图如下所示</p><p><img src="http://image.laijianfeng.org/20180917_225232.png" alt="装饰者模式类图"></p><h3 id="小结一下"><a href="#小结一下" class="headerlink" title="小结一下"></a>小结一下</h3><p>由于具体构件类和装饰类都实现了相同的抽象构件接口，因此装饰模式以对客户透明的方式动态地给一个对象附加上更多的责任，换言之，客户端并不会觉得对象在装饰前和装饰后有什么不同。</p><p>譬如我们给煎饼加上一个鸡蛋可以这么写 <code>aBattercake = new EggDecorator(aBattercake);</code>，客户端仍然可以把 <code>aBattercake</code> 当成原来的 <code>aBattercake</code>一样，不过现在的 <code>aBattercake</code>已经被装饰加上了鸡蛋</p><p>装饰模式可以在不需要创造更多子类的情况下，将对象的功能加以扩展。</p><h3 id="透明装饰模式与半透明装饰模式"><a href="#透明装饰模式与半透明装饰模式" class="headerlink" title="透明装饰模式与半透明装饰模式"></a>透明装饰模式与半透明装饰模式</h3><p>在上面的示例中，装饰后的对象是通过抽象构建类类型 <code>ABattercake</code> 的变量来引用的，在鸡蛋装饰器这个类中我们新增了 <code>egg()</code> 方法，如果此时我们想要<strong>单独调用该方法</strong>是调用不到的</p><p>除非引用变量的类型改为 <code>EggDecorator</code>，这样就可以调用了</p><pre><code>EggDecorator eggBattercake = new EggDecorator(aBattercake); eggBattercake.egg();</code></pre><p>在实际使用过程中，由于新增行为可能需要单独调用，因此这种形式的装饰模式也经常出现，这种装饰模式被称为<strong>半透明(Semi-transparent)装饰模式</strong>，而标准的装饰模式是<strong>透明(Transparent)装饰模式</strong>。</p><p><strong>(1) 透明装饰模式</strong></p><p>在透明装饰模式中，要求客户端完全针对抽象编程，装饰模式的透明性要求客户端程序不应该将对象声明为具体构件类型或具体装饰类型，而应该全部声明为抽象构件类型。</p><p><strong>(2) 半透明装饰模式</strong></p><p>透明装饰模式的设计难度较大，而且有时我们需要单独调用新增的业务方法。为了能够调用到新增方法，我们不得不用具体装饰类型来定义装饰之后的对象，而具体构件类型还是可以使用抽象构件类型来定义，这种装饰模式即为半透明装饰模式。</p><p>半透明装饰模式可以给系统带来更多的灵活性，设计相对简单，使用起来也非常方便；但是其最大的缺点在于<strong>不能实现对同一个对象的多次装饰</strong>，而且客户端需要有区别地对待装饰之前的对象和装饰之后的对象。</p><h3 id="装饰模式注意事项"><a href="#装饰模式注意事项" class="headerlink" title="装饰模式注意事项"></a>装饰模式注意事项</h3><p>(1) 尽量保持装饰类的接口与被装饰类的接口相同，这样，对于客户端而言，无论是装饰之前的对象还是装饰之后的对象都可以一致对待。这也就是说，在可能的情况下，我们应该尽量使用透明装饰模式。</p><p>(2) 尽量保持具体构件类是一个“轻”类，也就是说不要把太多的行为放在具体构件类中，我们可以通过装饰类对其进行扩展。</p><p>(3) 如果只有一个具体构件类，那么抽象装饰类可以作为该具体构件类的直接子类。</p><h2 id="源码分析装饰者模式的典型应用"><a href="#源码分析装饰者模式的典型应用" class="headerlink" title="源码分析装饰者模式的典型应用"></a>源码分析装饰者模式的典型应用</h2><h3 id="Java-I-O中的装饰者模式"><a href="#Java-I-O中的装饰者模式" class="headerlink" title="Java I/O中的装饰者模式"></a>Java I/O中的装饰者模式</h3><p>使用 Java I/O 的时候总是有各种输入流、输出流、字符流、字节流、过滤流、缓冲流等等各种各样的流，不熟悉里边的设计模式的话总会看得云里雾里的，现在通过设计模式的角度来看 Java I/O，会好理解很多。</p><p>先用一幅图来看看Java I/O到底是什么，下面的这幅图生动的刻画了Java I/O的作用。</p><p><img src="http://image.laijianfeng.org/java-io-flow.png" alt="Java I/O的作用图"></p><p>由上图可知在Java中应用程序通过输入流（InputStream）的Read方法从源地址处读取字节，然后通过输出流（OutputStream）的Write方法将流写入到目的地址。</p><p>流的来源主要有三种：本地的文件（File）、控制台、通过socket实现的网络通信 </p><p>下面的图可以看出Java中的装饰者类和被装饰者类以及它们之间的关系，这里只列出了InputStream中的关系：</p><p><img src="http://image.laijianfeng.org/20180918InputStream.png" alt="InputStream部分类关系"></p><p>由上图可以看出只要继承了FilterInputStream的类就是装饰者类，可以用于包装其他的流，装饰者类还可以对装饰者和类进行再包装。</p><p><strong>这里总结几种常用流的应用场景</strong>：</p><table><thead><tr><th>流名称</th><th>应用场景</th></tr></thead><tbody><tr><td>ByteArrayInputStream</td><td>访问数组，把内存中的一个缓冲区作为 InputStream 使用，CPU从缓存区读取数据比从存储介质的速率快10倍以上</td></tr><tr><td>StringBufferInputStream</td><td>把一个 String 对象作为。InputStream。不建议使用，在转换字符的问题上有缺陷</td></tr><tr><td>FileInputStream</td><td>访问文件，把一个文件作为 InputStream ，实现对文件的读取操作</td></tr><tr><td>PipedInputStream</td><td>访问管道，主要在线程中使用，一个线程通过管道输出流发送数据，而另一个线程通过管道输入流读取数据，这样可实现两个线程间的通讯</td></tr><tr><td>SequenceInputStream</td><td>把多个 InputStream 合并为一个 InputStream . “序列输入流”类允许应用程序把几个输入流连续地合并起来</td></tr><tr><td>DataInputStream</td><td>特殊流，读各种基本类型数据,如byte、int、String的功能</td></tr><tr><td>ObjectInputStream</td><td>对象流，读对象的功能</td></tr><tr><td>PushBackInputStream</td><td>推回输入流，可以把读取进来的某些数据重新回退到输入流的缓冲区之中</td></tr><tr><td>BufferedInputStream</td><td>缓冲流，增加了缓冲功能</td></tr></tbody></table><p><strong>下面看一下Java中包装流的实例</strong>：</p><pre><code>import java.io.BufferedInputStream;import java.io.DataInputStream;import java.io.FileInputStream;import java.io.IOException;public class StreamDemo {    public static void main(String[] args) throws IOException{        DataInputStream in=new DataInputStream(new BufferedInputStream(new  FileInputStream(&quot;D:\\hello.txt&quot;)));        while(in.available()!=0) {            System.out.print((char)in.readByte());        }        in.close();    }}</code></pre><p>输出结果</p><pre><code>hello world!hello Java I/O!</code></pre><p>上面程序中对流进行了两次包装，先用 BufferedInputStream将FileInputStream包装成缓冲流也就是给FileInputStream增加缓冲功能，再DataInputStream进一步包装方便数据处理。</p><p>如果要<strong>实现一个自己的包装流</strong>，根据上面的类图，需要继承抽象装饰类 FilterInputStream</p><p>譬如来实现这样一个操作的装饰者类：将输入流中的所有小写字母变成大写字母</p><pre><code>import java.io.FileInputStream;import java.io.FilterInputStream;import java.io.IOException;import java.io.InputStream;public class UpperCaseInputStream extends FilterInputStream {    protected UpperCaseInputStream(InputStream in) {        super(in);    }    @Override    public int read() throws IOException {        int c = super.read();        return (c == -1 ? c : Character.toUpperCase(c));    }    @Override    public int read(byte[] b, int off, int len) throws IOException {        int result = super.read(b, off, len);        for (int i = off; i &lt; off + result; i++) {            b[i] = (byte) Character.toUpperCase((char) b[i]);        }        return result;    }    public static void main(String[] args) throws IOException {        int c;        InputStream in = new UpperCaseInputStream(new FileInputStream(&quot;D:\\hello.txt&quot;));        try {            while ((c = in.read()) &gt;= 0) {                System.out.print((char) c);            }        } finally {            in.close();        }    }}</code></pre><p>输出</p><pre><code>HELLO WORLD!HELLO JAVA I/O!</code></pre><p>整个Java IO体系都是基于字符流(InputStream/OutputStream) 和 字节流(Reader/Writer)作为基类，下面画出OutputStream、Reader、Writer的部分类图，更多细节请查看其它资料</p><p><img src="http://image.laijianfeng.org/20180918OutputStream.png" alt="OutputStream类图"></p><p><img src="http://image.laijianfeng.org/20180918Reader.png" alt="Reader类图"></p><p><img src="http://image.laijianfeng.org/20180918Writer.png" alt="Writer类图"></p><h3 id="spring-cache-中的装饰者模式"><a href="#spring-cache-中的装饰者模式" class="headerlink" title="spring cache 中的装饰者模式"></a>spring cache 中的装饰者模式</h3><p>看 <code>org.springframework.cache.transaction</code> 包下的 <code>TransactionAwareCacheDecorator</code> 这个类</p><pre><code>public class TransactionAwareCacheDecorator implements Cache {    private final Cache targetCache;    public TransactionAwareCacheDecorator(Cache targetCache) {        Assert.notNull(targetCache, &quot;Target Cache must not be null&quot;);        this.targetCache = targetCache;    }    public &lt;T&gt; T get(Object key, Class&lt;T&gt; type) {        return this.targetCache.get(key, type);    }    public void put(final Object key, final Object value) {        // 判断是否开启了事务        if (TransactionSynchronizationManager.isSynchronizationActive()) {            // 将操作注册到 afterCommit 阶段            TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter() {                public void afterCommit() {                    TransactionAwareCacheDecorator.this.targetCache.put(key, value);                }            });        } else {            this.targetCache.put(key, value);        }    }    // ...省略...}</code></pre><p>该类实现了 <code>Cache</code> 接口，同时将 <code>Cache</code> 组合到类中成为了成员属性 <code>targetCache</code>，所以可以大胆猜测 <code>TransactionAwareCacheDecorator</code> 是一个装饰类，不过这里并没有抽象装饰类，且 <code>TransactionAwareCacheDecorator</code> 没有子类，这里的装饰类关系并没有Java I/O 中的装饰关系那么复杂</p><p><img src="http://image.laijianfeng.org/20180918Cache.png" alt="spring cache中类图关系"></p><p>该类的主要功能：通过 Spring 的 <code>TransactionSynchronizationManager</code> 将其 <code>put/evict/clear</code> 操作与 Spring 管理的事务同步，仅在成功的事务的 <code>after-commit</code> 阶段执行实际的缓存 <code>put/evict/clear</code> 操作。如果没有事务是 <code>active</code> 的，将立即执行 <code>put/evict/clear</code> 操作</p><h3 id="spring-session-中的装饰者模式"><a href="#spring-session-中的装饰者模式" class="headerlink" title="spring session 中的装饰者模式"></a>spring session 中的装饰者模式</h3><blockquote><p>注意：适配器模式的结尾也可能是 Wrapper</p></blockquote><p>类 <code>ServletRequestWrapper</code> 的代码如下：</p><pre><code>public class ServletRequestWrapper implements ServletRequest {    private ServletRequest request;    public ServletRequestWrapper(ServletRequest request) {        if (request == null) {            throw new IllegalArgumentException(&quot;Request cannot be null&quot;);        }        this.request = request;    }    @Override    public Object getAttribute(String name) {        return this.request.getAttribute(name);    }    //...省略...}    </code></pre><p>可以看到该类对 <code>ServletRequest</code> 进行了包装，这里是一个装饰者模式，再看下图，spring session 中 <code>SessionRepositoryFilter</code> 的一个内部类 <code>SessionRepositoryRequestWrapper</code> 与 <code>ServletRequestWrapper</code> 的关系</p><p><img src="http://image.laijianfeng.org/20180918HttpServletRequestWrapper.png" alt="ServletRequest类图"></p><p>可见 <code>ServletRequestWrapper</code> 是第一层包装，<code>HttpServletRequestWrapper</code> 通过继承进行包装，增加了 HTTP 相关的功能，<code>SessionRepositoryRequestWrapper</code> 又通过继承进行包装，增加了 Session 相关的功能</p><h3 id="Mybatis-缓存中的装饰者模式"><a href="#Mybatis-缓存中的装饰者模式" class="headerlink" title="Mybatis 缓存中的装饰者模式"></a>Mybatis 缓存中的装饰者模式</h3><p><code>org.apache.ibatis.cache</code> 包的文件结构如下所示</p><p><img src="http://image.laijianfeng.org/20180918_202157.png" alt="Mybatis cache 中的装饰者模式"></p><p>我们通过类所在的包名即可判断出该类的角色，<code>Cache</code> 为抽象构件类，<code>PerpetualCache</code> 为具体构件类，<code>decorators</code> 包下的类为装饰类，没有抽象装饰类</p><p>通过名称也可以判断出装饰类所要装饰的功能</p><h2 id="装饰者模式总结"><a href="#装饰者模式总结" class="headerlink" title="装饰者模式总结"></a>装饰者模式总结</h2><p>装饰模式的<strong>主要优点</strong>如下：</p><ol><li>对于扩展一个对象的功能，装饰模式比继承更加灵活性，不会导致类的个数急剧增加。</li><li>可以通过一种动态的方式来扩展一个对象的功能，通过配置文件可以在运行时选择不同的具体装饰类，从而实现不同的行为。</li><li>可以对一个对象进行多次装饰，通过使用不同的具体装饰类以及这些装饰类的排列组合，可以创造出很多不同行为的组合，得到功能更为强大的对象。</li><li>具体构件类与具体装饰类可以独立变化，用户可以根据需要增加新的具体构件类和具体装饰类，原有类库代码无须改变，符合 “开闭原则”。</li></ol><p>装饰模式的<strong>主要缺点</strong>如下：</p><ol><li>使用装饰模式进行系统设计时将产生很多小对象，这些对象的区别在于它们之间相互连接的方式有所不同，而不是它们的类或者属性值有所不同，大量小对象的产生势必会占用更多的系统资源，在一定程序上影响程序的性能。</li><li>装饰模式提供了一种比继承更加灵活机动的解决方案，但同时也意味着比继承更加易于出错，排错也很困难，对于多次装饰的对象，调试时寻找错误可能需要逐级排查，较为繁琐。</li></ol><p><strong>适用场景</strong>：</p><ol><li>在不影响其他对象的情况下，以动态、透明的方式给单个对象添加职责。</li><li>当不能采用继承的方式对系统进行扩展或者采用继承不利于系统扩展和维护时可以使用装饰模式。不能采用继承的情况主要有两类：第一类是系统中存在大量独立的扩展，为支持每一种扩展或者扩展之间的组合将产生大量的子类，使得子类数目呈爆炸性增长；第二类是因为类已定义为不能被继承（如Java语言中的final类）。</li></ol><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析<br><a href="https://blog.csdn.net/u013309870/article/details/75735676" target="_blank" rel="noopener">HankingHu：由装饰者模式来深入理解Java I/O整体框架</a><br><a href="https://blog.csdn.net/qq_33394088/article/details/78512407" target="_blank" rel="noopener">HryReal：Java的io类的使用场景</a></p></blockquote><h3 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h3><p><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483700&amp;idx=1&amp;sn=dd4d23f9400c8be248f5d125465ba941&amp;chksm=e9c2ed39deb5642fb809eca1351f00995f06c9a4875f09986cc5005059eff74d6c20fc1118a3&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 简单工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483704&amp;idx=1&amp;sn=fa3ae947cebf22da35e6ac0a37f566f8&amp;chksm=e9c2ed35deb564230a69e43d93a3b74618287c6ddd402a6f1dc6a5b14a896e99584985e7cf92&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 工厂方法模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483708&amp;idx=1&amp;sn=9b8c155b86511ea6ec323dc6a72c52df&amp;chksm=e9c2ed31deb56427b2a6bbcbad5bdd3a4ef68b52eb88cc47b5bcfc76773d3d983d8aaf57761c&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 抽象工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483712&amp;idx=1&amp;sn=1ffd9837eb9413dde74ff509bf69ecc5&amp;chksm=e9c2ed4ddeb5645b8cbf64c83d103a859ae49921c60e17fe8bebe63c26b04966be101d598848&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 建造者模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483716&amp;idx=1&amp;sn=df00c297c8f32e10e277db8941839c14&amp;chksm=e9c2ed49deb5645fa2586da358a8f0a00dd926f883637adebc59435f846c67c040ef759ba034&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 原型模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483721&amp;idx=1&amp;sn=721d0bce3bd516c10d4b6addbf3eced6&amp;chksm=e9c2ed44deb56452395c94a0b150994b94aa26cae71149e6c030d0ac32f9c3c37e2bfe9685b6&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 外观模式及典型应用</a></p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>设计模式 | 外观模式及典型应用</title>
      <link href="/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本文的主要内容：</p><ul><li>介绍外观模式</li><li>示例<ul><li>自己泡茶</li><li>到茶馆喝茶</li></ul></li><li>外观模式总结</li><li>外观模式的典型应用<ul><li>spring JDBC 中的外观模式</li><li>Mybatis中的外观模式</li><li>Tomcat 中的外观模式</li><li>SLF4J 中的外观模式</li></ul></li></ul><h3 id="外观模式"><a href="#外观模式" class="headerlink" title="外观模式"></a>外观模式</h3><p>外观模式是一种使用频率非常高的结构型设计模式，它通过引入一个外观角色来简化客户端与子系统之间的交互，为复杂的子系统调用提供一个统一的入口，降低子系统与客户端的耦合度，且客户端调用非常方便。</p><p>外观模式又称为门面模式，它是一种对象结构型模式。外观模式是迪米特法则的一种具体实现，通过引入一个新的外观角色可以降低原有系统的复杂度，同时降低客户类与子系统的耦合度。</p><p>外观模式包含如下两个角色：</p><p><strong>Facade（外观角色）</strong>：在客户端可以调用它的方法，在外观角色中可以知道相关的（一个或者多个）子系统的功能和责任；在正常情况下，它将所有从客户端发来的请求委派到相应的子系统去，传递给相应的子系统对象处理。</p><p><strong>SubSystem（子系统角色）</strong>：在软件系统中可以有一个或者多个子系统角色，每一个子系统可以不是一个单独的类，而是一个类的集合，它实现子系统的功能；每一个子系统都可以被客户端直接调用，或者被外观角色调用，它处理由外观类传过来的请求；子系统并不知道外观的存在，对于子系统而言，外观角色仅仅是另外一个客户端而已。</p><p>外观模式的目的不是给予子系统添加新的功能接口，而是为了让外部减少与子系统内多个模块的交互，松散耦合，从而让外部能够更简单地使用子系统。</p><p>外观模式的本质是：<strong>封装交互，简化调用</strong>。</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>泡茶需要水 <code>Water</code></p><pre><code>public class Water {    private int temperature;    // 温度    private int capacity;       // 容量    public Water() {        this.temperature = 0;        this.capacity = 10;    }    // 省略...}    </code></pre><p>泡茶需要茶叶 <code>TeaLeaf</code></p><pre><code>public class TeaLeaf {    private String teaName;    // 省略...}    </code></pre><p>烧水需要用水壶烧，将水加热</p><pre><code>public class KettleService {    public void waterBurning(String who, Water water, int burnTime) {        // 烧水，计算最终温度        int finalTermperature = Math.min(100, water.getTemperature() + burnTime * 20);        water.setTemperature(finalTermperature);        System.out.println(who + &quot; 使用水壶烧水，最终水温为 &quot; + finalTermperature);    }}</code></pre><p>泡茶，将烧好的水与茶叶进行冲泡，最终得到一杯茶水</p><pre><code>public class TeasetService {    public Teawater makeTeaWater(String who, Water water, TeaLeaf teaLeaf) {        String teawater = &quot;一杯容量为 &quot; + water.getCapacity() + &quot;, 温度为 &quot; + water.getTemperature() + &quot; 的&quot; + teaLeaf.getTeaName() + &quot;茶水&quot;;        System.out.println(who + &quot; 泡了&quot; + teawater);        return new Teawater(teawater);    }}</code></pre><p>人喝茶水</p><pre><code>public class Man {    private String name;    public Man(String name) {        this.name = name;    }    public void drink(Teawater teawater) {        System.out.println(name + &quot; 喝了&quot; + teawater.getTeaWater());    }}</code></pre><h4 id="自己泡茶喝"><a href="#自己泡茶喝" class="headerlink" title="自己泡茶喝"></a>自己泡茶喝</h4><p>张三、李四各自泡茶喝，各自都需要准备茶具、茶叶、水，各自还要完成烧水、泡茶等操作</p><pre><code>public class Main {    public static void main(String[] args) {        Man zhangsan = new Man(&quot;张三&quot;);        KettleService kettleService1 = new KettleService();        TeasetService teasetService1 = new TeasetService();        Water water1 = new Water();        TeaLeaf teaLeaf1 = new TeaLeaf(&quot;西湖龙井&quot;);        kettleService1.waterBurning(zhangsan.getName(), water1, 4);        Teawater teawater1 = teasetService1.makeTeaWater(zhangsan.getName(), water1, teaLeaf1);        zhangsan.drink(teawater1);        System.out.println();        Man lisi = new Man(&quot;李四&quot;);        KettleService kettleService2 = new KettleService();        TeasetService teasetService2 = new TeasetService();        Water water2 = new Water(10, 15);        TeaLeaf teaLeaf2 = new TeaLeaf(&quot;碧螺春&quot;);        kettleService2.waterBurning(lisi.getName(), water2, 4);        Teawater teawater2 = teasetService2.makeTeaWater(lisi.getName(), water2, teaLeaf2);        lisi.drink(teawater2);    }}</code></pre><p>输出为</p><pre><code>张三 使用水壶烧水，最终水温为 80张三 泡了一杯容量为 10, 温度为 80 的西湖龙井茶水张三 喝了一杯容量为 10, 温度为 80 的西湖龙井茶水李四 使用水壶烧水，最终水温为 90李四 泡了一杯容量为 15, 温度为 90 的碧螺春茶水李四 喝了一杯容量为 15, 温度为 90 的碧螺春茶水</code></pre><p>自己泡茶喝模式图</p><p><img src="http://image.laijianfeng.org/2018-09-16_174501.jpg" alt="自己泡茶喝模式图"></p><h4 id="到茶馆喝茶"><a href="#到茶馆喝茶" class="headerlink" title="到茶馆喝茶"></a>到茶馆喝茶</h4><p>茶馆，茶馆有不同的套餐</p><pre><code>public class TeaHouseFacade {    private String name;    private TeasetService teasetService;    private KettleService kettleService;    public TeaHouseFacade(String name) {        this.name = name;        this.teasetService = new TeasetService();        this.kettleService = new KettleService();    }    public Teawater makeTea(int teaNumber) {        switch (teaNumber) {            case 1:                Water water1 = new Water();                TeaLeaf teaLeaf1 = new TeaLeaf(&quot;西湖龙井&quot;);                kettleService.waterBurning(this.name, water1, 4);                Teawater teawater1 = teasetService.makeTeaWater(this.name, water1, teaLeaf1);                return teawater1;            case 2:                Water water2 = new Water(10, 15);                TeaLeaf teaLeaf2 = new TeaLeaf(&quot;碧螺春&quot;);                kettleService.waterBurning(this.name, water2, 4);                Teawater teawater2 = teasetService.makeTeaWater(this.name, water2, teaLeaf2);                return teawater2;            default:                Water water3 = new Water();                TeaLeaf teaLeaf3 = new TeaLeaf(&quot;招牌乌龙&quot;);                kettleService.waterBurning(this.name, water3, 5);                Teawater teawater3 = teasetService.makeTeaWater(this.name, water3, teaLeaf3);                return teawater3;        }    }}</code></pre><p>张三和李四点茶，只需要告诉茶馆套餐编号即可，水、茶叶由茶馆准备，烧水泡茶的操作由茶馆统一完成</p><pre><code>public class Test {    public static void main(String[] args) {        TeaHouseFacade teaHouseFacade = new TeaHouseFacade(&quot;老舍茶馆&quot;);        Man zhangsan = new Man(&quot;张三&quot;);        Teawater teawater = teaHouseFacade.makeTea(1);        zhangsan.drink(teawater);        System.out.println();        Man lisi = new Man(&quot;李四&quot;);        Teawater teawater1 = teaHouseFacade.makeTea(2);        lisi.drink(teawater1);    }}</code></pre><p>输出为</p><pre><code>老舍茶馆 使用水壶烧水，最终水温为 80老舍茶馆 泡了一杯容量为 10, 温度为 80 的西湖龙井茶水张三 喝了一杯容量为 10, 温度为 80 的西湖龙井茶水老舍茶馆 使用水壶烧水，最终水温为 90老舍茶馆 泡了一杯容量为 15, 温度为 90 的碧螺春茶水李四 喝了一杯容量为 15, 温度为 90 的碧螺春茶水</code></pre><p>到茶馆喝茶模式图</p><p><img src="http://image.laijianfeng.org/2018-09-16_174502.jpg" alt="到茶馆喝茶模式图"></p><h3 id="外观模式总结"><a href="#外观模式总结" class="headerlink" title="外观模式总结"></a>外观模式总结</h3><p>外观模式的<strong>主要优点</strong>如下：</p><ul><li>它对客户端屏蔽了子系统组件，减少了客户端所需处理的对象数目，并使得子系统使用起来更加容易。通过引入外观模式，客户端代码将变得很简单，与之关联的对象也很少。</li><li>它实现了子系统与客户端之间的松耦合关系，这使得子系统的变化不会影响到调用它的客户端，只需要调整外观类即可。</li><li>一个子系统的修改对其他子系统没有任何影响，而且子系统内部变化也不会影响到外观对象。</li></ul><p>外观模式的<strong>主要缺点</strong>如下：</p><ul><li>不能很好地限制客户端直接使用子系统类，如果对客户端访问子系统类做太多的限制则减少了可变性和灵活性。</li><li>如果设计不当，增加新的子系统可能需要修改外观类的源代码，违背了开闭原则。</li></ul><p><strong>适用场景：</strong></p><ul><li>当要为访问一系列复杂的子系统提供一个简单入口时可以使用外观模式。</li><li>客户端程序与多个子系统之间存在很大的依赖性。引入外观类可以将子系统与客户端解耦，从而提高子系统的独立性和可移植性。</li><li>在层次化结构中，可以使用外观模式定义系统中每一层的入口，层与层之间不直接产生联系，而通过外观类建立联系，降低层之间的耦合度。</li></ul><h3 id="源码分析外观模式的典型应用"><a href="#源码分析外观模式的典型应用" class="headerlink" title="源码分析外观模式的典型应用"></a>源码分析外观模式的典型应用</h3><h4 id="spring-jdbc中的外观模式"><a href="#spring-jdbc中的外观模式" class="headerlink" title="spring jdbc中的外观模式"></a>spring jdbc中的外观模式</h4><p>查看 <code>org.springframework.jdbc.support.JdbcUtils</code></p><pre><code>public abstract class JdbcUtils {    public static void closeConnection(Connection con) {        if (con != null) {            try {                con.close();            }            catch (SQLException ex) {                logger.debug(&quot;Could not close JDBC Connection&quot;, ex);            }            catch (Throwable ex) {                // We don&#39;t trust the JDBC driver: It might throw RuntimeException or Error.                logger.debug(&quot;Unexpected exception on closing JDBC Connection&quot;, ex);            }        }    }    public static Object getResultSetValue(ResultSet rs, int index, Class&lt;?&gt; requiredType) throws SQLException {        if (requiredType == null) {            return getResultSetValue(rs, index);        }        Object value = null;        boolean wasNullCheck = false;        // Explicitly extract typed value, as far as possible.        if (String.class.equals(requiredType)) {            value = rs.getString(index);        }        else if (boolean.class.equals(requiredType) || Boolean.class.equals(requiredType)) {            value = rs.getBoolean(index);            wasNullCheck = true;        }        else if (byte.class.equals(requiredType) || Byte.class.equals(requiredType)) {            value = rs.getByte(index);            wasNullCheck = true;        }        else if (short.class.equals(requiredType) || Short.class.equals(requiredType)) {            value = rs.getShort(index);            wasNullCheck = true;        }        else if (int.class.equals(requiredType) || Integer.class.equals(requiredType)) {            value = rs.getInt(index);            wasNullCheck = true;        }        else if (long.class.equals(requiredType) || Long.class.equals(requiredType)) {            value = rs.getLong(index);            wasNullCheck = true;        }        else if (float.class.equals(requiredType) || Float.class.equals(requiredType)) {            value = rs.getFloat(index);            wasNullCheck = true;        }        else if (double.class.equals(requiredType) || Double.class.equals(requiredType) ||                Number.class.equals(requiredType)) {            value = rs.getDouble(index);            wasNullCheck = true;        }        else if (byte[].class.equals(requiredType)) {            value = rs.getBytes(index);        }        else if (java.sql.Date.class.equals(requiredType)) {            value = rs.getDate(index);        }        else if (java.sql.Time.class.equals(requiredType)) {            value = rs.getTime(index);        }        else if (java.sql.Timestamp.class.equals(requiredType) || java.util.Date.class.equals(requiredType)) {            value = rs.getTimestamp(index);        }        else if (BigDecimal.class.equals(requiredType)) {            value = rs.getBigDecimal(index);        }        else if (Blob.class.equals(requiredType)) {            value = rs.getBlob(index);        }        else if (Clob.class.equals(requiredType)) {            value = rs.getClob(index);        }        else {            // Some unknown type desired -&gt; rely on getObject.            value = getResultSetValue(rs, index);        }        if (wasNullCheck &amp;&amp; value != null &amp;&amp; rs.wasNull()) {            value = null;        }        return value;    }    // ...省略...}    </code></pre><p>该工具类主要是对原生的 jdbc 进行了封装</p><h4 id="Mybatis中的外观模式"><a href="#Mybatis中的外观模式" class="headerlink" title="Mybatis中的外观模式"></a>Mybatis中的外观模式</h4><p>查看 <code>org.apache.ibatis.session.Configuration</code> 类中以 <code>new</code> 开头的方法</p><pre><code>public class Configuration {    public Executor newExecutor(Transaction transaction, ExecutorType executorType) {        executorType = executorType == null ? defaultExecutorType : executorType;        executorType = executorType == null ? ExecutorType.SIMPLE : executorType;        Executor executor;        if (ExecutorType.BATCH == executorType) {          executor = new BatchExecutor(this, transaction);        } else if (ExecutorType.REUSE == executorType) {          executor = new ReuseExecutor(this, transaction);        } else {          executor = new SimpleExecutor(this, transaction);        }        if (cacheEnabled) {          executor = new CachingExecutor(executor);        }        executor = (Executor) interceptorChain.pluginAll(executor);        return executor;    }    public ResultSetHandler newResultSetHandler(Executor executor, MappedStatement mappedStatement, RowBounds rowBounds, ParameterHandler parameterHandler,          ResultHandler resultHandler, BoundSql boundSql) {        ResultSetHandler resultSetHandler = new DefaultResultSetHandler(executor, mappedStatement, parameterHandler, resultHandler, boundSql, rowBounds);        resultSetHandler = (ResultSetHandler) interceptorChain.pluginAll(resultSetHandler);        return resultSetHandler;    }    // ...省略...}</code></pre><p>该类主要对一些创建对象的操作进行封装</p><h4 id="Tomcat-中的外观模式"><a href="#Tomcat-中的外观模式" class="headerlink" title="Tomcat 中的外观模式"></a>Tomcat 中的外观模式</h4><p>Tomcat 源码中大量使用了很多外观模式</p><p><img src="http://image.laijianfeng.org/20180916_193616.png" alt="Tomcat中的外观模式"></p><p><code>org.apache.catalina.connector.Request</code> 和 <code>org.apache.catalina.connector.RequestFacade</code> 这两个类都实现了 <code>HttpServletRequest</code> 接口</p><p>在 <code>Request</code> 中调用 <code>getRequest()</code> 实际获取的是 <code>RequestFacade</code> 的对象 </p><pre><code>protected RequestFacade facade = null;public HttpServletRequest getRequest() {    if (facade == null) {        facade = new RequestFacade(this);    }    return facade;}</code></pre><p>在 <code>RequestFacade</code> 中再对认为是子系统的操作进行封装</p><pre><code>public class RequestFacade implements HttpServletRequest {    /**     * The wrapped request.     */    protected Request request = null;    @Override    public Object getAttribute(String name) {        if (request == null) {            throw new IllegalStateException(sm.getString(&quot;requestFacade.nullRequest&quot;));        }        return request.getAttribute(name);    }    // ...省略...}    </code></pre><h4 id="SLF4J-中的外观模式"><a href="#SLF4J-中的外观模式" class="headerlink" title="SLF4J 中的外观模式"></a>SLF4J 中的外观模式</h4><p><code>SLF4J</code> 是简单的日志外观模式框架，抽象了各种日志框架例如 <code>Logback</code>、<code>Log4j</code>、<code>Commons-logging</code> 和 <code>JDK</code> 自带的 <code>logging</code> 实现接口。它使得用户可以在部署时使用自己想要的日志框架。</p><p><code>SLF4J</code> <strong>没有替代任何日志框架，它仅仅是标准日志框架的外观模式</strong>。如果在类路径下除了 <code>SLF4J</code> 再没有任何日志框架，那么默认状态是在控制台输出日志。</p><blockquote><p>日志处理框架 Logback 是 Log4j 的改进版本，原生支持SLF4J（因为是同一作者开发的），因此 Logback＋SLF4J 的组合是日志框架的最佳选择，比 SLF4J+其它日志框架 的组合要快一些。而且Logback的配置可以是XML或Groovy代码。</p></blockquote><p>SLF4J 的 helloworld 如下：</p><pre><code>import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class HelloWorld {  public static void main(String[] args) {    Logger logger = LoggerFactory.getLogger(HelloWorld.class);    logger.info(&quot;Hello World&quot;);  }}</code></pre><p>下图为 SLF4J 与日志处理框架的绑定调用关系</p><p><img src="https://www.slf4j.org/images/concrete-bindings.png" alt="SLF4J与日志处理框架的绑定调用关系"></p><p>应用层调用 <code>slf4j-api.jar</code>，<code>slf4j-api.jar</code> 再根据所绑定的日志处理框架调用不同的 jar 包进行处理</p><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析<br><a href="https://www.cnblogs.com/xrq730/p/8619156.html" target="_blank" rel="noopener">Java日志框架：slf4j作用及其实现原理</a></p></blockquote><h4 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h4><p><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483700&amp;idx=1&amp;sn=dd4d23f9400c8be248f5d125465ba941&amp;chksm=e9c2ed39deb5642fb809eca1351f00995f06c9a4875f09986cc5005059eff74d6c20fc1118a3&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 简单工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483704&amp;idx=1&amp;sn=fa3ae947cebf22da35e6ac0a37f566f8&amp;chksm=e9c2ed35deb564230a69e43d93a3b74618287c6ddd402a6f1dc6a5b14a896e99584985e7cf92&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 工厂方法模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483708&amp;idx=1&amp;sn=9b8c155b86511ea6ec323dc6a72c52df&amp;chksm=e9c2ed31deb56427b2a6bbcbad5bdd3a4ef68b52eb88cc47b5bcfc76773d3d983d8aaf57761c&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 抽象工厂模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483712&amp;idx=1&amp;sn=1ffd9837eb9413dde74ff509bf69ecc5&amp;chksm=e9c2ed4ddeb5645b8cbf64c83d103a859ae49921c60e17fe8bebe63c26b04966be101d598848&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 建造者模式及典型应用</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483716&amp;idx=1&amp;sn=df00c297c8f32e10e277db8941839c14&amp;chksm=e9c2ed49deb5645fa2586da358a8f0a00dd926f883637adebc59435f846c67c040ef759ba034&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 原型模式及典型应用</a></p><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>设计模式 | 原型模式及典型应用</title>
      <link href="/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本文的主要内容如下：</p><ul><li>介绍原型模式</li><li>示例<ul><li>Java语言的clone</li><li>浅克隆与深克隆</li><li>实现深克隆</li></ul></li><li>原型模式的典型应用</li></ul><h3 id="原型模式"><a href="#原型模式" class="headerlink" title="原型模式"></a>原型模式</h3><p><strong>原型模式(Prototype Pattern)</strong>：使用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。原型模式是一种对象创建型模式。</p><p>原型模式的工作原理很简单：将一个原型对象传给那个要发动创建的对象，这个要发动创建的对象通过请求原型对象拷贝自己来实现创建过程。</p><p>原型模式是一种“另类”的创建型模式，创建克隆对象的工厂就是原型类自身，工厂方法由克隆方法来实现。</p><p>需要注意的是通过克隆方法所创建的对象是全新的对象，它们在内存中拥有新的地址，通常对克隆所产生的对象进行修改对原型对象不会造成任何影响，每一个克隆对象都是相互独立的。通过不同的方式修改可以得到一系列相似但不完全相同的对象。</p><h4 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h4><ul><li><strong>Prototype（抽象原型类）</strong>：它是声明克隆方法的接口，是所有具体原型类的公共父类，可以是抽象类也可以是接口，甚至还可以是具体实现类。</li><li><strong>ConcretePrototype（具体原型类）</strong>：它实现在抽象原型类中声明的克隆方法，在克隆方法中返回自己的一个克隆对象。</li><li><strong>Client（客户类）</strong>：让一个原型对象克隆自身从而创建一个新的对象，在客户类中只需要直接实例化或通过工厂方法等方式创建一个原型对象，再通过调用该对象的克隆方法即可得到多个相同的对象。由于客户类针对抽象原型类Prototype编程，因此用户可以根据需要选择具体原型类，系统具有较好的可扩展性，增加或更换具体原型类都很方便。</li></ul><p>原型模式的<strong>核心在于如何实现克隆方法</strong>。</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><h4 id="Java语言提供的clone-方法"><a href="#Java语言提供的clone-方法" class="headerlink" title="Java语言提供的clone()方法"></a>Java语言提供的clone()方法</h4><p>学过Java语言的人都知道，所有的Java类都继承自 <code>java.lang.Object</code>。事实上，<code>Object</code> 类提供一个 <code>clone()</code> 方法，可以将一个Java对象复制一份。因此在Java中可以直接使用 <code>Object</code> 提供的 <code>clone()</code> 方法来实现对象的克隆，Java语言中的原型模式实现很简单。</p><p>需要注意的是能够实现克隆的Java类必须实现一个 <code>标识接口 Cloneable</code>，表示这个Java类支持被复制。如果一个类没有实现这个接口但是调用了clone()方法，Java编译器将抛出一个 <code>CloneNotSupportedException</code> 异常。</p><pre><code>public class Mail implements Cloneable{    private String name;    private String emailAddress;    private String content;    public Mail(){        System.out.println(&quot;Mail Class Constructor&quot;);    }    // ...省略 getter、setter    @Override    protected Object clone() throws CloneNotSupportedException {        System.out.println(&quot;clone mail object&quot;);        return super.clone();    }}</code></pre><p>在客户端创建原型对象和克隆对象也很简单，如下代码所示：</p><pre><code>public class Test {    public static void main(String[] args) throws CloneNotSupportedException {        Mail mail = new Mail();        mail.setContent(&quot;初始化模板&quot;);        System.out.println(&quot;初始化mail:&quot;+mail);        for(int i = 0;i &lt; 3;i++){            System.out.println();            Mail mailTemp = (Mail) mail.clone();            mailTemp.setName(&quot;姓名&quot;+i);            mailTemp.setEmailAddress(&quot;姓名&quot;+i+&quot;@test.com&quot;);            mailTemp.setContent(&quot;恭喜您，此次抽奖活动中奖了&quot;);            MailUtil.sendMail(mailTemp);            System.out.println(&quot;克隆的mailTemp:&quot;+mailTemp);        }        MailUtil.saveOriginMailRecord(mail);    }}</code></pre><p>其中的 <code>MailUtil</code> 工具类为</p><pre><code>public class MailUtil {    public static void sendMail(Mail mail) {        String outputContent = &quot;向{0}同学,邮件地址:{1},邮件内容:{2}发送邮件成功&quot;;        System.out.println(MessageFormat.format(outputContent, mail.getName(), mail.getEmailAddress(), mail.getContent()));    }    public static void saveOriginMailRecord(Mail mail) {        System.out.println(&quot;存储originMail记录,originMail:&quot; + mail.getContent());    }}</code></pre><p>输出如下：</p><pre><code>Mail Class Constructor初始化mail:Mail{name=&#39;null&#39;, emailAddress=&#39;null&#39;, content=&#39;初始化模板&#39;}com.designpattern.prototype.Mail@12edcd21clone mail object向姓名0同学,邮件地址:姓名0@test.com,邮件内容:恭喜您，此次抽奖活动中奖了发送邮件成功克隆的mailTemp:Mail{name=&#39;姓名0&#39;, emailAddress=&#39;姓名0@test.com&#39;, content=&#39;恭喜您，此次抽奖活动中奖了&#39;}com.designpattern.prototype.Mail@34c45dcaclone mail object向姓名1同学,邮件地址:姓名1@test.com,邮件内容:恭喜您，此次抽奖活动中奖了发送邮件成功克隆的mailTemp:Mail{name=&#39;姓名1&#39;, emailAddress=&#39;姓名1@test.com&#39;, content=&#39;恭喜您，此次抽奖活动中奖了&#39;}com.designpattern.prototype.Mail@52cc8049clone mail object向姓名2同学,邮件地址:姓名2@test.com,邮件内容:恭喜您，此次抽奖活动中奖了发送邮件成功克隆的mailTemp:Mail{name=&#39;姓名2&#39;, emailAddress=&#39;姓名2@test.com&#39;, content=&#39;恭喜您，此次抽奖活动中奖了&#39;}com.designpattern.prototype.Mail@5b6f7412存储originMail记录,originMail:初始化模板</code></pre><p>从输出结果中我们可以观察到：</p><ul><li>for循环中的 mailTemp 从 mail 对象中克隆得到，它们的内存地址均不同，说明不是同一个对象，克隆成功，克隆仅仅通过调用 <code>super.clone()</code> 即可。</li><li>最后调用的 <code>MailUtil.saveOriginMailRecord(mail);</code> 中的 <code>mail</code> 对象的内容仍为 for 循环之前设置的内容，并没有因为克隆而改变。</li><li>克隆的时候调用了 <code>clone</code> 方法，并没有调用 <code>Mail</code> 类的构造器，只在最前面 <code>new</code> 的时候才调用了一次</li></ul><p>关于输出的内存地址是怎么输出的，我们还需要看一下 <code>Object#toString</code> 方法</p><pre><code>public class Object {    public String toString() {        return getClass().getName() + &quot;@&quot; + Integer.toHexString(hashCode());    }    //...省略...}</code></pre><p>所以所谓的内存地址即为 <code>hashCode()</code> 的十六进制表示，这里简单的认为 内存地址相同则为同一个对象，不同则为不同对象</p><p>再来看一眼 <code>Object#clone</code> 方法</p><pre><code>protected native Object clone() throws CloneNotSupportedException;</code></pre><p>这是一个 <code>native</code> 关键字修饰的方法</p><p>一般而言，Java语言中的clone()方法满足：</p><ul><li>对任何对象x，都有 <code>x.clone() != x</code>，即克隆对象与原型对象不是同一个对象；</li><li>对任何对象x，都有 <code>x.clone().getClass() == x.getClass()</code>，即克隆对象与原型对象的类型一样；</li><li>如果对象x的 <code>equals()</code> 方法定义恰当，那么 <code>x.clone().equals(x)</code> 应该成立。</li></ul><p>为了获取对象的一份拷贝，我们可以直接利用Object类的clone()方法，具体步骤如下：</p><ol><li>在派生类中覆盖基类的 <code>clone()</code> 方法，并声明为public；</li><li>在派生类的 <code>clone()</code> 方法中，调用 <code>super.clone()</code>；</li><li>派生类需实现Cloneable接口。</li></ol><p>此时，Object类相当于<strong>抽象原型类</strong>，所有实现了Cloneable接口的类相当于<strong>具体原型类</strong>。</p><h4 id="浅克隆与深克隆"><a href="#浅克隆与深克隆" class="headerlink" title="浅克隆与深克隆"></a>浅克隆与深克隆</h4><p>看下面的示例</p><pre><code>public class Pig implements Cloneable{    private String name;    private Date birthday;    // ...getter, setter, construct    @Override    protected Object clone() throws CloneNotSupportedException {        Pig pig = (Pig)super.clone();        return pig;    }    @Override    public String toString() {        return &quot;Pig{&quot; +                &quot;name=&#39;&quot; + name + &#39;\&#39;&#39; +                &quot;, birthday=&quot; + birthday +                &#39;}&#39;+super.toString();    }}</code></pre><p>测试</p><pre><code>public class Test {    public static void main(String[] args) throws CloneNotSupportedException, NoSuchMethodException, InvocationTargetException, IllegalAccessException {        Date birthday = new Date(0L);        Pig pig1 = new Pig(&quot;佩奇&quot;,birthday);        Pig pig2 = (Pig) pig1.clone();        System.out.println(pig1);        System.out.println(pig2);        pig1.getBirthday().setTime(666666666666L);        System.out.println(pig1);        System.out.println(pig2);    }}</code></pre><p>输出如下</p><pre><code>Pig{name=&#39;佩奇&#39;, birthday=Thu Jan 01 08:00:00 CST 1970}com.designpattern.clone.Pig@27973e9bPig{name=&#39;佩奇&#39;, birthday=Thu Jan 01 08:00:00 CST 1970}com.designpattern.clone.Pig@312b1daePig{name=&#39;佩奇&#39;, birthday=Sat Feb 16 09:11:06 CST 1991}com.designpattern.clone.Pig@27973e9bPig{name=&#39;佩奇&#39;, birthday=Sat Feb 16 09:11:06 CST 1991}com.designpattern.clone.Pig@312b1dae</code></pre><p>我们照着上一小节说的实现 <code>Cloneable</code>，调用 <code>super.clone();</code> 进行克隆，中间我们对 <code>pig1</code> 对象设置了一个时间戳，从输出中我们可以发现什么问题呢？</p><p>我们可以发现：</p><ul><li><code>pig1</code> 与 <code>pig2</code> 的内存地址不同</li><li>对 <code>pig1</code> 设置了时间，同事 <code>pig2</code> 的时间也改变了</li></ul><p>我们通过 debug 来看一下</p><p><img src="http://image.laijianfeng.org/20180914_224723.png" alt="debug查看对象地址"></p><p>发现如下：</p><ul><li>pig1 与 pig2 地址不一样</li><li>pig1 的 birthday 与 pig2 的 birthday <strong>一样</strong></li></ul><p>这里引出浅拷贝与深拷贝。</p><p>在Java语言中，数据类型分为值类型（基本数据类型）和引用类型，<strong>值类型</strong>包括int、double、byte、boolean、char等简单数据类型，<strong>引用类型</strong>包括类、接口、数组等复杂类型。</p><p>浅克隆和深克隆的主要区别在于<strong>是否支持引用类型的成员变量的复制</strong>，下面将对两者进行详细介绍。</p><p><strong>浅克隆：</strong></p><ul><li><p>在浅克隆中，如果原型对象的成员变量是值类型，将复制一份给克隆对象；如果原型对象的成员变量是引用类型，则将引用对象的地址复制一份给克隆对象，也就是说原型对象和克隆对象的成员变量指向相同的内存地址。</p></li><li><p>简单来说，在浅克隆中，当对象被复制时<strong>只复制它本身和其中包含的值类型的成员变量</strong>，而<strong>引用类型的成员对象并没有复制</strong>。</p></li><li><p>在Java语言中，通过覆盖Object类的clone()方法可以实现浅克隆。</p></li></ul><p><strong>深克隆：</strong></p><ul><li><p>在深克隆中，<strong>无论原型对象的成员变量是值类型还是引用类型，都将复制一份给克隆对象</strong>，深克隆将原型对象的所有引用对象也复制一份给克隆对象。</p></li><li><p>简单来说，在深克隆中，除了对象本身被复制外，对象所包含的所有成员变量也将复制。</p></li><li><p>在Java语言中，如果需要实现深克隆，可以通过序列化(Serialization)等方式来实现。需要注意的是能够实现序列化的对象其类必须实现Serializable接口，否则无法实现序列化操作。</p></li></ul><h4 id="实现深克隆"><a href="#实现深克隆" class="headerlink" title="实现深克隆"></a>实现深克隆</h4><p>方式一，手动对引用对象进行克隆：</p><pre><code>    @Override    protected Object clone() throws CloneNotSupportedException {        Pig pig = (Pig)super.clone();        //深克隆        pig.birthday = (Date) pig.birthday.clone();        return pig;    }</code></pre><p>方式二，通过序列化的方式：</p><pre><code>public class Pig implements Serializable {    private String name;    private Date birthday;    // ...省略 getter, setter等    protected Object deepClone() throws CloneNotSupportedException, IOException, ClassNotFoundException {        //将对象写入流中        ByteArrayOutputStream bao = new ByteArrayOutputStream();        ObjectOutputStream oos = new ObjectOutputStream(bao);        oos.writeObject(this);        //将对象从流中取出        ByteArrayInputStream bis = new ByteArrayInputStream(bao.toByteArray());        ObjectInputStream ois = new ObjectInputStream(bis);        return (ois.readObject());    }}</code></pre><p><img src="http://image.laijianfeng.org/20180914_230920.png" alt="序列化方式的深克隆结果"></p><h3 id="破坏单例模式"><a href="#破坏单例模式" class="headerlink" title="破坏单例模式"></a>破坏单例模式</h3><p>饿汉式单例模式如下：</p><pre><code>public class HungrySingleton implements Serializable, Cloneable {    private final static HungrySingleton hungrySingleton;    static {        hungrySingleton = new HungrySingleton();    }    private HungrySingleton() {        if (hungrySingleton != null) {            throw new RuntimeException(&quot;单例构造器禁止反射调用&quot;);        }    }    public static HungrySingleton getInstance() {        return hungrySingleton;    }    private Object readResolve() {        return hungrySingleton;    }    @Override    protected Object clone() throws CloneNotSupportedException {        return super.clone();    }}</code></pre><p>使用反射获取对象，测试如下</p><pre><code>public class Test {    public static void main(String[] args) throws CloneNotSupportedException, NoSuchMethodException, InvocationTargetException, IllegalAccessException {        HungrySingleton hungrySingleton = HungrySingleton.getInstance();        Method method = hungrySingleton.getClass().getDeclaredMethod(&quot;clone&quot;);        method.setAccessible(true);        HungrySingleton cloneHungrySingleton = (HungrySingleton) method.invoke(hungrySingleton);        System.out.println(hungrySingleton);        System.out.println(cloneHungrySingleton);    }}</code></pre><p>输出</p><pre><code>com.designpattern.HungrySingleton@34c45dcacom.designpattern.HungrySingleton@52cc8049</code></pre><p>可以看到，通过原型模式，我们把单例模式给破坏了，现在有两个对象了</p><p>为了防止单例模式被破坏，我们可以：不实现 <code>Cloneable</code> 接口；或者把 <code>clone</code> 方法改为如下</p><pre><code>    @Override    protected Object clone() throws CloneNotSupportedException {        return getInstance();    }</code></pre><h3 id="原型模式的典型应用"><a href="#原型模式的典型应用" class="headerlink" title="原型模式的典型应用"></a>原型模式的典型应用</h3><ol><li><code>Object</code> 类中的 <code>clone</code> 接口</li><li><code>Cloneable</code> 接口的实现类，可以看到至少一千多个，找几个例子譬如：</li></ol><p><img src="http://image.laijianfeng.org/20180914_233315.png" alt="Cloneable接口的实现类"></p><p><code>ArrayList</code> 对 <code>clone</code> 的重写如下：</p><pre><code>public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;        implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable {    public Object clone() {        try {            ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone();            v.elementData = Arrays.copyOf(elementData, size);            v.modCount = 0;            return v;        } catch (CloneNotSupportedException e) {            // this shouldn&#39;t happen, since we are Cloneable            throw new InternalError(e);        }    }    //...省略}</code></pre><p>调用 <code>super.clone();</code> 之后把 <code>elementData</code> 数据 copy 了一份</p><p>同理，我们看看 <code>HashMap</code> 对 <code>clone</code> 方法的重写：</p><pre><code>public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable {    @Override    public Object clone() {        HashMap&lt;K,V&gt; result;        try {            result = (HashMap&lt;K,V&gt;)super.clone();        } catch (CloneNotSupportedException e) {            // this shouldn&#39;t happen, since we are Cloneable            throw new InternalError(e);        }        result.reinitialize();        result.putMapEntries(this, false);        return result;    }    // ...省略...}</code></pre><p>mybatis 中的 <code>org.apache.ibatis.cache.CacheKey</code> 对 <code>clone</code> 方法的重写：</p><pre><code>public class CacheKey implements Cloneable, Serializable {    private List&lt;Object&gt; updateList;    public CacheKey clone() throws CloneNotSupportedException {        CacheKey clonedCacheKey = (CacheKey)super.clone();        clonedCacheKey.updateList = new ArrayList(this.updateList);        return clonedCacheKey;    }    // ... 省略...}</code></pre><p>这里又要注意，<code>updateList</code> 是 <code>List&lt;Object&gt;</code> 类型，所以可能是值类型的List，也可能是引用类型的List，克隆的结果需要注意是否为深克隆或者浅克隆</p><p><strong>使用原始模式的时候一定要注意为深克隆还是浅克隆。</strong></p><h3 id="原型模式总结"><a href="#原型模式总结" class="headerlink" title="原型模式总结"></a>原型模式总结</h3><p>原型模式的<strong>主要优点</strong>如下：</p><ul><li>当创建新的对象实例较为复杂时，使用原型模式可以简化对象的创建过程，通过复制一个已有实例可以提高新实例的创建效率。</li><li>扩展性较好，由于在原型模式中提供了抽象原型类，在客户端可以针对抽象原型类进行编程，而将具体原型类写在配置文件中，增加或减少产品类对原有系统都没有任何影响。</li><li>原型模式提供了简化的创建结构，工厂方法模式常常需要有一个与产品类等级结构相同的工厂等级结构，而原型模式就不需要这样，原型模式中产品的复制是通过封装在原型类中的克隆方法实现的，无须专门的工厂类来创建产品。</li><li>可以使用深克隆的方式保存对象的状态，使用原型模式将对象复制一份并将其状态保存起来，以便在需要的时候使用（如恢复到某一历史状态），可辅助实现撤销操作。</li></ul><p>原型模式的<strong>主要缺点</strong>如下：</p><ul><li>需要为每一个类配备一个克隆方法，而且该克隆方法位于一个类的内部，当对已有的类进行改造时，需要修改源代码，违背了“开闭原则”。</li><li>在实现深克隆时需要编写较为复杂的代码，而且当对象之间存在多重的嵌套引用时，为了实现深克隆，每一层对象对应的类都必须支持深克隆，实现起来可能会比较麻烦。</li></ul><p><strong>适用场景：</strong></p><ul><li>创建新对象成本较大（如初始化需要占用较长的时间，占用太多的CPU资源或网络资源），新的对象可以通过原型模式对已有对象进行复制来获得，如果是相似对象，则可以对其成员变量稍作修改。</li><li>如果系统要保存对象的状态，而对象的状态变化很小，或者对象本身占用内存较少时，可以使用原型模式配合备忘录模式来实现。</li><li>需要避免使用分层次的工厂类来创建分层次的对象，并且类的实例对象只有一个或很少的几个组合状态，通过复制原型对象得到新实例可能比使用构造函数创建一个新实例更加方便。</li></ul><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析</p></blockquote><p><img src="http://image.laijianfeng.org/20180913_001328.png" alt="关注_小旋锋_微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>设计模式 | 建造者模式及典型应用</title>
      <link href="/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<h3 id="建造者模式"><a href="#建造者模式" class="headerlink" title="建造者模式"></a>建造者模式</h3><p>建造者模式(Builder Pattern)：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。建造者模式是一种对象创建型模式。</p><p>建造者模式一步一步创建一个复杂的对象，它允许用户只通过指定复杂对象的类型和内容就可以构建它们，用户不需要知道内部的具体构建细节。</p><h4 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h4><p><strong>Builder（抽象建造者）</strong>：它为创建一个产品Product对象的各个部件指定抽象接口，在该接口中一般声明两类方法，一类方法是buildPartX()，它们用于创建复杂对象的各个部件；另一类方法是getResult()，它们用于返回复杂对象。Builder既可以是抽象类，也可以是接口。</p><p><strong>ConcreteBuilder（具体建造者）</strong>：它实现了Builder接口，实现各个部件的具体构造和装配方法，定义并明确它所创建的复杂对象，也可以提供一个方法返回创建好的复杂产品对象。</p><p><strong>Product（产品角色）</strong>：它是被构建的复杂对象，包含多个组成部件，具体建造者创建该产品的内部表示并定义它的装配过程。</p><p><strong>Director（指挥者）</strong>：指挥者又称为导演类，它负责安排复杂对象的建造次序，指挥者与抽象建造者之间存在关联关系，可以在其construct()建造方法中调用建造者对象的部件构造与装配方法，完成复杂对象的建造。客户端一般只需要与指挥者进行交互，在客户端确定具体建造者的类型，并实例化具体建造者对象（也可以通过配置文件和反射机制），然后通过指挥者类的构造函数或者Setter方法将该对象传入指挥者类中。</p><p>在建造者模式的定义中提到了复杂对象，那么什么是复杂对象？简单来说，<strong>复杂对象</strong>是指那些包含多个成员属性的对象，这些成员属性也称为部件或零件，如汽车包括方向盘、发动机、轮胎等部件，电子邮件包括发件人、收件人、主题、内容、附件等部件</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>产品角色 <code>Computer</code></p><pre><code>public class Computer {    private String brand;    private String cpu;    private String mainBoard;    private String hardDisk;    private String displayCard;    private String power;    private String memory;    // 省略 getter, setter, toString}</code></pre><p>抽象建造者 <code>builder</code></p><pre><code>public abstract class Builder {    protected Computer computer = new Computer();    public abstract void buildBrand();    public abstract void buildCPU();    public abstract void buildMainBoard();    public abstract void buildHardDisk();    public abstract void buildDisplayCard();    public abstract void buildPower();    public abstract void buildMemory();    public Computer createComputer() {        return computer;    }}</code></pre><p>具体建造者 <code>DellComputerBuilder</code>，<code>ASUSComputerBuilder</code>，分别建造戴尔电脑和华硕电脑</p><pre><code>public class DellComputerBuilder extends Builder {    @Override    public void buildBrand() {        computer.setBrand(&quot;戴尔电脑&quot;);    }    @Override    public void buildCPU() {        computer.setCpu(&quot;i5-8300H 四核&quot;);    }    @Override    public void buildMainBoard() {        computer.setMainBoard(&quot;戴尔主板&quot;);    }    @Override    public void buildHardDisk() {        computer.setHardDisk(&quot;1T + 128GB SSD&quot;);    }    @Override    public void buildDisplayCard() {        computer.setDisplayCard(&quot;GTX1060 独立6GB&quot;);    }    @Override    public void buildPower() {        computer.setPower(&quot;4芯 锂离子电池 180W AC适配器&quot;);    }    @Override    public void buildMemory() {        computer.setMemory(&quot;4G + 4G&quot;);    }}public class ASUSComputerBuilder extends Builder{    @Override    public void buildBrand() {        computer.setBrand(&quot;华硕电脑&quot;);    }    @Override    public void buildCPU() {        computer.setCpu(&quot;Intel 第8代 酷睿&quot;);    }    @Override    public void buildMainBoard() {        computer.setMainBoard(&quot;华硕主板&quot;);    }    @Override    public void buildHardDisk() {        computer.setHardDisk(&quot;256GB SSD&quot;);    }    @Override    public void buildDisplayCard() {        computer.setDisplayCard(&quot;MX150 独立2GB&quot;);    }    @Override    public void buildPower() {        computer.setPower(&quot;3芯 锂离子电池 65W AC适配器&quot;);    }    @Override    public void buildMemory() {        computer.setMemory(&quot;1 x SO-DIMM  8GB&quot;);    }}</code></pre><p>指挥者 <code>ComputerDirector</code>，指挥构建过程</p><pre><code>public class ComputerDirector {    public Computer construct(Builder builder) {        // 逐步构建复杂产品对象        Computer computer;        builder.buildBrand();        builder.buildCPU();        builder.buildDisplayCard();        builder.buildHardDisk();        builder.buildMainBoard();        builder.buildMemory();        builder.buildPower();        computer = builder.createComputer();        return computer;    }}</code></pre><p>客户端测试</p><pre><code>public class Test {    public static void main(String[] args) {        ComputerDirector director = new ComputerDirector();        Builder asusBuilder = new ASUSComputerBuilder();        Computer asusComputer = director.construct(asusBuilder);        System.out.println(asusComputer.toString());        Builder dellBuilder = new DellComputerBuilder();        Computer dellComputer = director.construct(dellBuilder);        System.out.println(dellComputer.toString());    }}</code></pre><p>输出</p><pre><code>Computer{brand=&#39;华硕电脑&#39;, cpu=&#39;Intel 第8代 酷睿&#39;, mainBoard=&#39;华硕主板&#39;, hardDisk=&#39;256GB SSD&#39;, displayCard=&#39;MX150 独立2GB&#39;, power=&#39;3芯 锂离子电池 65W AC适配器&#39;, memory=&#39;1 x SO-DIMM  8GB&#39;}Computer{brand=&#39;戴尔电脑&#39;, cpu=&#39;i5-8300H 四核&#39;, mainBoard=&#39;戴尔主板&#39;, hardDisk=&#39;1T + 128GB SSD&#39;, displayCard=&#39;GTX1060 独立6GB&#39;, power=&#39;4芯 锂离子电池 180W AC适配器&#39;, memory=&#39;4G + 4G&#39;}</code></pre><p>可以通过反射机制和配置文件配合，创建具体建造者对象</p><pre><code>public class Test {    public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException {        ComputerDirector director = new ComputerDirector();        // 从数据库或者配置文件中读取具体建造者类名        Class c = Class.forName(&quot;com.designpattern.ASUSComputerBuilder&quot;);        Builder asusBuilder = (Builder) c.newInstance();        Computer asusComputer = director.construct(asusBuilder);        System.out.println(asusComputer.toString());    }}</code></pre><p><img src="http://image.laijianfeng.org/20180911_164411.png" alt="image"></p><h3 id="建造者模式总结"><a href="#建造者模式总结" class="headerlink" title="建造者模式总结"></a>建造者模式总结</h3><p>建造者模式的<strong>主要优点</strong>如下：</p><ul><li>在建造者模式中，客户端不必知道产品内部组成的细节，将产品本身与产品的创建过程解耦，使得相同的创建过程可以创建不同的产品对象。</li><li>每一个具体建造者都相对独立，而与其他的具体建造者无关，因此可以很方便地替换具体建造者或增加新的具体建造者，用户使用不同的具体建造者即可得到不同的产品对象。由于指挥者类针对抽象建造者编程，增加新的具体建造者无须修改原有类库的代码，系统扩展方便，符合 “开闭原则”。</li><li>可以更加精细地控制产品的创建过程。将复杂产品的创建步骤分解在不同的方法中，使得创建过程更加清晰，也更方便使用程序来控制创建过程。</li></ul><p>建造者模式的<strong>主要缺点</strong>如下：</p><ul><li>建造者模式所创建的产品一般具有较多的共同点，其组成部分相似，如果产品之间的差异性很大，例如很多组成部分都不相同，不适合使用建造者模式，因此其使用范围受到一定的限制。</li><li>如果产品的内部变化复杂，可能会导致需要定义很多具体建造者类来实现这种变化，导致系统变得很庞大，增加系统的理解难度和运行成本。</li></ul><p><strong>适用场景</strong>：</p><ul><li>需要生成的产品对象有复杂的内部结构，这些产品对象通常包含多个成员属性。</li><li>需要生成的产品对象的属性相互依赖，需要指定其生成顺序。</li><li>对象的创建过程独立于创建该对象的类。在建造者模式中通过引入了指挥者类，将创建过程封装在指挥者类中，而不在建造者类和客户类中。</li><li>隔离复杂对象的创建和使用，并使得相同的创建过程可以创建不同的产品。</li></ul><h3 id="建造者模式的典型应用和源码分析"><a href="#建造者模式的典型应用和源码分析" class="headerlink" title="建造者模式的典型应用和源码分析"></a>建造者模式的典型应用和源码分析</h3><h4 id="java-lang-StringBuilder-中的建造者模式"><a href="#java-lang-StringBuilder-中的建造者模式" class="headerlink" title="java.lang.StringBuilder 中的建造者模式"></a>java.lang.StringBuilder 中的建造者模式</h4><p><code>StringBuilder</code> 的继承实现关系如下所示</p><p><img src="http://image.laijianfeng.org/20180911_172041.png" alt="StringBuilder的类图"></p><p><code>Appendable</code> 接口如下</p><pre><code>public interface Appendable {    Appendable append(CharSequence csq) throws IOException;    Appendable append(CharSequence csq, int start, int end) throws IOException;    Appendable append(char c) throws IOException;}</code></pre><p><code>StringBuilder</code> 中的 <code>append</code> 方法使用了建造者模式，不过装配方法只有一个，并不算复杂，<code>append</code> 方法返回的是 <code>StringBuilder</code> 自身</p><pre><code>public final class StringBuilder extends AbstractStringBuilder implements java.io.Serializable, CharSequence {    @Override    public StringBuilder append(String str) {        super.append(str);        return this;    }    // ...省略...}</code></pre><p><code>StringBuilder</code> 的父类 <code>AbstractStringBuilder</code> 实现了 <code>Appendable</code> 接口</p><pre><code>abstract class AbstractStringBuilder implements Appendable, CharSequence {    char[] value;    int count;    public AbstractStringBuilder append(String str) {        if (str == null)            return appendNull();        int len = str.length();        ensureCapacityInternal(count + len);        str.getChars(0, len, value, count);        count += len;        return this;    }    private void ensureCapacityInternal(int minimumCapacity) {        // overflow-conscious code        if (minimumCapacity - value.length &gt; 0) {            value = Arrays.copyOf(value,                    newCapacity(minimumCapacity));        }    }    // ...省略...}</code></pre><p>我们可以看出，<code>Appendable</code> 为抽象建造者，定义了建造方法，<code>StringBuilder</code> 既充当指挥者角色，又充当产品角色，又充当具体建造者，建造方法的实现由 <code>AbstractStringBuilder</code> 完成，而 <code>StringBuilder</code> 继承了 <code>AbstractStringBuilder</code> </p><h4 id="java-lang-StringBuffer-中的建造者方法"><a href="#java-lang-StringBuffer-中的建造者方法" class="headerlink" title="java.lang.StringBuffer 中的建造者方法"></a>java.lang.StringBuffer 中的建造者方法</h4><p>StringBuffer 继承与实现关系如下</p><p><img src="http://image.laijianfeng.org/20180911_173716.png" alt="StringBuffer的类图"></p><p>这分明就与 <code>StringBuilder</code> 一样嘛！</p><p>那它们有什么不同呢？</p><pre><code>public final class StringBuffer extends AbstractStringBuilder implements java.io.Serializable, CharSequence {    @Override    public synchronized StringBuffer append(String str) {        toStringCache = null;        super.append(str);        return this;    }    //...省略...}</code></pre><p>看 <code>StringBuffer</code> 的源码如上，它们的区别就是： <code>StringBuffer</code> 中的 <code>append</code> 加了 <code>synchronized</code> 关键字，所以<code>StringBuffer</code> 是线程安全的，而 <code>StringBuilder</code> 是非线程安全的</p><p><code>StringBuffer</code> 中的建造者模式与 <code>StringBuilder</code> 是一致的</p><h4 id="Google-Guava-中的建造者模式"><a href="#Google-Guava-中的建造者模式" class="headerlink" title="Google Guava 中的建造者模式"></a>Google Guava 中的建造者模式</h4><p><code>ImmutableSet</code> 不可变Set的主要方法如下</p><p><img src="http://image.laijianfeng.org/20180911_234124.png" alt="ImmutableSet方法列表"></p><p><code>ImmutableSet</code> 类中 <code>of</code>, <code>copyOf</code> 等方法返回的是一个 <code>ImmutableSet</code> 对象，这里是一个建造者模式，所构建的复杂产品对象为 <code>ImmutableSet</code></p><p><code>ImmutableSet</code> 的内部类 <code>ImmutableSet.Builder</code> 如下所示</p><pre><code>public static class Builder&lt;E&gt; extends ArrayBasedBuilder&lt;E&gt; {    @CanIgnoreReturnValue    public ImmutableSet.Builder&lt;E&gt; add(E... elements) {        super.add(elements);        return this;    }    @CanIgnoreReturnValue    public ImmutableSet.Builder&lt;E&gt; addAll(Iterator&lt;? extends E&gt; elements) {        super.addAll(elements);        return this;    }    public ImmutableSet&lt;E&gt; build() {        ImmutableSet&lt;E&gt; result = ImmutableSet.construct(this.size, this.contents);        this.size = result.size();        return result;    }    //...省略...}</code></pre><p>其中的 <code>add</code>、<code>addAll</code>等方法返回的是 <code>ImmutableSet.Builder</code> 对象本身，而 <code>build</code> 则返回 <code>ImmutableSet</code> 对象，所以 <code>ImmutableSet.Builder</code> 是具体建造者，<code>add</code>、<code>addAll</code>等方法则相当于<code>buildPartX()</code>，是装配过程中的一部分，<code>build</code> 方法则是 <code>getResult()</code>，返回最终创建好的复杂产品对象</p><p>ImmutableSet 使用示例如下:</p><pre><code>public class Test2 {    public static void main(String[] args) {        Set&lt;String&gt; set = ImmutableSet.&lt;String&gt;builder().add(&quot;a&quot;).add(&quot;a&quot;).add(&quot;b&quot;).build();        System.out.println(set);        // [a, b]    }}</code></pre><p>再来看一个，一般创建一个 <code>guava缓存</code> 的写法如下所示</p><pre><code>final static Cache&lt;Integer, String&gt; cache = CacheBuilder.newBuilder()        //设置cache的初始大小为10，要合理设置该值          .initialCapacity(10)        //设置并发数为5，即同一时间最多只能有5个线程往cache执行写入操作          .concurrencyLevel(5)        //设置cache中的数据在写入之后的存活时间为10秒          .expireAfterWrite(10, TimeUnit.SECONDS)        //构建cache实例          .build();</code></pre><p>这里很明显，我们不用看源码就可以知道这里是一个典型的建造者模式，<code>CacheBuilder.newBuilder()</code> 创建了一个具体建造者，<code>.initialCapacity(10)</code>、<code>.concurrencyLevel(5)</code>、<code>.expireAfterWrite(10, TimeUnit.SECONDS)</code> 则是构建过程，最终的 <code>.build()</code> 返回创建完成的复杂产品对象</p><p>看看源码是不是符合我们的猜测</p><pre><code>public final class CacheBuilder&lt;K, V&gt; {    // 创建一个具体建造者    public static CacheBuilder&lt;Object, Object&gt; newBuilder() {        return new CacheBuilder();    }    // 建造过程之一    public CacheBuilder&lt;K, V&gt; initialCapacity(int initialCapacity) {        Preconditions.checkState(this.initialCapacity == -1, &quot;initial capacity was already set to %s&quot;, this.initialCapacity);        Preconditions.checkArgument(initialCapacity &gt;= 0);        this.initialCapacity = initialCapacity;        return this;    }    // 建造过程之一    public CacheBuilder&lt;K, V&gt; concurrencyLevel(int concurrencyLevel) {        Preconditions.checkState(this.concurrencyLevel == -1, &quot;concurrency level was already set to %s&quot;, this.concurrencyLevel);        Preconditions.checkArgument(concurrencyLevel &gt; 0);        this.concurrencyLevel = concurrencyLevel;        return this;    }    // 建造过程之一    public CacheBuilder&lt;K, V&gt; expireAfterWrite(long duration, TimeUnit unit) {        Preconditions.checkState(this.expireAfterWriteNanos == -1L, &quot;expireAfterWrite was already set to %s ns&quot;, this.expireAfterWriteNanos);        Preconditions.checkArgument(duration &gt;= 0L, &quot;duration cannot be negative: %s %s&quot;, duration, unit);        this.expireAfterWriteNanos = unit.toNanos(duration);        return this;    }    // 建造完成，返回创建完的复杂产品对象    public &lt;K1 extends K, V1 extends V&gt; Cache&lt;K1, V1&gt; build() {        this.checkWeightWithWeigher();        this.checkNonLoadingCache();        return new LocalManualCache(this);    }    // ...省略...}</code></pre><p>很明显符合我们的猜测，<code>initialCapacity()</code>、<code>concurrencyLevel()</code>、<code>expireAfterWrite()</code> 等方法对传进来的参数进行处理和设置，返回 <code>CacheBuilder</code> 对象本身，<code>build</code> 则把 <code>CacheBuilder</code> 对象 作为参数，new 了一个 <code>LocalManualCache</code> 对象返回</p><h4 id="mybatis-中的建造者模式"><a href="#mybatis-中的建造者模式" class="headerlink" title="mybatis 中的建造者模式"></a>mybatis 中的建造者模式</h4><p>我们来看 <code>org.apache.ibatis.session</code> 包下的 <code>SqlSessionFactoryBuilder</code> 类</p><p><img src="http://image.laijianfeng.org/20180912_002707.png" alt="SqlSessionFactoryBuilder的方法"></p><p>里边很多重载的 <code>build</code> 方法，返回值都是 <code>SqlSessionFactory</code>，除了最后两个所有的 <code>build</code> 最后都调用下面这个 <code>build</code> 方法</p><pre><code>    public SqlSessionFactory build(Reader reader, String environment, Properties properties) {        SqlSessionFactory var5;        try {            XMLConfigBuilder parser = new XMLConfigBuilder(reader, environment, properties);            var5 = this.build(parser.parse());        } catch (Exception var14) {            throw ExceptionFactory.wrapException(&quot;Error building SqlSession.&quot;, var14);        } finally {            ErrorContext.instance().reset();            try {                reader.close();            } catch (IOException var13) {                ;            }        }        return var5;    }</code></pre><p>其中最重要的是 <code>XMLConfigBuilder</code> 的 <code>parse</code> 方法，代码如下</p><pre><code>public class XMLConfigBuilder extends BaseBuilder {    public Configuration parse() {        if (this.parsed) {            throw new BuilderException(&quot;Each XMLConfigBuilder can only be used once.&quot;);        } else {            this.parsed = true;            this.parseConfiguration(this.parser.evalNode(&quot;/configuration&quot;));            return this.configuration;        }    }    private void parseConfiguration(XNode root) {        try {            Properties settings = this.settingsAsPropertiess(root.evalNode(&quot;settings&quot;));            this.propertiesElement(root.evalNode(&quot;properties&quot;));            this.loadCustomVfs(settings);            this.typeAliasesElement(root.evalNode(&quot;typeAliases&quot;));            this.pluginElement(root.evalNode(&quot;plugins&quot;));            this.objectFactoryElement(root.evalNode(&quot;objectFactory&quot;));            this.objectWrapperFactoryElement(root.evalNode(&quot;objectWrapperFactory&quot;));            this.reflectorFactoryElement(root.evalNode(&quot;reflectorFactory&quot;));            this.settingsElement(settings);            this.environmentsElement(root.evalNode(&quot;environments&quot;));            this.databaseIdProviderElement(root.evalNode(&quot;databaseIdProvider&quot;));            this.typeHandlerElement(root.evalNode(&quot;typeHandlers&quot;));            this.mapperElement(root.evalNode(&quot;mappers&quot;));        } catch (Exception var3) {            throw new BuilderException(&quot;Error parsing SQL Mapper Configuration. Cause: &quot; + var3, var3);        }    }    // ...省略...}</code></pre><p><code>parse</code> 方法最终要返回一个 <code>Configuration</code> 对象，构建 <code>Configuration</code> 对象的建造过程都在 <code>parseConfiguration</code> 方法中，这也就是 <code>Mybatis</code> 解析 <code>XML配置文件</code> 来构建 <code>Configuration</code> 对象的主要过程</p><p>所以 <code>XMLConfigBuilder</code> 是建造者 <code>SqlSessionFactoryBuilder</code> 中的建造者，复杂产品对象分别是 <code>SqlSessionFactory</code> 和 <code>Configuration</code></p><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>设计模式 | 抽象工厂模式及典型应用</title>
      <link href="/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<h3 id="抽象工厂模式"><a href="#抽象工厂模式" class="headerlink" title="抽象工厂模式"></a>抽象工厂模式</h3><p>抽象工厂模式(Abstract Factory Pattern)：提供一个创建一系列相关或相互依赖对象的接口，而无须指定它们具体的类。抽象工厂模式又称为Kit模式，它是一种对象创建型模式。</p><p>在抽象工厂模式中，每一个具体工厂都提供了多个工厂方法用于产生多种不同类型的产品。</p><h4 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h4><p>在抽象工厂模式包含如下几个角色：</p><ul><li><strong>AbstractFactory（抽象工厂）</strong>：它声明了一组用于创建一族产品的方法，每一个方法对应一种产品。</li><li><strong>ConcreteFactory（具体工厂）</strong>：它实现了在抽象工厂中声明的创建产品的方法，生成一组具体产品，这些产品构成了一个产品族，每一个产品都位于某个产品等级结构中。</li><li><strong>AbstractProduct（抽象产品）</strong>：它为每种产品声明接口，在抽象产品中声明了产品所具有的业务方法</li><li><strong>ConcreteProduct（具体产品）</strong>：它定义具体工厂生产的具体产品对象，实现抽象产品接口中声明的业务方法。</li></ul><p>在抽象工厂中声明了多个工厂方法，用于创建不同类型的产品，抽象工厂可以是接口，也可以是抽象类或者具体类</p><p>具体工厂实现了抽象工厂，每一个具体的工厂方法可以返回一个特定的产品对象，而同一个具体工厂所创建的产品对象构成了一个产品族</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>首先定义我们的抽象产品 <code>Article</code> 和 <code>Video</code>，他们是产品族的抽象类，有一个 <code>Article</code> 就有一个 <code>Video</code></p><pre><code>public abstract class Article {    public abstract void produce();}public abstract class Video {    public abstract void produce();}</code></pre><p>具体产品 <code>JavaArticle</code>、<code>PythonArticle</code>、<code>PythonVideo</code>、<code>JavaVideo</code></p><pre><code>public class JavaArticle extends Article {    @Override    public void produce() {        System.out.println(&quot;编写Java课程笔记记&quot;);    }}public class PythonArticle extends Article {    @Override    public void produce() {        System.out.println(&quot;编写Python课程笔记&quot;);    }}public class JavaVideo extends Video {    @Override    public void produce() {        System.out.println(&quot;录制Java课程视频&quot;);    }}public class PythonVideo extends Video {    @Override    public void produce() {        System.out.println(&quot;录制Python课程视频&quot;);    }}</code></pre><p>定义我们的抽象工厂 <code>CourseFactory</code>，与工厂方法模式不同，工厂方法模式中一个工厂只生产一个产品，而抽象工厂模式中一个工厂生产一族产品，有多个工厂方法</p><pre><code>public interface CourseFactory {    Video getVideo();    Article getArticle();}</code></pre><p>具体工厂 <code>JavaCourseFactory</code> 和 <code>PythonCourseFactory</code>，它们都继承抽象工厂接口 <code>CourseFactory</code></p><pre><code>public class JavaCourseFactory implements CourseFactory {    @Override    public Video getVideo() {        return new JavaVideo();    }    @Override    public Article getArticle() {        return new JavaArticle();    }}public class PythonCourseFactory implements CourseFactory {    @Override    public Video getVideo() {        return new PythonVideo();    }    @Override    public Article getArticle() {        return new PythonArticle();    }}</code></pre><p>客户端只需要指定具体工厂，就可以获取该工厂生产的一族产品</p><pre><code>public class Test {    public static void main(String[] args) {        CourseFactory courseFactory = new JavaCourseFactory();        Video video = courseFactory.getVideo();        Article article = courseFactory.getArticle();        video.produce();        article.produce();    }}</code></pre><p>输出</p><pre><code>录制Java课程视频编写Java课程笔记</code></pre><p>也可以利用反射机制和配置文件，当需要修改具体工厂的时候就不需要修改客户端代码，只改配置文件即可</p><pre><code>public class Test {    public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException {        // 从配置文件或数据库等外部渠道获取具体工厂类名        String factoryName = &quot;com.designpattern.JavaCourseFactory&quot;;        // 通过反射机制获取工厂类        Class c = Class.forName(factoryName);        CourseFactory courseFactory = (CourseFactory) c.newInstance();        Video video = courseFactory.getVideo();        Article article = courseFactory.getArticle();        video.produce();        article.produce();    }}</code></pre><p>最终的类图如下所示</p><p><img src="http://image.laijianfeng.org/20180910_231358.png" alt="示例.抽象工厂类图"></p><h3 id="抽象工厂模式总结"><a href="#抽象工厂模式总结" class="headerlink" title="抽象工厂模式总结"></a>抽象工厂模式总结</h3><p>抽象工厂模式的<strong>主要优点</strong>如下：</p><ul><li>抽象工厂模式隔离了具体类的生成，使得客户并不需要知道什么被创建。由于这种隔离，更换一个具体工厂就变得相对容易，所有的具体工厂都实现了抽象工厂中定义的那些公共接口，因此只需改变具体工厂的实例，就可以在某种程度上改变整个软件系统的行为。</li><li>当一个产品族中的多个对象被设计成一起工作时，它能够保证客户端始终只使用同一个产品族中的对象。</li><li>增加新的产品族很方便，无须修改已有系统，符合”开闭原则”。</li></ul><p>抽象工厂模式的<strong>主要缺点</strong>如下：</p><ul><li>增加新的产品等级结构麻烦，需要对原有系统进行较大的修改，甚至需要修改抽象层代码，这显然会带来较大的不便，违背了\”开闭原则”。</li></ul><p><strong>适用场景</strong>：</p><ul><li>一个系统不应当依赖于产品类实例如何被创建、组合和表达的细节，这对于所有类型的工厂模式都是很重要的，用户无须关心对象的创建过程，将对象的创建和使用解耦。</li><li>系统中有多于一个的产品族，而每次只使用其中某一产品族。可以通过配置文件等方式来使得用户可以动态改变产品族，也可以很方便地增加新的产品族。</li><li>属于同一个产品族的产品将在一起使用，这一约束必须在系统的设计中体现出来。同一个产品族中的产品可以是没有任何关系的对象，但是它们都具有一些共同的约束，如同一操作系统下的按钮和文本框，按钮与文本框之间没有直接关系，但它们都是属于某一操作系统的，此时具有一个共同的约束条件：操作系统的类型。</li><li>产品等级结构稳定，设计完成之后，不会向系统中增加新的产品等级结构或者删除已有的产品等级结构。</li></ul><h3 id="抽象工厂模式的典型应用及源码分析"><a href="#抽象工厂模式的典型应用及源码分析" class="headerlink" title="抽象工厂模式的典型应用及源码分析"></a>抽象工厂模式的典型应用及源码分析</h3><p>我们来看 <code>java.sql</code> 包下的 <code>Connection</code> 接口，该接口定义了与特定数据库的连接 <code>Connection</code>，执行 <code>SQL statements</code> 并返回 <code>results</code></p><pre><code>public interface Connection  extends Wrapper, AutoCloseable {    Statement createStatement() throws SQLException;    PreparedStatement prepareStatement(String sql) throws SQLException;    CallableStatement prepareCall(String sql) throws SQLException;    DatabaseMetaData getMetaData() throws SQLException;    Savepoint setSavepoint() throws SQLException;    Clob createClob() throws SQLException;    Blob createBlob() throws SQLException;    SQLXML createSQLXML() throws SQLException;    // ...省略...}</code></pre><p>其中 <code>Statement</code>、<code>PreparedStatement</code>、<code>CallableStatement</code>、<code>DatabaseMetaData</code>、<code>Savepoint</code>、<code>Clob</code>、<code>Blob</code>、<code>SQLXML</code> 等均为接口</p><p>我们来看 <code>Statement</code> 接口</p><pre><code>public interface Statement extends Wrapper, AutoCloseable {    ResultSet executeQuery(String sql) throws SQLException;    int executeUpdate(String sql) throws SQLException;    void close() throws SQLException;    int getMaxFieldSize() throws SQLException;    boolean execute(String sql) throws SQLException;    // ...省略...}</code></pre><p>其中的 <code>ResultSet</code> 又是一个接口</p><pre><code>public interface ResultSet extends Wrapper, AutoCloseable {    boolean next() throws SQLException;    void close() throws SQLException;    boolean wasNull() throws SQLException;    String getString(int columnIndex) throws SQLException;    //...省略...}</code></pre><p>我们可以看一下他们的实现类</p><p><img src="http://image.laijianfeng.org/20180910_234012.png" alt="Connection的实现类"></p><p><img src="http://image.laijianfeng.org/20180910_234051.png" alt="Statement的实现类"></p><p><img src="http://image.laijianfeng.org/20180910_234121.png" alt="ResultSet的实现类"></p><p>可以看出这里边的抽象工厂模式，<code>Connection</code> 为抽象工厂，工厂方法很多，其中一个抽象产品为 <code>Statement</code>，同时 <code>Statement</code> 也是一个抽象工厂，工厂方法也很多，其中一个抽象产品为 <code>ResultSet</code>，具体工厂和具体产品则为他们的实现类</p><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析</p></blockquote><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>设计模式 | 工厂方法模式及典型应用</title>
      <link href="/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<h3 id="工厂方法模式"><a href="#工厂方法模式" class="headerlink" title="工厂方法模式"></a>工厂方法模式</h3><p>工厂方法模式(Factory Method Pattern)：定义一个用于创建对象的接口，让子类决定将哪一个类实例化。工厂方法模式让一个类的实例化延迟到其子类。</p><p>工厂方法模式又简称为工厂模式(Factory Pattern)，又可称作虚拟构造器模式(Virtual Constructor Pattern)或多态工厂模式(Polymorphic Factory Pattern)。</p><p>工厂方法模式是一种类创建型模式。</p><h4 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h4><p>在工厂方法模式结构图中包含如下几个角色：</p><p><strong>Product（抽象产品）</strong>：它是定义产品的接口，是工厂方法模式所创建对象的超类型，也就是产品对象的公共父类</p><p><strong>ConcreteProduct（具体产品）</strong>：它实现了抽象产品接口，某种类型的具体产品由专门的具体工厂创建，具体工厂和具体产品之间一一对应。</p><p><strong>Factory（抽象工厂）</strong>：在抽象工厂类中，声明了工厂方法(Factory Method)，用于返回一个产品。抽象工厂是工厂方法模式的核心，所有创建对象的工厂类都必须实现该接口。</p><p><strong>ConcreteFactory（具体工厂）</strong>：它是抽象工厂类的子类，实现了抽象工厂中定义的工厂方法，并可由客户端调用，返回一个具体产品类的实例。</p><p>与简单工厂模式相比，工厂方法模式最重要的区别是引入了抽象工厂角色，抽象工厂可以是接口，也可以是抽象类或者具体类</p><h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><p>抽象产品类 Video</p><pre><code>public abstract class Video {    public abstract void produce();}</code></pre><p>具体产品类 JavaVideo 和 PythonVideo，需要继承抽象产品类 Video</p><pre><code>public class JavaVideo extends Video {    @Override    public void produce() {        System.out.println(&quot;录制Java课程视频&quot;);    }}public class PythonVideo extends Video {    @Override    public void produce() {        System.out.println(&quot;录制Python课程视频&quot;);    }}</code></pre><p>抽象工厂类 VideoFactory</p><pre><code>public abstract class VideoFactory {    public abstract Video getVideo();}</code></pre><p>具体工厂类 JavaVideoFactory 和 PythonVideoFactory，需要继承抽象工厂类 VideoFactory</p><pre><code>public class JavaVideoFactory extends VideoFactory {    @Override    public Video getVideo() {        return new JavaVideo();    }}public class PythonVideoFactory extends VideoFactory {    @Override    public Video getVideo() {        return new PythonVideo();    }}</code></pre><p>客户端类，需要什么产品则通过该产品对应的工厂类来获取，不需要知道具体的创建过程</p><pre><code>public class Test {    public static void main(String[] args) {        VideoFactory pythonVideoFactory = new PythonVideoFactory();        VideoFactory javaVideoFactory = new JavaVideoFactory();        Video pythonVideo = pythonVideoFactory.getVideo();        pythonVideo.produce();        Video javaVideo = javaVideoFactory.getVideo();        javaVideo.produce();    }}</code></pre><p>输出</p><pre><code>录制Python课程视频录制Java课程视频</code></pre><p>当需要增加一个产品 FEVideo 时，只需要增加 FEVideo 具体产品类和 FEVideoFactory 具体工厂类即可，不需要修改原有的产品类和工厂类</p><pre><code>public class FEVideo extends Video{    @Override    public void produce() {        System.out.println(&quot;录制FE课程视频&quot;);    }}public class FEVideoFactory extends VideoFactory{    @Override    public Video getVideo() {        return new FEVideo();    }}</code></pre><p>修改客户端代码</p><pre><code>public class Test {    public static void main(String[] args) {        VideoFactory feVideoFactory = new FEVideoFactory();        Video feVideo = feVideoFactory.getVideo();        feVideo.produce();    }}</code></pre><p>还可以通过反射机制和配置文件配合，连客户端代码都不需要修改</p><pre><code>public class Test {    public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException {        // 从文件或数据库等外部渠道获取 工厂类名        String factoryName = &quot;com.designpattern.factorymethod.JavaVideoFactory&quot;;        // 通过反射机制获取工厂类        Class c = Class.forName(factoryName);        VideoFactory factory = (VideoFactory)c.newInstance();        // 生产产品        Video video = factory.getVideo();        video.produce();    }}</code></pre><p>最终的类图如下所示</p><p><img src="http://image.laijianfeng.org/20180908_223324.png" alt="示例.工厂方法结构图"></p><h3 id="工厂方法模式总结"><a href="#工厂方法模式总结" class="headerlink" title="工厂方法模式总结"></a>工厂方法模式总结</h3><p>工厂方法模式是简单工厂模式的延伸，它继承了简单工厂模式的优点，同时还弥补了简单工厂模式的不足。工厂方法模式是使用频率最高的设计模式之一，是很多开源框架和API类库的核心模式。</p><h4 id="工厂方法模式的主要优点"><a href="#工厂方法模式的主要优点" class="headerlink" title="工厂方法模式的主要优点"></a>工厂方法模式的主要优点</h4><ul><li>在工厂方法模式中，工厂方法用来创建客户所需要的产品，同时还向客户隐藏了哪种具体产品类将被实例化这一细节，用户只需要关心所需产品对应的工厂，无须关心创建细节，甚至无须知道具体产品类的类名。</li><li>基于工厂角色和产品角色的多态性设计是工厂方法模式的关键。它能够让工厂可以自主确定创建何种产品对象，而如何创建这个对象的细节则完全封装在具体工厂内部。工厂方法模式之所以又被称为多态工厂模式，就正是因为所有的具体工厂类都具有同一抽象父类。</li><li>使用工厂方法模式的另一个优点是在系统中加入新产品时，无须修改抽象工厂和抽象产品提供的接口，无须修改客户端，也无须修改其他的具体工厂和具体产品，而只要添加一个具体工厂和具体产品就可以了，这样，系统的可扩展性也就变得非常好，完全符合”开闭原则”。</li></ul><h4 id="工厂方法模式的主要缺点"><a href="#工厂方法模式的主要缺点" class="headerlink" title="工厂方法模式的主要缺点"></a>工厂方法模式的主要缺点</h4><ul><li>在添加新产品时，需要编写新的具体产品类，而且还要提供与之对应的具体工厂类，系统中类的个数将成对增加，在一定程度上增加了系统的复杂度，有更多的类需要编译和运行，会给系统带来一些额外的开销。</li><li>由于考虑到系统的可扩展性，需要引入抽象层，在客户端代码中均使用抽象层进行定义，增加了系统的抽象性和理解难度，且在实现时可能需要用到DOM、反射等技术，增加了系统的实现难度。</li></ul><h4 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h4><ul><li>客户端不知道它所需要的对象的类。在工厂方法模式中，客户端不需要知道具体产品类的类名，只需要知道所对应的工厂即可，具体的产品对象由具体工厂类创建，可将具体工厂类的类名存储在配置文件或数据库中。</li><li>抽象工厂类通过其子类来指定创建哪个对象。在工厂方法模式中，对于抽象工厂类只需要提供一个创建产品的接口，而由其子类来确定具体要创建的对象，利用面向对象的多态性和里氏代换原则，在程序运行时，子类对象将覆盖父类对象，从而使得系统更容易扩展。</li></ul><h3 id="工厂方法模式的典型应用及源码分析"><a href="#工厂方法模式的典型应用及源码分析" class="headerlink" title="工厂方法模式的典型应用及源码分析"></a>工厂方法模式的典型应用及源码分析</h3><h4 id="Java集合接口-Collection-中的工厂方法模式"><a href="#Java集合接口-Collection-中的工厂方法模式" class="headerlink" title="Java集合接口 Collection 中的工厂方法模式"></a>Java集合接口 Collection 中的工厂方法模式</h4><p>Collection 中的 iterator 方法如下：</p><pre><code>public interface Collection&lt;E&gt; extends Iterable&lt;E&gt; {    Iterator&lt;E&gt; iterator();    // ...省略}</code></pre><blockquote><p>关于 iterator 方法的介绍：<br>Java的迭代器只在Collection中有，而Map没有迭代器，它有不同的迭代方法；<br> <strong>迭代器的终极目标</strong>：就是用统一的方法来迭代不同类型的集合！可能由于不同集合的内部数据结构不尽相同，如果要自己纯手工迭代的话相互之间会有很大的差别，而迭代器的作用就是统一的方法对不同的集合进行迭代，而在迭代器底层隐藏不同集合之间的差异，从而为迭代提供最大的方便<br><strong>使用用迭代器迭代的步骤</strong>： i. 第一步肯定是先获取集合的迭代器：调用集合的iterator方法就能获得，Iterator<e> Collection.iterator(); ii. 使用迭代器的hasNext、next往下迭代<br><strong>Iterator的常用方法</strong>：boolean hasNext()：是否还有下一个元素； Object next()：取出下一个元素并返回； void remove(); ：从容器中删除当前元素，直接会改变容器中的数据</e></p></blockquote><p>查看该接口的实现类，可以看到是非常的多</p><p><img src="http://image.laijianfeng.org/20180908_230822.png" alt="Collection接口的实现类(部分)"></p><p>我们仅看其中一个实现类 <code>java.util.ArrayList</code>，看其对 <code>iterator</code> 方法的实现</p><pre><code>public Iterator&lt;E&gt; iterator() {    return new Itr();}/** * An optimized version of AbstractList.Itr */private class Itr implements Iterator&lt;E&gt; {    int cursor;       // index of next element to return    int lastRet = -1; // index of last element returned; -1 if no such    int expectedModCount = modCount;    Itr() {}    public boolean hasNext() {        return cursor != size;    }    @SuppressWarnings(&quot;unchecked&quot;)    public E next() {        // ...省略...    }    public void remove() {        // ...省略...    }    @Override    @SuppressWarnings(&quot;unchecked&quot;)    public void forEachRemaining(Consumer&lt;? super E&gt; consumer) {        // ...省略...    }    final void checkForComodification() {        // ...省略...    }}</code></pre><p><code>Itr</code> 类实现了 <code>iterator</code> 接口，<code>iterator</code> 接口正是 <code>Collection</code> 接口中 <code>iterator</code> 方法的返回类型，其代码如下：</p><pre><code>public interface Iterator&lt;E&gt; {    boolean hasNext();    E next();    default void remove() {        throw new UnsupportedOperationException(&quot;remove&quot;);    }    default void forEachRemaining(Consumer&lt;? super E&gt; action) {        Objects.requireNonNull(action);        while (hasNext())            action.accept(next());    }}</code></pre><p><strong>由此可见</strong>，<code>Collection</code> 接口扮演了抽象工厂角色，工厂方法为 <code>iterator()</code>，<code>Collection</code> 的实现类譬如 <code>ArrayList</code> 扮演了具体工厂角色，而抽象产品为 <code>Iterator</code> 接口，具体产品为 <code>Itr</code> 类</p><h4 id="java-net-网络包中的工厂方法模式"><a href="#java-net-网络包中的工厂方法模式" class="headerlink" title="java.net 网络包中的工厂方法模式"></a>java.net 网络包中的工厂方法模式</h4><p>URLStreamHandlerFactory 接口为 URL 流协议处理程序定义一个工厂。URL 类使用它可为特定的协议创建 URLStreamHandler</p><pre><code>public interface URLStreamHandlerFactory {    /**     * Creates a new {@code URLStreamHandler} instance with the specified protocol.     *     * @param   protocol   the protocol (&quot;{@code ftp}&quot;, &quot;{@code http}&quot;, &quot;{@code nntp}&quot;, etc.).     * @return  a {@code URLStreamHandler} for the specific protocol.     * @see     java.net.URLStreamHandler     */    URLStreamHandler createURLStreamHandler(String protocol);}</code></pre><p>该接口的实现类为 <code>sun.misc.Launcher</code> 中的内部类 <code>Factory</code></p><pre><code>private static class Factory implements URLStreamHandlerFactory {    private static String PREFIX = &quot;sun.net.www.protocol&quot;;    private Factory() {    }    public URLStreamHandler createURLStreamHandler(String var1) {        String var2 = PREFIX + &quot;.&quot; + var1 + &quot;.Handler&quot;;        try {            Class var3 = Class.forName(var2);            return (URLStreamHandler)var3.newInstance();        } catch (ReflectiveOperationException var4) {            throw new InternalError(&quot;could not load &quot; + var1 + &quot;system protocol handler&quot;, var4);        }    }}</code></pre><p>可以看到 <code>createURLStreamHandler</code> 方法的实现为：传入参数，拼接前缀和后缀，之后通过反射机制获取创建一个 <code>URLStreamHandler</code> 对象</p><p><code>URLStreamHandler</code> 是一个抽象类，其中的方法如下图，只有 <code>openConnection</code> 为抽象方法，其他方法均有具体实现</p><p><img src="http://image.laijianfeng.org/20180908_235350.png" alt="URLStreamHandler抽象类中的方法"></p><blockquote><p>关于URLStreamHandler:<br>抽象类URLStreamHandler是所有流协议处理程序的通用超类。 流协议处理程序知道如何为特定协议类型建立连接，例如http或https</p></blockquote><p>其子类有如下(19个)：</p><p><img src="http://image.laijianfeng.org/20180908_234100.png" alt="URLStreamHandler的子类"></p><p>查看其中一个子类譬如 <code>sun.net.www.protocol.http.Handler</code></p><pre><code>public class Handler extends URLStreamHandler {    protected String proxy;    protected int proxyPort;    protected int getDefaultPort() {        return 80;    }    public Handler() {        this.proxy = null;        this.proxyPort = -1;    }    public Handler(String var1, int var2) {        this.proxy = var1;        this.proxyPort = var2;    }    protected URLConnection openConnection(URL var1) throws IOException {        return this.openConnection(var1, (Proxy)null);    }    protected URLConnection openConnection(URL var1, Proxy var2) throws IOException {        return new HttpURLConnection(var1, var2, this);    }}</code></pre><p>该类实现的 <code>openConnection</code> 方法的返回值类型为 <code>URLConnection</code>，最终返回了一个 <code>HttpURLConnection</code> 对象</p><p>我们又继续看 <code>java.net.URLConnection</code>，这也是一个抽象类</p><p><img src="http://image.laijianfeng.org/20180909_001513.png" alt="image"></p><blockquote><p><strong>URLConnection介绍</strong>：   </p><ul><li>URLConnection是一个功能强大的抽象类，它表示指向URL指定资源的活动连接。<br>与URL类相比，它与服务器的交互提供了更多的控制机制。尤其服务器是HTTP服务器，可以使用URLConnection对HTTP首部的访问，可以配置发送给服务器的请求参数。当然也可以通过它读取服务器的数据以及向服务器写入数据.   </li><li>URLConnection是Java的协议处理器机制的一部分。协议处理器机制是将处理协议的细节与特定数据类型分开。如果要实现一个特定的协议，则实现URLConnection的子类即可。程序运行时可以将该子类作为一个具体的协议处理器来使用。   </li><li><strong>使用URLConnection类的步骤</strong>：1.  构造一个URL对象；2. 调用该URL的openConnection()获取一个URLConnection；3. 配置这个URLConnection；4. 读取首部字段；5. 获得输入流并读取数据；6. 获得输出流并写入数据；7. 关闭连接</li></ul></blockquote><p>其子类有23个</p><p><img src="http://image.laijianfeng.org/20180909_001308.png" alt="image"></p><p>我们可以画出他们的关系图如下所示</p><p><img src="http://image.laijianfeng.org/20180909_164345.png" alt="URLConnection关系图"></p><p><strong>由此可知</strong>：抽象工厂角色为 <code>URLStreamHandlerFactory</code>，工厂方法为 <code>createURLStreamHandler</code>，抽象产品角色为 <code>URLStreamHandler</code>，具体产品角色为 <code>URLStreamHandler</code> 的子类譬如 <code>sun.net.www.protocol.http.Handler</code>、<code>sun.net.www.protocol.ftp.Handler</code> 等</p><p><strong>同时</strong>，<code>URLStreamHandler</code> 也扮演了抽象工厂角色，工厂方法为 <code>openConnection</code>，<code>URLStreamHandler</code> 的子类譬如 <code>sun.net.www.protocol.http.Handler</code> 也扮演了具体工厂角色，抽象产品为 <code>URLConnection</code>，具体产品角色为  <code>URLConnection</code> 的子类如 <code>sun.net.www.protocol.http.HttpURLConnection</code> 等</p><h4 id="Logback-中的工厂方法模式"><a href="#Logback-中的工厂方法模式" class="headerlink" title="Logback 中的工厂方法模式"></a>Logback 中的工厂方法模式</h4><p>在上一篇文章《<a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483700&amp;idx=1&amp;sn=dd4d23f9400c8be248f5d125465ba941&amp;chksm=e9c2ed39deb5642fb809eca1351f00995f06c9a4875f09986cc5005059eff74d6c20fc1118a3&amp;scene=0#rd" target="_blank" rel="noopener">设计模式 | 简单工厂模式及典型应用</a>》 介绍的 Logback 里有简单工厂模式，其实也有工厂方法模式，画图如下</p><p><img src="http://image.laijianfeng.org/20180909_170301.png" alt="iLoggerFactory类关系"></p><p><strong>可以看出</strong>，抽象工厂角色为 <code>ILoggerFactory</code> 接口，工厂方法为 <code>getLogger</code>，具体工厂角色为 <code>LoggerContext</code>、<code>NOPLoggerFactory</code>、<code>SubstituteLoggerFactory</code> 等，抽象产品角色为 <code>Logger</code>，具体产品角色为 <code>Logger</code> 的实现类如下</p><p><img src="http://image.laijianfeng.org/20180909_171112.png" alt="Logger 的实现类"></p><p>而简单工厂模式应用在 <code>LoggerContext</code> 的  <code>getLogger</code> 方法中，根据参数返回相应的 <code>Logger</code> 对象</p><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析</p></blockquote><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>设计模式 | 简单工厂模式及典型应用</title>
      <link href="/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/"/>
      <url>/2018/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>设计模式(Design Pattern)是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结，使用设计模式是为了可重用代码、让代码更容易被他人<br>理解并且保证代码可靠性。</p><p>本文主要介绍简单工厂模式及典型应用，内容如下：</p><ul><li>简单工厂模式的介绍</li><li>简单工厂模式的典型应用及源码分析<ul><li>Calendar 类获取日历类对象</li><li>JDBC 获取数据库连接</li><li>LoggerFactory 获取 Logger 对象</li></ul></li></ul><h3 id="简单工厂模式"><a href="#简单工厂模式" class="headerlink" title="简单工厂模式"></a>简单工厂模式</h3><p>工厂模式是最常用的一类创建型设计模式，包括 抽象工厂模式，工厂方法模式和简单工厂模式 这三种，简单工厂模式是其中最简单的一种</p><p>简单工厂模式(Simple Factory Pattern)：定义一个工厂类，它可以<strong>根据参数的不同</strong>返回不同类的实例，被创建的实例通常都具有共同的父类。</p><p>因为在简单工厂模式中用于创建实例的方法是静态(static)方法，因此简单工厂模式又被称为静态工厂方法(Static Factory Method)模式，它属于类创建型模式，但不属于GOF23种设计模式</p><h4 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h4><p><strong>Factory（工厂角色）</strong>：工厂角色即工厂类，它是<strong>简单工厂模式的核心</strong>，负责实现创建所有产品实例的内部逻辑；工厂类可以被外界直接调用，创建所需的产品对象；在工厂类中提供了静态的工厂方法factoryMethod()，它的返回类型为抽象产品类型Product</p><p><strong>Product（抽象产品角色）</strong>：它是工厂类所创建的所有对象的父类，封装了各种产品对象的公有方法，它的引入将提高系统的灵活性，使得在工厂类中只需定义一个通用的工厂方法，因为所有创建的具体产品对象都是其子类对象。</p><p><strong>ConcreteProduct（具体产品角色）</strong>：它是简单工厂模式的创建目标，所有被创建的对象都充当这个角色的某个具体类的实例。每一个具体产品角色都继承了抽象产品角色，需要实现在抽象产品中声明的抽象方法</p><p>在简单工厂模式中，客户端通过工厂类来创建一个产品类的实例，而无须直接使用new关键字来创建对象，它是工厂模式家族中最简单的一员</p><h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><p>抽象产品类 Video，定义了抽象方法 produce()</p><pre><code>public abstract class Video {    public abstract void produce();}</code></pre><p>具体产品类 JavaVideo 和 PythonVideo，都继承了抽象产品类 Video</p><pre><code>public class JavaVideo extends Video {    @Override    public void produce() {        System.out.println(&quot;录制Java课程视频&quot;);    }}public class PythonVideo extends Video {    @Override    public void produce() {        System.out.println(&quot;录制Python课程视频&quot;);    }}</code></pre><p>工厂类实现的两种方法：使用<code>if-else</code>判断和使用反射来创建对象</p><pre><code>public class VideoFactory {    /**     * 使用if else 判断类型，type 为 Java 则返回 JavaVideo， type为Python则返回 PythonVideo     */    public Video getVideo(String type) {        if (&quot;java&quot;.equalsIgnoreCase(type)) {            return new JavaVideo();        } else if (&quot;python&quot;.equalsIgnoreCase(type)) {            return new PythonVideo();        }        return null;    }    /**     * 使用反射来创建对象     */    public Video getVideo(Class c) {        Video video = null;        try {            video = (Video) Class.forName(c.getName()).newInstance();        } catch (InstantiationException e) {            e.printStackTrace();        } catch (IllegalAccessException e) {            e.printStackTrace();        } catch (ClassNotFoundException e) {            e.printStackTrace();        }        return video;    }}</code></pre><p>使用一个客户端来调用工厂类</p><pre><code>public class Test {    public static void main(String[] args) {        VideoFactory videoFactory = new VideoFactory();        Video video1 = videoFactory.getVideo(&quot;python&quot;);        if (video1 == null) {            return;        }        video1.produce();        Video video2 = videoFactory.getVideo(JavaVideo.class);        if (video2 == null) {            return;        }        video2.produce();    }}</code></pre><p>输出</p><pre><code>录制Python课程视频录制Java课程视频</code></pre><p><img src="http://image.laijianfeng.org/20180907_211234.png" alt="示例.简单工厂模式类图"></p><p>Test 类通过传递参数给 <code>VideoFactory.getVideo()</code> 来获取对象，创建对象的逻辑交给了工厂类 <code>VideoFactory</code> 来完成</p><h4 id="简单工厂模式总结"><a href="#简单工厂模式总结" class="headerlink" title="简单工厂模式总结"></a>简单工厂模式总结</h4><p>简单工厂模式的<strong>主要优点</strong>如下：</p><ul><li>工厂类包含必要的判断逻辑，可以决定在什么时候创建哪一个产品类的实例，客户端可以免除直接创建产品对象的职责，而仅仅“消费”产品，简单工厂模式实现了对象创建和使用的分离。</li><li>客户端无须知道所创建的具体产品类的类名，只需要知道具体产品类所对应的参数即可，对于一些复杂的类名，通过简单工厂模式可以在一定程度减少使用者的记忆量。</li><li>通过引入配置文件，可以在不修改任何客户端代码的情况下更换和增加新的具体产品类，在一定程度上提高了系统的灵活性。</li></ul><p>简单工厂模式的<strong>主要缺点</strong>如下：</p><ul><li>由于工厂类集中了所有产品的创建逻辑，职责过重，一旦不能正常工作，整个系统都要受到影响。</li><li>使用简单工厂模式势必会增加系统中类的个数（引入了新的工厂类），增加了系统的复杂度和理解难度。</li><li>系统扩展困难，一旦添加新产品就不得不修改工厂逻辑，在产品类型较多时，有可能造成工厂逻辑过于复杂，不利于系统的扩展和维护，且违背开闭原则。</li><li>简单工厂模式由于使用了静态工厂方法，造成工厂角色无法形成基于继承的等级结构。</li></ul><p><strong>适用场景</strong>：</p><ul><li>工厂类负责创建的对象比较少，由于创建的对象较少，不会造成工厂方法中的业务逻辑太过复杂。</li><li>客户端只知道传入工厂类的参数，对于如何创建对象并不关心。</li></ul><h3 id="简单工厂模式的典型应用及源码分析"><a href="#简单工厂模式的典型应用及源码分析" class="headerlink" title="简单工厂模式的典型应用及源码分析"></a>简单工厂模式的典型应用及源码分析</h3><h4 id="Calendar-类获取日历类对象"><a href="#Calendar-类获取日历类对象" class="headerlink" title="Calendar 类获取日历类对象"></a>Calendar 类获取日历类对象</h4><p><code>Calendar</code> 抽象类，该类的子类有 <code>BuddhistCalendar</code>、<code>JapaneseImperialCalendar</code>、<code>GregorianCalendar</code>、<code>RollingCalendar</code>等</p><p><code>getInstance</code>方法，根据参数获取一个<code>Calendar</code>子类对象，该方法实际将参数传给 <code>createCalendar</code> 方法，<code>createCalendar</code> 在根据参数通过 <code>provider</code> 或 <code>switch</code> 或者 <code>if-else</code> 创建相应的子类对象</p><p>以下为 Java8 中的 <code>Calendar</code> 类代码，Java7 中的实现为 <code>if-else</code> 方式</p><pre><code>public static Calendar getInstance(TimeZone zone, Locale aLocale) {    return createCalendar(zone, aLocale);}private static Calendar createCalendar(TimeZone zone, Locale aLocale) {    CalendarProvider provider = LocaleProviderAdapter.getAdapter(CalendarProvider.class, aLocale).getCalendarProvider();    if (provider != null) {        try {            return provider.getInstance(zone, aLocale);        } catch (IllegalArgumentException iae) {        }    }    Calendar cal = null;    if (aLocale.hasExtensions()) {        String caltype = aLocale.getUnicodeLocaleType(&quot;ca&quot;);        if (caltype != null) {            switch (caltype) {                case &quot;buddhist&quot;:                    cal = new BuddhistCalendar(zone, aLocale); break;                case &quot;japanese&quot;:                    cal = new JapaneseImperialCalendar(zone, aLocale); break;                case &quot;gregory&quot;:                    cal = new GregorianCalendar(zone, aLocale); break;            }        }    }    if (cal == null) {        if (aLocale.getLanguage() == &quot;th&quot; &amp;&amp; aLocale.getCountry() == &quot;TH&quot;) {            cal = new BuddhistCalendar(zone, aLocale);        } else if (aLocale.getVariant() == &quot;JP&quot; &amp;&amp; aLocale.getLanguage() == &quot;ja&quot; &amp;&amp; aLocale.getCountry() == &quot;JP&quot;) {            cal = new JapaneseImperialCalendar(zone, aLocale);        } else {            cal = new GregorianCalendar(zone, aLocale);        }    }    return cal;}</code></pre><p><img src="http://image.laijianfeng.org/20180907_213426.png" alt="Calendar的继承关系"></p><p>可以看到<code>抽象产品角色</code>和<code>工厂角色</code>都由  <code>Calendar</code> 担任，<code>具体产品角色</code>由 <code>Calendar</code> 的子类担任</p><h4 id="JDBC-获取数据库连接"><a href="#JDBC-获取数据库连接" class="headerlink" title="JDBC 获取数据库连接"></a>JDBC 获取数据库连接</h4><p>一般JDBC获取MySQL连接的写法如下：</p><pre><code>//加载MySql驱动Class.forName(&quot;com.mysql.jdbc.Driver&quot;);DriverManager.getConnection(&quot;jdbc:mysql://127.0.0.1:3306/test&quot;, &quot;root&quot;, &quot;123456&quot;);</code></pre><p>首先通过反射加载驱动类 <code>com.mysql.jdbc.Driver</code> 类，然后再通过 <code>DriverManager</code> 获取连接</p><p>看看 <code>com.mysql.jdbc.Driver</code> 的代码，该类主要的内容是静态代码块，其会随着类的加载一块执行</p><pre><code>public class Driver extends NonRegisteringDriver implements java.sql.Driver {    public Driver() throws SQLException {    }    static {        try {            DriverManager.registerDriver(new Driver());        } catch (SQLException var1) {            throw new RuntimeException(&quot;Can&#39;t register driver!&quot;);        }    }}</code></pre><p>静态代码块：new 一个 <code>Driver</code> 类并注册到 <code>DriverManager</code> 驱动管理类中</p><pre><code>public static synchronized void registerDriver(java.sql.Driver driver, DriverAction da) throws SQLException {    /* Register the driver if it has not already been added to our list */    if(driver != null) {        registeredDrivers.addIfAbsent(new DriverInfo(driver, da));    } else {        throw new NullPointerException();    }    println(&quot;registerDriver: &quot; + driver);}</code></pre><p>其中的 <code>registeredDrivers</code> 是一个 <code>CopyOnWriteArrayList</code> 对象</p><pre><code>private final static CopyOnWriteArrayList&lt;DriverInfo&gt; registeredDrivers = new CopyOnWriteArrayList&lt;&gt;();</code></pre><blockquote><p>CopyOnWriteArrayList是Java并发包中提供的一个并发容器，它是个线程安全且读操作无锁的ArrayList，写操作则通过创建底层数组的新副本来实现，是一种读写分离的并发策略，我们也可以称这种容器为”写时复制器”，Java并发包中类似的容器还有CopyOnWriteSet<br>一篇CopyOnWriteArrayList的文章：<a href="https://www.cnblogs.com/chengxiao/p/6881974.html" target="_blank" rel="noopener">https://www.cnblogs.com/chengxiao/p/6881974.html</a></p></blockquote><p>再通过 <code>DriverManager.getConnection</code> 获取连接对象的主要代码如下：通过for循环从已注册的驱动中(registeredDrivers)获取驱动，尝试连接，成功则返回连接</p><pre><code>private static Connection getConnection(String url, java.util.Properties info, Class&lt;?&gt; caller) throws SQLException {    // ...省略...    println(&quot;DriverManager.getConnection(\&quot;&quot; + url + &quot;\&quot;)&quot;);    for(DriverInfo aDriver : registeredDrivers) {        // If the caller does not have permission to load the driver then skip it.        if(isDriverAllowed(aDriver.driver, callerCL)) {            try {                println(&quot;    trying &quot; + aDriver.driver.getClass().getName());                Connection con = aDriver.driver.connect(url, info);                if (con != null) {                    // Success!                    println(&quot;getConnection returning &quot; + aDriver.driver.getClass().getName());                    return (con);                }            } catch (SQLException ex) {                if (reason == null) {                    reason = ex;                }            }        } else {            println(&quot;    skipping: &quot; + aDriver.getClass().getName());        }    }    // ...省略...}</code></pre><p><img src="http://image.laijianfeng.org/20180907_225826.png" alt="Connection 接口及子类实现关系"></p><p>工厂角色为 <code>DriverManager</code> 类，抽象产品角色为 <code>Connection</code>，具体产品角色则很多</p><h4 id="Logback-中的-LoggerFactory-获取-Logger-对象"><a href="#Logback-中的-LoggerFactory-获取-Logger-对象" class="headerlink" title="Logback 中的 LoggerFactory 获取 Logger 对象"></a>Logback 中的 LoggerFactory 获取 Logger 对象</h4><p>查看 <code>LoggerFactory</code> 类的 <code>getLogger</code> 方法，可看到调用了 <code>iLoggerFactory.getLogger()</code>，其中 <code>iLoggerFactory</code> 是一个接口</p><pre><code>public static Logger getLogger(String name) {    ILoggerFactory iLoggerFactory = getILoggerFactory();    return iLoggerFactory.getLogger(name);}public static Logger getLogger(Class clazz) {    return getLogger(clazz.getName());}</code></pre><p><code>iLoggerFactory</code> 接口只有一个 <code>getLogger</code> 方法</p><pre><code>public interface ILoggerFactory {    Logger getLogger(String var1);}</code></pre><p>查看其子类依赖关系</p><p><img src="http://image.laijianfeng.org/20180907_223038.png" alt="iLoggerFactory接口子类的依赖关系"></p><p>再看一个子类 <code>LoggerContext</code> 对 ILoggerFactory 的实现</p><p><img src="http://image.laijianfeng.org/20180907_222610.png" alt="image"></p><p>可看到这是通过 <code>if-else</code> 方式的简单工厂模式</p><p><img src="http://image.laijianfeng.org/20180907_230131.png" alt="Logger 接口及子类实现关系"></p><p>工厂角色为 <code>iLoggerFactory</code> 接口的子类如 <code>LoggerContext</code>，抽象产品角色为 <code>Logger</code>，具体产品角色为 <code>Logger</code> 的子类，主要是 <code>NOPLogger</code> 和 <code>Logger</code> 类</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>下一篇介绍工厂方法及典型应用</p><blockquote><p>参考：<br>刘伟：设计模式Java版<br>慕课网java设计模式精讲 Debug 方式+内存分析</p></blockquote><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Elasticsearch 6.3.2 启动过程</title>
      <link href="/2018/09/Elasticsearch-6-3-2-%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/"/>
      <url>/2018/09/Elasticsearch-6-3-2-%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/</url>
      <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本文探究Elasticsearch 6.3.2的启动流程</p><h4 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h4><p>使用工具：IDEA，XMind</p><p>关于ES调试环境的搭建，可以参考前面的文章 《<a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483676&amp;idx=1&amp;sn=1d88a883ce21d7dcacd073a8fa85dbfc&amp;chksm=e9c2ed11deb56407879ba0b22a4ef96916f8a9e7931e1efb99df57991966a3dc475eb3e23101&amp;mpshare=1&amp;scene=1&amp;srcid=0901DM6ZqcQqSqyujfIApsDj#rd" target="_blank" rel="noopener">教你编译调试Elasticsearch 6.3.2源码</a>》</p><p>然后通过设置断点，从 <code>org.elasticsearch.bootstrap.ElasticSearch</code> 的入口函数开始，一步一步调试</p><p><img src="http://image.laijianfeng.org/20180901_131938.png" alt="IDEA 2018.2 调试按钮"></p><p>上图为使用 IDEA 2018.2 进行调试的一个截图，左上角84行出红点为一个断点，1、2、3编号的3个按钮是较为常用的按钮，作用如下：</p><ul><li>按钮1：step over，执行到下一行，遇到方法<strong>不进入</strong>方法内部</li><li>按钮2：step into，执行到下一句代码，遇到方法则<strong>进入</strong>方法内部</li><li>按钮3：Run to cursor，执行到下一个断点处，后面没有断点则执行到结束</li></ul><h4 id="通过XMind记录ES启动流程的整个过程"><a href="#通过XMind记录ES启动流程的整个过程" class="headerlink" title="通过XMind记录ES启动流程的整个过程"></a>通过XMind记录ES启动流程的整个过程</h4><p><img src="http://image.laijianfeng.org/ES_startup_process.jpg" alt="ES 6.3.2 启动流程"></p><p>根据上图，作者大概地把ES启动流程分为四个阶段：</p><ul><li>Elasticsearch 解析 Command，加载配置</li><li>Bootstrap 初始化，资源检查</li><li>Node 创建节点</li><li>Bootstrap 启动节点和保活线程</li></ul><h3 id="Elasticsearch-解析-Command，加载配置"><a href="#Elasticsearch-解析-Command，加载配置" class="headerlink" title="Elasticsearch 解析 Command，加载配置"></a>Elasticsearch 解析 Command，加载配置</h3><p>首先可以看一下入口方法 <code>Elasticsearch.main</code>：</p><pre><code>    public static void main(final String[] args) throws Exception {        System.setSecurityManager(new SecurityManager() {            @Override            public void checkPermission(Permission perm) {                // grant all permissions so that we can later set the security manager to the one that we want            }        });        LogConfigurator.registerErrorListener();        final Elasticsearch elasticsearch = new Elasticsearch();        int status = main(args, elasticsearch, Terminal.DEFAULT);        if (status != ExitCodes.OK) {            exit(status);        }    }</code></pre><p>1.1, 创建 SecurityManager 安全管理器</p><blockquote><p>关于 SecurityManager:<br>安全管理器在Java语言中的作用就是<strong>检查操作是否有权限执行</strong>，通过则顺序进行，否则抛出一个异常<br>网上一篇文章：<a href="https://blog.csdn.net/wwwdc1012/article/details/82287474" target="_blank" rel="noopener">Java安全——安全管理器、访问控制器和类装载器</a></p></blockquote><p>1.2, LogConfigurator.registerErrorListener() 注册侦听器</p><p>1.3, 创建Elasticsearch对象</p><p>Elasticsearch 入口类的继承关系如下：</p><p><img src="http://image.laijianfeng.org/20180901_143515.png" alt="Elasticsearch 入口类的继承关系"></p><p>可以看到Elasticsearch继承了EnvironmentAwareCommand，Command，这几个类的功能简要介绍如下：</p><ul><li>Elasticsearch: This class starts elasticsearch.</li><li>EnvironmentAwareCommand: A cli command which requires an <code>org.elasticsearch.env.Environment</code> to use current paths and settings</li><li>Command: An action to execute within a cli.</li></ul><p>可以看出Elasticsearch的一个重要作用是解析命令参数</p><p>执行带 <code>-h</code> 参数的Elasticsearch启动命令</p><p><img src="http://image.laijianfeng.org/20180901_144410.png" alt="带参数的Elasticsearch启动命令"></p><p>可以发现这几个参数与 Cammand 类 和 Elasticsearch 的几个私有变量是对应的</p><p>Elasticsearch的构造函数如下：</p><pre><code>Elasticsearch() {    super(&quot;starts elasticsearch&quot;, () -&gt; {}); // we configure logging later so we override the base class from configuring logging    versionOption = parser.acceptsAll(Arrays.asList(&quot;V&quot;, &quot;version&quot;), &quot;Prints elasticsearch version information and exits&quot;);    daemonizeOption = parser.acceptsAll(Arrays.asList(&quot;d&quot;, &quot;daemonize&quot;), &quot;Starts Elasticsearch in the background&quot;)        .availableUnless(versionOption);    pidfileOption = parser.acceptsAll(Arrays.asList(&quot;p&quot;, &quot;pidfile&quot;), &quot;Creates a pid file in the specified path on start&quot;)        .availableUnless(versionOption).withRequiredArg().withValuesConvertedBy(new PathConverter());    quietOption = parser.acceptsAll(Arrays.asList(&quot;q&quot;, &quot;quiet&quot;), &quot;Turns off standard output/error streams logging in console&quot;)        .availableUnless(versionOption).availableUnless(daemonizeOption);}</code></pre><p>1.4, 接着进入 <code>Command.main</code> 方法</p><p>该方法给当前Runtime类添加一个hook线程，该线程作用是：当Runtime异常关闭时打印异常信息</p><p>1.5, <code>Command.mainWithoutErrorHandling</code> 方法，根据命令行参数，打印或者设置参数，然后执行命令，有异常则抛出所有异常</p><p>1.6, <code>EnvironmentAwareCommand.execute</code>，确保 <code>es.path.data</code>, <code>es.path.home</code>, <code>es.path.logs</code> 等参数已设置，否则从 <code>System.properties</code> 中读取</p><pre><code>putSystemPropertyIfSettingIsMissing(settings, &quot;path.data&quot;, &quot;es.path.data&quot;);putSystemPropertyIfSettingIsMissing(settings, &quot;path.home&quot;, &quot;es.path.home&quot;);putSystemPropertyIfSettingIsMissing(settings, &quot;path.logs&quot;, &quot;es.path.logs&quot;);execute(terminal, options, createEnv(terminal, settings));</code></pre><p>1.7, <code>EnvironmentAwareCommand.createEnv</code>，读取config下的配置文件<code>elasticsearch.yml</code>内容，收集plugins，bin，lib，modules等目录下的文件信息</p><p>createEnv最后返回一个 Environment 对象，执行结果如下</p><p><img src="http://image.laijianfeng.org/20180901_160825.png" alt="EnvironmentAwareCommand.createEnv"></p><p>1.8, <code>Elasticsearch.execute</code> ，读取daemonize， pidFile，quiet 的值，并 确保配置的临时目录(temp)是有效目录</p><p>进入Bootstrap初始化阶段</p><pre><code>Bootstrap.init(!daemonize, pidFile, quiet, initialEnv);</code></pre><h3 id="Bootstrap初始化阶段"><a href="#Bootstrap初始化阶段" class="headerlink" title="Bootstrap初始化阶段"></a>Bootstrap初始化阶段</h3><h4 id="Bootstrap-init"><a href="#Bootstrap-init" class="headerlink" title="Bootstrap.init"></a>Bootstrap.init</h4><p>2.1, 进入 <code>Bootstrap.init</code>, This method is invoked by <code>Elasticsearch#main(String[])</code> to startup elasticsearch.</p><p><code>INSTANCE = new Bootstrap();</code>, 创建一个Bootstrap对象作为类对象，该类构造函数会创建一个用户线程，添加到Runtime Hook中，进行 countDown 操作</p><pre><code> private final CountDownLatch keepAliveLatch = new CountDownLatch(1); /** creates a new instance */    Bootstrap() {        keepAliveThread = new Thread(new Runnable() {            @Override            public void run() {                try {                    keepAliveLatch.await();                } catch (InterruptedException e) {                }            }        }, &quot;elasticsearch[keepAlive/&quot; + Version.CURRENT + &quot;]&quot;);        keepAliveThread.setDaemon(false);        // keep this thread alive (non daemon thread) until we shutdown        Runtime.getRuntime().addShutdownHook(new Thread() {            @Override            public void run() {                keepAliveLatch.countDown();            }        });    }</code></pre><blockquote><p>CountDownLatch是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程执行完后再执行。例如，应用程序的主线程希望在负责启动框架服务的线程已经启动所有框架服务之后执行。<br>CountDownLatch是通过一个计数器来实现的，计数器的初始化值为线程的数量。每当一个线程完成了自己的任务后，计数器的值就相应得减1。当计数器到达0时，表示所有的线程都已完成任务，然后在闭锁上等待的线程就可以恢复执行任务。<br>更多介绍请看文章：<a href="https://blog.csdn.net/wwwdc1012/article/details/82288473" target="_blank" rel="noopener">并发工具类 CountDownLatch</a></p></blockquote><p>2.2, 加载 keystore 安全配置，keystore文件不存在则创建，保存；存在则解密，更新keystore</p><p>2.3, 根据已有的配置信息，创建一个Environment对象</p><p>2.4, LogConfigurator log4j日志配置</p><p>2.5, 检查pid文件是否存在，不存在则创建</p><blockquote><p>关于 pid 文件：<br>(1) <strong>pid文件的内容</strong>：pid文件为文本文件，内容只有一行，记录了该进程的ID，用cat命令可以看到。<br>(2) <strong>pid文件的作用</strong>：防止进程启动多个副本。只有获得pid文件(固定路径固定文件名)写入权限(F_WRLCK)的进程才能正常启动并把自身的PID写入该文件中，其它同一个程序的多余进程则自动退出。</p></blockquote><p>2.6, 检查Lucene版本与实际的Lucene Jar文件的版本是否一致，不一致则抛异常</p><p>2.7, 设置未捕获异常的处理 Thread.setDefaultUncaughtExceptionHandler</p><p>在Thread ApI中提供了UncaughtExceptionHandle，它能检测出某个由于未捕获的异常而终结的情况</p><blockquote><p>朱小厮 <a href="https://blog.csdn.net/u013256816/article/details/50417822" target="_blank" rel="noopener">JAVA多线程之UncaughtExceptionHandler——处理非正常的线程中止</a></p></blockquote><h4 id="INSTANCE-setup-true-environment"><a href="#INSTANCE-setup-true-environment" class="headerlink" title="INSTANCE.setup(true, environment);"></a>INSTANCE.setup(true, environment);</h4><p>3.1，<code>spawner.spawnNativeControllers(environment);</code></p><p>遍历每个模块，生成本机控制类（native Controller）：读取modules文件夹下所有的文件夹中的模块信息，保存为一个 PluginInfo  对象，为合适的模块生成控制类，通过 <code>Files.isRegularFile(spawnPath)</code> 来判断</p><p>尝试为给定模块生成控制器(native Controller)守护程序。    生成的进程将通过其stdin，stdout和stderr流保持与此JVM的连接，但对此包之外的代码不能使用对这些流的引用。</p><p>3.2， <code>initializeNatives(Path tmpFile, boolean mlockAll, boolean systemCallFilter, boolean ctrlHandler)</code>初始化本地资源</p><p>检查用户是否为root用户，是则抛异常;<br>尝试启用 系统调用过滤器 system call filter;<br>如果设置了则进行 mlockall<br>Windows关闭事件监听器<br>init lucene random seed.   </p><p>这个过程中使用到了 Natives 类:<br>Natives类是一个包装类，用于检查调用本机方法所需的类是否在启动时可用。如果它们不可用，则此类将避免调用加载这些类的代码</p><p>3.3, 添加一个Hook： Runtime.getRuntime().addShutdownHook，当ES退出时用于关闭必要的IO流，日志器上下文和配置器等</p><p>3.4, 使用 JarHell 检查重复的 jar 文件</p><p>3.5, 初始化 SecurityManager</p><pre><code>// install SM after natives, shutdown hooks, etc.Security.configure(environment, BootstrapSettings.SECURITY_FILTER_BAD_DEFAULTS_SETTING.get(settings));</code></pre><h3 id="创建-node-节点"><a href="#创建-node-节点" class="headerlink" title="创建 node 节点"></a>创建 node 节点</h3><pre><code>node = new Node(environment) {    @Override    protected void validateNodeBeforeAcceptingRequests(        final BootstrapContext context,        final BoundTransportAddress boundTransportAddress, List&lt;BootstrapCheck&gt; checks) throws NodeValidationException {        BootstrapChecks.check(context, boundTransportAddress, checks);    }};</code></pre><p>4.1, 这里直接贴一下代码（前半部分）</p><pre><code>    protected Node(final Environment environment, Collection&lt;Class&lt;? extends Plugin&gt;&gt; classpathPlugins) {        final List&lt;Closeable&gt; resourcesToClose = new ArrayList&lt;&gt;(); // register everything we need to release in the case of an error        boolean success = false;        {            // use temp logger just to say we are starting. we can&#39;t use it later on because the node name might not be set            Logger logger = Loggers.getLogger(Node.class, NODE_NAME_SETTING.get(environment.settings()));            logger.info(&quot;initializing ...&quot;);        }        try {            originalSettings = environment.settings();            Settings tmpSettings = Settings.builder().put(environment.settings())                .put(Client.CLIENT_TYPE_SETTING_S.getKey(), CLIENT_TYPE).build();            // create the node environment as soon as possible, to recover the node id and enable logging            try {                nodeEnvironment = new NodeEnvironment(tmpSettings, environment);                resourcesToClose.add(nodeEnvironment);            } catch (IOException ex) {                throw new IllegalStateException(&quot;Failed to create node environment&quot;, ex);            }            final boolean hadPredefinedNodeName = NODE_NAME_SETTING.exists(tmpSettings);            final String nodeId = nodeEnvironment.nodeId();            tmpSettings = addNodeNameIfNeeded(tmpSettings, nodeId);            final Logger logger = Loggers.getLogger(Node.class, tmpSettings);            // this must be captured after the node name is possibly added to the settings            final String nodeName = NODE_NAME_SETTING.get(tmpSettings);            if (hadPredefinedNodeName == false) {                logger.info(&quot;node name derived from node ID [{}]; set [{}] to override&quot;, nodeId, NODE_NAME_SETTING.getKey());            } else {                logger.info(&quot;node name [{}], node ID [{}]&quot;, nodeName, nodeId);            }            final JvmInfo jvmInfo = JvmInfo.jvmInfo();            logger.info(                &quot;version[{}], pid[{}], build[{}/{}/{}/{}], OS[{}/{}/{}], JVM[{}/{}/{}/{}]&quot;,                Version.displayVersion(Version.CURRENT, Build.CURRENT.isSnapshot()),                jvmInfo.pid(),                Build.CURRENT.flavor().displayName(),                Build.CURRENT.type().displayName(),                Build.CURRENT.shortHash(),                Build.CURRENT.date(),                Constants.OS_NAME,                Constants.OS_VERSION,                Constants.OS_ARCH,                Constants.JVM_VENDOR,                Constants.JVM_NAME,                Constants.JAVA_VERSION,                Constants.JVM_VERSION);            logger.info(&quot;JVM arguments {}&quot;, Arrays.toString(jvmInfo.getInputArguments()));            warnIfPreRelease(Version.CURRENT, Build.CURRENT.isSnapshot(), logger);            if (logger.isDebugEnabled()) {                logger.debug(&quot;using config [{}], data [{}], logs [{}], plugins [{}]&quot;,                    environment.configFile(), Arrays.toString(environment.dataFiles()), environment.logsFile(), environment.pluginsFile());            }            this.pluginsService = new PluginsService(tmpSettings, environment.configFile(), environment.modulesFile(), environment.pluginsFile(), classpathPlugins);            this.settings = pluginsService.updatedSettings();            localNodeFactory = new LocalNodeFactory(settings, nodeEnvironment.nodeId());            // create the environment based on the finalized (processed) view of the settings            // this is just to makes sure that people get the same settings, no matter where they ask them from            this.environment = new Environment(this.settings, environment.configFile());            Environment.assertEquivalent(environment, this.environment);            final List&lt;ExecutorBuilder&lt;?&gt;&gt; executorBuilders = pluginsService.getExecutorBuilders(settings);            final ThreadPool threadPool = new ThreadPool(settings, executorBuilders.toArray(new ExecutorBuilder[0]));            resourcesToClose.add(() -&gt; ThreadPool.terminate(threadPool, 10, TimeUnit.SECONDS));            // adds the context to the DeprecationLogger so that it does not need to be injected everywhere            DeprecationLogger.setThreadContext(threadPool.getThreadContext());            resourcesToClose.add(() -&gt; DeprecationLogger.removeThreadContext(threadPool.getThreadContext()));            final List&lt;Setting&lt;?&gt;&gt; additionalSettings = new ArrayList&lt;&gt;(pluginsService.getPluginSettings());            final List&lt;String&gt; additionalSettingsFilter = new ArrayList&lt;&gt;(pluginsService.getPluginSettingsFilter());            for (final ExecutorBuilder&lt;?&gt; builder : threadPool.builders()) {                additionalSettings.addAll(builder.getRegisteredSettings());            }            client = new NodeClient(settings, threadPool);    ...</code></pre><p>这里进行的主要操作有:</p><ol><li>生命周期Lifecycle设置为 初始化状态 INITIALIZED</li><li>创建一个 NodeEnvironment 对象保存节点环境信息，如各种数据文件的路径</li><li>读取JVM信息</li><li>创建 PluginsService 对象，创建过程中会读取并加载所有的模块和插件</li><li>创建一个最终的 Environment 对象</li><li>创建线程池 ThreadPool 后面各类对象基本都是通过线程来提供服务，这个线程池可以管理各类线程</li><li>创建 节点客户端 NodeClient</li></ol><p><strong>这里重点介绍 PluginsService 和 ThreadPool 这两个类</strong></p><h4 id="PluginsService"><a href="#PluginsService" class="headerlink" title="PluginsService"></a>PluginsService</h4><p>在构造该类对象是传入的参数如下：</p><p><img src="http://image.laijianfeng.org/20180901_175542.png" alt="PluginsService 构造方法的参数"></p><p>在构造方法中加载所有的模块</p><pre><code>Set&lt;Bundle&gt; seenBundles = new LinkedHashSet&lt;&gt;();List&lt;PluginInfo&gt; modulesList = new ArrayList&lt;&gt;();Set&lt;Bundle&gt; modules = getModuleBundles(modulesDirectory); for (Bundle bundle : modules) {   modulesList.add(bundle.plugin);}seenBundles.addAll(modules);/** Get bundles for plugins installed in the given modules directory. */static Set&lt;Bundle&gt; getModuleBundles(Path modulesDirectory) throws IOException {    return findBundles(modulesDirectory, &quot;module&quot;).stream().flatMap(b -&gt; b.bundles().stream()).collect(Collectors.toSet());}</code></pre><p>其中的 Bundle是一个内部类（a “bundle” is a group of plugins in a single classloader）<br>而 PluginInfo 则是 An in-memory representation of the plugin descriptor. 存在内存中的用来描述一个 plugin 的类</p><p>插件加载的实际代码如下：</p><pre><code>    /**     * Reads the plugin descriptor file.     *     * @param path           the path to the root directory for the plugin     * @return the plugin info     * @throws IOException if an I/O exception occurred reading the plugin descriptor     */    public static PluginInfo readFromProperties(final Path path) throws IOException {        final Path descriptor = path.resolve(ES_PLUGIN_PROPERTIES);        final Map&lt;String, String&gt; propsMap;        {            final Properties props = new Properties();            try (InputStream stream = Files.newInputStream(descriptor)) {                props.load(stream);            }            propsMap = props.stringPropertyNames().stream().collect(Collectors.toMap(Function.identity(), props::getProperty));        }        final String name = propsMap.remove(&quot;name&quot;);        if (name == null || name.isEmpty()) {            throw new IllegalArgumentException(                    &quot;property [name] is missing in [&quot; + descriptor + &quot;]&quot;);        }        final String description = propsMap.remove(&quot;description&quot;);        if (description == null) {            throw new IllegalArgumentException(                    &quot;property [description] is missing for plugin [&quot; + name + &quot;]&quot;);        }        final String version = propsMap.remove(&quot;version&quot;);        if (version == null) {            throw new IllegalArgumentException(                    &quot;property [version] is missing for plugin [&quot; + name + &quot;]&quot;);        }        final String esVersionString = propsMap.remove(&quot;elasticsearch.version&quot;);        if (esVersionString == null) {            throw new IllegalArgumentException(                    &quot;property [elasticsearch.version] is missing for plugin [&quot; + name + &quot;]&quot;);        }        final Version esVersion = Version.fromString(esVersionString);        final String javaVersionString = propsMap.remove(&quot;java.version&quot;);        if (javaVersionString == null) {            throw new IllegalArgumentException(                    &quot;property [java.version] is missing for plugin [&quot; + name + &quot;]&quot;);        }        JarHell.checkVersionFormat(javaVersionString);        final String classname = propsMap.remove(&quot;classname&quot;);        if (classname == null) {            throw new IllegalArgumentException(                    &quot;property [classname] is missing for plugin [&quot; + name + &quot;]&quot;);        }        final String extendedString = propsMap.remove(&quot;extended.plugins&quot;);        final List&lt;String&gt; extendedPlugins;        if (extendedString == null) {            extendedPlugins = Collections.emptyList();        } else {            extendedPlugins = Arrays.asList(Strings.delimitedListToStringArray(extendedString, &quot;,&quot;));        }        final String hasNativeControllerValue = propsMap.remove(&quot;has.native.controller&quot;);        final boolean hasNativeController;        if (hasNativeControllerValue == null) {            hasNativeController = false;        } else {            switch (hasNativeControllerValue) {                case &quot;true&quot;:                    hasNativeController = true;                    break;                case &quot;false&quot;:                    hasNativeController = false;                    break;                default:                    final String message = String.format(                            Locale.ROOT,                            &quot;property [%s] must be [%s], [%s], or unspecified but was [%s]&quot;,                            &quot;has_native_controller&quot;,                            &quot;true&quot;,                            &quot;false&quot;,                            hasNativeControllerValue);                    throw new IllegalArgumentException(message);            }        }        if (esVersion.before(Version.V_6_3_0) &amp;&amp; esVersion.onOrAfter(Version.V_6_0_0_beta2)) {            propsMap.remove(&quot;requires.keystore&quot;);        }        if (propsMap.isEmpty() == false) {            throw new IllegalArgumentException(&quot;Unknown properties in plugin descriptor: &quot; + propsMap.keySet());        }        return new PluginInfo(name, description, version, esVersion, javaVersionString,                              classname, extendedPlugins, hasNativeController);    }</code></pre><p>其中的两个常量的值</p><pre><code>    public static final String ES_PLUGIN_PROPERTIES = &quot;plugin-descriptor.properties&quot;;    public static final String ES_PLUGIN_POLICY = &quot;plugin-security.policy&quot;;</code></pre><p>从以上代码可以看出<strong>模块的加载过程</strong>：</p><ol><li>读取模块的配置文件 <code>plugin-descriptor.properties</code>，解析出内容并存储到 Map 中</li><li>分别校验 <code>name</code>, <code>description</code>, <code>version</code>, <code>elasticsearch.version</code>, <code>java.version</code>, <code>classname</code>, <code>extended.plugins</code>, <code>has.native.controller</code>, <code>requires.keystore</code> 这些配置项，缺失或者不按要求则抛出异常</li><li>根据配置项构造一个 PluginInfo 对象返回</li></ol><p>举例：读取出的 aggs-matrix-stats 模块的配置项信息如下</p><p><img src="http://image.laijianfeng.org/20180901_181500.png" alt="读取插件配置文件并解析文件内容"></p><p>加载插件与加载模块调用的是相同的方法</p><h3 id="ThreadPool-线程池"><a href="#ThreadPool-线程池" class="headerlink" title="ThreadPool 线程池"></a>ThreadPool 线程池</h3><p>线程池的构造方法如下：</p><pre><code>    public ThreadPool(final Settings settings, final ExecutorBuilder&lt;?&gt;... customBuilders) {        super(settings);        assert Node.NODE_NAME_SETTING.exists(settings);        final Map&lt;String, ExecutorBuilder&gt; builders = new HashMap&lt;&gt;();        final int availableProcessors = EsExecutors.numberOfProcessors(settings);        final int halfProcMaxAt5 = halfNumberOfProcessorsMaxFive(availableProcessors);        final int halfProcMaxAt10 = halfNumberOfProcessorsMaxTen(availableProcessors);        final int genericThreadPoolMax = boundedBy(4 * availableProcessors, 128, 512);        builders.put(Names.GENERIC, new ScalingExecutorBuilder(Names.GENERIC, 4, genericThreadPoolMax, TimeValue.timeValueSeconds(30)));        builders.put(Names.INDEX, new FixedExecutorBuilder(settings, Names.INDEX, availableProcessors, 200, true));        builders.put(Names.WRITE, new FixedExecutorBuilder(settings, Names.WRITE, &quot;bulk&quot;, availableProcessors, 200));        builders.put(Names.GET, new FixedExecutorBuilder(settings, Names.GET, availableProcessors, 1000));        builders.put(Names.ANALYZE, new FixedExecutorBuilder(settings, Names.ANALYZE, 1, 16));        builders.put(Names.SEARCH, new AutoQueueAdjustingExecutorBuilder(settings,                        Names.SEARCH, searchThreadPoolSize(availableProcessors), 1000, 1000, 1000, 2000));        builders.put(Names.MANAGEMENT, new ScalingExecutorBuilder(Names.MANAGEMENT, 1, 5, TimeValue.timeValueMinutes(5)));        // no queue as this means clients will need to handle rejections on listener queue even if the operation succeeded        // the assumption here is that the listeners should be very lightweight on the listeners side        builders.put(Names.LISTENER, new FixedExecutorBuilder(settings, Names.LISTENER, halfProcMaxAt10, -1));        builders.put(Names.FLUSH, new ScalingExecutorBuilder(Names.FLUSH, 1, halfProcMaxAt5, TimeValue.timeValueMinutes(5)));        builders.put(Names.REFRESH, new ScalingExecutorBuilder(Names.REFRESH, 1, halfProcMaxAt10, TimeValue.timeValueMinutes(5)));        builders.put(Names.WARMER, new ScalingExecutorBuilder(Names.WARMER, 1, halfProcMaxAt5, TimeValue.timeValueMinutes(5)));        builders.put(Names.SNAPSHOT, new ScalingExecutorBuilder(Names.SNAPSHOT, 1, halfProcMaxAt5, TimeValue.timeValueMinutes(5)));        builders.put(Names.FETCH_SHARD_STARTED, new ScalingExecutorBuilder(Names.FETCH_SHARD_STARTED, 1, 2 * availableProcessors, TimeValue.timeValueMinutes(5)));        builders.put(Names.FORCE_MERGE, new FixedExecutorBuilder(settings, Names.FORCE_MERGE, 1, -1));        builders.put(Names.FETCH_SHARD_STORE, new ScalingExecutorBuilder(Names.FETCH_SHARD_STORE, 1, 2 * availableProcessors, TimeValue.timeValueMinutes(5)));        for (final ExecutorBuilder&lt;?&gt; builder : customBuilders) {            if (builders.containsKey(builder.name())) {                throw new IllegalArgumentException(&quot;builder with name [&quot; + builder.name() + &quot;] already exists&quot;);            }            builders.put(builder.name(), builder);        }        this.builders = Collections.unmodifiableMap(builders);        threadContext = new ThreadContext(settings);        final Map&lt;String, ExecutorHolder&gt; executors = new HashMap&lt;&gt;();        for (@SuppressWarnings(&quot;unchecked&quot;) final Map.Entry&lt;String, ExecutorBuilder&gt; entry : builders.entrySet()) {            final ExecutorBuilder.ExecutorSettings executorSettings = entry.getValue().getSettings(settings);            final ExecutorHolder executorHolder = entry.getValue().build(executorSettings, threadContext);            if (executors.containsKey(executorHolder.info.getName())) {                throw new IllegalStateException(&quot;duplicate executors with name [&quot; + executorHolder.info.getName() + &quot;] registered&quot;);            }            logger.debug(&quot;created thread pool: {}&quot;, entry.getValue().formatInfo(executorHolder.info));            executors.put(entry.getKey(), executorHolder);        }        executors.put(Names.SAME, new ExecutorHolder(DIRECT_EXECUTOR, new Info(Names.SAME, ThreadPoolType.DIRECT)));        this.executors = unmodifiableMap(executors);        this.scheduler = Scheduler.initScheduler(settings);        TimeValue estimatedTimeInterval = ESTIMATED_TIME_INTERVAL_SETTING.get(settings);        this.cachedTimeThread = new CachedTimeThread(EsExecutors.threadName(settings, &quot;[timer]&quot;), estimatedTimeInterval.millis());        this.cachedTimeThread.start();    }</code></pre><p>参考着文档来理解这里的代码：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-threadpool.html" target="_blank" rel="noopener">Elasticsearch Reference [6.4] » Modules » Thread Pool</a> 和 <a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=9405389" target="_blank" rel="noopener">apachecn 线程池</a></p><h4 id="线程池类型-ThreadPoolType"><a href="#线程池类型-ThreadPoolType" class="headerlink" title="线程池类型 ThreadPoolType"></a>线程池类型 ThreadPoolType</h4><p><strong>fixed</strong>（固定）：fixed线程池拥有固定数量的线程来处理请求，在没有空闲线程时请求将被挂在队列中。queue_size参数可以控制在没有空闲线程时，能排队挂起的请求数</p><p><strong>fixed_auto_queue_size</strong>：此类型为实验性的，将被更改或删除，不关注</p><p><strong>scaling</strong>（弹性）：scaling线程池拥有的线程数量是动态的，这个数字介于core和max参数的配置之间变化。keep_alive参数用来控制线程在线程池中空闲的最长时间</p><p><strong>direct</strong>：此类线程是一种不支持关闭的线程,就意味着一旦使用,则会一直存活下去.</p><h4 id="一些重要的线程池"><a href="#一些重要的线程池" class="headerlink" title="一些重要的线程池"></a>一些重要的线程池</h4><p><strong>generic</strong>：用于通用的请求（例如：后台节点发现），线程池类型为 scaling。</p><p><strong>index</strong>：用于index/delete请求，线程池类型为 fixed， 大小的为处理器数量，队列大小为200，最大线程数为 1 + 处理器数量。</p><p><strong>search</strong>：用于count/search/suggest请求。线程池类型为 fixed， 大小的为 int((处理器数量 3) / 2) +1，队列大小为1000。*</p><p><strong>get</strong>：用于get请求。线程池类型为 fixed，大小的为处理器数量，队列大小为1000。</p><p><strong>analyze</strong>：用于analyze请求。线程池类型为 fixed，大小的1，队列大小为16</p><p><strong>write</strong>：用于单个文档的 index/delete/update 请求以及 <strong>bulk 请求</strong>，线程池类型为 fixed，大小的为处理器数量，队列大小为200，最大线程数为 1 + 处理器数量。</p><p><strong>snapshot</strong>：用于snaphost/restore请求。线程池类型为 scaling，线程保持存活时间为5分钟，最大线程数为min(5, (处理器数量)/2)。</p><p><strong>warmer</strong>：用于segment warm-up请求。线程池类型为 scaling，线程保持存活时间为5分钟，最大线程数为min(5, (处理器数量)/2)。</p><p><strong>refresh</strong>：用于refresh请求。线程池类型为 scaling，线程空闲保持存活时间为5分钟，最大线程数为min(10, (处理器数量)/2)。</p><p><strong>listener</strong>：主要用于Java客户端线程监听器被设置为true时执行动作。线程池类型为 scaling，最大线程数为min(10, (处理器数量)/2)。</p><p>ThreadPool 类中除了以上线程队列，还可以看到有 CachedTimeThread（缓存系统时间）、ExecutorService（在当前线程上执行提交的任务）、ThreadContext（线程上下文）、ScheduledThreadPoolExecutor（Java任务调度）等</p><blockquote><p>参考文章：<a href="https://my.oschina.net/u/3145136/blog/848079" target="_blank" rel="noopener">Java并发编程14-ScheduledThreadPoolExecutor详解</a><br><a href="https://www.jianshu.com/p/4b8a257f1b90" target="_blank" rel="noopener">Java线程池原理分析ScheduledThreadPoolExecutor篇</a><br>关于 ScheduledThreadPoolExecutor 更多的细节应该看书或者官方文档</p></blockquote><h4 id="关于线程"><a href="#关于线程" class="headerlink" title="关于线程"></a>关于线程</h4><p>了解了线程池，继续深究ES线程是什么样子的</p><p>在 <code>ScalingExecutorBuilder.build</code> 中可以发现 <code>ExecutorService</code> 对象是由 <code>EsExecutors.newScaling</code> 创建的</p><pre><code>public static EsThreadPoolExecutor newScaling(String name, int min, int max, long keepAliveTime, TimeUnit unit, ThreadFactory threadFactory, ThreadContext contextHolder) {    ExecutorScalingQueue&lt;Runnable&gt; queue = new ExecutorScalingQueue&lt;&gt;();    EsThreadPoolExecutor executor = new EsThreadPoolExecutor(name, min, max, keepAliveTime, unit, queue, threadFactory, new ForceQueuePolicy(), contextHolder);    queue.executor = executor;    return executor;}</code></pre><p>再看看 <code>EsThreadPoolExecutor</code> 这个类的继承关系，其是扩展自Java的线程池 <code>ThreadPoolExecutor</code></p><p><img src="http://image.laijianfeng.org/20180901_192545.png" alt="EsThreadPoolExecutor的继承链"></p><pre><code>    EsThreadPoolExecutor(String name, int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit,            BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, XRejectedExecutionHandler handler,            ThreadContext contextHolder) {        super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, handler);        this.name = name;        this.contextHolder = contextHolder;    }</code></pre><h3 id="回到-Node-节点的创建"><a href="#回到-Node-节点的创建" class="headerlink" title="回到 Node 节点的创建"></a>回到 Node 节点的创建</h3><p>4.2, 创建各种服务类对象 ResourceWatcherService、NetworkService、ClusterService、IngestService、ClusterInfoService、UsageService、MonitorService、CircuitBreakerService、MetaStateService、IndicesService、MetaDataIndexUpgradeService、TemplateUpgradeService、TransportService、ResponseCollectorService、SearchTransportService、NodeService、SearchService、PersistentTasksClusterService</p><p>这些服务类是的功能可以根据名称做一个大概的判断，具体还需要看文档和源码，限于篇幅，在此不做探究</p><p>4.3, ModulesBuilder类加入各种模块 ScriptModule、AnalysisModule、SettingsModule、pluginModule、ClusterModule、IndicesModule、SearchModule、GatewayModule、RepositoriesModule、ActionModule、NetworkModule、DiscoveryModule</p><p>4.4, guice 绑定依赖以及依赖注入</p><blockquote><p>关于 guice 可以参考之前的文章:<br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483683&amp;idx=1&amp;sn=0d77085a0234b2c5b7c679e62200e6f5&amp;chksm=e9c2ed2edeb56438010b5f5d487bcb7f0529c85d50ac7c858e1a8e3a9279c15007341170c5ac&amp;mpshare=1&amp;scene=1&amp;srcid=0901SWQiIdjHZ3endUHZqjkP#rd" target="_blank" rel="noopener">Google Guice 快速入门</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NDU0MTE1NA==&amp;mid=2247483691&amp;idx=1&amp;sn=3c7175d318bce6728c2105d27ae6bafe&amp;chksm=e9c2ed26deb56430289edabd15cef1a0cf777c5dfe4f4ad5013655e9d3607958e0fe16ac5436&amp;mpshare=1&amp;scene=1&amp;srcid=0901u1aslOFhg6UmeBkLw8BY#rd" target="_blank" rel="noopener">Elasticsearch 中的 Guice</a></p></blockquote><p>elasticsearch里面的组件基本都进行进行了模块化管理，elasticsearch对guice进行了封装，通过ModulesBuilder类构建es的模块（一般包括的模块在 4.3 中列举了）</p><pre><code>// 依赖绑定modules.add(b -&gt; {        b.bind(Node.class).toInstance(this);        b.bind(NodeService.class).toInstance(nodeService);        b.bind(NamedXContentRegistry.class).toInstance(xContentRegistry);        b.bind(PluginsService.class).toInstance(pluginsService);        b.bind(Client.class).toInstance(client);        b.bind(NodeClient.class).toInstance(client);        b.bind(Environment.class).toInstance(this.environment);        b.bind(ThreadPool.class).toInstance(threadPool);        b.bind(NodeEnvironment.class).toInstance(nodeEnvironment);        b.bind(ResourceWatcherService.class).toInstance(resourceWatcherService);        b.bind(CircuitBreakerService.class).toInstance(circuitBreakerService);        b.bind(BigArrays.class).toInstance(bigArrays);        b.bind(ScriptService.class).toInstance(scriptModule.getScriptService());        b.bind(AnalysisRegistry.class).toInstance(analysisModule.getAnalysisRegistry());        b.bind(IngestService.class).toInstance(ingestService);        b.bind(UsageService.class).toInstance(usageService);        b.bind(NamedWriteableRegistry.class).toInstance(namedWriteableRegistry);        b.bind(MetaDataUpgrader.class).toInstance(metaDataUpgrader);        b.bind(MetaStateService.class).toInstance(metaStateService);        b.bind(IndicesService.class).toInstance(indicesService);        b.bind(SearchService.class).toInstance(searchService);        b.bind(SearchTransportService.class).toInstance(searchTransportService);        b.bind(SearchPhaseController.class).toInstance(new SearchPhaseController(settings,            searchService::createReduceContext));        b.bind(Transport.class).toInstance(transport);        b.bind(TransportService.class).toInstance(transportService);        b.bind(NetworkService.class).toInstance(networkService);        b.bind(UpdateHelper.class).toInstance(new UpdateHelper(settings, scriptModule.getScriptService()));        b.bind(MetaDataIndexUpgradeService.class).toInstance(metaDataIndexUpgradeService);        b.bind(ClusterInfoService.class).toInstance(clusterInfoService);        b.bind(GatewayMetaState.class).toInstance(gatewayMetaState);        b.bind(Discovery.class).toInstance(discoveryModule.getDiscovery());        {            RecoverySettings recoverySettings = new RecoverySettings(settings, settingsModule.getClusterSettings());            processRecoverySettings(settingsModule.getClusterSettings(), recoverySettings);            b.bind(PeerRecoverySourceService.class).toInstance(new PeerRecoverySourceService(settings, transportService,                    indicesService, recoverySettings));            b.bind(PeerRecoveryTargetService.class).toInstance(new PeerRecoveryTargetService(settings, threadPool,                    transportService, recoverySettings, clusterService));        }        httpBind.accept(b);        pluginComponents.stream().forEach(p -&gt; b.bind((Class) p.getClass()).toInstance(p));        b.bind(PersistentTasksService.class).toInstance(persistentTasksService);        b.bind(PersistentTasksClusterService.class).toInstance(persistentTasksClusterService);        b.bind(PersistentTasksExecutorRegistry.class).toInstance(registry);    });injector = modules.createInjector();</code></pre><h3 id="Bootstrap-启动"><a href="#Bootstrap-启动" class="headerlink" title="Bootstrap 启动"></a>Bootstrap 启动</h3><p>5.1， 通过 <code>injector</code> 获取各个类的对象，调用 <code>start()</code> 方法启动（实际进入各个类的中 <code>doStart</code> 方法）: LifecycleComponent、IndicesService、IndicesClusterStateService、SnapshotsService、SnapshotShardsService、RoutingService、SearchService、MonitorService、NodeConnectionsService、ResourceWatcherService、GatewayService、Discovery、TransportService</p><p>这里简要介绍一下各个服务类的职能：</p><p>IndicesService：索引管理<br>IndicesClusterStateService：跨集群同步<br>SnapshotsService：负责创建快照<br>SnapshotShardsService：此服务在数据和主节点上运行，并控制这些节点上当前快照的分片。 它负责启动和停止分片级别快照<br>RoutingService：侦听集群状态，当它收到ClusterChangedEvent（集群改变事件）将验证集群状态，路由表可能会更新<br>SearchService：搜索服务<br>MonitorService：监控<br>NodeConnectionsService：此组件负责在节点添加到群集状态后连接到节点，并在删除它们时断开连接。 此外，它会定期检查所有连接是否仍处于打开状态，并在需要时还原它们。 请注意，如果节点断开/不响应ping，则此组件不负责从群集中删除节点。 这是由NodesFaultDetection完成的。 主故障检测由链接MasterFaultDetection完成。<br>ResourceWatcherService：通用资源观察器服务<br>GatewayService：网关</p><p>如果该节点是主节点或数据节点，还需要进行相关的职能操作</p><p>5.2, 集群发现与监控等，启动 HttpServerTransport， 绑定服务端口</p><pre><code>validateNodeBeforeAcceptingRequests(new BootstrapContext(settings, onDiskMetadata), transportService.boundAddress(), pluginsService    .filterPlugins(Plugin    .class)    .stream()    .flatMap(p -&gt; p.getBootstrapChecks().stream()).collect(Collectors.toList()));clusterService.addStateApplier(transportService.getTaskManager());// start after transport service so the local disco is knowndiscovery.start(); // start before cluster service so that it can set initial state on ClusterApplierServiceclusterService.start();assert clusterService.localNode().equals(localNodeFactory.getNode())    : &quot;clusterService has a different local node than the factory provided&quot;;transportService.acceptIncomingRequests();discovery.startInitialJoin();// tribe nodes don&#39;t have a master so we shouldn&#39;t register an observer         sfinal TimeValue initialStateTimeout = DiscoverySettings.INITIAL_STATE_TIMEOUT_SETTING.get(settings);if (initialStateTimeout.millis() &gt; 0) {    final ThreadPool thread = injector.getInstance(ThreadPool.class);    ClusterState clusterState = clusterService.state();    ClusterStateObserver observer = new ClusterStateObserver(clusterState, clusterService, null, logger, thread.getThreadContext());    if (clusterState.nodes().getMasterNodeId() == null) {        logger.debug(&quot;waiting to join the cluster. timeout [{}]&quot;, initialStateTimeout);        final CountDownLatch latch = new CountDownLatch(1);        observer.waitForNextChange(new ClusterStateObserver.Listener() {            @Override            public void onNewClusterState(ClusterState state) { latch.countDown(); }            @Override            public void onClusterServiceClose() {                latch.countDown();            }            @Override            public void onTimeout(TimeValue timeout) {                logger.warn(&quot;timed out while waiting for initial discovery state - timeout: {}&quot;,                    initialStateTimeout);                latch.countDown();            }        }, state -&gt; state.nodes().getMasterNodeId() != null, initialStateTimeout);        try {            latch.await();        } catch (InterruptedException e) {            throw new ElasticsearchTimeoutException(&quot;Interrupted while waiting for initial discovery state&quot;);        }    }}if (NetworkModule.HTTP_ENABLED.get(settings)) {    injector.getInstance(HttpServerTransport.class).start();}if (WRITE_PORTS_FILE_SETTING.get(settings)) {    if (NetworkModule.HTTP_ENABLED.get(settings)) {        HttpServerTransport http = injector.getInstance(HttpServerTransport.class);        writePortsFile(&quot;http&quot;, http.boundAddress());    }    TransportService transport = injector.getInstance(TransportService.class);    writePortsFile(&quot;transport&quot;, transport.boundAddress());}</code></pre><p>5.3, 启动保活线程 keepAliveThread.start 进行心跳检测</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>过程很漫长，后面很多类的功能未了解，之后补上</p><p>有理解错误的地方请大家多多指教</p><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Google guava工具类的介绍和使用</title>
      <link href="/2018/08/Google-guava%E5%B7%A5%E5%85%B7%E7%B1%BB%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BD%BF%E7%94%A8/"/>
      <url>/2018/08/Google-guava%E5%B7%A5%E5%85%B7%E7%B1%BB%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BD%BF%E7%94%A8/</url>
      <content type="html"><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>工具类 就是封装平常用的方法，不需要你重复造轮子，节省开发人员时间，提高工作效率。谷歌作为大公司，当然会从日常的工作中提取中很多高效率的方法出来。所以就诞生了guava。</p><p>guava的优点：</p><ul><li>高效设计良好的API，被Google的开发者设计，实现和使用</li><li>遵循高效的java语法实践</li><li>使代码更刻度，简洁，简单</li><li>节约时间，资源，提高生产力</li></ul><p>Guava工程包含了若干被Google的 Java项目广泛依赖 的核心库，例如：</p><ul><li>集合 [collections]</li><li>缓存 [caching]</li><li>原生类型支持 [primitives support]</li><li>并发库 [concurrency libraries]</li><li>通用注解 [common annotations]</li><li>字符串处理 [string processing]</li><li>I/O 等等。</li></ul><p>这里借用龙果学院深入浅出Guava课程的一张图</p><p><img src="http://image.laijianfeng.org/20180830_234930.png" alt="龙果学院深入浅出Guava"></p><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>引入gradle依赖（引入Jar包）</p><pre><code>compile &#39;com.google.guava:guava:26.0-jre&#39;</code></pre><h4 id="1-集合的创建"><a href="#1-集合的创建" class="headerlink" title="1.集合的创建"></a>1.集合的创建</h4><pre><code>// 普通Collection的创建List&lt;String&gt; list = Lists.newArrayList();Set&lt;String&gt; set = Sets.newHashSet();Map&lt;String, String&gt; map = Maps.newHashMap();// 不变Collection的创建ImmutableList&lt;String&gt; iList = ImmutableList.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;);ImmutableSet&lt;String&gt; iSet = ImmutableSet.of(&quot;e1&quot;, &quot;e2&quot;);ImmutableMap&lt;String, String&gt; iMap = ImmutableMap.of(&quot;k1&quot;, &quot;v1&quot;, &quot;k2&quot;, &quot;v2&quot;);</code></pre><p>创建不可变集合 先理解什么是immutable(不可变)对象</p><ul><li>在多线程操作下，是线程安全的</li><li>所有不可变集合会比可变集合更有效的利用资源</li><li>中途不可改变</li></ul><pre><code>ImmutableList&lt;String&gt; immutableList = ImmutableList.of(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;);</code></pre><p>这声明了一个<strong>不可变</strong>的List集合，List中有数据1，2，3，4。类中的 操作集合的方法（譬如add, set, sort, replace等）都被声明过期，并且抛出异常。 而没用guava之前是需要声明并且加各种包裹集合才能实现这个功能</p><pre><code>  // add 方法  @Deprecated @Override  public final void add(int index, E element) {    throw new UnsupportedOperationException();  }</code></pre><p><strong>当我们需要一个map中包含key为String类型，value为List类型的时候</strong>，以前我们是这样写的</p><pre><code>Map&lt;String,List&lt;Integer&gt;&gt; map = new HashMap&lt;String,List&lt;Integer&gt;&gt;();List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();list.add(1);list.add(2);map.put(&quot;aa&quot;, list);System.out.println(map.get(&quot;aa&quot;));//[1, 2]</code></pre><p>而现在</p><pre><code>Multimap&lt;String,Integer&gt; map = ArrayListMultimap.create();        map.put(&quot;aa&quot;, 1);map.put(&quot;aa&quot;, 2);System.out.println(map.get(&quot;aa&quot;));  //[1, 2]</code></pre><p><strong>其他的黑科技集合</strong></p><pre><code>MultiSet: 无序+可重复   count()方法获取单词的次数  增强了可读性+操作简单创建方式:  Multiset&lt;String&gt; set = HashMultiset.create();Multimap: key-value  key可以重复  创建方式: Multimap&lt;String, String&gt; teachers = ArrayListMultimap.create();BiMap: 双向Map(Bidirectional Map) 键与值都不能重复创建方式:  BiMap&lt;String, String&gt; biMap = HashBiMap.create();Table: 双键的Map Map--&gt; Table--&gt;rowKey+columnKey+value  //和sql中的联合主键有点像创建方式: Table&lt;String, String, Integer&gt; tables = HashBasedTable.create();...等等(guava中还有很多java里面没有给出的集合类型)</code></pre><h4 id="2-将集合转换为特定规则的字符串"><a href="#2-将集合转换为特定规则的字符串" class="headerlink" title="2.将集合转换为特定规则的字符串"></a>2.将集合转换为特定规则的字符串</h4><p>以前我们将list转换为特定规则的字符串是这样写的:</p><pre><code>//use javaList&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(&quot;aa&quot;);list.add(&quot;bb&quot;);list.add(&quot;cc&quot;);String str = &quot;&quot;;for(int i=0; i&lt;list.size(); i++){    str = str + &quot;-&quot; +list.get(i);}//str 为-aa-bb-cc//use guavaList&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(&quot;aa&quot;);list.add(&quot;bb&quot;);list.add(&quot;cc&quot;);String result = Joiner.on(&quot;-&quot;).join(list);//result为  aa-bb-cc</code></pre><p>把map集合转换为特定规则的字符串</p><pre><code>Map&lt;String, Integer&gt; map = Maps.newHashMap();map.put(&quot;xiaoming&quot;, 12);map.put(&quot;xiaohong&quot;,13);String result = Joiner.on(&quot;,&quot;).withKeyValueSeparator(&quot;=&quot;).join(map);// result为 xiaoming=12,xiaohong=13</code></pre><h4 id="3-将String转换为特定的集合"><a href="#3-将String转换为特定的集合" class="headerlink" title="3.将String转换为特定的集合"></a>3.将String转换为特定的集合</h4><pre><code>//use javaList&lt;String&gt; list = new ArrayList&lt;String&gt;();String a = &quot;1-2-3-4-5-6&quot;;String[] strs = a.split(&quot;-&quot;);for(int i=0; i&lt;strs.length; i++){    list.add(strs[i]);}//use guavaString str = &quot;1-2-3-4-5-6&quot;;List&lt;String&gt; list = Splitter.on(&quot;-&quot;).splitToList(str);//list为  [1, 2, 3, 4, 5, 6]</code></pre><p>如果</p><pre><code>str=&quot;1-2-3-4- 5-  6  &quot;;</code></pre><p>guava还可以使用 <code>omitEmptyStrings().trimResults()</code> 去除空串与空格</p><pre><code>String str = &quot;1-2-3-4-  5-  6   &quot;;  List&lt;String&gt; list = Splitter.on(&quot;-&quot;).omitEmptyStrings().trimResults().splitToList(str);System.out.println(list);</code></pre><p><strong>将String转换为map</strong></p><pre><code>String str = &quot;xiaoming=11,xiaohong=23&quot;;Map&lt;String,String&gt; map = Splitter.on(&quot;,&quot;).withKeyValueSeparator(&quot;=&quot;).split(str);</code></pre><h4 id="4-guava还支持多个字符切割，或者特定的正则分隔"><a href="#4-guava还支持多个字符切割，或者特定的正则分隔" class="headerlink" title="4.guava还支持多个字符切割，或者特定的正则分隔"></a>4.guava还支持多个字符切割，或者特定的正则分隔</h4><pre><code>String input = &quot;aa.dd,,ff,,.&quot;;List&lt;String&gt; result = Splitter.onPattern(&quot;[.|,]&quot;).omitEmptyStrings().splitToList(input);</code></pre><p>关于字符串的操作 都是在Splitter这个类上进行的</p><pre><code>// 判断匹配结果boolean result = CharMatcher.inRange(&#39;a&#39;, &#39;z&#39;).or(CharMatcher.inRange(&#39;A&#39;, &#39;Z&#39;)).matches(&#39;K&#39;); //true// 保留数字文本  CharMatcher.digit() 已过时   retain 保留//String s1 = CharMatcher.digit().retainFrom(&quot;abc 123 efg&quot;); //123String s1 = CharMatcher.inRange(&#39;0&#39;, &#39;9&#39;).retainFrom(&quot;abc 123 efg&quot;); // 123// 删除数字文本  remove 删除// String s2 = CharMatcher.digit().removeFrom(&quot;abc 123 efg&quot;);    //abc  efgString s2 = CharMatcher.inRange(&#39;0&#39;, &#39;9&#39;).removeFrom(&quot;abc 123 efg&quot;); // abc  efg</code></pre><h4 id="5-集合的过滤"><a href="#5-集合的过滤" class="headerlink" title="5. 集合的过滤"></a>5. 集合的过滤</h4><p>我们对于集合的过滤，思路就是迭代，然后再具体对每一个数判断，这样的代码放在程序中，难免会显得很臃肿，虽然功能都有，但是很不好看。</p><p>guava写法</p><pre><code>//按照条件过滤ImmutableList&lt;String&gt; names = ImmutableList.of(&quot;begin&quot;, &quot;code&quot;, &quot;Guava&quot;, &quot;Java&quot;);Iterable&lt;String&gt; fitered = Iterables.filter(names, Predicates.or(Predicates.equalTo(&quot;Guava&quot;), Predicates.equalTo(&quot;Java&quot;)));System.out.println(fitered); // [Guava, Java]//自定义过滤条件   使用自定义回调方法对Map的每个Value进行操作ImmutableMap&lt;String, Integer&gt; m = ImmutableMap.of(&quot;begin&quot;, 12, &quot;code&quot;, 15);        // Function&lt;F, T&gt; F表示apply()方法input的类型，T表示apply()方法返回类型        Map&lt;String, Integer&gt; m2 = Maps.transformValues(m, new Function&lt;Integer, Integer&gt;() {            public Integer apply(Integer input) {                if(input&gt;12){                    return input;                }else{                    return input+1;                }            }        });System.out.println(m2);   //{begin=13, code=15}</code></pre><p>set的交集, 并集, 差集</p><pre><code>HashSet setA = newHashSet(1, 2, 3, 4, 5);  HashSet setB = newHashSet(4, 5, 6, 7, 8);  SetView union = Sets.union(setA, setB);    System.out.println(&quot;union:&quot;);  for (Integer integer : union)      System.out.println(integer);           //union 并集:12345867SetView difference = Sets.difference(setA, setB);  System.out.println(&quot;difference:&quot;);  for (Integer integer : difference)      System.out.println(integer);        //difference 差集:123SetView intersection = Sets.intersection(setA, setB);  System.out.println(&quot;intersection:&quot;);  for (Integer integer : intersection)      System.out.println(integer);  //intersection 交集:45</code></pre><p>map的交集，并集，差集</p><pre><code>HashMap&lt;String, Integer&gt; mapA = Maps.newHashMap();mapA.put(&quot;a&quot;, 1);mapA.put(&quot;b&quot;, 2);mapA.put(&quot;c&quot;, 3);HashMap&lt;String, Integer&gt; mapB = Maps.newHashMap();mapB.put(&quot;b&quot;, 20);mapB.put(&quot;c&quot;, 3);mapB.put(&quot;d&quot;, 4);MapDifference differenceMap = Maps.difference(mapA, mapB);differenceMap.areEqual();Map entriesDiffering = differenceMap.entriesDiffering();Map entriesOnlyLeft = differenceMap.entriesOnlyOnLeft();Map entriesOnlyRight = differenceMap.entriesOnlyOnRight();Map entriesInCommon = differenceMap.entriesInCommon();System.out.println(entriesDiffering);   // {b=(2, 20)}System.out.println(entriesOnlyLeft);    // {a=1}System.out.println(entriesOnlyRight);   // {d=4}System.out.println(entriesInCommon);    // {c=3}</code></pre><h4 id="6-检查参数"><a href="#6-检查参数" class="headerlink" title="6.检查参数"></a>6.检查参数</h4><pre><code>//use javaif(list!=null &amp;&amp; list.size()&gt;0)&#39;&#39;&#39;if(str!=null &amp;&amp; str.length()&gt;0)&#39;&#39;&#39;if(str !=null &amp;&amp; !str.isEmpty())//use guavaif(!Strings.isNullOrEmpty(str))//use javaif (count &lt;= 0) {    throw new IllegalArgumentException(&quot;must be positive: &quot; + count);         }    //use guavaPreconditions.checkArgument(count &gt; 0, &quot;must be positive: %s&quot;, count);  </code></pre><p>免去了很多麻烦！并且会使你的代码看上去更好看。而不是代码里面充斥着 <code>!=null</code>， <code>!=&quot;&quot;</code></p><p><strong>检查是否为空,不仅仅是字符串类型，其他类型的判断，全部都封装在 Preconditions类里，里面的方法全为静态</strong></p><p>其中的一个方法的源码</p><pre><code>@CanIgnoreReturnValuepublic static &lt;T&gt; T checkNotNull(T reference) {    if (reference == null) {      throw new NullPointerException();    }    return reference;}</code></pre><table><thead><tr><th>方法声明（不包括额外参数）</th><th>描述</th><th>检查失败时抛出的异常</th></tr></thead><tbody><tr><td>checkArgument(boolean)</td><td>检查boolean是否为true，用来检查传递给方法的参数。</td><td>IllegalArgumentException</td></tr><tr><td>checkNotNull(T)</td><td>检查value是否为null，该方法直接返回value，因此可以内嵌使用checkNotNull。</td><td>NullPointerException</td></tr><tr><td>checkState(boolean)</td><td>用来检查对象的某些状态。</td><td>IllegalStateException</td></tr><tr><td>checkElementIndex(int index, int size)</td><td>检查index作为索引值对某个列表、字符串或数组是否有效。   index &gt; 0 &amp;&amp; index &lt; size</td><td>IndexOutOfBoundsException</td></tr><tr><td>checkPositionIndexes(int start, int end, int size)</td><td>检查[start,end]表示的位置范围对某个列表、字符串或数组是否有效</td><td>IndexOutOfBoundsException</td></tr></tbody></table><h4 id="7-MoreObjects"><a href="#7-MoreObjects" class="headerlink" title="7. MoreObjects"></a>7. MoreObjects</h4><p>这个方法是在Objects过期后官方推荐使用的替代品，该类最大的好处就是不用大量的重写 <code>toString</code>，用一种很优雅的方式实现重写，或者在某个场景定制使用。</p><pre><code>Person person = new Person(&quot;aa&quot;,11);String str = MoreObjects.toStringHelper(&quot;Person&quot;).add(&quot;age&quot;, person.getAge()).toString();System.out.println(str);  //输出Person{age=11}</code></pre><h4 id="8-强大的Ordering排序器"><a href="#8-强大的Ordering排序器" class="headerlink" title="8.强大的Ordering排序器"></a>8.强大的Ordering排序器</h4><p>排序器[Ordering]是Guava流畅风格比较器[Comparator]的实现，它可以用来为构建复杂的比较器，以完成集合排序的功能。</p><pre><code>natural()    对可排序类型做自然排序，如数字按大小，日期按先后排序usingToString()    按对象的字符串形式做字典排序[lexicographical ordering]from(Comparator)    把给定的Comparator转化为排序器reverse()    获取语义相反的排序器nullsFirst()    使用当前排序器，但额外把null值排到最前面。nullsLast()    使用当前排序器，但额外把null值排到最后面。compound(Comparator)    合成另一个比较器，以处理当前排序器中的相等情况。lexicographical()    基于处理类型T的排序器，返回该类型的可迭代对象Iterable&lt;T&gt;的排序器。onResultOf(Function)    对集合中元素调用Function，再按返回值用当前排序器排序。</code></pre><p>示例</p><pre><code>Person person = new Person(&quot;aa&quot;,14);  //String name  ,Integer agePerson ps = new Person(&quot;bb&quot;,13);Ordering&lt;Person&gt; byOrdering = Ordering.natural().nullsFirst().onResultOf(new Function&lt;Person,String&gt;(){    public String apply(Person person){        return person.age.toString();    }});byOrdering.compare(person, ps);System.out.println(byOrdering.compare(person, ps)); //1      person的年龄比ps大 所以输出1</code></pre><h4 id="9-计算中间代码的运行时间"><a href="#9-计算中间代码的运行时间" class="headerlink" title="9.计算中间代码的运行时间"></a>9.计算中间代码的运行时间</h4><pre><code>Stopwatch stopwatch = Stopwatch.createStarted();for(int i=0; i&lt;100000; i++){    // do some thing}long nanos = stopwatch.elapsed(TimeUnit.MILLISECONDS);System.out.println(nanos);</code></pre><p>TimeUnit 可以指定时间输出精确到多少时间</p><h4 id="10-文件操作"><a href="#10-文件操作" class="headerlink" title="10.文件操作"></a>10.文件操作</h4><p>以前我们写文件读取的时候要定义缓冲区，各种条件判断，各种 <code>$%#$@#</code></p><p>而现在我们只需要使用好guava的api 就能使代码变得简洁，并且不用担心因为写错逻辑而背锅了</p><pre><code>File file = new File(&quot;test.txt&quot;);List&lt;String&gt; list = null;try {    list = Files.readLines(file, Charsets.UTF_8);} catch (Exception e) {}Files.copy(from,to);  //复制文件Files.deleteDirectoryContents(File directory); //删除文件夹下的内容(包括文件与子文件夹)  Files.deleteRecursively(File file); //删除文件或者文件夹  Files.move(File from, File to); //移动文件URL url = Resources.getResource(&quot;abc.xml&quot;); //获取classpath根下的abc.xml文件url</code></pre><p>Files类中还有许多方法可以用，可以多多翻阅</p><h4 id="11-guava缓存"><a href="#11-guava缓存" class="headerlink" title="11.guava缓存"></a>11.guava缓存</h4><p>guava的缓存设计的比较巧妙，可以很精巧的使用。guava缓存创建分为两种，一种是CacheLoader,另一种则是callback方式</p><p>CacheLoader:</p><pre><code>LoadingCache&lt;String,String&gt; cahceBuilder=CacheBuilder                .newBuilder()                .build(new CacheLoader&lt;String, String&gt;(){                    @Override                    public String load(String key) throws Exception {                                String strProValue=&quot;hello &quot;+key+&quot;!&quot;;                                        return strProValue;                    }                });        System.out.println(cahceBuilder.apply(&quot;begincode&quot;));  //hello begincode!System.out.println(cahceBuilder.get(&quot;begincode&quot;)); //hello begincode!System.out.println(cahceBuilder.get(&quot;wen&quot;)); //hello wen!System.out.println(cahceBuilder.apply(&quot;wen&quot;)); //hello wen!System.out.println(cahceBuilder.apply(&quot;da&quot;));//hello da!cahceBuilder.put(&quot;begin&quot;, &quot;code&quot;);System.out.println(cahceBuilder.get(&quot;begin&quot;)); //code</code></pre><p>api中已经把apply声明为过期，声明中推荐使用get方法获取值</p><p>callback方式:</p><pre><code> Cache&lt;String, String&gt; cache = CacheBuilder.newBuilder().maximumSize(1000).build();              String resultVal = cache.get(&quot;code&quot;, new Callable&lt;String&gt;() {                  public String call() {                      String strProValue=&quot;begin &quot;+&quot;code&quot;+&quot;!&quot;;                                    return strProValue;                }              });   System.out.println(&quot;value : &quot; + resultVal); //value : begin code!</code></pre><p>以上只是guava使用的一小部分，guava是个大的工具类，第一版guava是2010年发布的，每一版的更新和迭代都是一种创新。</p><p>jdk的升级很多都是借鉴guava里面的思想来进行的。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>代码可以在 <a href="https://github.com/whirlys/elastic-example/tree/master/guava" target="_blank" rel="noopener">https://github.com/whirlys/elastic-example/tree/master/guava</a> 下载</p><p>细节请翻看 guava 文档 <a href="https://github.com/google/guava/wiki" target="_blank" rel="noopener">https://github.com/google/guava/wiki</a></p><blockquote><p>参考：<br><a href="https://my.oschina.net/u/2551035/blog/802634" target="_blank" rel="noopener">Google guava工具类的介绍和使用</a><br><a href="https://blog.csdn.net/ac_dao_di/article/details/53750028" target="_blank" rel="noopener">Guava工具类学习</a></p></blockquote><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Elasticsearch 中的 Guice</title>
      <link href="/2018/08/Elasticsearch-%E4%B8%AD%E7%9A%84-Guice/"/>
      <url>/2018/08/Elasticsearch-%E4%B8%AD%E7%9A%84-Guice/</url>
      <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>Elasticsearch 源代码中使用了Guice框架进行依赖注入. 为了方便阅读源码, 此处我先通过模仿ES guice的使用方式简单写了一个基本Demo 方便理解, 之后再来理一下ES的Guice使用. 编写的测试类原理图如下:</p><p><img src="http://image.laijianfeng.org/2778947-7847f61cf5180bdc.webp" alt="ES Guice Demo"></p><p>总共有两个Module，一个是ToolModule，<strong>用于绑定</strong>IAnimal接口、ITool接口以及Map对象. 另一个是HumanModule 用于绑定Person对象。   </p><p>其中Person的构造函数通过 <code>@Inject</code> 注解注入其他实例</p><p>gradle 需要引入的 Jar 包</p><pre><code>compile group: &#39;com.google.inject.extensions&#39;, name: &#39;guice-multibindings&#39;, version: &#39;4.2.0&#39;compile group: &#39;com.google.inject&#39;, name: &#39;guice&#39;, version: &#39;4.2.0&#39;</code></pre><h3 id="1、Demo"><a href="#1、Demo" class="headerlink" title="1、Demo"></a>1、Demo</h3><h4 id="iTool接口与实现类"><a href="#iTool接口与实现类" class="headerlink" title="iTool接口与实现类"></a>iTool接口与实现类</h4><pre><code>public interface ITool {    public void doWork();}</code></pre><pre><code>import com.whirly.guice.example.ITool;public class IToolImpl implements ITool {    @Override    public void doWork() {        System.out.println(&quot;use tool to work&quot;);    }}</code></pre><h4 id="IAnimal-接口与实现类"><a href="#IAnimal-接口与实现类" class="headerlink" title="IAnimal 接口与实现类"></a>IAnimal 接口与实现类</h4><pre><code>public interface IAnimal {    void work();}</code></pre><pre><code>public class IAnimalImpl implements IAnimal {    @Override    public void work() {        System.out.println(&quot;animals can also do work&quot;);    }}</code></pre><h4 id="ToolModule的实现-它绑了三个实例"><a href="#ToolModule的实现-它绑了三个实例" class="headerlink" title="ToolModule的实现, 它绑了三个实例"></a>ToolModule的实现, 它绑了三个实例</h4><pre><code>public class ToolModule extends AbstractModule {    @Override    protected void configure() {        //此处注入的实例可以注入到其他类的构造函数中, 只要那个类使用@Inject进行注入即可        bind(IAnimal.class).to(IAnimalImpl.class);        bind(ITool.class).to(IToolImpl.class);        // 注入Map实例        MapBinder&lt;String, String&gt; mapBinder = MapBinder.newMapBinder(binder(), String.class, String.class);        mapBinder.addBinding(&quot;test1&quot;).toInstance(&quot;test1&quot;);        mapBinder.addBinding(&quot;test2&quot;).toInstance(&quot;test2&quot;);    }}</code></pre><p><code>bind(IAnimal.class).to(IAnimalImpl.class);bind(ITool.class).to(IToolImpl.class);</code>  是将接口与其具体实现绑定起来</p><p><code>MapBinder&lt;String,String&gt; mapBinder =MapBinder.newMapBinder(binder(), String.class, String.class);mapBinder.addBinding(&quot;test1&quot;).toInstance(&quot;test1&quot;);mapBinder.addBinding(&quot;test2&quot;).toInstance(&quot;test2&quot;);</code> 则是完成Map的绑定. </p><p>后面来看看Person类和HumanModule</p><h4 id="Person-类"><a href="#Person-类" class="headerlink" title="Person 类"></a>Person 类</h4><pre><code>public class Person {    private IAnimal iAnimal;    private ITool iTool;    private Map&lt;String, String&gt; map;    @Inject    public Person(IAnimal iAnimal, ITool iTool, Map&lt;String, String&gt; map) {        this.iAnimal = iAnimal;        this.iTool = iTool;        this.map = map;    }    public void startwork() {        iTool.doWork();        iAnimal.work();        for (Map.Entry entry : map.entrySet()) {            System.out.println(&quot;注入的map 是 &quot; + entry.getKey() + &quot; value &quot; + entry.getValue());        }    }}</code></pre><p>Person 类中由 <code>IAnimal</code>、<code>ITool</code> 和 <code>Map&lt;String, String&gt;</code> 这三个接口定义的变量，对象将通过 <code>@Inject</code> 从构造方法中注入进来</p><pre><code>public class HumanModule extends AbstractModule {    @Override    protected void configure() {        bind(Person.class).asEagerSingleton();    }}</code></pre><p>Person类的构造函数是通过注入的方式，注入对象实例的</p><p>最后 <code>CustomModuleBuilder</code> 进行<strong>统一管理所有的Module</strong>，实例化所有Module中的对象. 完成依赖注入。</p><p>这里的CustomModuleBuilder是修改自Elasticsearch中的ModulesBuilder，其原理是一样的。</p><p>就是一个迭代器，<strong>内部封装的是Module集合, 统一管理所有的Module</strong></p><h4 id="CustomModuleBuilder-统一管理-Module"><a href="#CustomModuleBuilder-统一管理-Module" class="headerlink" title="CustomModuleBuilder 统一管理 Module"></a>CustomModuleBuilder 统一管理 Module</h4><pre><code>public class CustomModuleBuilder implements Iterable&lt;Module&gt; {    private final List&lt;Module&gt; modules = new ArrayList&lt;&gt;();    public CustomModuleBuilder add(Module... newModules) {        for (Module module : newModules) {            modules.add(module);        }        return this;    }    @Override    public Iterator&lt;Module&gt; iterator() {        return modules.iterator();    }    public Injector createInjector() {        Injector injector = Guice.createInjector(modules);        return injector;    }}</code></pre><p>这样就可以从Main方法是如何进行使用的</p><h4 id="Main-方法"><a href="#Main-方法" class="headerlink" title="Main 方法"></a>Main 方法</h4><pre><code>public class Main {    public static void main(String[] args) {        CustomModuleBuilder moduleBuilder = new CustomModuleBuilder();        moduleBuilder.add(new ToolModule());        moduleBuilder.add(new HumanModule());        Injector injector = moduleBuilder.createInjector();        Person person = injector.getInstance(Person.class);        person.startwork();    }}</code></pre><p>运行结果</p><pre><code>use tool to workanimals can also do work注入的map 是 test1 value test1注入的map 是 test2 value test2</code></pre><p>通过CustomModuleBuilder 的createInjector获取Injector 对象, 根据Injector 对象取相应的具体实例对象.</p><h3 id="2、ES-中Guice的使用"><a href="#2、ES-中Guice的使用" class="headerlink" title="2、ES 中Guice的使用"></a>2、ES 中Guice的使用</h3><p>ES中TransportClient初始化时的Guice的使用是这样的, 如下图所示</p><p><img src="http://image.laijianfeng.org/2778947-ab2035e865492a2b.png" alt="ES中TransportClient初始化时的Guice的使用（ES版本不是6.3.2）"></p><h4 id="TransportClient的初始化代码"><a href="#TransportClient的初始化代码" class="headerlink" title="TransportClient的初始化代码"></a>TransportClient的初始化代码</h4><p>Elasticsearch 6.3.2 </p><pre><code>private static ClientTemplate buildTemplate(Settings providedSettings, Settings defaultSettings,                                            Collection&lt;Class&lt;? extends Plugin&gt;&gt; plugins, HostFailureListener failureListner) {    // 省略 ...    try {        // 省略 ...        // 创建一个迭代器, 然后将各个Module通过add方法加入进去        ModulesBuilder modules = new ModulesBuilder();        // plugin modules must be added here, before others or we can get crazy injection errors...        for (Module pluginModule : pluginsService.createGuiceModules()) {            modules.add(pluginModule);        }        modules.add(b -&gt; b.bind(ThreadPool.class).toInstance(threadPool));        ActionModule actionModule = new ActionModule(true, settings, null, settingsModule.getIndexScopedSettings(),                settingsModule.getClusterSettings(), settingsModule.getSettingsFilter(), threadPool,                pluginsService.filterPlugins(ActionPlugin.class), null, null, null);        modules.add(actionModule);        CircuitBreakerService circuitBreakerService = Node.createCircuitBreakerService(settingsModule.getSettings(),            settingsModule.getClusterSettings());        resourcesToClose.add(circuitBreakerService);        PageCacheRecycler pageCacheRecycler = new PageCacheRecycler(settings);        BigArrays bigArrays = new BigArrays(pageCacheRecycler, circuitBreakerService);        resourcesToClose.add(bigArrays);        modules.add(settingsModule);        NetworkModule networkModule = new NetworkModule(settings, true, pluginsService.filterPlugins(NetworkPlugin.class), threadPool,            bigArrays, pageCacheRecycler, circuitBreakerService, namedWriteableRegistry, xContentRegistry, networkService, null);        final Transport transport = networkModule.getTransportSupplier().get();        final TransportService transportService = new TransportService(settings, transport, threadPool,            networkModule.getTransportInterceptor(),            boundTransportAddress -&gt; DiscoveryNode.createLocal(settings, new TransportAddress(TransportAddress.META_ADDRESS, 0),                UUIDs.randomBase64UUID()), null, Collections.emptySet());        modules.add((b -&gt; {            b.bind(BigArrays.class).toInstance(bigArrays);            b.bind(PluginsService.class).toInstance(pluginsService);            b.bind(CircuitBreakerService.class).toInstance(circuitBreakerService);            b.bind(NamedWriteableRegistry.class).toInstance(namedWriteableRegistry);            b.bind(Transport.class).toInstance(transport);            b.bind(TransportService.class).toInstance(transportService);            b.bind(NetworkService.class).toInstance(networkService);        }));        // 注入所有module下的实例        Injector injector = modules.createInjector();        final TransportClientNodesService nodesService =            new TransportClientNodesService(settings, transportService, threadPool, failureListner == null                ? (t, e) -&gt; {} : failureListner);        // construct the list of client actions        final List&lt;ActionPlugin&gt; actionPlugins = pluginsService.filterPlugins(ActionPlugin.class);        final List&lt;GenericAction&gt; clientActions =                actionPlugins.stream().flatMap(p -&gt; p.getClientActions().stream()).collect(Collectors.toList());        // add all the base actions        final List&lt;? extends GenericAction&lt;?, ?&gt;&gt; baseActions =                actionModule.getActions().values().stream().map(ActionPlugin.ActionHandler::getAction).collect(Collectors.toList());        clientActions.addAll(baseActions);        final TransportProxyClient proxy = new TransportProxyClient(settings, transportService, nodesService, clientActions);        List&lt;LifecycleComponent&gt; pluginLifecycleComponents = new ArrayList&lt;&gt;(pluginsService.getGuiceServiceClasses().stream()            .map(injector::getInstance).collect(Collectors.toList()));        resourcesToClose.addAll(pluginLifecycleComponents);        // 启动服务        transportService.start();        transportService.acceptIncomingRequests();        ClientTemplate transportClient = new ClientTemplate(injector, pluginLifecycleComponents, nodesService, proxy, namedWriteableRegistry);        resourcesToClose.clear();        return transportClient;    } finally {        IOUtils.closeWhileHandlingException(resourcesToClose);    }}</code></pre><p>可以看到确实是先通 <code>过ModulesBuilder modules = new ModulesBuilder()</code> 创建一个迭代器, 然后将各个Module通过add方法加入进去, 最后通过 <code>Injector injector = modules.createInjector();</code> 创建Injector对象, <strong>之后便可根据Injector对象去获取实例了</strong>. </p><p>各个Module会绑定自己所需要的实例, 这里以 SettingsModule 举例:</p><pre><code>public class SettingsModule extends AbstractModule {    private final Settings settings;    private final Set&lt;String&gt; settingsFilterPattern = new HashSet&lt;&gt;();    private final Map&lt;String, Setting&lt;?&gt;&gt; nodeSettings = new HashMap&lt;&gt;();    private final Map&lt;String, Setting&lt;?&gt;&gt; indexSettings = new HashMap&lt;&gt;();    private final Logger logger;    private final IndexScopedSettings indexScopedSettings;    private final ClusterSettings clusterSettings;    private final SettingsFilter settingsFilter;    public SettingsModule(Settings settings, Setting&lt;?&gt;... additionalSettings) {        this(settings, Arrays.asList(additionalSettings), Collections.emptyList());    }    @Override    public void configure(Binder binder) {        binder.bind(Settings.class).toInstance(settings);        binder.bind(SettingsFilter.class).toInstance(settingsFilter);        binder.bind(ClusterSettings.class).toInstance(clusterSettings);        binder.bind(IndexScopedSettings.class).toInstance(indexScopedSettings);    }    //...}</code></pre><p>可以看到它绑定了四个,分别是 Settings.class，SettingsFilter.class，ClusterSettings.class，IndexScopedSettings.class</p><p>它们的实例对象都可以通过Injector来获取</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>示例代码可在 <a href="https://github.com/whirlys/elastic-example/tree/master/guice" target="_blank" rel="noopener">https://github.com/whirlys/elastic-example/tree/master/guice</a> 处下载</p><blockquote><p>参考：<br>kason_zhang <a href="https://www.jianshu.com/p/0a1e6267b46f" target="_blank" rel="noopener">Elasticsearch Guice 的使用</a></p></blockquote><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Elasticsearch 分布式特性</title>
      <link href="/2018/08/Elasticsearch-%E5%88%86%E5%B8%83%E5%BC%8F%E7%89%B9%E6%80%A7/"/>
      <url>/2018/08/Elasticsearch-%E5%88%86%E5%B8%83%E5%BC%8F%E7%89%B9%E6%80%A7/</url>
      <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本文的主要内容：</p><ul><li>分布式介绍及cerebro</li><li>构建集群</li><li>副本与分片</li><li>集群状态与故障转移</li><li>文档分布式存储</li><li>脑裂问题</li><li>shard详解</li></ul><h3 id="分布式介绍及cerebro"><a href="#分布式介绍及cerebro" class="headerlink" title="分布式介绍及cerebro"></a>分布式介绍及cerebro</h3><p>ES支持集群模式，是一个分布式系统，其好处主要有两个：</p><ul><li>增大系统容量，如内存、磁盘，使得ES集群可以支持PB级的数据</li><li>提高系统可用性，即使部分节点停止服务，整个集群依然可以正常服务</li></ul><p>ES集群由多个ES实例组成</p><ul><li>不同集群通过集群名称来区分，可通过cluster.name进行修改，名称默认为elasticsearch</li><li>每个ES实例本质上是一个JVM进程，且有自己的名字，通过node.name进行修改</li></ul><h4 id="cerebro"><a href="#cerebro" class="headerlink" title="cerebro"></a>cerebro</h4><p>cerebro 是一个ES Web管理工具，项目地址 <a href="https://github.com/lmenezes/cerebro" target="_blank" rel="noopener">https://github.com/lmenezes/cerebro</a> </p><p>其配置文件为 conf/application.conf，启动 cerebro ，默认监听的地址为 0.0.0.0:9000</p><pre><code>bin/cerebro# 也可指定监听ip和端口号bin/cerebro -Dhttp.port=1234 -Dhttp.address=127.0.0.1</code></pre><p>访问 <a href="http://yourhost:9000" target="_blank" rel="noopener">http://yourhost:9000</a> ，填写要监控的 ES 地址：<a href="http://eshost:9200" target="_blank" rel="noopener">http://eshost:9200</a> 即可进入管理界面</p><p><img src="http://image.laijianfeng.org/20180825_150701.png" alt="cerebro管理界面"></p><p><img src="http://image.laijianfeng.org/20180825_151133.png" alt="cerebro 节点信息"></p><p><img src="http://image.laijianfeng.org/20180825_151323.png" alt="cerebro 集群配置"></p><p>在cerebro管理界面中我们可以看到 ES节点、索引、shard的分布、集群参数配置等多种信息</p><h3 id="构建集群"><a href="#构建集群" class="headerlink" title="构建集群"></a>构建集群</h3><p>如果只有一台机器，可以执行下面的命令，每次指定相同的集群名称，不同的节点名称和端口，即可在同一台机器上启动多个ES节点</p><pre><code>bin/elasticsearch -Ecluster.name=my_cluster -Enode.name=node1 -Ehttp.port=9200 -d</code></pre><p>作者的是在 virtualbox 上安装Ubuntu虚拟机，在安装好开发环境，正常启动ES之后，采取复制虚拟机的做法，复制后需要修改虚拟机的UUID，做法可自行上网搜索。</p><p>作者复制了两个，准备构建一个拥有三个ES节点的集群。启动虚拟机后可以进行关闭防火墙，配置hosts以使相互之间能够通过主机名访问，配置ssh免密访问等操作</p><p>分别修改ES节点中的 <code>cluster.name</code> 为相同名称，<code>node.name</code> 为各自的主机名，<code>network.host</code> 为 <code>0.0.0.0</code>，<code>discovery.zen.ping.unicast.hosts</code> 列表中中加入各自的 <code>node.name</code></p><p>在ES主目录下执行命令启动ES</p><pre><code>bin/elasticsearch</code></pre><p>查看日志可见集群搭建完毕</p><h4 id="Cluster-State-集群状态"><a href="#Cluster-State-集群状态" class="headerlink" title="Cluster State 集群状态"></a>Cluster State 集群状态</h4><p>与ES集群相关的数据称为cluster state，主要记录如下信息：</p><ul><li>节点信息，比如节点名称、连接地址等</li><li>索引信息，比如索引名称，配置等</li><li>其他。。</li></ul><h4 id="Master-Node-主节点"><a href="#Master-Node-主节点" class="headerlink" title="Master Node 主节点"></a>Master Node 主节点</h4><ul><li>可以修改cluster state的节点成为master节点，一个集群<strong>只能有一个</strong></li><li>cluster state存储在每个节点上，master维护最新版本并<strong>同步</strong>给其他节点</li><li>master节点是通过集群中所有节点<strong>选举产生</strong>的，可以<strong>被选举</strong>的节点成为master-eligible（候选）节点，相关配置如下：<code>node.master: true</code></li></ul><h4 id="Coordinating-Node"><a href="#Coordinating-Node" class="headerlink" title="Coordinating Node"></a>Coordinating Node</h4><ul><li><strong>处理请求</strong>的节点即为coordinating节点，该节点为所有节点的默认角色，不能取消</li><li>路由请求到正确的节点处理，比如创建索引的请求到master节点</li></ul><h4 id="Data-Node-数据节点"><a href="#Data-Node-数据节点" class="headerlink" title="Data Node 数据节点"></a>Data Node 数据节点</h4><ul><li><strong>存储数据</strong>的节点即为Data节点，默认节点都是data类型，相关配置如下：<code>node.data: true</code></li></ul><h3 id="副本与分片"><a href="#副本与分片" class="headerlink" title="副本与分片"></a>副本与分片</h3><h4 id="提高系统可用性"><a href="#提高系统可用性" class="headerlink" title="提高系统可用性"></a>提高系统可用性</h4><p>提高系统可用性可从两个方面考虑：服务可用性和数据可用性</p><p>服务可用性：</p><ul><li>2个节点的情况下，允许其中1个节点停止服务</li></ul><p>数据可用性</p><ul><li>引入副本（Replication）解决</li><li>每个节点上都有完备的数据</li></ul><h4 id="增大系统容量"><a href="#增大系统容量" class="headerlink" title="增大系统容量"></a>增大系统容量</h4><p>如何将数据分布于所有节点上？</p><ul><li>引入分片（shard）解决问题</li></ul><p>分片是ES支持PB级数据的基石</p><ul><li>分片存储了部分数据，可以分布于任意节点上</li><li>分片数在索引创建时指定且后续不允许再修改，默认为5个</li><li>分片有主分片和副本分片之分，以实现数据的高可用</li><li>副本分片的数据由主分片同步，可以有多个，从而提高读取的吞吐量</li></ul><h4 id="分片的分布"><a href="#分片的分布" class="headerlink" title="分片的分布"></a>分片的分布</h4><p>下图演示的是 3 个节点的集群中test_index的分片分布情况，创建时我们指定了3个分片和副本</p><pre><code>PUT test_index{  &quot;settings&quot;: {    &quot;number_of_replicas&quot;: 1,    &quot;number_of_shards&quot;: 3  }}</code></pre><p><img src="http://image.laijianfeng.org/20180825_164121.png" alt="主副分片的分布"></p><p>大致是均匀分布，实验中如果由于磁盘空间不足导致有分片未分配，为了测试可以将集群设置 <code>cluster.routing.allocation.disk.threshold_enabled</code> 设置为 false</p><ul><li><strong>此时增加节点是否能提高索引的数据容量？</strong></li></ul><p>不能，因为已经设置了分片数为 3 ，shard的数量已经确定，新增的节点无法利用，</p><ul><li><strong>此时增加副本数能否提高索引的读取吞吐量？</strong></li></ul><p>不能，因为新增的副本分片也是分布在这 3 台节点上，利用了同样的资源（CPU，内存，IO等）。如果要增加吞吐量，同时还需要增加节点的数量</p><ul><li><strong>分片数的设定很重要，需要提前规划好</strong><ul><li>过小会导致后续无法通过增加节点实现水平扩容</li><li>过大会导致一个节点上分布过多分片，造成资源浪费，同时会影响查询性能</li><li>shard的数量的确定：一般建议一个shard的数据量不要超过 <code>30G</code>，shard数量最小为 2</li></ul></li></ul><h3 id="Cluster-Health-集群健康"><a href="#Cluster-Health-集群健康" class="headerlink" title="Cluster Health 集群健康"></a>Cluster Health 集群健康</h3><p>通过如下API可以查看集群健康状况，状态status包括以下三种：</p><ul><li>green 健康状态，指所有主副分片都正常分配</li><li>yellow 指所有主分片都正常分配，但有副本分片未正常分配</li><li>red 有主分片未分配</li></ul><pre><code>GET _cluster/health# 结果{  &quot;cluster_name&quot;: &quot;elasticsearch&quot;,  &quot;status&quot;: &quot;yellow&quot;,  &quot;timed_out&quot;: false,  &quot;number_of_nodes&quot;: 1,  &quot;number_of_data_nodes&quot;: 1,  &quot;active_primary_shards&quot;: 115,  &quot;active_shards&quot;: 115,  &quot;relocating_shards&quot;: 0,  &quot;initializing_shards&quot;: 0,  &quot;unassigned_shards&quot;: 111,  &quot;delayed_unassigned_shards&quot;: 0,  &quot;number_of_pending_tasks&quot;: 0,  &quot;number_of_in_flight_fetch&quot;: 0,  &quot;task_max_waiting_in_queue_millis&quot;: 0,  &quot;active_shards_percent_as_number&quot;: 50.88495575221239}</code></pre><h4 id="Failover-故障转移"><a href="#Failover-故障转移" class="headerlink" title="Failover 故障转移"></a>Failover 故障转移</h4><p>集群由 3 个节点组成，名称分别为 master，Hadoop2，Hadoop3， 其中 master 为主节点，集群状态status为 green</p><p><img src="http://image.laijianfeng.org/20180825_174406.png" alt="集群状态green"></p><p><strong>如果此时 master 所在机器宕机导致服务终止，此时集群如何处理？</strong></p><p>Hadoop2 和 Hadoop3 发现 master 无法响应一段时间后会发起 master 主节点选举，比如这里选择 Hadoop2 为 master 节点。由于此时主分片 P0 和 P2 下线，集群状态变为 Red</p><p><img src="http://image.laijianfeng.org/20180825_174933.png" alt="节点master宕机"></p><p>node2 发现主分片 P0 和 P2 未分配，将 R0 和 R2 提升为主分片，此时由于所有主分片都正常分配，集群状态变为 yellow</p><p><img src="http://image.laijianfeng.org/20180825_175028.png" alt="image"></p><p>Hadoop2 为 P0 和 P2 生成新的副本，集群状态变为绿色</p><p><img src="http://image.laijianfeng.org/20180825_175235.png" alt="image"></p><p>最后看看 Hadoop2 打印的日志</p><p><img src="http://image.laijianfeng.org/20180825_175517.png" alt="image"></p><h3 id="文档分布式存储"><a href="#文档分布式存储" class="headerlink" title="文档分布式存储"></a>文档分布式存储</h3><p>文档最终会存储在分片上。文档选择分片需要文档到分片的<strong>映射算法</strong>，目的是使得文档均匀分布在所有分片上，以充分利用资源。</p><p>算法：</p><ul><li>随机选择或者round-robin算法？不可取，因为需要维护文档到分片的映射关系，成本巨大</li><li><strong>根据文档值实时计算对应的分片</strong></li></ul><h4 id="文档到分片的映射算法"><a href="#文档到分片的映射算法" class="headerlink" title="文档到分片的映射算法"></a>文档到分片的映射算法</h4><p>ES通过如下的公式计算文档对应的分片</p><ul><li><code>shard = hash(routing) % number_of_primary_shards</code></li><li>hash算法保证可以将数据均匀地分散在分片中</li><li>routing是一个关键参数，默认是文档id，也可以自行指定</li><li>number_of_primary_shards是主分片数</li></ul><p>该算法与主分片数相关，这也是分片数一旦确定后便不能更改的原因</p><h4 id="文档创建流程"><a href="#文档创建流程" class="headerlink" title="文档创建流程"></a>文档创建流程</h4><ol><li>Client向node3发起创建文档的请求</li><li>node3通过routing计算该文档应该存储在shard1上，查询cluster state后确认主分片P1在node2上，然后转发创建文档的请求到node2</li><li>P1 接收并执行创建文档请求后，将同样的请求发送到副本分片R1</li><li>R1接收并执行创建文档请求后，通知P1成功的结果</li><li>P1接收副本分片结果后，通知node3创建成功</li><li>node3返回结果到Client</li></ol><p><img src="http://image.laijianfeng.org/20180825_181026.png" alt="文档创建流程"></p><h4 id="文档读取流程"><a href="#文档读取流程" class="headerlink" title="文档读取流程"></a>文档读取流程</h4><ol><li>Client向node3发起获取文档1的请求</li><li>node3通过routing计算该文档在shard1上，查询cluster state后获取shard1的主副分片列表，然后以轮询的机制获取一个shard，比如这里是R1，然后转发读取文档的请求到node1</li><li>R1接收并执行读取文档请求后，将结果返回node3</li><li>node3返回结果给client</li></ol><p><img src="http://image.laijianfeng.org/20180825_181511.png" alt="文档读取流程"></p><h4 id="文档批量创建的流程"><a href="#文档批量创建的流程" class="headerlink" title="文档批量创建的流程"></a>文档批量创建的流程</h4><ol><li>client向node3发起批量创建文档的请求（bulk）</li><li>node3通过routing计算所有文档对应的shard，然后按照主shard分配对应执行的操作，同时发送请求到涉及的主shard，比如这里3个主shard都需要参与</li><li>主shard接收并执行请求后，将同样的请求同步到对应的副本shard</li><li>副本shard执行结果后返回到主shard，主shard再返回node3</li><li>node3整合结果后返回client</li></ol><p><img src="http://image.laijianfeng.org/20180825_181725.png" alt="文档批量创建的流程 bulk"></p><h4 id="文档批量读取的流程"><a href="#文档批量读取的流程" class="headerlink" title="文档批量读取的流程"></a>文档批量读取的流程</h4><ol><li>client向node3发起批量获取所有文档的请求（mget）</li><li>node3通过routing计算所有文档对应的shard，然后通过轮询的机制获取要参与shard，按照shard投建mget请求，通过发送请求到涉及shard，比如这里有2个shard需要参与</li><li>R1，R2返回文档结果</li><li>node3返回结果给client</li></ol><p><img src="http://image.laijianfeng.org/20180825_182023.png" alt="文档批量读取的流程 mget"></p><h3 id="脑裂问题"><a href="#脑裂问题" class="headerlink" title="脑裂问题"></a>脑裂问题</h3><p>脑裂问题，英文为split-brain，是分布式系统中的经典网络问题，如下图所示：</p><p>3个节点组成的集群，突然node1的网络和其他两个节点中断<br><img src="http://image.laijianfeng.org/20180807_1234.png" alt="image"></p><p>node2与node3会重新选举master，比如node2成为了新的master，此时会更新cluster state</p><p>node1自己组成集群后，也更新cluster state</p><p>同一个集群有两个master，而且维护不同的cluster state，网络恢复后无法选择正确的master</p><p><img src="http://image.laijianfeng.org/20180807_1235.png" alt="image"></p><p><strong>解决方案</strong>为仅在可选举master-eligible节点数大于等于quorum时才可以进行master选举</p><ul><li><code>quorum = master-eligible节点数/2 + 1</code>，例如3个master-eligible节点时，quorum 为2 </li><li>设定 <code>discovery.zen.minimun_master_nodes</code> 为 <code>quorum</code> 即可避免脑裂问题</li></ul><p><img src="http://image.laijianfeng.org/20180807_1236.png" alt="image"></p><h3 id="倒排索引的不可变更"><a href="#倒排索引的不可变更" class="headerlink" title="倒排索引的不可变更"></a>倒排索引的不可变更</h3><p>倒排索引一旦生成，不能更改<br>其好处如下：</p><ul><li>不用考虑并发写文件的问题，杜绝了锁机制带来的性能问题</li><li>由于文件不再更改，可以充分利用文件系统缓存，只需载入一次，只要内存足够，对该文件的读取都会从内存读取，性能高</li><li>利于生成缓存数据</li><li>利于对文件进行压缩存储，节省磁盘和内存存储空间</li></ul><p>坏处为需要写入新文档时，必须重新构建倒排索引文件，然后替换老文件后，新文档才能被检索，导致文档实时性差</p><h3 id="文档搜索实时性"><a href="#文档搜索实时性" class="headerlink" title="文档搜索实时性"></a>文档搜索实时性</h3><p><strong>解决方案</strong>是新文档直接生成新的倒排索引文件，查询的时候同时查询所有的倒排文件，然后做结果的汇总计算即可</p><p>Lucene便是采用了这种方案，它构建的单个倒排索引称为segment，合在一起称为index，与ES中的Index概念不同，ES中的一个shard对应一个Lucene Index</p><p>Lucene会有一个专门的文件来记录所有的segment信息，称为commit point<br><img src="http://image.laijianfeng.org/20180807_1237.png" alt="image"></p><h4 id="refresh"><a href="#refresh" class="headerlink" title="refresh"></a>refresh</h4><p>segment写入磁盘的过程依然很耗时，可以借助文件系统缓存的特性，现将segment在缓存中创建并开放查询来进一步提升实时性，该过程在ES中被称为<code>refresh</code></p><p>在refresh之前文档会先存储在一个buffer中，refresh时将buffer中的所有文档清空并生成segment</p><p>ES默认每1秒执行一次refresh，因此文档的实时性被提高到1秒，这也是ES被称为 近实时(Near Real Time)的原因<br><img src="http://image.laijianfeng.org/20180807_1238.png" alt="image"></p><h4 id="translog"><a href="#translog" class="headerlink" title="translog"></a>translog</h4><p>如果在内存中的segment还没有写入磁盘前发生了宕机，那么其中的文档就无法恢复了，如何解决这个问题呢？</p><ul><li>ES引入translog机制，写入文档到buffer时，同时将该操作写入translog</li><li>translog文件会即时写入磁盘(fsync)，6.x默认每个请求都会落盘</li></ul><p><img src="http://image.laijianfeng.org/20180807_1345.png" alt="image"></p><h4 id="flush"><a href="#flush" class="headerlink" title="flush"></a>flush</h4><p>flush负责将内存中的segment写入磁盘，主要做成如下的工作：</p><ul><li>将translog写入磁盘</li><li>将index buffer清空，其中的文档生成一个新的segment，相当于一个refresh操作</li><li>更新commit point并写入磁盘</li><li>执行fsync操作，将内存中的segment写入磁盘</li><li>删除旧的translog文件</li></ul><p><img src="http://image.laijianfeng.org/20180807_1239.png" alt="image"></p><p>flush发生的时机主要有如下几种情况：</p><ul><li>间隔时间达到时，默认是30分钟，5.x之前可以通过<code>index.translog.flush_threshold_period</code>修改，之后无法修改</li><li>translog占满时，其大小可以通过<code>index.translog.flush_threshold_size</code>控制，默认是512mb，每个index有自己的translog</li></ul><h4 id="refresh-1"><a href="#refresh-1" class="headerlink" title="refresh"></a>refresh</h4><p>refresh发生的时机主要有如下几种情况：</p><ul><li>间隔时间达到时，通过<code>index.settings.refresh_interval</code>来设定，默认是1秒</li><li><code>index.buffer</code>占满时，其大小通过<code>indices.memory.index_buffer_size</code>设置，默认为JVM heap的10%，所有shard共享</li><li>flush发生时也会发生refresh</li></ul><h4 id="删除与更新文档"><a href="#删除与更新文档" class="headerlink" title="删除与更新文档"></a>删除与更新文档</h4><p>segment一旦生成就不能更改，那么如果你要删除文档该如何操作？</p><ul><li>Lucene专门维护一个<code>.del</code>文件，记录所有已经删除的文档，注意<code>.del</code>上记录的是文档在Lucene内部的id</li><li>在查询结果返回前会过滤掉<code>.del</code>中所有的文档</li></ul><p>要更新文档如何进行呢？</p><ul><li>首先删除文档，然后再创建新文档</li></ul><h4 id="整体视角"><a href="#整体视角" class="headerlink" title="整体视角"></a>整体视角</h4><p>ES Index与Lucene Index的术语对照如下所示：<br><img src="http://image.laijianfeng.org/20180807_1346.png" alt="image"></p><h4 id="Segment-Merging"><a href="#Segment-Merging" class="headerlink" title="Segment Merging"></a>Segment Merging</h4><p>随着segment的增多，由于一次查询的segment数增多，查询速度会变慢<br>ES会定时在后台进行segment merge的操作，减少segment的数量<br>通过force_merge api可以手动强制做segment merge的操作</p><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>23个最有用的ES检索技巧(Java API实现)</title>
      <link href="/2018/08/23%E4%B8%AA%E6%9C%80%E6%9C%89%E7%94%A8%E7%9A%84ES%E6%A3%80%E7%B4%A2%E6%8A%80%E5%B7%A7-Java-API%E5%AE%9E%E7%8E%B0/"/>
      <url>/2018/08/23%E4%B8%AA%E6%9C%80%E6%9C%89%E7%94%A8%E7%9A%84ES%E6%A3%80%E7%B4%A2%E6%8A%80%E5%B7%A7-Java-API%E5%AE%9E%E7%8E%B0/</url>
      <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本文是对 <code>23个最有用的Elasticseaerch检索技巧</code> 一文提到的ES检索技巧进行 Java API 的简单实现，但仅限于简单实现，并不考虑包括参数校验，异常处理，日志处理，安全等问题，仅供参考</p><p>代码见 <a href="https://github.com/whirlys/elastic-example/tree/master/UsefullESSearchSkill" target="_blank" rel="noopener">UsefullESSearchSkill</a> ,<strong>原查询语句请对照原文</strong></p><h4 id="运行环境"><a href="#运行环境" class="headerlink" title="运行环境"></a>运行环境</h4><p>JDK version : 10.0.2<br>gradle version : 4.7<br>Elasticsearch version : 6.3.2<br>IDEA version : 2018.2</p><p>运行前请启动 ES 实例，并修改 <code>application.properties</code> 文件中的ES配置</p><h3 id="类介绍"><a href="#类介绍" class="headerlink" title="类介绍"></a>类介绍</h3><h4 id="实体类-Book"><a href="#实体类-Book" class="headerlink" title="实体类 Book"></a>实体类 Book</h4><p>注意：日期 publish_date 的类型设置为 String 是避免 Java 到 ES 之间复杂的转换工作，在ES中该字段仍然被识别为 date 类型</p><pre><code>public class Book {    public static SimpleDateFormat simpleDateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;);    private String id;    private String title;    private List&lt;String&gt; authors;    private String summary;    private String publish_date;    private Integer num_reviews;    private String publisher;    ...}</code></pre><h4 id="公共类-Constants"><a href="#公共类-Constants" class="headerlink" title="公共类 Constants"></a>公共类 Constants</h4><p>定义了一些常用的常量</p><pre><code>public class Constants {    // 字段名    public static String ID = &quot;id&quot;;    public static String TITLE = &quot;title&quot;;    public static String AUTHORS = &quot;authors&quot;;    public static String SUMMARY = &quot;summary&quot;;    public static String PUBLISHDATE = &quot;publish_date&quot;;    public static String PUBLISHER = &quot;publisher&quot;;    public static String NUM_REVIEWS = &quot;num_reviews&quot;;    public static String TITLE_KEYWORD = &quot;title.keyword&quot;;    public static String PUBLISHER_KEYWORD = &quot;publisher.keyword&quot;;    // 过滤要返回的字段    public static String[] fetchFieldsTSPD = {ID, TITLE, SUMMARY, PUBLISHDATE};    public static String[] fetchFieldsTA = {ID, TITLE, AUTHORS};    public static String[] fetchFieldsSA = {ID, SUMMARY, AUTHORS};    public static String[] fetchFieldsTSA = {ID, TITLE, SUMMARY, AUTHORS};    public static String[] fetchFieldsTPPD = {ID, TITLE, PUBLISHER, PUBLISHDATE};    public static String[] fetchFieldsTSPN = {ID, TITLE, SUMMARY, PUBLISHER, NUM_REVIEWS};    // 高亮    public static HighlightBuilder highlightS = new HighlightBuilder().field(SUMMARY);}</code></pre><h4 id="公共类-EsConfig"><a href="#公共类-EsConfig" class="headerlink" title="公共类 EsConfig"></a>公共类 EsConfig</h4><p>创建 ES 客户端实例，ES 客户端用于与 ES 集群进行交互</p><pre><code>@Configurationpublic class EsConfig {    @Value(&quot;${elasticsearch.cluster-nodes}&quot;)    private String clusterNodes;    @Value(&quot;${elasticsearch.cluster-name}&quot;)    private String clusterName;    @Bean    public Client client() {        Settings settings = Settings.builder().put(&quot;cluster.name&quot;, clusterName)                .put(&quot;client.transport.sniff&quot;, true).build();        TransportClient client = new PreBuiltTransportClient(settings);        try {            if (clusterNodes != null &amp;&amp; !&quot;&quot;.equals(clusterNodes)) {                for (String node : clusterNodes.split(&quot;,&quot;)) {                    String[] nodeInfo = node.split(&quot;:&quot;);                    client.addTransportAddress(new TransportAddress(InetAddress.getByName(nodeInfo[0]), Integer.parseInt(nodeInfo[1])));                }            }        } catch (UnknownHostException e) {        }        return client;    }}</code></pre><h4 id="数据获取工具类-DataUtil"><a href="#数据获取工具类-DataUtil" class="headerlink" title="数据获取工具类 DataUtil"></a>数据获取工具类 DataUtil</h4><p>这里的数据也就是 <code>23个最有用的ES检索技巧</code> 文中用于实验的4条数据</p><pre><code>public class DataUtil {    public static SimpleDateFormat dateFormater = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;);    /**     * 模拟获取数据     */    public static List&lt;Book&gt; batchData() {        List&lt;Book&gt; list = new LinkedList&lt;&gt;();        Book book1 = new Book(&quot;1&quot;, &quot;Elasticsearch: The Definitive Guide&quot;, Arrays.asList(&quot;clinton gormley&quot;, &quot;zachary tong&quot;),                &quot;A distibuted real-time search and analytics engine&quot;, &quot;2015-02-07&quot;, 20, &quot;oreilly&quot;);        Book book2 = new Book(&quot;2&quot;, &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;, Arrays.asList(&quot;grant ingersoll&quot;, &quot;thomas morton&quot;, &quot;drew farris&quot;),                &quot;organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization&quot;,                &quot;2013-01-24&quot;, 12, &quot;manning&quot;);        Book book3 = new Book(&quot;3&quot;, &quot;Elasticsearch in Action&quot;, Arrays.asList(&quot;radu gheorge&quot;, &quot;matthew lee hinman&quot;, &quot;roy russo&quot;),                &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;,                &quot;2015-12-03&quot;, 18, &quot;manning&quot;);        Book book4 = new Book(&quot;4&quot;, &quot;Solr in Action&quot;, Arrays.asList(&quot;trey grainger&quot;, &quot;timothy potter&quot;), &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,                &quot;2014-04-05&quot;, 23, &quot;manning&quot;);        list.add(book1);        list.add(book2);        list.add(book3);        list.add(book4);        return list;    }    public static Date parseDate(String dateStr) {        try {            return dateFormater.parse(dateStr);        } catch (ParseException e) {        }        return null;    }</code></pre><h4 id="公共查询工具类-CommonQueryUtils"><a href="#公共查询工具类-CommonQueryUtils" class="headerlink" title="公共查询工具类 CommonQueryUtils"></a>公共查询工具类 CommonQueryUtils</h4><p>对执行完ES查询请求后的数据进行解析</p><pre><code>public class CommonQueryUtils {    public static Gson gson = new GsonBuilder().setDateFormat(&quot;YYYY-MM-dd&quot;).create();    /**     * 处理ES返回的数据，封装     */    public static List&lt;Book&gt; parseResponse(SearchResponse searchResponse) {        List&lt;Book&gt; list = new LinkedList&lt;&gt;();        for (SearchHit hit : searchResponse.getHits().getHits()) {            // 用gson直接解析            Book book = gson.fromJson(hit.getSourceAsString(), Book.class);            list.add(book);        }        return list;    }    /**     * 解析完数据后，构建 Response 对象     */    public static Response&lt;List&lt;Book&gt;&gt; buildResponse(SearchResponse searchResponse) {        // 超时处理        if (searchResponse.isTimedOut()) {            return new Response&lt;&gt;(ResponseCode.ESTIMEOUT);        }        // 处理ES返回的数据        List&lt;Book&gt; list = parseResponse(searchResponse);        // 有shard执行失败        if (searchResponse.getFailedShards() &gt; 0) {            return new Response&lt;&gt;(ResponseCode.FAILEDSHARDS, list);        }        return new Response&lt;&gt;(ResponseCode.OK, list);    }    ...}</code></pre><h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><h4 id="BulkTests"><a href="#BulkTests" class="headerlink" title="BulkTests"></a>BulkTests</h4><p>创建索引，以及使用 bulk API 批量插入数据</p><pre><code>@RunWith(SpringRunner.class)@SpringBootTestpublic class BulkTests {    // 在Test中 Autowired需要引入包 org.elasticsearch.plugin:transport-netty4-client:6.3.2，否则异常找不到Transport类    @Autowired    private Client client;    @Value(&quot;${elasticsearch.bookIndex}&quot;)    private String bookIndex;    @Value(&quot;${elasticsearch.bookType}&quot;)    private String bookType;    private Gson gson = new GsonBuilder().setDateFormat(&quot;YYYY-MM-dd&quot;).create();    /**     * 创建索引，设置 settings，设置mappings     */    @Test    public void createIndex() {        int settingShards = 1;        int settingReplicas = 0;        // 判断索引是否存在，存在则删除        IndicesExistsResponse indicesExistsResponse = client.admin().indices().prepareExists(bookIndex).get();        if (indicesExistsResponse.isExists()) {            System.out.println(&quot;索引 &quot; + bookIndex + &quot; 存在！&quot;);            // 删除索引，防止报异常  ResourceAlreadyExistsException[index [bookdb_index/yL05ZfXFQ4GjgOEM5x8tFQ] already exists            DeleteIndexResponse deleteResponse = client.admin().indices().prepareDelete(bookIndex).get();            if (deleteResponse.isAcknowledged()){                System.out.println(&quot;索引&quot; + bookIndex + &quot;已删除&quot;);            }else {                System.out.println(&quot;索引&quot; + bookIndex + &quot;删除失败&quot;);            }        } else {            System.out.println(&quot;索引 &quot; + bookIndex + &quot; 不存在！&quot;);        }        // 设置Settings        CreateIndexResponse response = client.admin().indices().prepareCreate(bookIndex)                .setSettings(Settings.builder()                        .put(&quot;index.number_of_shards&quot;, settingShards)                        .put(&quot;index.number_of_replicas&quot;, settingReplicas))                .get();        // 查看结果        GetSettingsResponse getSettingsResponse = client.admin().indices()                .prepareGetSettings(bookIndex).get();        System.out.println(&quot;索引设置结果&quot;);        for (ObjectObjectCursor&lt;String, Settings&gt; cursor : getSettingsResponse.getIndexToSettings()) {            String index = cursor.key;            Settings settings = cursor.value;            Integer shards = settings.getAsInt(&quot;index.number_of_shards&quot;, null);            Integer replicas = settings.getAsInt(&quot;index.number_of_replicas&quot;, null);            System.out.println(&quot;index:&quot; + index + &quot;, shards:&quot; + shards + &quot;, replicas:&quot; + replicas);            Assert.assertEquals(java.util.Optional.of(settingShards), java.util.Optional.of(shards));            Assert.assertEquals(java.util.Optional.of(settingReplicas), java.util.Optional.of(replicas));        }    }    /**     * Bulk 批量插入数据     */    @Test    public void bulk() {        List&lt;Book&gt; list = DateUtil.batchData();        BulkRequestBuilder bulkRequestBuilder = client.prepareBulk();        // 添加index操作到 bulk 中        list.forEach(book -&gt; {            // 新版的API中使用setSource时，参数的个数必须是偶数，否则需要加上 setSource(json, XContentType.JSON)            bulkRequestBuilder.add(client.prepareIndex(bookIndex, bookType, book.getId()).setSource(gson.toJson(book), XContentType.JSON));        });        BulkResponse responses = bulkRequestBuilder.get();        if (responses.hasFailures()) {            // bulk有失败            for (BulkItemResponse res : responses) {                System.out.println(res.getFailure());            }            Assert.assertTrue(false);        }    }}</code></pre><h3 id="开始查询"><a href="#开始查询" class="headerlink" title="开始查询"></a>开始查询</h3><h4 id="控制类"><a href="#控制类" class="headerlink" title="控制类"></a>控制类</h4><p>查询接口</p><pre><code>@RestController@RequestMapping(&quot;basicmatch&quot;)public class BasicMatchQueryController {    @Autowired    private BasicMatchQueryService basicMatchQueryService;    /**     * 1.1 对 &quot;guide&quot; 执行全文检索     * 测试：http://localhost:8080/basicmatch/multimatch?query=guide     */    @RequestMapping(&quot;multimatch&quot;)    public Response&lt;List&lt;Book&gt;&gt; multiMatch(@RequestParam(value = &quot;query&quot;, required = true) String query) {        return basicMatchQueryService.multiBatch(query);    }    /**     * 1.2 指定特定字段检索     * 测试：http://localhost:8080/basicmatch/match?title=in action&amp;from=0&amp;size=4     */    @RequestMapping(&quot;match&quot;)    public ResponsePage&lt;List&lt;Book&gt;&gt; match(MatchForm form) {        return basicMatchQueryService.match(form);    }    /**     * 2 对 &quot;guide&quot; 执行多字段检索     * 测试：http://localhost:8080/basicmatch/multifield?query=guide     */    @RequestMapping(&quot;multifield&quot;)    public Response&lt;List&lt;Book&gt;&gt; multiField(@RequestParam(value = &quot;query&quot;, required = true) String query) {        return basicMatchQueryService.multiField(query);    }    /**     * 3、 Boosting提升某字段得分的检索( Boosting): 将“摘要”字段的得分提高了3倍     * 测试：http://localhost:8080/basicmatch/multifieldboost?query=elasticsearch guide     */    @RequestMapping(&quot;multifieldboost&quot;)    public Response&lt;List&lt;Book&gt;&gt; multiFieldboost(@RequestParam(value = &quot;query&quot;, required = true) String query) {        return basicMatchQueryService.multiFieldboost(query);    }    /**     * 4、Bool检索( Bool Query)     * 测试：http://localhost:8080/basicmatch/bool?shouldTitles=Elasticsearch&amp;shouldTitles=Solr&amp;mustAuthors=clinton gormely&amp;mustNotAuthors=radu gheorge     */    @RequestMapping(&quot;bool&quot;)    public Response&lt;List&lt;Book&gt;&gt; bool(@ModelAttribute BoolForm form) {        return basicMatchQueryService.bool(form);    }    /**     * 5、 Fuzzy 模糊检索( Fuzzy Queries)     */    @RequestMapping(&quot;fuzzy&quot;)    public Response&lt;List&lt;Book&gt;&gt; fuzzy(String query) {        return basicMatchQueryService.fuzzy(query);    }    /**     * 6、 Wildcard Query 通配符检索     * 测试：http://localhost:8080/basicmatch/wildcard?pattern=t*     */    @RequestMapping(&quot;wildcard&quot;)    public Response&lt;List&lt;Book&gt;&gt; wildcard(String pattern) {        return basicMatchQueryService.wildcard(Constants.AUTHORS, pattern);    }    /**     * 7、正则表达式检索( Regexp Query)     * 测试：http://localhost:8080/basicmatch/regexp     */    @RequestMapping(&quot;regexp&quot;)    public Response&lt;List&lt;Book&gt;&gt; regexp(String regexp) {        // 由于Tomcat的原因，直接接收有特殊字符的 正则表达式 会异常，所以这里写死，不过多探究        // 若        regexp = &quot;t[a-z]*y&quot;;        return basicMatchQueryService.regexp(Constants.AUTHORS, regexp);    }    /**     * 8、匹配短语检索( Match Phrase Query)     * 测试：http://localhost:8080/basicmatch/phrase?query=search engine     */    @RequestMapping(&quot;phrase&quot;)    public Response&lt;List&lt;Book&gt;&gt; phrase(String query) {        return basicMatchQueryService.phrase(query);    }    /**     * 9、匹配词组前缀检索     * 测试：http://localhost:8080/basicmatch/phraseprefix?query=search en     */    @RequestMapping(&quot;phraseprefix&quot;)    public Response&lt;List&lt;Book&gt;&gt; phrasePrefix(String query) {        return basicMatchQueryService.phrasePrefix(query);    }    /**     * 10、字符串检索（ Query String）     * 测试：http://localhost:8080/basicmatch/querystring?query=(saerch~1 algorithm~1) AND (grant ingersoll)  OR (tom morton)     */    @RequestMapping(&quot;querystring&quot;)    public Response&lt;List&lt;Book&gt;&gt; queryString(String query) {        return basicMatchQueryService.queryString(query);    }    /**     * 11、简化的字符串检索 （Simple Query String）     * 测试：http://localhost:8080/basicmatch/simplequerystring?query=(saerch~1 algorithm~1) AND (grant ingersoll)  OR (tom morton)     */    @RequestMapping(&quot;simplequerystring&quot;)    public Response&lt;List&lt;Book&gt;&gt; simplequerystring(String query) {        // 这里写死，仅为测试        query = &quot;(saerch~1 algorithm~1) + (grant ingersoll)  | (tom morton)&quot;;        return basicMatchQueryService.simpleQueryString(query);    }    /**     * 12、Term=检索（指定字段检索）     * 测试：http://localhost:8080/basicmatch/term?query=manning     */    @RequestMapping(&quot;term&quot;)    public Response&lt;List&lt;Book&gt;&gt; term(String query) {        return basicMatchQueryService.term(query);    }    /**     * 13、Term排序检索-（Term Query - Sorted）     * 测试：http://localhost:8080/basicmatch/termsort?query=manning     */    @RequestMapping(&quot;termsort&quot;)    public Response&lt;List&lt;Book&gt;&gt; termsort(String query) {        return basicMatchQueryService.termsort(query);    }    /**     * 14、范围检索（Range query）     * 测试：http://localhost:8080/basicmatch/range?startDate=2015-01-01&amp;endDate=2015-12-31     */    @RequestMapping(&quot;range&quot;)    public Response&lt;List&lt;Book&gt;&gt; range(String startDate, String endDate) {        return basicMatchQueryService.range(startDate, endDate);    }    /**     * 15. 过滤检索     * 测试：http://localhost:8080/basicmatch/filter?query=elasticsearch&amp;gte=20     */    @RequestMapping(&quot;filter&quot;)    public Response&lt;List&lt;Book&gt;&gt; filter(String query, Integer gte, Integer lte) {        return basicMatchQueryService.filter(query, gte, lte);    }    /**     * 17、 Function 得分：Field值因子（ Function Score: Field Value Factor）     * 测试：http://localhost:8080/basicmatch/fieldvaluefactor?query=search engine     */    @RequestMapping(&quot;fieldvaluefactor&quot;)    public Response&lt;List&lt;Book&gt;&gt; fieldValueFactor(String query) {        return basicMatchQueryService.fieldValueFactor(query);    }    /**     * 18、 Function 得分：衰减函数( Function Score: Decay Functions )     * 测试：http://localhost:8080/basicmatch/decay?query=search engines&amp;origin=2014-06-15     */    @RequestMapping(&quot;decay&quot;)    public Response&lt;List&lt;Book&gt;&gt; decay(String query, @RequestParam(value = &quot;origin&quot;, defaultValue = &quot;2014-06-15&quot;) String origin) {        return basicMatchQueryService.decay(query, origin);    }    /**     * 19、Function得分：脚本得分（ Function Score: Script Scoring ）     * 测试：ES需要配置允许groovy脚本运行才可以     */    @RequestMapping(&quot;script&quot;)    public Response&lt;List&lt;Book&gt;&gt; script(String query, @RequestParam(value = &quot;threshold&quot;, defaultValue = &quot;2015-07-30&quot;) String threshold) {        return basicMatchQueryService.script(query, threshold);    }}</code></pre><h3 id="服务类"><a href="#服务类" class="headerlink" title="服务类"></a>服务类</h3><pre><code>@Servicepublic class BasicMatchQueryService {    @Autowired    private Client client;    @Value(&quot;${elasticsearch.bookIndex}&quot;)    private String bookIndex;    @Value(&quot;${elasticsearch.bookType}&quot;)    private String bookType;    /**     * 进行ES查询，执行请求前后打印出 查询语句 和 查询结果     */    private SearchResponse requestGet(String queryName, SearchRequestBuilder requestBuilder) {        System.out.println(queryName + &quot; 构建的查询：&quot; + requestBuilder.toString());        SearchResponse searchResponse = requestBuilder.get();        System.out.println(queryName + &quot; 搜索结果：&quot; + searchResponse.toString());        return searchResponse;    }    ...}</code></pre><h4 id="1-1-对-“guide”-执行全文检索-Multi-Match-Query"><a href="#1-1-对-“guide”-执行全文检索-Multi-Match-Query" class="headerlink" title="1.1 对 “guide” 执行全文检索 Multi Match Query"></a>1.1 对 “guide” 执行全文检索 Multi Match Query</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; multiBatch(String query) {        MultiMatchQueryBuilder queryBuilder = new MultiMatchQueryBuilder(query);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex)                .setTypes(bookType).setQuery(queryBuilder);        SearchResponse searchResponse = requestGet(&quot;multiBatch&quot;, requestBuilder);        return CommonQueryUtils.buildResponse(searchResponse);    }</code></pre><h4 id="1-2-在标题字段-title-中搜索带有-“in-action”-字样的图书"><a href="#1-2-在标题字段-title-中搜索带有-“in-action”-字样的图书" class="headerlink" title="1.2 在标题字段(title)中搜索带有 “in action” 字样的图书"></a>1.2 在标题字段(title)中搜索带有 “in action” 字样的图书</h4><pre><code>    public ResponsePage&lt;List&lt;Book&gt;&gt; match(MatchForm form) {        MatchQueryBuilder matchQueryBuilder = new MatchQueryBuilder(&quot;title&quot;, form.getTitle());        // 高亮        HighlightBuilder highlightBuilder = new HighlightBuilder().field(&quot;title&quot;).fragmentSize(200);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex)                .setTypes(bookType).setQuery(matchQueryBuilder)                .setFrom(form.getFrom()).setSize(form.getSize())                .highlighter(highlightBuilder)                // 设置 _source 要返回的字段                .setFetchSource(Constants.fetchFieldsTSPD, null);        ...    }</code></pre><h4 id="多字段检索-Multi-field-Search"><a href="#多字段检索-Multi-field-Search" class="headerlink" title="多字段检索 (Multi-field Search)"></a>多字段检索 (Multi-field Search)</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; multiField(String query) {        MultiMatchQueryBuilder queryBuilder = new MultiMatchQueryBuilder(query).field(&quot;title&quot;).field(&quot;summary&quot;);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex)                .setTypes(bookType).setQuery(queryBuilder);        ...    }</code></pre><h4 id="3、-Boosting提升某字段得分的检索-Boosting-将“摘要”字段的得分提高了3倍"><a href="#3、-Boosting提升某字段得分的检索-Boosting-将“摘要”字段的得分提高了3倍" class="headerlink" title="3、 Boosting提升某字段得分的检索( Boosting),将“摘要”字段的得分提高了3倍"></a>3、 Boosting提升某字段得分的检索( Boosting),将“摘要”字段的得分提高了3倍</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; multiFieldboost(String query) {        MultiMatchQueryBuilder queryBuilder = new MultiMatchQueryBuilder(query).field(&quot;title&quot;).field(&quot;summary&quot;, 3);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex)                .setTypes(bookType).setQuery(queryBuilder);        ...    }</code></pre><h4 id="4、Bool检索-Bool-Query"><a href="#4、Bool检索-Bool-Query" class="headerlink" title="4、Bool检索( Bool Query)"></a>4、Bool检索( Bool Query)</h4><pre><code>    /**     * 在标题中搜索一本名为 &quot;Elasticsearch&quot; 或 &quot;Solr&quot; 的书，     * AND由 &quot;clinton gormley&quot; 创作，但NOT由 &quot;radu gheorge&quot; 创作     */    public Response&lt;List&lt;Book&gt;&gt; bool(BoolForm form) {        BoolQueryBuilder boolQuery = new BoolQueryBuilder();        // 搜索标题 should        BoolQueryBuilder shouldTitleBool = new BoolQueryBuilder();        form.getShouldTitles().forEach(title -&gt; {            shouldTitleBool.should().add(new MatchQueryBuilder(&quot;title&quot;, title));        });        boolQuery.must().add(shouldTitleBool);        // match 作者        form.getMustAuthors().forEach(author -&gt; {            boolQuery.must().add(new MatchQueryBuilder(&quot;authors&quot;, author));        });        // not match 作者        form.getMustNotAuthors().forEach(author -&gt; {            boolQuery.mustNot().add(new MatchQueryBuilder(&quot;authors&quot;, author));        });        ...    }</code></pre><h4 id="5、-Fuzzy-模糊检索-Fuzzy-Queries"><a href="#5、-Fuzzy-模糊检索-Fuzzy-Queries" class="headerlink" title="5、 Fuzzy 模糊检索( Fuzzy Queries)"></a>5、 Fuzzy 模糊检索( Fuzzy Queries)</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; fuzzy(String query) {        MultiMatchQueryBuilder queryBuilder = new MultiMatchQueryBuilder(query)                .field(&quot;title&quot;).field(&quot;summary&quot;)                .fuzziness(Fuzziness.AUTO);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex)                .setTypes(bookType).setQuery(queryBuilder)                .setFetchSource(Constants.fetchFieldsTSPD, null)                .setSize(2);        ...    }</code></pre><h4 id="6、-Wildcard-Query-通配符检索"><a href="#6、-Wildcard-Query-通配符检索" class="headerlink" title="6、 Wildcard Query 通配符检索"></a>6、 Wildcard Query 通配符检索</h4><pre><code>    /**     * 要查找具有以 &quot;t&quot; 字母开头的作者的所有记录     */    public Response&lt;List&lt;Book&gt;&gt; wildcard(String fieldName, String pattern) {        WildcardQueryBuilder wildcardQueryBuilder = new WildcardQueryBuilder(fieldName, pattern);        HighlightBuilder highlightBuilder = new HighlightBuilder().field(Constants.AUTHORS, 200);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex)                .setTypes(bookType).setQuery(wildcardQueryBuilder)                .setFetchSource(Constants.fetchFieldsTA, null)                .highlighter(highlightBuilder);    }</code></pre><h4 id="7、正则表达式检索-Regexp-Query"><a href="#7、正则表达式检索-Regexp-Query" class="headerlink" title="7、正则表达式检索( Regexp Query)"></a>7、正则表达式检索( Regexp Query)</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; regexp(String fieldName, String regexp) {        RegexpQueryBuilder queryBuilder = new RegexpQueryBuilder(fieldName, regexp);        HighlightBuilder highlightBuilder = new HighlightBuilder().field(Constants.AUTHORS);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex)                .setQuery(queryBuilder).setTypes(bookType).highlighter(highlightBuilder)                .setFetchSource(Constants.fetchFieldsTA, null);    }</code></pre><h4 id="8、匹配短语检索-Match-Phrase-Query"><a href="#8、匹配短语检索-Match-Phrase-Query" class="headerlink" title="8、匹配短语检索( Match Phrase Query)"></a>8、匹配短语检索( Match Phrase Query)</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; phrase(String query) {        MultiMatchQueryBuilder queryBuilder = new MultiMatchQueryBuilder(query)                .field(Constants.TITLE).field(Constants.SUMMARY)                .type(MultiMatchQueryBuilder.Type.PHRASE).slop(3);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(queryBuilder)                .setFetchSource(Constants.fetchFieldsTSPD, null);    }</code></pre><h4 id="9、匹配词组前缀检索"><a href="#9、匹配词组前缀检索" class="headerlink" title="9、匹配词组前缀检索"></a>9、匹配词组前缀检索</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; phrasePrefix(String query) {        MatchPhrasePrefixQueryBuilder queryBuilder = new MatchPhrasePrefixQueryBuilder(Constants.SUMMARY, query)                .slop(3).maxExpansions(10);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(queryBuilder).setFetchSource(Constants.fetchFieldsTSPD, null);    }</code></pre><h4 id="10、字符串检索（-Query-String）"><a href="#10、字符串检索（-Query-String）" class="headerlink" title="10、字符串检索（ Query String）"></a>10、字符串检索（ Query String）</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; queryString(String query) {        QueryStringQueryBuilder queryBuilder = new QueryStringQueryBuilder(query);        queryBuilder.field(Constants.SUMMARY, 2).field(Constants.TITLE)                .field(Constants.AUTHORS).field(Constants.PUBLISHER);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(queryBuilder).setFetchSource(Constants.fetchFieldsTSA, null);    }</code></pre><h4 id="11、简化的字符串检索-（Simple-Query-String）"><a href="#11、简化的字符串检索-（Simple-Query-String）" class="headerlink" title="11、简化的字符串检索 （Simple Query String）"></a>11、简化的字符串检索 （Simple Query String）</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; simpleQueryString(String query) {        SimpleQueryStringBuilder queryBuilder = new SimpleQueryStringBuilder(query);        queryBuilder.field(Constants.SUMMARY, 2).field(Constants.TITLE)                .field(Constants.AUTHORS).field(Constants.PUBLISHER);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(queryBuilder).setFetchSource(Constants.fetchFieldsTSA, null)                .highlighter(Constants.highlightS);    }</code></pre><h4 id="12、Term-Terms检索（指定字段检索）"><a href="#12、Term-Terms检索（指定字段检索）" class="headerlink" title="12、Term/Terms检索（指定字段检索）"></a>12、Term/Terms检索（指定字段检索）</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; term(String query) {        TermQueryBuilder termQueryBuilder = new TermQueryBuilder(Constants.PUBLISHER, query);        // terms 查询        /*String[] values = {&quot;manning&quot;, &quot;oreilly&quot;};        TermsQueryBuilder termsQueryBuilder = new TermsQueryBuilder(Constants.PUBLISHER, values);*/        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(termQueryBuilder)                .setFetchSource(Constants.fetchFieldsTPPD, null);    }</code></pre><h4 id="13、Term排序检索-（Term-Query-Sorted）"><a href="#13、Term排序检索-（Term-Query-Sorted）" class="headerlink" title="13、Term排序检索-（Term Query - Sorted）"></a>13、Term排序检索-（Term Query - Sorted）</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; termsort(String query) {        TermQueryBuilder termQueryBuilder = new TermQueryBuilder(Constants.PUBLISHER, query);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(termQueryBuilder)                .addSort(Constants.PUBLISHER_KEYWORD, SortOrder.DESC)                .addSort(Constants.TITLE_KEYWORD, SortOrder.ASC)                .setFetchSource(Constants.fetchFieldsTPPD, null);    }</code></pre><h4 id="14、范围检索（Range-query）"><a href="#14、范围检索（Range-query）" class="headerlink" title="14、范围检索（Range query）"></a>14、范围检索（Range query）</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; range(String startDate, String endDate) {        RangeQueryBuilder queryBuilder = new RangeQueryBuilder(Constants.PUBLISHDATE)                .gte(startDate).lte(endDate);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(queryBuilder)                .setFetchSource(Constants.fetchFieldsTPPD, null);    }</code></pre><h4 id="15-过滤检索"><a href="#15-过滤检索" class="headerlink" title="15. 过滤检索"></a>15. 过滤检索</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; filter(String query, Integer gte, Integer lte) {        BoolQueryBuilder queryBuilder = new BoolQueryBuilder();        queryBuilder.must().add(new MultiMatchQueryBuilder(query).field(Constants.TITLE).field(Constants.SUMMARY));        if (gte != null || lte != null) {            RangeQueryBuilder rangeQueryBuilder = new RangeQueryBuilder(Constants.NUM_REVIEWS);            if (gte != null) {                rangeQueryBuilder.gte(gte);            }            if (lte != null) {                rangeQueryBuilder.lte(lte);            }            queryBuilder.filter().add(rangeQueryBuilder);        }        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(queryBuilder).setFetchSource(Constants.fetchFieldsTSPN, null);    }</code></pre><h4 id="17、-Function-得分：Field值因子（-Function-Score-Field-Value-Factor）"><a href="#17、-Function-得分：Field值因子（-Function-Score-Field-Value-Factor）" class="headerlink" title="17、 Function 得分：Field值因子（ Function Score: Field Value Factor）"></a>17、 Function 得分：Field值因子（ Function Score: Field Value Factor）</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; fieldValueFactor(String query) {        // query        MultiMatchQueryBuilder multiMatchQueryBuilder = new MultiMatchQueryBuilder(query)                .field(Constants.TITLE).field(Constants.SUMMARY);        // fieldValueFactor        FieldValueFactorFunctionBuilder fieldValueFactor = ScoreFunctionBuilders.fieldValueFactorFunction(Constants.NUM_REVIEWS)                .factor(2).modifier(FieldValueFactorFunction.Modifier.LOG1P);        // functionscore        FunctionScoreQueryBuilder queryBuilder = QueryBuilders.functionScoreQuery(multiMatchQueryBuilder, fieldValueFactor);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(queryBuilder).setFetchSource(Constants.fetchFieldsTSPN, null);    }</code></pre><h4 id="18、-Function-得分：衰减函数-Function-Score-Decay-Functions"><a href="#18、-Function-得分：衰减函数-Function-Score-Decay-Functions" class="headerlink" title="18、 Function 得分：衰减函数( Function Score: Decay Functions )"></a>18、 Function 得分：衰减函数( Function Score: Decay Functions )</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; decay(String query, String origin) {        MultiMatchQueryBuilder multiMatchQueryBuilder = new MultiMatchQueryBuilder(query)                .field(Constants.TITLE).field(Constants.SUMMARY);        ExponentialDecayFunctionBuilder exp = ScoreFunctionBuilders.exponentialDecayFunction(Constants.PUBLISHDATE, origin, &quot;30d&quot;, &quot;7d&quot;);        FunctionScoreQueryBuilder queryBuilder = QueryBuilders.functionScoreQuery(multiMatchQueryBuilder, exp).boostMode(CombineFunction.REPLACE);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(queryBuilder).setFetchSource(Constants.fetchFieldsTSPN, null);    }</code></pre><h4 id="19、Function得分：脚本得分（-Function-Score-Script-Scoring-）"><a href="#19、Function得分：脚本得分（-Function-Score-Script-Scoring-）" class="headerlink" title="19、Function得分：脚本得分（ Function Score: Script Scoring ）"></a>19、Function得分：脚本得分（ Function Score: Script Scoring ）</h4><pre><code>    public Response&lt;List&lt;Book&gt;&gt; script(String query, String threshold) {        MultiMatchQueryBuilder multiMatchQueryBuilder = new MultiMatchQueryBuilder(query)                .field(Constants.TITLE).field(Constants.SUMMARY);        // 参数        Map&lt;String, Object&gt; params = new HashMap&lt;&gt;();        params.put(&quot;threshold&quot;, threshold);        // 脚本        String scriptStr = &quot;publish_date = doc[&#39;publish_date&#39;].value; num_reviews = doc[&#39;num_reviews&#39;].value; if (publish_date &gt; Date.parse(&#39;yyyy-MM-dd&#39;, threshold).getTime()) { return log(2.5 + num_reviews) }; return log(1 + num_reviews);&quot;;        Script script = new Script(ScriptType.INLINE, &quot;painless&quot;, scriptStr, params);        ScriptScoreFunctionBuilder scriptScoreFunctionBuilder = ScoreFunctionBuilders.scriptFunction(script);        FunctionScoreQueryBuilder queryBuilder = QueryBuilders.functionScoreQuery(multiMatchQueryBuilder, scriptScoreFunctionBuilder);        SearchRequestBuilder requestBuilder = client.prepareSearch(bookIndex).setTypes(bookType)                .setQuery(queryBuilder).setFetchSource(Constants.fetchFieldsTSPN, null);    }</code></pre><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>教你编译调试Elasticsearch 6.3.2源码</title>
      <link href="/2018/08/%E6%95%99%E4%BD%A0%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95Elasticsearch-6-3-2%E6%BA%90%E7%A0%81/"/>
      <url>/2018/08/%E6%95%99%E4%BD%A0%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95Elasticsearch-6-3-2%E6%BA%90%E7%A0%81/</url>
      <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>想深入理解 Elasticsearch，阅读它的源码是很有必要的，一来可以了解它内部的具体实现，有助于调优，二来可以了解优秀开源项目的代码架构，提高我们的代码架构能力等</p><p>阅读Elasticsearch源码的第一步是搭建调试环境，然后作者在这个过程中遇到很多麻烦，在网上找不到想要的答案，历经千辛最后一一解决，所以记录下，帮助有需要的童鞋</p><h4 id="软件环境"><a href="#软件环境" class="headerlink" title="软件环境"></a>软件环境</h4><ul><li>操作系统：win7</li><li>Elasticsearch 源码版本: 6.3.2</li><li>JDK版本： 10.0.2</li><li>Gradle版本： 4.7</li><li>Intellij Idea版本： 2018.2</li></ul><h3 id="环境准备及工程导入"><a href="#环境准备及工程导入" class="headerlink" title="环境准备及工程导入"></a>环境准备及工程导入</h3><h4 id="1-安装JDK"><a href="#1-安装JDK" class="headerlink" title="1.安装JDK"></a>1.安装JDK</h4><p>Elasticsearch 6.3.3需要JDK1.9编译，否则后面步骤会报错。</p><p>Java SE Downloads 地址：<br><a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="noopener">http://www.oracle.com/technetwork/java/javase/downloads/index.html</a></p><p>作者装的是 JDK 10.0.2</p><h4 id="2-下载Elasticsearch源码，并且切换到6-3-2分支"><a href="#2-下载Elasticsearch源码，并且切换到6-3-2分支" class="headerlink" title="2.下载Elasticsearch源码，并且切换到6.3.2分支"></a>2.下载Elasticsearch源码，并且切换到6.3.2分支</h4><p>Elasticsearch github源码托管地址：<br><a href="https://github.com/elastic/elasticsearch.git" target="_blank" rel="noopener">https://github.com/elastic/elasticsearch.git</a></p><pre><code>git checkout v6.3.2</code></pre><p>也可直接下载源码包，地址在 <a href="https://github.com/elastic/elasticsearch/releases" target="_blank" rel="noopener">https://github.com/elastic/elasticsearch/releases</a></p><h4 id="3-下载gradle的安装包"><a href="#3-下载gradle的安装包" class="headerlink" title="3.下载gradle的安装包"></a>3.下载gradle的安装包</h4><p>查看 <code>elasticsearch\gradle\wrapper\gradle-wrapper.properties</code> 发现如下配置：</p><pre><code>distributionUrl=https://services.gradle.org/distributions/gradle-4.5-all.zip</code></pre><p>Elasticsearch 6.3.2需要安装gradle-4.5，官方下载地址：<br><a href="https://services.gradle.org/distributions/gradle-4.5-all.zip" target="_blank" rel="noopener">https://services.gradle.org/distributions/gradle-4.5-all.zip</a></p><blockquote><p>注意：由于国内网速问题，为了加快速度，进行第4步操作</p></blockquote><h4 id="4-拷贝文件"><a href="#4-拷贝文件" class="headerlink" title="4.拷贝文件"></a>4.拷贝文件</h4><p>将下载的gradle-4.5-all.zip包放到 <code>elasticsearch\gradle\wrapper</code> 目录下，<br>确保和 <code>elasticsearch\gradle\wrapper\gradle-wrapper.properties</code> 在同级目录，<br>然后修改 <code>elasticsearch\gradle\wrapper\gradle-wrapper.properties</code> 配置如下：</p><pre><code>distributionUrl=gradle-4.5-all.zip</code></pre><h4 id="5-修改源码Maven仓库地址"><a href="#5-修改源码Maven仓库地址" class="headerlink" title="5.修改源码Maven仓库地址"></a>5.修改源码Maven仓库地址</h4><p>国内下载国外仓库的jar包速度慢，需要替换Maven地址，设置为本地或者国内可用的Maven仓库。</p><p>需要修改下列文件的 maven URL 配置：</p><ul><li>elasticsearch\benchmarks\build.gradle</li><li>elasticsearch\client\benchmark\build.gradle</li></ul><p>修改源码中上面build.gradle文件里面的<code>repositories-maven-url</code>的值，<br>配置为可用的仓库地址，譬如修改为阿里云maven地址 <code>http://maven.aliyun.com/nexus/content/groups/public/</code>，修改示例如下：</p><pre><code>buildscript {    repositories {        maven {            url &#39;http://maven.aliyun.com/nexus/content/groups/public/&#39;        }    }    dependencies {        classpath &#39;com.github.jengelman.gradle.plugins:shadow:2.0.2&#39;    }}</code></pre><h4 id="6-修改全局Maven仓库地址"><a href="#6-修改全局Maven仓库地址" class="headerlink" title="6.修改全局Maven仓库地址"></a>6.修改全局Maven仓库地址</h4><p>在<code>USER_HOME/.gradle/</code>下面创建新文件 <code>init.gradle</code>，输入下面的内容并保存。</p><pre><code>allprojects{    repositories {        def REPOSITORY_URL = &#39;http://maven.aliyun.com/nexus/content/groups/public/&#39;        all {            ArtifactRepository repo -&gt;    if (repo instanceof MavenArtifactRepository) {                def url = repo.url.toString()                if (url.startsWith(&#39;https://repo.maven.org/maven2&#39;) || url.startsWith(&#39;https://jcenter.bintray.com/&#39;)) {                    project.logger.lifecycle &quot;Repository ${repo.url} replaced by $REPOSITORY_URL.&quot;                    remove repo                }            }        }        maven {            url REPOSITORY_URL        }    }}</code></pre><p>其中<code>USER_HOME/.gradle/</code>是自己的gradle安装目录，示例值：<code>C:\Users\Administrator\.gradle</code>，<br>如果没有<code>.gradle</code>目录，可用自己创建，或者先执行第7步，等gradle安装后再回来修改。<br>上面脚本把url匹配到的仓库都替换成了阿里云的仓库，<br>如果有未匹配到的导致编译失败，可用自己仿照着添加匹配条件。</p><h4 id="7-gradle编译源码"><a href="#7-gradle编译源码" class="headerlink" title="7.gradle编译源码"></a>7.gradle编译源码</h4><p>windows运行cmd，进入DOS命令行，然后切换到elasticsearch源码的根目录，执行如下命令，把elasticsearch编译为 idea 工程：</p><pre><code>gradlew idea</code></pre><p>编译失败则按照错误信息解决问题，可用使用如下命令帮助定位问题：</p><pre><code>gradlew idea -infogradlew idea -debug</code></pre><p>一般是Maven仓库地址不可用导致jar包无法下载，从而编译失败，此时请参考步骤5和6修改相关的仓库地址。</p><p>编译成功后打印日志：</p><pre><code>BUILD SUCCESSFUL in 1m 23s</code></pre><h4 id="8-idea-导入elasticsearch工程"><a href="#8-idea-导入elasticsearch工程" class="headerlink" title="8. idea 导入elasticsearch工程"></a>8. idea 导入elasticsearch工程</h4><p>idea 中 <code>File -&gt; New Project From Existing Sources</code> 选择你下载的 Elasticsearch 根目录，然后点 <code>open</code> ，之后 <code>Import project from external model -&gt; Gradle</code> , 选中 <code>Use auto-import</code>, 然后就可以了</p><p>导入进去后，gradle 又会编译一遍，需要等一会，好了之后如下：</p><p><img src="http://image.laijianfeng.org/20180822_142155.png" alt="IDEA导入Elasticsearch6.3.2之后"></p><h3 id="运行，开始-solve-error-模式"><a href="#运行，开始-solve-error-模式" class="headerlink" title="运行，开始 solve error 模式"></a>运行，开始 solve error 模式</h3><blockquote><p>前面的步骤都挺顺利，接下来遇到的 ERROR &amp; EXCEPTION 让作者耗费了好几天，心力交瘁，好在最终运行成功   </p></blockquote><p>在 <code>elasticsearch/server/src/main/org/elasticsearch/bootstrap</code> 下找到Elasticsearch的启动类 <code>Elasticsearch.java</code>，打开文件，右键 <code>Run Elasticsearch.main()</code>，运行main方法</p><p><strong>1、 报错如下：</strong></p><pre><code>ERROR: the system property [es.path.conf] must be set</code></pre><p>这是需要配置 es.path.conf 参数，我们先在 elasticsearch 源码目录下新建一个 home 目录，然后在 <a href="https://www.elastic.co/downloads/elasticsearch" target="_blank" rel="noopener"><code>https://www.elastic.co/downloads/elasticsearch</code></a> 下载一个同版本号的 Elasticsearch6.3.2 发行版，解压，将 config 目录拷贝到 home 目录中</p><p>然后打开 <code>Edit Configurations</code>，在 <code>VM options</code> 加入如下配置：</p><p><img src="http://image.laijianfeng.org/20180822_144736.png" alt="Edit Configurations"></p><pre><code>-Des.path.conf=D:\elasticsearch-6.3.2\home\config</code></pre><p>再次运行 <code>Run Elasticsearch.main()</code></p><p><strong>2、报错如下：</strong></p><pre><code>Exception in thread &quot;main&quot; java.lang.IllegalStateException: path.home is not configured    at org.elasticsearch.env.Environment.&lt;init&gt;(Environment.java:103)...</code></pre><p>需要配置 <code>path.home</code> 这个参数，在 VM options 中添加如下配置：</p><pre><code>-Des.path.home=D:\elasticsearch-6.3.2</code></pre><p>再次RUN</p><p><strong>3、报错如下：</strong></p><pre><code>2018-08-22 15:07:17,094 main ERROR Could not register mbeans java.security.AccessControlException: access denied (&quot;javax.management.MBeanTrustPermission&quot; &quot;register&quot;)...Caused by: java.nio.file.NoSuchFileException: D:\elasticsearch-6.3.2\modules\aggs-matrix-stats\plugin-descriptor.properties...</code></pre><p>在 VM options 中把 path.home 的值修改为如下：</p><pre><code>-Des.path.home=D:\elasticsearch-6.3.2\home</code></pre><p>然后把 ES6.3.2 发行版中的 <code>modules</code> 文件夹复制到 <code>home</code> 目录下，然后再次RUN</p><p><strong>4、报错如下：</strong></p><pre><code>2018-08-22 15:12:29,876 main ERROR Could not register mbeans java.security.AccessControlException: access denied (&quot;javax.management.MBeanTrustPermission&quot; &quot;register&quot;)...</code></pre><p>在 <code>VM options</code> 中加入</p><pre><code>-Dlog4j2.disable.jmx=true</code></pre><p>1、2、3、4 的配置最终如下：</p><p><img src="http://image.laijianfeng.org/20180823_013945.png" alt="image"></p><p>再次RUN</p><p><strong>5、报错如下：</strong></p><pre><code>[2018-08-23T00:53:17,003][ERROR][o.e.b.ElasticsearchUncaughtExceptionHandler] [] fatal error in thread [main], exitingjava.lang.NoClassDefFoundError: org/elasticsearch/plugins/ExtendedPluginsClassLoader    at org.elasticsearch.plugins.PluginsService.loadBundle(PluginsService.java:632) ~[main/:?]    at org.elasticsearch.plugins.PluginsService.loadBundles(PluginsService.java:557) ~[main/:?]    at org.elasticsearch.plugins.PluginsService.&lt;init&gt;(PluginsService.java:162) ~[main/:?]    at org.elasticsearch.node.Node.&lt;init&gt;(Node.java:311) ~[main/:?]    at org.elasticsearch.node.Node.&lt;init&gt;(Node.java:252) ~[main/:?]    at org.elasticsearch.bootstrap.Bootstrap$5.&lt;init&gt;(Bootstrap.java:213) ~[main/:?]    at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:213) ~[main/:?]    at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:326) ~[main/:?]    at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:136) ~[main/:?]    at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:127) ~[main/:?]    at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86) ~[main/:?]    at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124) ~[main/:?]    at org.elasticsearch.cli.Command.main(Command.java:90) ~[main/:?]    at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:93) ~[main/:?]    at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:86) ~[main/:?]Caused by: java.lang.ClassNotFoundException: org.elasticsearch.plugins.ExtendedPluginsClassLoader    at jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:582) ~[?:?]    at jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:190) ~[?:?]    at java.lang.ClassLoader.loadClass(ClassLoader.java:499) ~[?:?]    ... 15 more</code></pre><p>这个问题其实不算真正的问题，但是说起来挺好笑，为了解决这个问题耗费了作者好几天，心力交瘁，当最后发现问题所在的时候，哭笑不得 ~_~  正是所谓的 <code>踏破铁鞋无觅处，得来全不费工夫</code> </p><p><strong>解决方法：</strong> 打开 IDEA <code>Edit Configurations</code> ，给 <code>Include dependencies with Provided scope</code> 打上勾即可解决，很简单吧！！</p><p><img src="http://image.laijianfeng.org/20180823_011036.png" alt="image"></p><p>继续RUN，又来一个 Exception</p><p><strong>6、报错如下：</strong></p><pre><code>[2018-08-23T01:13:38,551][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [] uncaught exception in thread [main]org.elasticsearch.bootstrap.StartupException: java.security.AccessControlException: access denied (&quot;java.lang.RuntimePermission&quot; &quot;createClassLoader&quot;)    at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:140) ~[main/:?]    at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:127) ~[main/:?]    at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86) ~[main/:?]    at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124) ~[main/:?]    at org.elasticsearch.cli.Command.main(Command.java:90) ~[main/:?]    at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:93) ~[main/:?]    at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:86) ~[main/:?]Caused by: java.security.AccessControlException: access denied (&quot;java.lang.RuntimePermission&quot; &quot;createClassLoader&quot;)    at java.security.AccessControlContext.checkPermission(AccessControlContext.java:472) ~[?:?]    at java.security.AccessController.checkPermission(AccessController.java:895) ~[?:?]    at java.lang.SecurityManager.checkPermission(SecurityManager.java:335) ~[?:?]    at java.lang.SecurityManager.checkCreateClassLoader(SecurityManager.java:397) ~[?:?]...Exception: java.security.AccessControlException thrown from the UncaughtExceptionHandler in thread &quot;Thread-2&quot;</code></pre><p>这个问题也找了挺久，最终才发现解决方法（两种）：</p><p><strong>第一种：</strong> 在 <code>home/config</code> 目录下新建 <code>java.policy</code> 文件，填入下面内容</p><pre><code>grant {    permission java.lang.RuntimePermission &quot;createClassLoader&quot;;};</code></pre><p>然后在 <code>VM options</code> 加入 <code>java.security.policy</code> 的设置，指向该文件即可</p><pre><code>-Djava.security.policy=D:\elasticsearch-6.3.2\home\config\java.policy</code></pre><p><strong>第二种：</strong> 就是在 <code>%JAVA_HOME%/conf/security</code> 目录下（JDK10是这个路径，之前的版本不确定），我的目录是 <code>C:\Program Files\Java\jdk-10.0.2\conf\security</code>，打开 <code>java.policy</code> 文件，在 <code>grant</code> 中加入下面这句，赋予权限</p><pre><code>permission java.lang.RuntimePermission &quot;createClassLoader&quot;;</code></pre><p>效果如下：</p><p><img src="http://image.laijianfeng.org/20180823_013422.png" alt="java.policy"><br><img src="http://image.laijianfeng.org/20180823_012205.png" alt="createClassLoader"></p><p>再RUN，这次可终于运行起来了！！！</p><p>来看一下效果，浏览器访问 <code>http://localhost:9200/</code></p><p><img src="http://image.laijianfeng.org/20180823_012641.png" alt="image1"></p><p>浏览器访问 <code>http://localhost:9200/_cat/health?v</code></p><p><img src="http://image.laijianfeng.org/20180823_012827.png" alt="image"></p><p>一切正常，终于可以愉快的 DEBUG 源码啦！！！</p><h3 id="另一种源码调试方式：远程调试"><a href="#另一种源码调试方式：远程调试" class="headerlink" title="另一种源码调试方式：远程调试"></a>另一种源码调试方式：远程调试</h3><p>如果上面第五个报错之后解决不了无法继续进行，可以选择这种方式:</p><p>在 Elasticsearch 源码目录下打开 CMD，输入下面的命令启动一个 debug 实例</p><pre><code>gradlew run --debug-jvm</code></pre><p>如果启动失败可能需要先执行 <code>gradlew clean</code> 再 <code>gradlew run --debug-jvm</code> 或者 先退出 IDEA</p><p><img src="http://image.laijianfeng.org/20180823_111933.png" alt="image"></p><p>在 IDEA 中打开 <code>Edit Configurations</code>，添加 remote</p><p><img src="http://image.laijianfeng.org/20180823_104521.png" alt="image"></p><p>配置 host 和 port</p><p><img src="http://image.laijianfeng.org/20180823_110657.png" alt="image"></p><p>点击 debug，浏览器访问 <code>http://localhost:9200/</code>，即可看到ES返回的信息</p><p>随机调试一下， 打开 <code>elasticsearch/server/src/main/org/elasticsearch/rest/action/cat</code> 下的 <code>RestHealthAction</code> 类，在第 54 行出设置一个断点，然后浏览器访问 <code>http://localhost:9200/_cat/health</code>，可以看到断点已经捕获到该请求了</p><p><img src="http://image.laijianfeng.org/20180823_113341.png" alt="image"></p><p>运行成功，可以开始设置断点进行其他调试</p><h3 id="其他可能遇到的问题"><a href="#其他可能遇到的问题" class="headerlink" title="其他可能遇到的问题"></a>其他可能遇到的问题</h3><p><strong>1. 错误信息如下</strong></p><pre><code>JAVA8_HOME required to run tasks gradle</code></pre><p>配置环境变量 <code>JAVA8_HOME</code>，值为 JDK8 的安装目录</p><p><strong>2. 错误信息如下</strong></p><pre><code>[2018-08-22T13:07:23,197][INFO ][o.e.t.TransportService   ] [EFQliuV] publish_address {10.100.99.118:9300}, bound_addresses {[::]:9300}[2018-08-22T13:07:23,211][INFO ][o.e.b.BootstrapChecks    ] [EFQliuV] bound or publishing to a non-loopback address, enforcing bootstrap checksERROR: [1] bootstrap checks failed[1]: initial heap size [268435456] not equal to maximum heap size [4273995776]; this can cause resize pauses and prevents mlockall from locking the entire heap[2018-08-22T13:07:23,219][INFO ][o.e.n.Node               ] [EFQliuV] stopping ...2018-08-22 13:07:23,269 Thread-2 ERROR No log4j2 configuration file found. Using default configuration: logging only errors to the console. Set system property &#39;log4j2.debug&#39; to show Log4j2 internal initialization logging.Disconnected from the target VM, address: &#39;127.0.0.1:5272&#39;, transport: &#39;socket&#39;</code></pre><p>在 <code>Edit Configurations</code> 的 <code>VM options</code> 加入下面配置</p><pre><code>-Xms2g -Xmx2g </code></pre><blockquote><p>参考文档：</p><ol><li><a href="https://www.jianshu.com/p/61dfe6fb6625" target="_blank" rel="noopener">Eclipse导入Elasticsearch源码</a></li><li><a href="https://www.felayman.com/articles/2017/11/10/1510291087246.html" target="_blank" rel="noopener">Elasticsearch源码分析—环境准备(一)</a></li><li><a href="http://www.54tianzhisheng.cn/2018/08/05/es-code01/" target="_blank" rel="noopener">渣渣菜鸡的 ElasticSearch 源码解析 —— 环境搭建</a></li><li><a href="http://www.54tianzhisheng.cn/2018/08/14/idea-remote-debug-elasticsearch" target="_blank" rel="noopener">教你如何在 IDEA 远程 Debug ElasticSearch</a></li></ol></blockquote><hr><p>打开微信扫一扫，关注【小旋锋】微信公众号，及时接收博文推送</p><p><img src="http://image.laijianfeng.org/%E5%B0%8F%E6%97%8B%E9%94%8B%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="小旋锋的微信公众号"></p>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>20180818音乐会</title>
      <link href="/2018/08/20180818%E9%9F%B3%E4%B9%90%E4%BC%9A/"/>
      <url>/2018/08/20180818%E9%9F%B3%E4%B9%90%E4%BC%9A/</url>
      <content type="html"><![CDATA[<div style="text-align: center"><br><br><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=116837&auto=1&height=66"></iframe><br><br></div><p>感受幸福，感受快乐，感受…悲伤….</p><p><img src="http://image.laijianfeng.org/20180818224224.jpg" alt="丹麦钢琴家克里斯蒂娜·比约克独奏音乐会"></p>]]></content>
      
      <categories>
          
          <category> 生活杂记 </category>
          
      </categories>
      
      
    </entry>
    
    <entry>
      <title>Lucene初体验</title>
      <link href="/2018/08/Lucene%E5%88%9D%E4%BD%93%E9%AA%8C/"/>
      <url>/2018/08/Lucene%E5%88%9D%E4%BD%93%E9%AA%8C/</url>
      <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本文的简要内容：</p><ol><li>Lucene简介</li><li>体验Lucene Demo</li><li>Lucene 核心类介绍</li><li>Lucene 索引文件格式</li></ol><h3 id="Lucene简介"><a href="#Lucene简介" class="headerlink" title="Lucene简介"></a>Lucene简介</h3><p>Lucene是目前最流行的Java开源搜索引擎类库,最新版本为7.4.0。Lucene通常用于全文检索,Lucene具有简单高效跨平台等特点,因此有不少搜索引擎都是基于Lucene构建的,例如:Elasticsearch,Solr等等。</p><p>现代搜索引擎的两大核心就是索引和搜索，建立索引的过程就是对源数据进行处理，例如过滤掉一些特殊字符或词语，单词大小写转换，分词，建立倒排索引等支持后续高效准确的搜索。而搜索则是直接提供给用户的功能，尽管面向的用户不同，诸如百度，谷歌等互联网公司以及各种企业都提供了各自的搜索引擎。搜索过程需要对搜索关键词进行分词等处理，然后再引擎内部构建查询，还要根据相关度对搜索结果进行排序，最终把命中结果展示给用户。</p><p>Lucene只是一个提供索引和查询的<strong>类库</strong>，并不是一个应用，程序员需要根据自己的应用场景进行如数据获取、数据预处理、用户界面提供等工作。</p><p>搜索程序的典型组件如下所示：</p><p><img src="http://image.laijianfeng.org/20180818_132723.jpg" alt="搜索程序的典型组件"></p><p>下图为Lucene与应用程序的关系:</p><p><img src="http://image.laijianfeng.org/fig001.jpg" alt="Lucene与应用程序的关系"></p><h3 id="体验Lucene-Demo"><a href="#体验Lucene-Demo" class="headerlink" title="体验Lucene Demo"></a>体验Lucene Demo</h3><p>接下来先来看一个简单的demo</p><blockquote><p>note:<br>代码在 <a href="https://github.com/whirlys/elastic-example/tree/master/startlucene/src/main/java/startlucene" target="_blank" rel="noopener">start Lucene</a></p></blockquote><h4 id="引入-Maven-依赖"><a href="#引入-Maven-依赖" class="headerlink" title="引入 Maven 依赖"></a>引入 Maven 依赖</h4><pre><code>    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;        &lt;lucene.version&gt;7.4.0&lt;/lucene.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;junit&lt;/groupId&gt;            &lt;artifactId&gt;junit&lt;/artifactId&gt;            &lt;version&gt;4.11&lt;/version&gt;            &lt;scope&gt;test&lt;/scope&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;            &lt;artifactId&gt;lucene-core&lt;/artifactId&gt;            &lt;version&gt;${lucene.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;            &lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt;            &lt;version&gt;${lucene.version}&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;</code></pre><h4 id="索引类-IndexFiles-java"><a href="#索引类-IndexFiles-java" class="headerlink" title="索引类 IndexFiles.java"></a>索引类 IndexFiles.java</h4><pre><code>import org.apache.lucene.analysis.*;import org.apache.lucene.analysis.standard.*;import org.apache.lucene.document.*;import org.apache.lucene.index.*;import org.apache.lucene.store.*;import java.io.*;import java.nio.charset.*;import java.nio.file.*;import java.nio.file.attribute.*;public class IndexFiles {    public static void main(String[] args) {        String indexPath = &quot;D:/lucene_test/index&quot;; // 建立索引文件的目录        String docsPath = &quot;D:/lucene_test/docs&quot;; // 读取文本文件的目录        Path docDir = Paths.get(docsPath);        IndexWriter writer = null;        try {            // 存储索引数据的目录            Directory dir = FSDirectory.open(Paths.get(indexPath));            // 创建分析器            Analyzer analyzer = new StandardAnalyzer();            IndexWriterConfig iwc = new IndexWriterConfig(analyzer);            iwc.setOpenMode(IndexWriterConfig.OpenMode.CREATE);            writer = new IndexWriter(dir, iwc);            indexDocs(writer, docDir);            writer.close();        } catch (IOException e) {            e.printStackTrace();        }    }    private static void indexDocs(final IndexWriter writer, Path path) throws IOException {        if (Files.isDirectory(path)) {            Files.walkFileTree(path, new SimpleFileVisitor&lt;Path&gt;() {                @Override                public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) {                    try {                        indexDoc(writer, file);                    } catch (IOException ignore) {                        // 不索引那些不能读取的文件,忽略该异常                    }                    return FileVisitResult.CONTINUE;                }            });        } else {            indexDoc(writer, path);        }    }    private static void indexDoc(IndexWriter writer, Path file) throws IOException {        try (InputStream stream = Files.newInputStream(file)) {            // 创建一个新的空文档            Document doc = new Document();            // 添加字段            Field pathField = new StringField(&quot;path&quot;, file.toString(), Field.Store.YES);            doc.add(pathField);            Field contentsField = new TextField(&quot;contents&quot;,                    new BufferedReader(new InputStreamReader(stream, StandardCharsets.UTF_8)));            doc.add(contentsField);            System.out.println(&quot;adding &quot; + file);            // 写文档            writer.addDocument(doc);        }    }}</code></pre><h4 id="查询类-SearchFiles-java"><a href="#查询类-SearchFiles-java" class="headerlink" title="查询类 SearchFiles.java"></a>查询类 SearchFiles.java</h4><pre><code>import org.apache.lucene.analysis.*;import org.apache.lucene.analysis.standard.*;import org.apache.lucene.document.*;import org.apache.lucene.index.*;import org.apache.lucene.queryparser.classic.*;import org.apache.lucene.search.*;import org.apache.lucene.store.*;import java.io.*;import java.nio.charset.*;import java.nio.file.*;public class SearchFiles {    public static void main(String[] args) throws Exception {        String indexPath = &quot;D:/lucene_test/index&quot;; // 建立索引文件的目录        String field = &quot;contents&quot;;        IndexReader reader = DirectoryReader.open(FSDirectory.open(Paths.get(indexPath)));        IndexSearcher searcher = new IndexSearcher(reader);        Analyzer analyzer = new StandardAnalyzer();        BufferedReader in = null;        in = new BufferedReader(new InputStreamReader(System.in, StandardCharsets.UTF_8));        QueryParser parser = new QueryParser(field, analyzer);        System.out.println(&quot;Enter query:&quot;);        // 从Console读取要查询的语句        String line = in.readLine();        if (line == null || line.length() == -1) {            return;        }        line = line.trim();        if (line.length() == 0) {            return;        }        Query query = parser.parse(line);        System.out.println(&quot;Searching for:&quot; + query.toString(field));        doPagingSearch(searcher, query);        in.close();        reader.close();    }    private static void doPagingSearch(IndexSearcher searcher, Query query) throws IOException {        // TopDocs保存搜索结果        TopDocs results = searcher.search(query, 10);        ScoreDoc[] hits = results.scoreDocs;        int numTotalHits = Math.toIntExact(results.totalHits);        System.out.println(numTotalHits + &quot; total matching documents&quot;);        for (ScoreDoc hit : hits) {            Document document = searcher.doc(hit.doc);            System.out.println(&quot;文档:&quot; + document.get(&quot;path&quot;));            System.out.println(&quot;相关度:&quot; + hit.score);            System.out.println(&quot;================================&quot;);        }    }}</code></pre><h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><p>首先创建文件夹 <code>D:\lucene_test</code>，在 <code>lucene_test</code> 下再创建 <code>docs</code> 文件夹，用来存储要索引的测试文件</p><p>在 <code>docs</code> 下创建3个文件 test1.txt, test2.txt, test3.txt，分别写入 hello world、 hello lucene、 hello elasticsearch</p><p>运行索引类 IndexFiles.java，可看到Console输出</p><pre><code>adding D:\lucene_test\docs\test1.txtadding D:\lucene_test\docs\test2.txtadding D:\lucene_test\docs\test3.txt</code></pre><p><img src="http://image.laijianfeng.org/20180818_135449.png" alt="Lucene的索引文件"></p><p>运行查询类 SearchFiles.java，搜索 hello ，三个文件相关度一样</p><pre><code>Enter query:helloSearching for:hello3 total matching documents文档:D:\lucene_test\docs\test1.txt相关度:0.13353139================================文档:D:\lucene_test\docs\test2.txt相关度:0.13353139================================文档:D:\lucene_test\docs\test3.txt相关度:0.13353139================================</code></pre><p>搜索 hello lucene，test2.txt的相关度比其他两个高</p><pre><code>Enter query:hello luceneSearching for:hello lucene3 total matching documents文档:D:\lucene_test\docs\test2.txt相关度:1.1143606================================文档:D:\lucene_test\docs\test1.txt相关度:0.13353139================================文档:D:\lucene_test\docs\test3.txt相关度:0.13353139================================</code></pre><h3 id="Lucene-核心类介绍"><a href="#Lucene-核心类介绍" class="headerlink" title="Lucene 核心类介绍"></a>Lucene 核心类介绍</h3><h4 id="核心索引类"><a href="#核心索引类" class="headerlink" title="核心索引类"></a>核心索引类</h4><p>IndexWriter</p><pre><code>进行索引写操作的一个中心组件不能进行读取和搜索</code></pre><p>Directory</p><pre><code>Directory代表Lucene索引的存放位置常用的实现：    FSDerectory:表示一个存储在文件系统中的索引的位置    RAMDirectory:表示一个存储在内存当中的索引的位置作用：    IndexWriter通过获取Directory的一个具体实现，在Directory指向的位置中操作索引</code></pre><p>Analyzer</p><pre><code>Analyzer，分析器，相当于筛子，对内容进行过滤，分词，转换等作用：把过滤之后的数据交给indexWriter进行索引</code></pre><p>Document</p><pre><code>用来存放文档（数据），该文档为非结构化数据中抓取的相关数据通过Field(域)组成Document，类似于mysql中的一个个字段组成的一条记录</code></pre><p>Field</p><pre><code>Document中的一个字段</code></pre><h4 id="核心搜索类"><a href="#核心搜索类" class="headerlink" title="核心搜索类"></a>核心搜索类</h4><p>IndexSearcher</p><pre><code>IndexSearcher在建立好的索引上进行搜索它只能以 只读 的方式打开一个索引，所以可以有多个IndexSearcher的实例在一个索引上进行操作</code></pre><p>Term</p><pre><code>Term是搜索的基本单元，一个Term由 key:value 组成（类似于mysql中的  字段名称=查询的内容）例子： Query query = new TermQuery(new Term(&quot;filename&quot;, &quot;lucene&quot;));</code></pre><p>Query</p><pre><code>Query是一个抽象类，用来将用户输入的查询字符串封装成Lucene能够识别的Query</code></pre><p>TermQuery</p><pre><code>Query子类，Lucene支持的最基本的一个查询类例子：TermQuery termQuery = new TermQuery(new Term(&quot;filename&quot;, &quot;lucene&quot;));</code></pre><p>BooleanQuery</p><pre><code>BooleanQUery，布尔查询,是一个组合Query（多个查询条件的组合）BooleanQuery是可以嵌套的栗子：BooleanQuery query = new BooleanQuery();BooleanQuery query2 = new BooleanQuery();TermQuery termQuery1 = new TermQuery(new Term(&quot;fileName&quot;, &quot;lucene&quot;));TermQuery termQuery2 = new TermQuery(new Term(&quot;fileName&quot;, &quot;name&quot;));query2.add(termQuery1, Occur.SHOULD);query.add(termQuery2, Occur.SHOULD);query.add(query2, Occur.SHOULD);;        //BooleanQuery是可以嵌套的Occur枚举：    MUST    SHOULD    FILTER    MUST_NOT</code></pre><p>NumericRangeQuery</p><pre><code>数字区间查询栗子：Query newLongRange = NumericRangeQuery.newLongRange(&quot;fileSize&quot;,0l, 100l, true, true);</code></pre><p>PrefixQuery</p><pre><code>前缀查询，查询分词中含有指定字符开头的内容栗子：PrefixQuery query = new PrefixQuery(new Term(&quot;fileName&quot;,&quot;hell&quot;));</code></pre><p>PhraseQuery</p><pre><code>短语查询栗子1：    PhraseQuery query = new PhraseQuery();    query.add(new Term(&quot;fileName&quot;,&quot;lucene&quot;));</code></pre><p>FuzzyQuery</p><pre><code>模糊查询栗子：FuzzyQuery query = new FuzzyQuery(new Term(&quot;fileName&quot;,&quot;lucene&quot;));</code></pre><p>WildcardQuery</p><pre><code>通配符查询：* ：任意字符（0或多个）? : 一个字符栗子：WildcardQuery query = new WildcardQuery(new Term(&quot;fileName&quot;,&quot;*&quot;));</code></pre><p>RegexQuery</p><pre><code>正则表达式查询栗子：搜索含有最少1个字符，最多6个字符的RegexQuery query = new RegexQuery(new Term(&quot;fileName&quot;,&quot;[a-z]{1,6}&quot;));</code></pre><p>MultiFieldQueryParser</p><pre><code>查询多个field栗子：String[] fields = {&quot;fileName&quot;,&quot;fileContent&quot;};MultiFieldQueryParser queryParser = new MultiFieldQueryParser(fields, new StandardAnalyzer());Query query = queryParser.parse(&quot;fileName:lucene AND filePath:a&quot;);</code></pre><p>TopDocs</p><pre><code>TopDocs类是一个简单的指针容器,指针一般指向前N个排名的搜索结果,搜索结果即匹配条件的文档TopDocs会记录前N个结果中每个结果的int docID和浮点数型分数(反映相关度)栗子：    TermQuery searchingBooks = new TermQuery(new Term(&quot;subject&quot;,&quot;search&quot;));     Directory dir = TestUtil.getBookIndexDirectory();    IndexSearcher searcher = new IndexSearcher(dir);    TopDocs matches = searcher.search(searchingBooks, 10);</code></pre><h3 id="Lucene-6-0-索引文件格式"><a href="#Lucene-6-0-索引文件格式" class="headerlink" title="Lucene 6.0 索引文件格式"></a>Lucene 6.0 索引文件格式</h3><h4 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h4><p>谈到倒排索引，那么首先看看正排是什么样子的呢？假设文档1包含【中文、英文、日文】，文档2包含【英文、日文、韩文】，文档3包含【韩文，中文】，那么根据文档去查找内容的话</p><pre><code>文档1-&gt;【中文、英文、日文】文档2-&gt;【英文、日文、韩文】文档3-&gt;【韩文，中文】</code></pre><p>反过来，根据内容去查找文档</p><pre><code>中文-&gt;【文档1、文档3】英文-&gt;【文档1、文档2】日文-&gt;【文档1、文档2】韩文-&gt;【文档2、文档3】</code></pre><p>这就是倒排索引，而Lucene擅长的也正在于此</p><h4 id="段（Segments）"><a href="#段（Segments）" class="headerlink" title="段（Segments）"></a>段（Segments）</h4><p>Lucene的索引可能是由多个子索引或Segments组成。每个Segment是一个完全独立的索引，可以单独用于搜索，索引涉及</p><ol><li>为新添加的documents创建新的segments</li><li>合并已经存在的segments</li></ol><p>搜索可能涉及多个segments或多个索引，每个索引可能由一组segments组成</p><h4 id="文档编号"><a href="#文档编号" class="headerlink" title="文档编号"></a>文档编号</h4><p>Lucene通过一个整型的文档编号指向每个文档，第一个被加入索引的文档编号为0，后续加入的文档编号依次递增。<br>注意文档编号是可能发生变化的，所以在Lucene外部存储这些值时需要格外小心。</p><h4 id="索引结构概述"><a href="#索引结构概述" class="headerlink" title="索引结构概述"></a>索引结构概述</h4><p>每个segment索引包括信息</p><ul><li>Segment info：包含有关segment的元数据，例如文档编号，使用的文件</li><li>Field names：包含索引中使用的字段名称集合</li><li>Stored Field values：对于每个document，它包含属性-值对的列表，其中属性是字段名称。这些用于存储有关文档的辅助信息，例如其标题、url或访问数据库的标识符</li><li>Term dictionary：包含所有文档的所有索引字段中使用的所有terms的字典。字典还包括包含term的文档编号，以及指向term的频率和接近度的指针</li><li>Term Frequency data：对于字典中的每个term，包含该term的所有文档的数量以及该term在该文档中的频率，除非省略频率（IndexOptions.DOCS）</li><li>Term Proximity data：对于字典中的每个term，term在每个文档中出现的位置。注意，如果所有文档中的所有字段都省略位置数据，则不会存在</li><li>Normalization factors：对于每个文档中的每个字段，存储一个值，该值将乘以该字段上的匹配的分数</li><li>Term Vectors：对于每个文档中的每个字段，可以存储term vector，term vector由term文本和term频率组成</li><li>Per-document values：与存储的值类似，这些也以文档编号作为key，但通常旨在被加载到主存储器中以用于快速访问。存储的值通常用于汇总来自搜索的结果，而每个文档值对于诸如评分因子是有用的</li><li>Live documents：一个可选文件，指示哪些文档是活动的</li><li>Point values：可选的文件对，记录索引字段尺寸，以实现快速数字范围过滤和大数值（例如BigInteger、BigDecimal（1D）、地理形状交集（2D，3D））</li></ul><h4 id="文件命名"><a href="#文件命名" class="headerlink" title="文件命名"></a>文件命名</h4><p>属于一个段的所有文件具有相同的名称和不同的扩展名。当使用复合索引文件，这些文件（除了段信息文件、锁文件和已删除的文档文件）将压缩成单个.cfs文件。当任何索引文件被保存到目录时，它被赋予一个从未被使用过的文件名字</p><p><img src="http://image.laijianfeng.org/20180818_161352.png" alt="复合索引文件"></p><h4 id="文件扩展名摘要"><a href="#文件扩展名摘要" class="headerlink" title="文件扩展名摘要"></a>文件扩展名摘要</h4><table><thead><tr><th>名称</th><th>文件扩展名</th><th>简短描述</th></tr></thead><tbody><tr><td>Segments File</td><td>segments_N</td><td>保存了一个提交点（a commit point）的信息</td></tr><tr><td>Lock File</td><td>write.lock</td><td>防止多个IndexWriter同时写到一份索引文件中</td></tr><tr><td>Segment Info</td><td>.si</td><td>保存了索引段的元数据信息</td></tr><tr><td>Compound File</td><td>.cfs，.cfe</td><td>一个可选的虚拟文件，把所有索引信息都存储到复合索引文件中</td></tr><tr><td>Fields</td><td>.fnm</td><td>保存fields的相关信息</td></tr><tr><td>Field Index</td><td>.fdx</td><td>保存指向field data的指针</td></tr><tr><td>Field Data</td><td>.fdt</td><td>文档存储的字段的值</td></tr><tr><td>Term Dictionary</td><td>.tim</td><td>term词典，存储term信息</td></tr><tr><td>Term Index</td><td>.tip</td><td>到Term Dictionary的索引</td></tr><tr><td>Frequencies</td><td>.doc</td><td>由包含每个term以及频率的docs列表组成</td></tr><tr><td>Positions</td><td>.pos</td><td>存储出现在索引中的term的位置信息</td></tr><tr><td>Payloads</td><td>.pay</td><td>存储额外的per-position元数据信息，例如字符偏移和用户payloads</td></tr><tr><td>Norms</td><td>.nvd，.nvm</td><td>.nvm文件保存索引字段加权因子的元数据，.nvd文件保存索引字段加权数据</td></tr><tr><td>Per-Document Values</td><td>.dvd，.dvm</td><td>.dvm文件保存索引文档评分因子的元数据，.dvd文件保存索引文档评分数据</td></tr><tr><td>Term Vector Index</td><td>.tvx</td><td>将偏移存储到文档数据文件中</td></tr><tr><td>Term Vector Documents</td><td>.tvd</td><td>包含有term vectors的每个文档信息</td></tr><tr><td>Term Vector Fields</td><td>.tvf</td><td>字段级别有关term vectors的信息</td></tr><tr><td>Live Documents</td><td>.liv</td><td>哪些是有效文件的信息</td></tr><tr><td>Point values</td><td>.dii，.dim</td><td>保留索引点，如果有的话</td></tr></tbody></table><h4 id="锁文件"><a href="#锁文件" class="headerlink" title="锁文件"></a>锁文件</h4><p>默认情况下，存储在索引目录中的锁文件名为 <code>write.lock</code>。如果锁目录与索引目录不同，则锁文件将命名为“XXXX-write.lock”，其中XXXX是从索引目录的完整路径导出的唯一前缀。此锁文件确保每次只有一个写入程序在修改索引。</p><blockquote><p>参考：</p><ol><li><a href="http://sndragon.com/2018/05/03/Lucene%E5%88%9D%E8%AF%86%E5%8F%8A%E6%A0%B8%E5%BF%83%E7%B1%BB%E4%BB%8B%E7%BB%8D/" target="_blank" rel="noopener">Lucene初识及核心类介绍</a></li><li><a href="http://qguofeng.oschina.io/2018/03/17/Lucene/2018-03-17-Lucene%E6%A0%B8%E5%BF%83%E7%B1%BB/" target="_blank" rel="noopener">Lucene核心类</a></li><li><a href="http://codepub.cn/2016/12/05/Lucene-6-0-index-file-format/" target="_blank" rel="noopener">Lucene 6.0 索引文件格式</a></li><li>Lucene实战.pdf</li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> lucene </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Elasticsearch 6.x Mapping设置</title>
      <link href="/2018/08/Elasticsearch-6-x-Mapping%E8%AE%BE%E7%BD%AE/"/>
      <url>/2018/08/Elasticsearch-6-x-Mapping%E8%AE%BE%E7%BD%AE/</url>
      <content type="html"><![CDATA[<h3 id="Mapping"><a href="#Mapping" class="headerlink" title="Mapping"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html" target="_blank" rel="noopener">Mapping</a></h3><p>类似于数据库中的表结构定义，主要作用如下：</p><ul><li>定义Index下字段名（Field Name）</li><li>定义字段的类型，比如数值型，字符串型、布尔型等</li><li>定义倒排索引的相关配置，比如是否索引、记录postion等   </li></ul><p>需要注意的是，在索引中定义太多字段可能会导致索引膨胀，出现内存不足和难以恢复的情况，下面有几个设置：</p><ul><li>index.mapping.total_fields.limit：一个索引中能定义的字段的最大数量，默认是 1000</li><li>index.mapping.depth.limit：字段的最大深度，以内部对象的数量来计算，默认是20</li><li>index.mapping.nested_fields.limit：索引中嵌套字段的最大数量，默认是50</li></ul><h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html" target="_blank" rel="noopener">数据类型</a></h3><h4 id="核心数据类型"><a href="#核心数据类型" class="headerlink" title="核心数据类型"></a>核心数据类型</h4><ul><li>字符串 - text<ul><li>用于全文索引，该类型的字段将通过分词器进行分词，最终用于构建索引</li></ul></li><li>字符串 - keyword<ul><li>不分词，只能搜索该字段的完整的值，只用于 filtering </li></ul></li><li>数值型 <ul><li>long：有符号64-bit integer：-2^63 ~ 2^63 - 1 </li><li>integer：有符号32-bit integer，-2^31 ~ 2^31 - 1 </li><li>short：有符号16-bit integer，-32768 ~ 32767</li><li>byte： 有符号8-bit integer，-128 ~ 127</li><li>double：64-bit IEEE 754 浮点数</li><li>float：32-bit IEEE 754 浮点数</li><li>half_float：16-bit IEEE 754 浮点数</li><li>scaled_float</li></ul></li><li>布尔 - boolean<ul><li>值：false, “false”, true, “true”</li></ul></li><li>日期 - date<ul><li>由于Json没有date类型，所以es通过识别字符串是否符合format定义的格式来判断是否为date类型</li><li>format默认为：<code>strict_date_optional_time||epoch_millis</code> <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-date-format.html" target="_blank" rel="noopener">format</a></li></ul></li><li>二进制 - binary<ul><li>该类型的字段把值当做经过 base64 编码的字符串，默认不存储，且不可搜索</li></ul></li><li><p>范围类型</p><ul><li>范围类型表示值是一个范围，而不是一个具体的值</li><li>譬如 age 的类型是 integer_range，那么值可以是  {“gte” : 10, “lte” : 20}；搜索 “term” : {“age”: 15} 可以搜索该值；搜索 “range”: {“age”: {“gte”:11, “lte”: 15}} 也可以搜索到</li><li>range参数 relation 设置匹配模式<ul><li>INTERSECTS ：默认的匹配模式，只要搜索值与字段值有交集即可匹配到</li><li>WITHIN：字段值需要完全包含在搜索值之内，也就是字段值是搜索值的子集才能匹配</li><li>CONTAINS：与WITHIN相反，只搜索字段值包含搜索值的文档</li></ul></li><li>integer_range</li><li>float_range</li><li>long_range</li><li>double_range</li><li>date_range：64-bit 无符号整数，时间戳（单位：毫秒）</li><li><p>ip_range：IPV4 或 IPV6 格式的字符串</p><p>​</p></li></ul></li></ul><pre><code># 创建range索引PUT range_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;properties&quot;: {        &quot;expected_attendees&quot;: {          &quot;type&quot;: &quot;integer_range&quot;        },        &quot;time_frame&quot;: {          &quot;type&quot;: &quot;date_range&quot;,           &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;        }      }    }  }}# 插入一个文档PUT range_index/_doc/1{  &quot;expected_attendees&quot; : {     &quot;gte&quot; : 10,    &quot;lte&quot; : 20  },  &quot;time_frame&quot; : {     &quot;gte&quot; : &quot;2015-10-31 12:00:00&quot;,     &quot;lte&quot; : &quot;2015-11-05&quot;  }}# 12在 10~20的范围内，可以搜索到文档1GET range_index/_search{  &quot;query&quot; : {    &quot;term&quot; : {      &quot;expected_attendees&quot; : {        &quot;value&quot;: 12      }    }  }}# within可以搜索到文档# 可以修改日期，然后分别对比CONTAINS，WITHIN，INTERSECTS的区别GET range_index/_search{  &quot;query&quot; : {    &quot;range&quot; : {      &quot;time_frame&quot; : {         &quot;gte&quot; : &quot;2015-11-02&quot;,        &quot;lte&quot; : &quot;2015-11-03&quot;,        &quot;relation&quot; : &quot;within&quot;       }    }  }}</code></pre><h4 id="复杂数据类型"><a href="#复杂数据类型" class="headerlink" title="复杂数据类型"></a>复杂数据类型</h4><ul><li>数组类型 Array<ul><li>字符串数组 [ “one”, “two” ]</li><li>整数数组 [ 1, 2 ]</li><li>数组的数组  [ 1, [ 2, 3 ]]，相当于 [ 1, 2, 3 ]</li><li>Object对象数组 [ { “name”: “Mary”, “age”: 12 }, { “name”: “John”, “age”: 10 }]</li><li>同一个数组只能存同类型的数据，不能混存，譬如 [ 10, “some string” ] 是错误的</li><li>数组中的 null 值将被 null_value 属性设置的值代替或者被忽略</li><li>空数组 [] 被当做 missing field 处理</li></ul></li><li><p>对象类型 Object</p><ul><li>对象类型可能有内部对象</li><li><p>被索引的形式为：manager.name.first</p><p>​</p></li></ul></li></ul><pre><code># tags字符串数组，lists 对象数组PUT my_index/_doc/1{  &quot;message&quot;: &quot;some arrays in this document...&quot;,  &quot;tags&quot;:  [ &quot;elasticsearch&quot;, &quot;wow&quot; ],   &quot;lists&quot;: [     {      &quot;name&quot;: &quot;prog_list&quot;,      &quot;description&quot;: &quot;programming list&quot;    },    {      &quot;name&quot;: &quot;cool_list&quot;,      &quot;description&quot;: &quot;cool stuff list&quot;    }  ]}</code></pre><ul><li>嵌套类型 Nested<ul><li>nested 类型是一种对象类型的特殊版本，它允许索引对象数组，<strong>独立地索引每个对象</strong></li></ul></li></ul><h4 id="嵌套类型与Object类型的区别"><a href="#嵌套类型与Object类型的区别" class="headerlink" title="嵌套类型与Object类型的区别"></a>嵌套类型与Object类型的区别</h4><p>通过例子来说明:</p><ol><li>插入一个文档，不设置mapping，此时 user 字段被自动识别为<strong>对象数组</strong></li></ol><pre><code>DELETE my_indexPUT my_index/_doc/1{  &quot;group&quot; : &quot;fans&quot;,  &quot;user&quot; : [     {      &quot;first&quot; : &quot;John&quot;,      &quot;last&quot; :  &quot;Smith&quot;    },    {      &quot;first&quot; : &quot;Alice&quot;,      &quot;last&quot; :  &quot;White&quot;    }  ]}</code></pre><ol start="2"><li>查询 user.first为 Alice，user.last 为 Smith的文档，理想中应该找不到匹配的文档</li><li>结果是查到了文档1，为什么呢？</li></ol><pre><code>GET my_index/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: [        { &quot;match&quot;: { &quot;user.first&quot;: &quot;Alice&quot; }},        { &quot;match&quot;: { &quot;user.last&quot;:  &quot;Smith&quot; }}      ]    }  }}</code></pre><ol start="4"><li>是由于Object对象类型在内部被转化成如下格式的文档：<pre><code>{&quot;group&quot; :        &quot;fans&quot;,&quot;user.first&quot; : [ &quot;alice&quot;, &quot;john&quot; ],&quot;user.last&quot; :  [ &quot;smith&quot;, &quot;white&quot; ]}</code></pre></li><li>user.first 和 user.last 扁平化为多值字段，alice 和 white 的<strong>关联关系丢失了</strong>。导致这个文档错误地匹配对 alice 和 smith 的查询</li><li>如果最开始就把user设置为 nested 嵌套对象呢？</li></ol><pre><code>DELETE my_indexPUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;properties&quot;: {        &quot;user&quot;: {          &quot;type&quot;: &quot;nested&quot;         }      }    }  }}PUT my_index/_doc/1{  &quot;group&quot;: &quot;fans&quot;,  &quot;user&quot;: [    {      &quot;first&quot;: &quot;John&quot;,      &quot;last&quot;: &quot;Smith&quot;    },    {      &quot;first&quot;: &quot;Alice&quot;,      &quot;last&quot;: &quot;White&quot;    }  ]}</code></pre><ol start="7"><li>再来进行查询，可以发现以下第一个查不到文档，第二个查询到文档1，符合我们预期</li></ol><pre><code>GET my_index/_search{  &quot;query&quot;: {    &quot;nested&quot;: {      &quot;path&quot;: &quot;user&quot;,      &quot;query&quot;: {        &quot;bool&quot;: {          &quot;must&quot;: [            { &quot;match&quot;: { &quot;user.first&quot;: &quot;Alice&quot; }},            { &quot;match&quot;: { &quot;user.last&quot;:  &quot;Smith&quot; }}           ]        }      }    }  }}GET my_index/_search{  &quot;query&quot;: {    &quot;nested&quot;: {      &quot;path&quot;: &quot;user&quot;,      &quot;query&quot;: {        &quot;bool&quot;: {          &quot;must&quot;: [            { &quot;match&quot;: { &quot;user.first&quot;: &quot;Alice&quot; }},            { &quot;match&quot;: { &quot;user.last&quot;:  &quot;White&quot; }}           ]        }      },      &quot;inner_hits&quot;: {         &quot;highlight&quot;: {          &quot;fields&quot;: {            &quot;user.first&quot;: {}          }        }      }    }  }}</code></pre><ol start="8"><li><p>nested对象将数组中每个对象作为独立隐藏文档来索引，这意味着每个嵌套对象都可以独立被搜索</p></li><li><p>需要注意的是：</p></li></ol><ul><li>使用 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-nested-query.html" target="_blank" rel="noopener">nested 查询</a>来搜索</li><li>使用 nested 和 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-reverse-nested-aggregation.html" target="_blank" rel="noopener">reverse_nested</a> 聚合来分析</li><li>使用 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-sort.html#nested-sorting" target="_blank" rel="noopener">nested sorting</a> 来排序</li><li>使用 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-inner-hits.html#nested-inner-hits" target="_blank" rel="noopener">nested inner hits</a> 来检索和高亮</li></ul><h4 id="地理位置数据类型"><a href="#地理位置数据类型" class="headerlink" title="地理位置数据类型"></a>地理位置数据类型</h4><ul><li>geo_point<ul><li>地理位置，其值可以有如下四中表现形式：<ul><li>object对象：”location”: {“lat”: 41.12, “lon”: -71.34}</li><li>字符串：”location”: “41.12,-71.34”</li><li><a href="http://geohash.gofreerange.com/" target="_blank" rel="noopener">geohash</a>：”location”: “drm3btev3e86” </li><li>数组：”location”: [ -71.34, 41.12 ] </li></ul></li><li>查询的时候通过 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-geo-bounding-box-query.html" target="_blank" rel="noopener">Geo Bounding Box Query </a> 进行查询</li></ul></li><li>geo_shape</li></ul><h4 id="专用数据类型"><a href="#专用数据类型" class="headerlink" title="专用数据类型"></a>专用数据类型</h4><ul><li>记录IP地址 ip</li><li>实现自动补全 completion</li><li>记录分词数 token_count</li><li>记录字符串hash值 murmur3</li><li>Percolator</li></ul><pre><code># ip类型，存储IPPUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;properties&quot;: {        &quot;ip_addr&quot;: {          &quot;type&quot;: &quot;ip&quot;        }      }    }  }}PUT my_index/_doc/1{  &quot;ip_addr&quot;: &quot;192.168.1.1&quot;}GET my_index/_search{  &quot;query&quot;: {    &quot;term&quot;: {      &quot;ip_addr&quot;: &quot;192.168.0.0/16&quot;    }  }}</code></pre><h4 id="多字段特性-multi-fields"><a href="#多字段特性-multi-fields" class="headerlink" title="多字段特性 multi-fields"></a>多字段特性 multi-fields</h4><ul><li>允许对同一个字段采用不同的配置，比如分词，常见例子如对人名实现拼音搜索，只需要在人名中新增一个<strong>子字段</strong>为 pinyin 即可</li><li>通过参数 fields 设置</li></ul><h4 id="设置Mapping"><a href="#设置Mapping" class="headerlink" title="设置Mapping"></a>设置Mapping</h4><p><img src="http://image.laijianfeng.org/20180804_024134.png" alt="image"></p><pre><code>GET my_index/_mapping# 结果{  &quot;my_index&quot;: {    &quot;mappings&quot;: {      &quot;doc&quot;: {        &quot;properties&quot;: {          &quot;age&quot;: {            &quot;type&quot;: &quot;integer&quot;          },          &quot;created&quot;: {            &quot;type&quot;: &quot;date&quot;          },          &quot;name&quot;: {            &quot;type&quot;: &quot;text&quot;          },          &quot;title&quot;: {            &quot;type&quot;: &quot;text&quot;          }        }      }    }  }}</code></pre><h3 id="Mapping参数"><a href="#Mapping参数" class="headerlink" title="Mapping参数"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-params.html" target="_blank" rel="noopener">Mapping参数</a></h3><h4 id="analyzer"><a href="#analyzer" class="headerlink" title="analyzer"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analyzer.html" target="_blank" rel="noopener">analyzer</a></h4><ul><li>分词器，默认为standard analyzer，当该字段被索引和搜索时对字段进行分词处理</li></ul><h4 id="boost"><a href="#boost" class="headerlink" title="boost"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-boost.html" target="_blank" rel="noopener">boost</a></h4><ul><li>字段权重，默认为1.0</li></ul><h4 id="dynamic"><a href="#dynamic" class="headerlink" title="dynamic"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic.html" target="_blank" rel="noopener">dynamic</a></h4><ul><li>Mapping中的字段类型一旦设定后，禁止直接修改，原因是：Lucene实现的倒排索引生成后不允许修改</li><li>只能新建一个索引，然后reindex数据</li><li>默认允许新增字段</li><li><p>通过dynamic参数来控制字段的新增：</p><ul><li>true（默认）允许自动新增字段</li><li>false 不允许自动新增字段，但是文档可以正常写入，但无法对新增字段进行查询等操作</li><li><p>strict 文档不能写入，报错</p><p>​</p></li></ul></li></ul><pre><code>PUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;dynamic&quot;: false,       &quot;properties&quot;: {        &quot;user&quot;: {           &quot;properties&quot;: {            &quot;name&quot;: {              &quot;type&quot;: &quot;text&quot;            },            &quot;social_networks&quot;: {               &quot;dynamic&quot;: true,              &quot;properties&quot;: {}            }          }        }      }    }  }}</code></pre><p>定义后my_index这个索引下不能自动新增字段，但是在user.social_networks下可以自动新增子字段</p><h4 id="copy-to"><a href="#copy-to" class="headerlink" title="copy_to"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/copy-to.html" target="_blank" rel="noopener">copy_to</a></h4><ul><li>将该字段复制到目标字段，实现类似_all的作用</li><li>不会出现在_source中，只用来搜索</li></ul><pre><code>DELETE my_indexPUT my_index{  &quot;mappings&quot;: {    &quot;doc&quot;: {      &quot;properties&quot;: {        &quot;first_name&quot;: {          &quot;type&quot;: &quot;text&quot;,          &quot;copy_to&quot;: &quot;full_name&quot;         },        &quot;last_name&quot;: {          &quot;type&quot;: &quot;text&quot;,          &quot;copy_to&quot;: &quot;full_name&quot;         },        &quot;full_name&quot;: {          &quot;type&quot;: &quot;text&quot;        }      }    }  }}PUT my_index/doc/1{  &quot;first_name&quot;: &quot;John&quot;,  &quot;last_name&quot;: &quot;Smith&quot;}GET my_index/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;full_name&quot;: {         &quot;query&quot;: &quot;John Smith&quot;,        &quot;operator&quot;: &quot;and&quot;      }    }  }}</code></pre><h4 id="index"><a href="#index" class="headerlink" title="index"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-index.html" target="_blank" rel="noopener">index</a></h4><ul><li>控制当前字段是否索引，默认为true，即记录索引，false不记录，即不可搜索</li></ul><h4 id="index-options"><a href="#index-options" class="headerlink" title="index_options"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index-options.html" target="_blank" rel="noopener">index_options</a></h4><ul><li>index_options参数控制将哪些信息添加到倒排索引，以用于搜索和突出显示，可选的值有：docs，freqs，positions，offsets</li><li>docs：只索引 doc id</li><li>freqs：索引 doc id 和词频，平分时可能要用到词频</li><li>positions：索引 doc id、词频、位置，做 proximity or phrase queries 时可能要用到位置信息</li><li>offsets：索引doc id、词频、位置、开始偏移和结束偏移，高亮功能需要用到offsets</li></ul><h4 id="fielddata"><a href="#fielddata" class="headerlink" title="fielddata"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/fielddata.html" target="_blank" rel="noopener">fielddata</a></h4><ul><li>是否预加载 fielddata，默认为false</li><li>Elasticsearch第一次查询时完整加载这个字段所有 Segment 中的倒排索引到内存中</li><li>如果我们有一些 5 GB 的索引段，并希望加载 10 GB 的 fielddata 到内存中，这个过程可能会要数十秒</li><li>将 fielddate 设置为 true ,将载入 fielddata 的代价转移到索引刷新的时候，而不是查询时，从而大大提高了搜索体验</li><li>参考：<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/preload-fielddata.html" target="_blank" rel="noopener">预加载 fielddata</a></li></ul><h4 id="eager-global-ordinals"><a href="#eager-global-ordinals" class="headerlink" title="eager_global_ordinals"></a>eager_global_ordinals</h4><ul><li>是否预构建全局序号，默认false</li><li>参考：<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/preload-fielddata.html#global-ordinals" target="_blank" rel="noopener">预构建全局序号（Eager global ordinals）</a></li></ul><h4 id="doc-values"><a href="#doc-values" class="headerlink" title="doc_values"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/doc-values.html" target="_blank" rel="noopener">doc_values</a></h4><ul><li>参考：<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/docvalues-and-fielddata.html" target="_blank" rel="noopener">Doc Values and Fielddata</a></li></ul><h4 id="fields"><a href="#fields" class="headerlink" title="fields"></a>fields</h4><ul><li>该参数的目的是为了实现 multi-fields</li><li>一个字段，多种数据类型</li><li>譬如：一个字段 city 的数据类型为 text ，用于全文索引，可以通过 fields 为该字段定义 keyword 类型，用于排序和聚合</li></ul><pre><code># 设置 mappingPUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;properties&quot;: {        &quot;city&quot;: {          &quot;type&quot;: &quot;text&quot;,          &quot;fields&quot;: {            &quot;raw&quot;: {               &quot;type&quot;:  &quot;keyword&quot;            }          }        }      }    }  }}# 插入两条数据PUT my_index/_doc/1{  &quot;city&quot;: &quot;New York&quot;}PUT my_index/_doc/2{  &quot;city&quot;: &quot;York&quot;}# 查询，city用于全文索引 match，city.raw用于排序和聚合GET my_index/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;city&quot;: &quot;york&quot;     }  },  &quot;sort&quot;: {    &quot;city.raw&quot;: &quot;asc&quot;   },  &quot;aggs&quot;: {    &quot;Cities&quot;: {      &quot;terms&quot;: {        &quot;field&quot;: &quot;city.raw&quot;       }    }  }}</code></pre><h4 id="format"><a href="#format" class="headerlink" title="format"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-date-format.html" target="_blank" rel="noopener">format</a></h4><ul><li>由于JSON没有date类型，Elasticsearch预先通过format参数定义时间格式，将匹配的字符串识别为date类型，转换为时间戳（单位：毫秒）</li><li>format默认为：<code>strict_date_optional_time||epoch_millis</code></li><li>Elasticsearch内建的时间格式:</li></ul><table><thead><tr><th>名称</th><th>格式</th></tr></thead><tbody><tr><td>epoch_millis</td><td>时间戳（单位：毫秒）</td></tr><tr><td>epoch_second</td><td>时间戳（单位：秒）</td></tr><tr><td>date_optional_time</td><td></td></tr><tr><td>basic_date</td><td>yyyyMMdd</td></tr><tr><td>basic_date_time</td><td>yyyyMMdd’T’HHmmss.SSSZ</td></tr><tr><td>basic_date_time_no_millis</td><td>yyyyMMdd’T’HHmmssZ</td></tr><tr><td>basic_ordinal_date</td><td>yyyyDDD</td></tr><tr><td>basic_ordinal_date_time</td><td>yyyyDDD’T’HHmmss.SSSZ</td></tr><tr><td>basic_ordinal_date_time_no_millis</td><td>yyyyDDD’T’HHmmssZ</td></tr><tr><td>basic_time</td><td>HHmmss.SSSZ</td></tr><tr><td>basic_time_no_millis</td><td>HHmmssZ</td></tr><tr><td>basic_t_time</td><td>‘T’HHmmss.SSSZ</td></tr><tr><td>basic_t_time_no_millis</td><td>‘T’HHmmssZ</td></tr></tbody></table><ul><li>上述名称加前缀 <code>strict_</code> 表示为严格格式</li><li>更多的查看文档</li></ul><h4 id="properties"><a href="#properties" class="headerlink" title="properties"></a>properties</h4><ul><li>用于_doc，object和nested类型的字段定义<strong>子字段</strong></li></ul><pre><code>PUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {       &quot;properties&quot;: {        &quot;manager&quot;: {           &quot;properties&quot;: {            &quot;age&quot;:  { &quot;type&quot;: &quot;integer&quot; },            &quot;name&quot;: { &quot;type&quot;: &quot;text&quot;  }          }        },        &quot;employees&quot;: {           &quot;type&quot;: &quot;nested&quot;,          &quot;properties&quot;: {            &quot;age&quot;:  { &quot;type&quot;: &quot;integer&quot; },            &quot;name&quot;: { &quot;type&quot;: &quot;text&quot;  }          }        }      }    }  }}PUT my_index/_doc/1 {  &quot;region&quot;: &quot;US&quot;,  &quot;manager&quot;: {    &quot;name&quot;: &quot;Alice White&quot;,    &quot;age&quot;: 30  },  &quot;employees&quot;: [    {      &quot;name&quot;: &quot;John Smith&quot;,      &quot;age&quot;: 34    },    {      &quot;name&quot;: &quot;Peter Brown&quot;,      &quot;age&quot;: 26    }  ]}</code></pre><h4 id="normalizer"><a href="#normalizer" class="headerlink" title="normalizer"></a>normalizer</h4><ul><li>与 analyzer 类似，只不过 analyzer 用于 text 类型字段，分词产生多个 token，而 normalizer 用于 keyword 类型，只产生一个 token（整个字段的值作为一个token，而不是分词拆分为多个token）</li><li>定义一个自定义 normalizer，使用大写uppercase过滤器</li></ul><pre><code>PUT test_index_4{  &quot;settings&quot;: {    &quot;analysis&quot;: {      &quot;normalizer&quot;: {        &quot;my_normalizer&quot;: {          &quot;type&quot;: &quot;custom&quot;,          &quot;char_filter&quot;: [],          &quot;filter&quot;: [&quot;uppercase&quot;, &quot;asciifolding&quot;]        }      }    }  },  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;properties&quot;: {        &quot;foo&quot;: {          &quot;type&quot;: &quot;keyword&quot;,          &quot;normalizer&quot;: &quot;my_normalizer&quot;        }      }    }  }}# 插入数据POST test_index_4/_doc/1{  &quot;foo&quot;: &quot;hello world&quot;}POST test_index_4/_doc/2{  &quot;foo&quot;: &quot;Hello World&quot;}POST test_index_4/_doc/3{  &quot;foo&quot;: &quot;hello elasticsearch&quot;}# 搜索hello，结果为空，而不是3条！！ GET test_index_4/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;foo&quot;: &quot;hello&quot;    }  }}# 搜索 hello world，结果2条，1 和 2GET test_index_4/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;foo&quot;: &quot;hello world&quot;    }  }}</code></pre><h4 id="其他字段"><a href="#其他字段" class="headerlink" title="其他字段"></a>其他字段</h4><ul><li>coerce<ul><li>强制类型转换，把json中的值转为ES中字段的数据类型，譬如：把字符串”5”转为integer的5</li><li>coerce默认为 true</li><li>如果coerce设置为 false，当json的值与es字段类型不匹配将会 rejected</li><li>通过 “settings”: { “index.mapping.coerce”: false } 设置索引的 coerce</li></ul></li><li>enabled<ul><li>是否索引，默认为 true</li><li>可以在_doc和字段两个粒度进行设置</li></ul></li><li>ignore_above<ul><li>设置能被索引的字段的长度</li><li>超过这个长度，该字段将不被索引，所以无法搜索，但聚合的terms可以看到</li></ul></li><li>null_value<ul><li>该字段定义遇到null值时的处理策略，默认为Null，即空值，此时ES会忽略该值</li><li>通过设定该值可以设定字段为 null 时的默认值</li></ul></li><li>ignore_malformed<ul><li>当数据类型不匹配且 coerce 强制转换时,默认情况会抛出异常,并拒绝整个文档的插入</li><li>若设置该参数为 true，则忽略该异常，并强制赋值，但是不会被索引，其他字段则照常</li></ul></li><li>norms<ul><li>norms 存储各种标准化因子，为后续查询计算文档对该查询的匹配分数提供依据</li><li>norms 参数对<strong>评分</strong>很有用，但需要占用大量的磁盘空间</li><li>如果不需要计算字段的评分，可以取消该字段 norms 的功能</li></ul></li><li>position_increment_gap<ul><li>与 proximity queries（近似查询）和 phrase queries（短语查询）有关</li><li>默认值 100</li></ul></li><li>search_analyzer<ul><li>搜索分词器，查询时使用</li><li>默认与 analyzer 一样</li></ul></li><li>similarity<ul><li>设置相关度算法，ES5.x 和 ES6.x 默认的算法为 BM25</li><li>另外也可选择 classic 和 boolean</li></ul></li><li>store<ul><li>store 的意思是：是否在 _source 之外在独立存储一份，默认值为 false</li><li>es在存储数据的时候把json对象存储到”_source”字段里，”_source”把所有字段保存为一份文档存储（读取需要1次IO），要取出某个字段则通过 source filtering 过滤</li><li>当字段比较多或者内容比较多，并且不需要取出所有字段的时候，可以把特定字段的store设置为true单独存储（读取需要1次IO），同时在_source设置exclude</li><li>关于该字段的理解，参考： <a href="https://blog.csdn.net/helllochun/article/details/52136954" target="_blank" rel="noopener">es设置mapping store属性</a></li></ul></li><li>term_vector<ul><li>与倒排索引相关</li></ul></li></ul><h3 id="Dynamic-Mapping"><a href="#Dynamic-Mapping" class="headerlink" title="Dynamic Mapping"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-mapping.html" target="_blank" rel="noopener">Dynamic Mapping</a></h3><p>ES是依靠JSON文档的字段类型来实现自动识别字段类型，支持的类型如下：</p><table><thead><tr><th>JSON 类型</th><th>ES 类型</th></tr></thead><tbody><tr><td>null</td><td>忽略</td></tr><tr><td>boolean</td><td>boolean</td></tr><tr><td>浮点类型</td><td>float</td></tr><tr><td>整数</td><td>long</td></tr><tr><td>object</td><td>object</td></tr><tr><td>array</td><td>由第一个非 null 值的类型决定</td></tr><tr><td>string</td><td>匹配为日期则设为date类型（默认开启）；<br>匹配为数字则设置为 float或long类型（默认关闭）；<br>设为text类型，并附带keyword的子字段</td></tr></tbody></table><p>举栗子</p><pre><code>POST my_index/doc{  &quot;username&quot;:&quot;whirly&quot;,  &quot;age&quot;:22,  &quot;birthday&quot;:&quot;1995-01-01&quot;}GET my_index/_mapping# 结果{  &quot;my_index&quot;: {    &quot;mappings&quot;: {      &quot;doc&quot;: {        &quot;properties&quot;: {          &quot;age&quot;: {            &quot;type&quot;: &quot;long&quot;          },          &quot;birthday&quot;: {            &quot;type&quot;: &quot;date&quot;          },          &quot;username&quot;: {            &quot;type&quot;: &quot;text&quot;,            &quot;fields&quot;: {              &quot;keyword&quot;: {                &quot;type&quot;: &quot;keyword&quot;,                &quot;ignore_above&quot;: 256              }            }          }        }      }    }  }}</code></pre><h4 id="日期的自动识别"><a href="#日期的自动识别" class="headerlink" title="日期的自动识别"></a>日期的自动识别</h4><ul><li>dynamic_date_formats 参数为自动识别的日期格式，默认为 [ “strict_date_optional_time”,”yyyy/MM/dd HH:mm:ss Z||yyyy/MM/dd Z”]</li><li>date_detection可以关闭日期自动识别机制</li></ul><pre><code># 自定义日期识别格式PUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;dynamic_date_formats&quot;: [&quot;MM/dd/yyyy&quot;]    }  }}# 关闭日期自动识别机制PUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;date_detection&quot;: false    }  }}</code></pre><h4 id="数字的自动识别"><a href="#数字的自动识别" class="headerlink" title="数字的自动识别"></a>数字的自动识别</h4><ul><li>字符串是数字时，默认不会自动识别为整形，因为字符串中出现数字完全是合理的</li><li>numeric_detection 参数可以开启字符串中数字的自动识别</li></ul><h3 id="Dynamic-templates"><a href="#Dynamic-templates" class="headerlink" title="Dynamic templates"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-templates.html" target="_blank" rel="noopener">Dynamic templates</a></h3><p>允许根据ES自动识别的数据类型、字段名等来动态设定字段类型，可以实现如下效果：</p><ul><li>所有字符串类型都设定为keyword类型，即不分词</li><li>所有以message开头的字段都设定为text类型，即分词</li><li>所有以long_开头的字段都设定为long类型</li><li>所有自动匹配为double类型的都设定为float类型，以节省空间</li></ul><h4 id="Dynamic-templates-API"><a href="#Dynamic-templates-API" class="headerlink" title="Dynamic templates API"></a>Dynamic templates API</h4><pre><code>&quot;dynamic_templates&quot;: [    {      &quot;my_template_name&quot;: {         ...  match conditions ...         &quot;mapping&quot;: { ... }       }    },    ...]</code></pre><p>匹配规则一般有如下几个参数：</p><ul><li>match_mapping_type 匹配ES自动识别的字段类型，如boolean，long，string等</li><li>match, unmatch 匹配字段名</li><li>match_pattern 匹配正则表达式</li><li>path_match, path_unmatch 匹配路径</li></ul><pre><code># double类型的字段设定为float以节省空间PUT my_index{  &quot;mappings&quot;: {    &quot;_doc&quot;: {      &quot;dynamic_templates&quot;: [        {          &quot;integers&quot;: {            &quot;match_mapping_type&quot;: &quot;double&quot;,            &quot;mapping&quot;: {              &quot;type&quot;: &quot;float&quot;            }          }        }      ]    }  }}</code></pre><h5 id="自定义Mapping的建议"><a href="#自定义Mapping的建议" class="headerlink" title="自定义Mapping的建议"></a>自定义Mapping的建议</h5><ol><li>写入一条文档到ES的临时索引中，获取ES自动生成的Mapping</li><li>修改步骤1得到的Mapping，自定义相关配置</li><li>使用步骤2的Mapping创建实际所需索引</li></ol><h3 id="Index-Template-索引模板"><a href="#Index-Template-索引模板" class="headerlink" title="Index Template 索引模板"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/indices-templates.html" target="_blank" rel="noopener">Index Template 索引模板</a></h3><ul><li>索引模板，主要用于在新建索引时自动应用预先设定的配置，简化索引创建的操作步骤<ul><li>可以设定索引的setting和mapping</li><li>可以有多个模板，根据order设置，order大的覆盖小的配置</li></ul></li><li>索引模板API，endpoint为 _template</li></ul><pre><code># 创建索引模板，匹配 test-index-map 开头的索引PUT _template/template_1{  &quot;index_patterns&quot;: [&quot;test-index-map*&quot;],  &quot;order&quot;: 2,  &quot;settings&quot;: {    &quot;number_of_shards&quot;: 1  },  &quot;mappings&quot;: {    &quot;doc&quot;: {      &quot;_source&quot;: {        &quot;enabled&quot;: false      },      &quot;properties&quot;: {        &quot;name&quot;: {          &quot;type&quot;: &quot;keyword&quot;        },        &quot;created_at&quot;: {          &quot;type&quot;: &quot;date&quot;,          &quot;format&quot;: &quot;YYYY/MM/dd HH:mm:ss&quot;        }      }    }  }}# 插入一个文档POST test-index-map_1/doc{  &quot;name&quot; : &quot;小旋锋&quot;,  &quot;created_at&quot;: &quot;2018/08/16 20:11:11&quot;}# 获取该索引的信息，可以发现 settings 和 mappings 和索引模板里设置的一样GET test-index-map_1# 删除DELETE /_template/template_1# 查询GET /_template/template_1</code></pre><blockquote><p>参考文档： </p><ol><li>elasticsearch 官方文档</li><li><a href="https://coding.imooc.com/class/181.html" target="_blank" rel="noopener">慕课网 Elastic Stack从入门到实践</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>倒排索引与分词</title>
      <link href="/2018/08/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E4%B8%8E%E5%88%86%E8%AF%8D/"/>
      <url>/2018/08/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E4%B8%8E%E5%88%86%E8%AF%8D/</url>
      <content type="html"><![CDATA[<h3 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h3><ul><li>正排索引：文档id到单词的关联关系</li><li>倒排索引：单词到文档id的关联关系</li></ul><p>示例：<br>对以下三个文档去除停用词后构造倒排索引<br><img src="http://image.laijianfeng.org/20180803_223406.png" alt="image"></p><h4 id="倒排索引-查询过程"><a href="#倒排索引-查询过程" class="headerlink" title="倒排索引-查询过程"></a>倒排索引-查询过程</h4><p>查询包含“搜索引擎”的文档</p><ol><li>通过倒排索引获得“搜索引擎”对应的文档id列表，有1，3</li><li>通过正排索引查询1和3的完整内容</li><li>返回最终结果</li></ol><h4 id="倒排索引-组成"><a href="#倒排索引-组成" class="headerlink" title="倒排索引-组成"></a>倒排索引-组成</h4><ul><li>单词词典（Term Dictionary）</li><li>倒排列表（Posting List）</li></ul><h4 id="单词词典（Term-Dictionary）"><a href="#单词词典（Term-Dictionary）" class="headerlink" title="单词词典（Term Dictionary）"></a>单词词典（Term Dictionary）</h4><p>单词词典的实现一般用B+树，B+树构造的可视化过程网址: <a href="https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html" target="_blank" rel="noopener">B+ Tree Visualization</a></p><blockquote><p>关于B树和B+树</p><ol><li><a href="https://zh.wikipedia.org/wiki/B%E6%A0%91" target="_blank" rel="noopener">维基百科-B树</a></li><li><a href="https://zh.wikipedia.org/wiki/B%2B%E6%A0%91" target="_blank" rel="noopener">维基百科-B+树</a></li><li><a href="https://www.cnblogs.com/nullzx/p/8729425.html" target="_blank" rel="noopener">B树和B+树的插入、删除图文详解</a></li></ol></blockquote><p><img src="http://image.laijianfeng.org/20180803_225118.png" alt="image"></p><h4 id="倒排列表（Posting-List）"><a href="#倒排列表（Posting-List）" class="headerlink" title="倒排列表（Posting List）"></a>倒排列表（Posting List）</h4><ul><li>倒排列表记录了单词对应的文档集合，有倒排索引项（Posting）组成</li><li>倒排索引项主要包含如下信息：<ol><li>文档id用于获取原始信息</li><li>单词频率（TF，Term Frequency），记录该单词在该文档中出现的次数，用于后续相关性算分</li><li>位置（Posting），记录单词在文档中的分词位置（多个），用于做词语搜索（Phrase Query）</li><li>偏移（Offset），记录单词在文档的开始和结束位置，用于高亮显示</li></ol></li></ul><p><img src="http://image.laijianfeng.org/20180803_225931.png" alt="image"></p><p>B+树<strong>内部结点存索引，叶子结点存数据</strong>，这里的 单词词典就是B+树索引，倒排列表就是数据，整合在一起后如下所示</p><p><img src="http://image.laijianfeng.org/20180803_232214.png" alt="image"></p><p>ES存储的是一个JSON格式的文档，其中包含多个字段，每个字段会有自己的倒排索引</p><h3 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h3><p>分词是将文本转换成一系列单词（Term or Token）的过程，也可以叫文本分析，在ES里面称为Analysis</p><p><img src="http://image.laijianfeng.org/20180803_232909.png" alt="image"></p><h4 id="分词器"><a href="#分词器" class="headerlink" title="分词器"></a>分词器</h4><p>分词器是ES中专门处理分词的组件，英文为Analyzer，它的组成如下：</p><ul><li>Character Filters：针对原始文本进行处理，比如去除html标签</li><li>Tokenizer：将原始文本按照一定规则切分为单词</li><li>Token Filters：针对Tokenizer处理的单词进行再加工，比如转小写、删除或增新等处理</li></ul><p>分词器调用顺序<br><img src="http://image.laijianfeng.org/20180803_234047.png" alt="image"></p><h3 id="Analyze-API"><a href="#Analyze-API" class="headerlink" title="Analyze API"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis.html" target="_blank" rel="noopener">Analyze API</a></h3><p>ES提供了一个可以测试分词的API接口，方便验证分词效果，endpoint是_analyze</p><ul><li>可以直接指定analyzer进行测试</li></ul><p><img src="http://image.laijianfeng.org/20180803_234732.png" alt="image"></p><ul><li>可以直接指定索引中的字段进行测试</li></ul><pre><code>POST test_index/doc{  &quot;username&quot;: &quot;whirly&quot;,  &quot;age&quot;:22}POST test_index/_analyze{  &quot;field&quot;: &quot;username&quot;,  &quot;text&quot;: [&quot;hello world&quot;]}</code></pre><ul><li>可以自定义分词器进行测试</li></ul><pre><code>POST _analyze{  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;filter&quot;: [&quot;lowercase&quot;],  &quot;text&quot;: [&quot;Hello World&quot;]}</code></pre><h3 id="预定义的分词器"><a href="#预定义的分词器" class="headerlink" title="预定义的分词器"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-analyzers.html" target="_blank" rel="noopener">预定义的分词器</a></h3><p>ES自带的分词器有如下：</p><ul><li>Standard Analyzer<ul><li>默认分词器</li><li>按词切分，支持多语言</li><li>小写处理</li></ul></li><li>Simple Analyzer<ul><li>按照非字母切分</li><li>小写处理</li></ul></li><li>Whitespace Analyzer<ul><li>空白字符作为分隔符</li></ul></li><li>Stop Analyzer<ul><li>相比Simple Analyzer多了去除请用词处理</li><li>停用词指语气助词等修饰性词语，如the, an, 的， 这等</li></ul></li><li>Keyword Analyzer<ul><li>不分词，直接将输入作为一个单词输出</li></ul></li><li>Pattern Analyzer<ul><li>通过正则表达式自定义分隔符</li><li>默认是\W+，即非字词的符号作为分隔符</li></ul></li><li>Language Analyzer<ul><li>提供了30+种常见语言的分词器</li></ul></li></ul><p>示例：停用词分词器</p><pre><code>POST _analyze{  &quot;analyzer&quot;: &quot;stop&quot;,  &quot;text&quot;: [&quot;The 2 QUICK Brown Foxes jumped over the lazy dog&#39;s bone.&quot;]}</code></pre><p>结果</p><pre><code>{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;quick&quot;,      &quot;start_offset&quot;: 6,      &quot;end_offset&quot;: 11,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 1    },    {      &quot;token&quot;: &quot;brown&quot;,      &quot;start_offset&quot;: 12,      &quot;end_offset&quot;: 17,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 2    },    {      &quot;token&quot;: &quot;foxes&quot;,      &quot;start_offset&quot;: 18,      &quot;end_offset&quot;: 23,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 3    },    {      &quot;token&quot;: &quot;jumped&quot;,      &quot;start_offset&quot;: 24,      &quot;end_offset&quot;: 30,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 4    },    {      &quot;token&quot;: &quot;over&quot;,      &quot;start_offset&quot;: 31,      &quot;end_offset&quot;: 35,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 5    },    {      &quot;token&quot;: &quot;lazy&quot;,      &quot;start_offset&quot;: 40,      &quot;end_offset&quot;: 44,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 7    },    {      &quot;token&quot;: &quot;dog&quot;,      &quot;start_offset&quot;: 45,      &quot;end_offset&quot;: 48,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 8    },    {      &quot;token&quot;: &quot;s&quot;,      &quot;start_offset&quot;: 49,      &quot;end_offset&quot;: 50,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 9    },    {      &quot;token&quot;: &quot;bone&quot;,      &quot;start_offset&quot;: 51,      &quot;end_offset&quot;: 55,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 10    }  ]}</code></pre><h3 id="中文分词"><a href="#中文分词" class="headerlink" title="中文分词"></a>中文分词</h3><ul><li>难点<ul><li>中文分词指的是将一个汉字序列切分为一个一个的单独的词。在英文中，单词之间以空格作为自然分界词，汉语中词没有一个形式上的分界符</li><li>上下文不同，分词结果迥异，比如交叉歧义问题</li></ul></li><li>常见分词系统<ul><li><a href="https://github.com/medcl/elasticsearch-analysis-ik" target="_blank" rel="noopener">IK</a>：实现中英文单词的切分，可自定义词库，支持热更新分词词典</li><li><a href="https://github.com/sing1ee/elasticsearch-jieba-plugin" target="_blank" rel="noopener">jieba</a>：支持分词和词性标注，支持繁体分词，自定义词典，并行分词等</li><li><a href="https://github.com/hankcs/HanLP" target="_blank" rel="noopener">Hanlp</a>：由一系列模型与算法组成的Java工具包，目标是普及自然语言处理在生产环境中的应用</li><li><a href="https://github.com/microbun/elasticsearch-thulac-plugin" target="_blank" rel="noopener">THUAC</a>：中文分词和词性标注</li></ul></li></ul><h4 id="安装ik中文分词插件"><a href="#安装ik中文分词插件" class="headerlink" title="安装ik中文分词插件"></a>安装ik中文分词插件</h4><pre><code># 在Elasticsearch安装目录下执行命令，然后重启esbin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.3.0/elasticsearch-analysis-ik-6.3.0.zip# 如果由于网络慢，安装失败，可以先下载好zip压缩包，将下面命令改为实际的路径，执行，然后重启esbin/elasticsearch-plugin install file:///path/to/elasticsearch-analysis-ik-6.3.0.zip</code></pre><ul><li>ik测试 - ik_smart</li></ul><pre><code>POST _analyze{  &quot;analyzer&quot;: &quot;ik_smart&quot;,  &quot;text&quot;: [&quot;公安部：各地校车将享最高路权&quot;]}# 结果{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;公安部&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 3,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 0    },    {      &quot;token&quot;: &quot;各地&quot;,      &quot;start_offset&quot;: 4,      &quot;end_offset&quot;: 6,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 1    },    {      &quot;token&quot;: &quot;校车&quot;,      &quot;start_offset&quot;: 6,      &quot;end_offset&quot;: 8,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 2    },    {      &quot;token&quot;: &quot;将&quot;,      &quot;start_offset&quot;: 8,      &quot;end_offset&quot;: 9,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 3    },    {      &quot;token&quot;: &quot;享&quot;,      &quot;start_offset&quot;: 9,      &quot;end_offset&quot;: 10,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 4    },    {      &quot;token&quot;: &quot;最高&quot;,      &quot;start_offset&quot;: 10,      &quot;end_offset&quot;: 12,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 5    },    {      &quot;token&quot;: &quot;路&quot;,      &quot;start_offset&quot;: 12,      &quot;end_offset&quot;: 13,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 6    },    {      &quot;token&quot;: &quot;权&quot;,      &quot;start_offset&quot;: 13,      &quot;end_offset&quot;: 14,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 7    }  ]}</code></pre><ul><li>ik测试 - ik_max_word</li></ul><pre><code>POST _analyze{  &quot;analyzer&quot;: &quot;ik_max_word&quot;,  &quot;text&quot;: [&quot;公安部：各地校车将享最高路权&quot;]}# 结果{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;公安部&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 3,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 0    },    {      &quot;token&quot;: &quot;公安&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 2,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 1    },    {      &quot;token&quot;: &quot;部&quot;,      &quot;start_offset&quot;: 2,      &quot;end_offset&quot;: 3,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 2    },    {      &quot;token&quot;: &quot;各地&quot;,      &quot;start_offset&quot;: 4,      &quot;end_offset&quot;: 6,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 3    },    {      &quot;token&quot;: &quot;校车&quot;,      &quot;start_offset&quot;: 6,      &quot;end_offset&quot;: 8,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 4    },    {      &quot;token&quot;: &quot;将&quot;,      &quot;start_offset&quot;: 8,      &quot;end_offset&quot;: 9,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 5    },    {      &quot;token&quot;: &quot;享&quot;,      &quot;start_offset&quot;: 9,      &quot;end_offset&quot;: 10,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 6    },    {      &quot;token&quot;: &quot;最高&quot;,      &quot;start_offset&quot;: 10,      &quot;end_offset&quot;: 12,      &quot;type&quot;: &quot;CN_WORD&quot;,      &quot;position&quot;: 7    },    {      &quot;token&quot;: &quot;路&quot;,      &quot;start_offset&quot;: 12,      &quot;end_offset&quot;: 13,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 8    },    {      &quot;token&quot;: &quot;权&quot;,      &quot;start_offset&quot;: 13,      &quot;end_offset&quot;: 14,      &quot;type&quot;: &quot;CN_CHAR&quot;,      &quot;position&quot;: 9    }  ]}</code></pre><ul><li><p>ik两种分词模式ik_max_word 和 ik_smart 什么区别?</p><ul><li><p>ik_max_word: 会将文本做最细粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,和,国国,国歌”，会穷尽各种可能的组合；</p></li><li><p>ik_smart: 会做最粗粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,国歌”。</p></li></ul></li></ul><h3 id="自定义分词"><a href="#自定义分词" class="headerlink" title="自定义分词"></a>自定义分词</h3><p>当自带的分词无法满足需求时，可以自定义分词，通过定义Character Filters、Tokenizer和Token Filters实现</p><h4 id="Character-Filters"><a href="#Character-Filters" class="headerlink" title="Character Filters"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-charfilters.html" target="_blank" rel="noopener">Character Filters</a></h4><ul><li>在Tokenizer之前对原始文本进行处理，比如增加、删除或替换字符等</li><li>自带的如下:<ul><li>HTML Strip Character Filter：去除HTML标签和转换HTML实体</li><li>Mapping Character Filter：进行字符替换操作</li><li>Pattern Replace Character Filter：进行正则匹配替换</li></ul></li><li>会影响后续tokenizer解析的position和offset信息</li></ul><h4 id="Character-Filters测试"><a href="#Character-Filters测试" class="headerlink" title="Character Filters测试"></a>Character Filters测试</h4><pre><code>POST _analyze{  &quot;tokenizer&quot;: &quot;keyword&quot;,  &quot;char_filter&quot;: [&quot;html_strip&quot;],  &quot;text&quot;: [&quot;&lt;p&gt;I&amp;apos;m so &lt;b&gt;happy&lt;/b&gt;!&lt;/p&gt;&quot;]}# 结果{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;&quot;&quot;I&#39;m so happy!&quot;&quot;&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 32,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 0    }  ]}</code></pre><h4 id="Tokenizers"><a href="#Tokenizers" class="headerlink" title="Tokenizers"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenizers.html" target="_blank" rel="noopener">Tokenizers</a></h4><ul><li>将原始文本按照一定规则切分为单词（term or token）</li><li>自带的如下：<ul><li>standard 按照单词进行分割</li><li>letter 按照非字符类进行分割</li><li>whitespace 按照空格进行分割</li><li>UAX URL Email 按照standard进行分割，但不会分割邮箱和URL</li><li>Ngram 和 Edge NGram 连词分割</li><li>Path Hierarchy 按照文件路径进行分割</li></ul></li></ul><h4 id="Tokenizers-测试"><a href="#Tokenizers-测试" class="headerlink" title="Tokenizers 测试"></a>Tokenizers 测试</h4><pre><code>POST _analyze{  &quot;tokenizer&quot;: &quot;path_hierarchy&quot;,  &quot;text&quot;: [&quot;/path/to/file&quot;]}# 结果{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;/path&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 5,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 0    },    {      &quot;token&quot;: &quot;/path/to&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 8,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 0    },    {      &quot;token&quot;: &quot;/path/to/file&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 13,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 0    }  ]}</code></pre><h4 id="Token-Filters"><a href="#Token-Filters" class="headerlink" title="Token Filters"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenfilters.html" target="_blank" rel="noopener">Token Filters</a></h4><ul><li>对于tokenizer输出的单词（term）进行增加、删除、修改等操作</li><li>自带的如下：<ul><li>lowercase 将所有term转为小写</li><li>stop 删除停用词</li><li>Ngram 和 Edge NGram 连词分割</li><li>Synonym 添加近义词的term</li></ul></li></ul><h4 id="Token-Filters测试"><a href="#Token-Filters测试" class="headerlink" title="Token Filters测试"></a>Token Filters测试</h4><pre><code>POST _analyze{  &quot;text&quot;: [    &quot;a Hello World!&quot;  ],  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;filter&quot;: [    &quot;stop&quot;,    &quot;lowercase&quot;,    {      &quot;type&quot;: &quot;ngram&quot;,      &quot;min_gram&quot;: 4,      &quot;max_gram&quot;: 4    }  ]}# 结果{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;hell&quot;,      &quot;start_offset&quot;: 2,      &quot;end_offset&quot;: 7,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 1    },    {      &quot;token&quot;: &quot;ello&quot;,      &quot;start_offset&quot;: 2,      &quot;end_offset&quot;: 7,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 1    },    {      &quot;token&quot;: &quot;worl&quot;,      &quot;start_offset&quot;: 8,      &quot;end_offset&quot;: 13,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 2    },    {      &quot;token&quot;: &quot;orld&quot;,      &quot;start_offset&quot;: 8,      &quot;end_offset&quot;: 13,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 2    }  ]}</code></pre><h4 id="自定义分词-1"><a href="#自定义分词-1" class="headerlink" title="自定义分词"></a>自定义分词</h4><p>自定义分词需要在索引配置中设定 char_filter、tokenizer、filter、analyzer等</p><p>自定义分词示例:</p><ul><li>分词器名称：my_custom\</li><li>过滤器将token转为大写</li></ul><pre><code>PUT test_index_1{  &quot;settings&quot;: {    &quot;analysis&quot;: {      &quot;analyzer&quot;: {        &quot;my_custom_analyzer&quot;: {          &quot;type&quot;:      &quot;custom&quot;,          &quot;tokenizer&quot;: &quot;standard&quot;,          &quot;char_filter&quot;: [            &quot;html_strip&quot;          ],          &quot;filter&quot;: [            &quot;uppercase&quot;,            &quot;asciifolding&quot;          ]        }      }    }  }}</code></pre><h4 id="自定义分词器测试"><a href="#自定义分词器测试" class="headerlink" title="自定义分词器测试"></a>自定义分词器测试</h4><pre><code>POST test_index_1/_analyze{  &quot;analyzer&quot;: &quot;my_custom_analyzer&quot;,  &quot;text&quot;: [&quot;&lt;p&gt;I&amp;apos;m so &lt;b&gt;happy&lt;/b&gt;!&lt;/p&gt;&quot;]}# 结果{  &quot;tokens&quot;: [    {      &quot;token&quot;: &quot;I&#39;M&quot;,      &quot;start_offset&quot;: 3,      &quot;end_offset&quot;: 11,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 0    },    {      &quot;token&quot;: &quot;SO&quot;,      &quot;start_offset&quot;: 12,      &quot;end_offset&quot;: 14,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 1    },    {      &quot;token&quot;: &quot;HAPPY&quot;,      &quot;start_offset&quot;: 18,      &quot;end_offset&quot;: 27,      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,      &quot;position&quot;: 2    }  ]}</code></pre><h4 id="分词使用说明"><a href="#分词使用说明" class="headerlink" title="分词使用说明"></a>分词使用说明</h4><p>分词会在如下两个时机使用：</p><ul><li>创建或更新文档时(Index Time)，会对相应的文档进行分词处理</li><li>查询时（Search Time），会对查询语句进行分词<ul><li>查询时通过analyzer指定分词器</li><li>通过index mapping设置search_analyzer实现</li><li>一般不需要特别指定查询时分词器，直接使用索引分词器即可，否则会出现无法匹配的情况</li></ul></li></ul><h4 id="分词使用建议"><a href="#分词使用建议" class="headerlink" title="分词使用建议"></a>分词使用建议</h4><ul><li>明确字段是否需要分词，不需要分词的字段就将type设置为keyword，可以节省空间和提高写性能</li><li>善用_analyze API，查看文档的分词结果</li></ul><blockquote><p>更多内容请访问我的个人网站： <a href="http://laijianfeng.org">http://laijianfeng.org</a><br>参考文档： </p><ol><li>elasticsearch 官方文档</li><li><a href="https://coding.imooc.com/class/181.html" target="_blank" rel="noopener">慕课网 Elastic Stack从入门到实践</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ElasticSearch初体验</title>
      <link href="/2018/08/ElasticSearch%E5%88%9D%E4%BD%93%E9%AA%8C/"/>
      <url>/2018/08/ElasticSearch%E5%88%9D%E4%BD%93%E9%AA%8C/</url>
      <content type="html"><![CDATA[<h3 id="需要明白的问题"><a href="#需要明白的问题" class="headerlink" title="需要明白的问题"></a>需要明白的问题</h3><ol><li>什么是倒排索引？它的组成是什么？</li><li>常见的相关性算分方法有哪些？</li><li>为什么查询语句没有返回预期的文档？</li><li>常用的数据类型有哪些？Text和Keyword的区别是什么？</li><li>集群是如何搭建起来的？是如何实现故障转移的？</li><li>Shard具体是由什么组成的？</li></ol><h2 id="Elastic-Stack"><a href="#Elastic-Stack" class="headerlink" title="Elastic Stack"></a>Elastic Stack</h2><p>构建在开源基础之上, Elastic Stack 让您能够安全可靠地获取任何来源、任何格式的数据，并且能够实时地对数据进行搜索、分析和可视化</p><p><strong>Elasticsearch</strong> 是基于 JSON 的分布式搜索和分析引擎，专为实现水平扩展、高可用和管理便捷性而设计。</p><p><strong>Kibana</strong> 能够以图表的形式呈现数据，并且具有可扩展的用户界面，供您全方位配置和管理 Elastic Stack。</p><p><strong>Logstash</strong> 是动态数据收集管道，拥有可扩展的插件生态系统，能够与 Elasticsearch 产生强大的协同作用。</p><p><strong>Beats</strong> 是轻量型采集器的平台，从边缘机器向 Logstash 和 Elasticsearch 发送数据。</p><h3 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/_basic_concepts.html" target="_blank" rel="noopener">基础概念</a></h3><ul><li>文档 Document ：用户存储在ES中的数据文档</li><li>索引 Index ：由具有一些相同字段的文档的集合</li><li>类型 Type :  允许将不同类型的文档存储在同一索引中，6.0开始官方不允许在一个index下建立多个type，统一type名称：doc</li><li>节点 Node ：一个Elasticsearch的运行实例，是集群的构成单元，存储部分或全部数据，并参与集群的索引和搜索功能</li><li>集群 Cluster ：由一个或多个节点组成的集合，共同保存所有的数据，对外提供服务（包括跨所有节点的联合索引和搜索功能等）</li><li>分片 Shards ：分片是为了解决存储大规模数据的问题，将数据切分分别存储到不同的分片中</li><li>副本 Replicas ：副本可以在分片或节点发生故障时提高可用性，而且由于可以在所有副本上进行并行搜索，所以也可以提高集群的吞吐量</li><li>近实时 Near Realtime(NRT)：从索引文档到可搜索文档的时间有一点延迟（通常为一秒）</li></ul><blockquote><p>note:</p><ol><li>在创建索引的时候如果没有配置索引Mapping，一个索引默认有5个shard和1个副本，一个索引总共有10个shard（算上副本shard）</li><li>Elasticsearch 的shard实际上是一个Lucene索引，截止Lucene-5843，一个Lucene索引限制的最大文档数为2,147,483,519 (= Integer.MAX_VALUE - 128)</li></ol></blockquote><h3 id="安装Elasticsearch-amp-Kibana"><a href="#安装Elasticsearch-amp-Kibana" class="headerlink" title="安装Elasticsearch &amp; Kibana"></a>安装Elasticsearch &amp; Kibana</h3><p>ES和Kibana的安装很简单，前提需要先安装好Java8，然后执行以下命令即可</p><h5 id="elasticsearch单节点最简安装"><a href="#elasticsearch单节点最简安装" class="headerlink" title="elasticsearch单节点最简安装"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/_installation.html" target="_blank" rel="noopener">elasticsearch单节点最简安装</a></h5><pre><code># 在Ubuntu16.04上安装，方式有很多种，选择二进制压缩包的方式安装# 1. 在普通用户家目录下，下载压缩包curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.3.2.tar.gz# 2. 解压tar -xvf elasticsearch-6.3.2.tar.gz# 3. 移动至/opt目录下sudo mv elasticsearch-6.3.2 /opt# 4. 修改配置文件elasticsearch.yml中的 network.host 值为 0.0.0.0，其他的配置参考官方文档cd /opt/elasticsearch-6.3.2vi config/elasticsearch.yml# 5. 启动单节点，然后浏览器访问host:9200即可看到ES集群信息bin/elasticsearch</code></pre><p><img src="http://image.laijianfeng.org/20180815_153244.png" alt="image"></p><h5 id="kibana最简安装"><a href="#kibana最简安装" class="headerlink" title="kibana最简安装"></a><a href="https://www.elastic.co/guide/en/kibana/current/targz.html" target="_blank" rel="noopener">kibana最简安装</a></h5><pre><code>wget https://artifacts.elastic.co/downloads/kibana/kibana-6.3.2-linux-x86_64.tar.gzshasum -a 512 kibana-6.3.2-linux-x86_64.tar.gz tar -xzf kibana-6.3.2-linux-x86_64.tar.gzsudo mv kibana-6.3.2-linux-x86_64 /optcd /opt/kibana-6.3.2-linux-x86_64# 修改 config/kibana.yml中 server.host: 0.0.0.0# 启动Kibana，访问 host:5601即可进入kibana界面</code></pre><p><img src="http://image.laijianfeng.org/20180815_153435.png" alt="image"></p><h3 id="交互方式-Rest-API"><a href="#交互方式-Rest-API" class="headerlink" title="交互方式 Rest API"></a>交互方式 Rest API</h3><p>Elasticsearch集群对外提供RESTful API</p><ul><li>Curl命令行</li><li>Kibana Devtools</li><li>Java API</li><li>其他各种API，如Python API等</li></ul><blockquote><p>note:<br>我们后面主要使用 Kibana Devtools 这种交互方式</p></blockquote><p><img src="http://image.laijianfeng.org/20180815_154136.png" alt="image"></p><h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html" target="_blank" rel="noopener">数据类型</a></h3><ul><li>字符串： text（分词）, keyword（不分词）</li><li>数值型： long, integer, byte, double, float, half_float, scaled_float</li><li>布尔： boolean</li><li>日期： date</li><li>二进制： binary</li><li>范围类型： integer_range, float_range, long_range, double_range, date_range</li><li>复杂数据类型： Array, Object, Nested</li><li>地理： geo_point， geo_shape</li><li>专业： ip，completion， token_count， murmur3， Percolator， join</li><li>组合的</li></ul><h3 id="探索ES集群"><a href="#探索ES集群" class="headerlink" title="探索ES集群"></a>探索ES集群</h3><p>Check your cluster, node, and index health, status, and statistics<br>Administer your cluster, node, and index data and metadata<br>Perform CRUD (Create, Read, Update, and Delete) and search operations against your indexes<br>Execute advanced search operations such as paging, sorting, filtering, scripting, aggregations, and many others</p><h5 id="使用-cat-API探索集群的健康情况"><a href="#使用-cat-API探索集群的健康情况" class="headerlink" title="使用_cat API探索集群的健康情况"></a>使用_cat API探索集群的健康情况</h5><pre><code>GET /_cat/health?v# 结果epoch      timestamp cluster       status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent1534319381 15:49:41  elasticsearch green           3         3    118  59    0    0        0             0                  -                100.0%</code></pre><p>集群的健康状态(status)有三种:</p><ul><li>green：一切正常（集群功能齐全）</li><li>yellow：所有数据都可用，但存在一些副本未分配（群集功能齐全）</li><li>red：一些数据由于某种原因不可用（群集部分功能失效）</li></ul><h5 id="查看节点信息"><a href="#查看节点信息" class="headerlink" title="查看节点信息"></a>查看节点信息</h5><pre><code>GET /_cat/nodes?v# 结果（我的ES集群安装了三个节点）ip            heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name10.100.97.207           30          96  13    0.15    0.08     0.08 mdi       *      master10.100.97.246           68          96   3    0.00    0.00     0.00 mdi       -      hadoop210.100.98.22            15          97   2    0.00    0.02     0.04 mdi       -      hadoop3</code></pre><h5 id="查看索引信息"><a href="#查看索引信息" class="headerlink" title="查看索引信息"></a>查看索引信息</h5><pre><code>GET /_cat/indices?v# 结果health status index                           uuid                   pri rep docs.count docs.deleted store.size pri.store.sizegreen  open   logstash-2015.05.20             4BjPjpq6RhOSCNUPMsY0MQ   5   1       4750            0     46.8mb         24.5mbgreen  open   logstash-2015.05.18             mDkUKHSWR0a8UeZlKzts8Q   5   1       4631            0     45.6mb         23.8mbgreen  open   hockey                          g1omiazvRSOE117w_uy_wA   5   1         11            0     45.3kb         22.6kbgreen  open   .kibana                         AGdo8im_TxC04ARexUxqxw   1   1        143           10    665.6kb        332.8kbgreen  open   shakespeare                     5009bDa7T16f5qTeyOdTlw   5   1     111396            0     43.9mb           22mbgreen  open   logstash-2015.05.19             az4Jen4nT7-J9yRYpZ0A9A   5   1       4624            0     44.7mb         23.1mb...</code></pre><h3 id="操作数据"><a href="#操作数据" class="headerlink" title="操作数据"></a>操作数据</h3><h5 id="插入文档并查询"><a href="#插入文档并查询" class="headerlink" title="插入文档并查询"></a>插入文档并查询</h5><pre><code># 插入一个文档PUT /customer/_doc/1?pretty{  &quot;name&quot;: &quot;John Doe&quot;}# 结果{  &quot;_index&quot;: &quot;customer&quot;,  &quot;_type&quot;: &quot;_doc&quot;,  &quot;_id&quot;: &quot;1&quot;,  &quot;_version&quot;: 1,  &quot;result&quot;: &quot;updated&quot;,  &quot;_shards&quot;: {    &quot;total&quot;: 2,    &quot;successful&quot;: 2,    &quot;failed&quot;: 0  },  &quot;_seq_no&quot;: 1,  &quot;_primary_term&quot;: 1}# 查询该文档GET /customer/_doc/1#结果{  &quot;_index&quot;: &quot;customer&quot;,  &quot;_type&quot;: &quot;_doc&quot;,  &quot;_id&quot;: &quot;1&quot;,  &quot;_version&quot;: 1,  &quot;found&quot;: true,  &quot;_source&quot;: {    &quot;name&quot;: &quot;John Doe&quot;  }}</code></pre><blockquote><p>note:</p><ol><li><code>customer</code> 为索引名，<code>_doc</code> 为type，1为文档_id，需要注意的是：在es6.x建议索引的type值固定为<code>_doc</code>，在之后的版本将删除type了；文档id若不指定，es会自动分配一个_id给文档</li><li>插入文档后，查看索引信息<code>GET /_cat/indices?v</code>可以看到多了 customer 的索引信息</li><li>文档结果，_source字段是原始的json内容，其他的为文档元数据</li></ol></blockquote><h5 id="文档元数据"><a href="#文档元数据" class="headerlink" title="文档元数据"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-fields.html" target="_blank" rel="noopener">文档元数据</a></h5><p>用于标注文档的元信息</p><ul><li>_index: 文档所在的索引名</li><li>_type: 文档所在的类型名</li><li>_id: 文档的唯一id</li><li>_uid: 组合id，由_type和_id组成（6.0开始_type不再起作用，同_id一样）</li><li>_source: 文档的原始json数据，可以从这里获取每个字段的内容</li><li>_all: 整合所有字段内容到该字段，默认禁用</li><li>_routing 默认值为 _id，决定文档存储在哪个shard上：<code>shard_num = hash(_routing) % num_primary_shards</code> </li></ul><h5 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h5><pre><code>DELETE customer#结果{  &quot;acknowledged&quot;: true}GET /_cat/indices?v# 再次查看索引信息，可以发现 customer 不存在，已被删除</code></pre><h5 id="更新文档"><a href="#更新文档" class="headerlink" title="更新文档"></a>更新文档</h5><pre><code>PUT /customer/_doc/1?pretty{  &quot;name&quot;: &quot;John Doe&quot;}POST /customer/_doc/1/_update{  &quot;doc&quot;: { &quot;name&quot;: &quot;Jane Doe&quot; }}POST /customer/_doc/1/_update{  &quot;doc&quot;: { &quot;name&quot;: &quot;Jane Doe&quot;, &quot;age&quot;: 20 }}# 可以看到 \_version的值一直在增加</code></pre><h5 id="删除文档"><a href="#删除文档" class="headerlink" title="删除文档"></a>删除文档</h5><pre><code>DELETE /customer/_doc/2</code></pre><h5 id="批量操作"><a href="#批量操作" class="headerlink" title="批量操作"></a>批量操作</h5><p>es提供了<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/docs-bulk.html" target="_blank" rel="noopener">_bulk API</a>供批量操作，可以提高索引、更新、删除等操作的效率</p><p>_bulk操作的类型有四种：</p><ul><li>index 索引：若已存在，则覆盖，文档不存在则创建</li><li>create 创建：文档不存在则异常</li><li>delete 删除</li><li>update 更新</li></ul><pre><code># _bulk 任务：# 1. index创建 customer索引下id为3的文档# 2. delete删除 customer索引下id为3的文档# 3. create创建 customer索引下id为3的文档# 4. update更新 customer索引下id为3的文档POST _bulk{&quot;index&quot;:{&quot;_index&quot;:&quot;customer&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;3&quot;}}{&quot;name&quot;:&quot;whirly&quot;}{&quot;delete&quot;:{&quot;_index&quot;:&quot;customer&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;3&quot;}}{&quot;create&quot;:{&quot;_index&quot;:&quot;customer&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;3&quot;}}{&quot;name&quot;:&quot;whirly2&quot;}{&quot;update&quot;:{&quot;_index&quot;:&quot;customer&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;3&quot;}}{&quot;doc&quot;:{&quot;name&quot;:&quot;whirly3&quot;}}</code></pre><p><img src="http://image.laijianfeng.org/20180815_164226.png" alt="image"></p><blockquote><p>note:</p><ol><li>批量查询用的是 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/docs-multi-get.html" target="_blank" rel="noopener">Multi Get API</a></li></ol></blockquote><h3 id="探索数据"><a href="#探索数据" class="headerlink" title="探索数据"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/_exploring_your_data.html" target="_blank" rel="noopener">探索数据</a></h3><p>一个<a href="https://raw.githubusercontent.com/elastic/elasticsearch/master/docs/src/test/resources/accounts.json" target="_blank" rel="noopener">简单的数据集</a>，数据结构如下：</p><pre><code>{    &quot;account_number&quot;: 0,    &quot;balance&quot;: 16623,    &quot;firstname&quot;: &quot;Bradshaw&quot;,    &quot;lastname&quot;: &quot;Mckenzie&quot;,    &quot;age&quot;: 29,    &quot;gender&quot;: &quot;F&quot;,    &quot;address&quot;: &quot;244 Columbus Place&quot;,    &quot;employer&quot;: &quot;Euron&quot;,    &quot;email&quot;: &quot;bradshawmckenzie@euron.com&quot;,    &quot;city&quot;: &quot;Hobucken&quot;,    &quot;state&quot;: &quot;CO&quot;}</code></pre><p>导入这个简单的数据集到es中</p><pre><code># 下载wget https://raw.githubusercontent.com/elastic/elasticsearch/master/docs/src/test/resources/accounts.json# 导入curl -H &quot;Content-Type: application/json&quot; -XPOST &quot;localhost:9200/bank/_doc/_bulk?pretty&amp;refresh&quot; --data-binary &quot;@accounts.json&quot;</code></pre><p>上述命令是通过 _bulk API 将 account.json 的内容插入 bank 索引中，type 为 _doc</p><pre><code># account.json的内容:{&quot;index&quot;:{&quot;_id&quot;:&quot;1&quot;}}{&quot;account_number&quot;:1,&quot;balance&quot;:39225,&quot;firstname&quot;:&quot;Amber&quot;,&quot;lastname&quot;:&quot;Duke&quot;,&quot;age&quot;:32,&quot;gender&quot;:&quot;M&quot;,&quot;address&quot;:&quot;880 Holmes Lane&quot;,&quot;employer&quot;:&quot;Pyrami&quot;,&quot;email&quot;:&quot;amberduke@pyrami.com&quot;,&quot;city&quot;:&quot;Brogan&quot;,&quot;state&quot;:&quot;IL&quot;}...# 导入完成后可以看到 bank 索引已存在 1000 条数据GET bank/_search</code></pre><h5 id="查询数据-API"><a href="#查询数据-API" class="headerlink" title="查询数据 API"></a>查询数据 API</h5><p>任务：查询所有数据，根据 account_number 字段升序排序</p><ol><li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/search-uri-request.html#search-uri-request" target="_blank" rel="noopener">URI Search 方式</a></p><pre><code>GET /bank/_search?q=*&amp;sort=account_number:asc&amp;pretty</code></pre></li><li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/search-request-body.html" target="_blank" rel="noopener">Request Body Search</a> 方式</p><pre><code>GET /bank/_search{&quot;query&quot;: { &quot;match_all&quot;: {} },&quot;sort&quot;: [ { &quot;account_number&quot;: &quot;asc&quot; }]}</code></pre></li></ol><p>结果</p><pre><code>{  &quot;took&quot;: 41,  &quot;timed_out&quot;: false,  &quot;_shards&quot;: {    &quot;total&quot;: 5,    &quot;successful&quot;: 5,    &quot;skipped&quot;: 0,    &quot;failed&quot;: 0  },  &quot;hits&quot;: {    &quot;total&quot;: 1000,    &quot;max_score&quot;: null,    &quot;hits&quot;: [      {        &quot;_index&quot;: &quot;bank&quot;,        &quot;_type&quot;: &quot;account&quot;,        &quot;_id&quot;: &quot;0&quot;,        &quot;_score&quot;: null,        &quot;_source&quot;: {          &quot;account_number&quot;: 0,          &quot;balance&quot;: 16623,          &quot;firstname&quot;: &quot;Bradshaw&quot;,          &quot;lastname&quot;: &quot;Mckenzie&quot;,          &quot;age&quot;: 29,          &quot;gender&quot;: &quot;F&quot;,          &quot;address&quot;: &quot;244 Columbus Place&quot;,          &quot;employer&quot;: &quot;Euron&quot;,          &quot;email&quot;: &quot;bradshawmckenzie@euron.com&quot;,          &quot;city&quot;: &quot;Hobucken&quot;,          &quot;state&quot;: &quot;CO&quot;        },        &quot;sort&quot;: [          0        ]      }...    ]  }}</code></pre><p>各个参数意思：</p><ul><li>took：本次查询耗费的时间（单位：毫秒）</li><li>timed_out：是否超时</li><li>_shards：本次查询搜索的 shard 的数量，包括成功的和失败的</li><li>hits：查询结果</li><li>hits.total：匹配的文档数量</li><li>hits.hits：匹配的文档，默认返回10个文档</li><li>hits.sort：排序的值</li><li>_score：文档的得分</li><li>hits.max_score：所有文档最高的得分</li></ul><h3 id="简要介绍-Query-DSL"><a href="#简要介绍-Query-DSL" class="headerlink" title="简要介绍 Query DSL"></a>简要介绍 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/query-dsl.html" target="_blank" rel="noopener">Query DSL</a></h3><p>这个Elasticsearch提供的基于 json 的查询语言，我们通过一个小任务来了解一下</p><p>任务要求：</p><ol><li>查询 firstname 中为 “R” 开头，年龄在 20 到 30 岁之间的人物信息</li><li>限制返回的字段为 firstname,city,address,email,balance</li><li>根据年龄倒序排序，返回前十条数据</li><li>对 firstname 字段进行高亮显示</li><li>同时求所有匹配人物的 平均balance</li></ol><pre><code>GET bank/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: [        {          &quot;match_phrase_prefix&quot;: {            &quot;firstname&quot;: &quot;R&quot;          }        }      ],      &quot;filter&quot;: {        &quot;range&quot;: {          &quot;age&quot;: {            &quot;gte&quot;: 20,            &quot;lte&quot;: 30          }        }      }    }  },  &quot;from&quot;: 0,  &quot;size&quot;: 10,  &quot;sort&quot;: [    {      &quot;age&quot;: {        &quot;order&quot;: &quot;desc&quot;      }    }  ],  &quot;_source&quot;: [    &quot;firstname&quot;,    &quot;city&quot;,    &quot;address&quot;,    &quot;email&quot;,    &quot;balance&quot;  ],  &quot;highlight&quot;: {    &quot;fields&quot;: {      &quot;firstname&quot;: {}    }  },  &quot;aggs&quot;: {    &quot;avg_age&quot;: {      &quot;avg&quot;: {        &quot;field&quot;: &quot;balance&quot;      }    }  }}</code></pre><p>其中：</p><ul><li>query 部分可以写各种查询条件</li><li>from, size 设置要返回的文档的起始序号</li><li>sort 设置排序规则</li><li>_source 设置要返回的文档的字段</li><li>highlight 设置高亮的字段</li><li>aggs 为设置聚合统计规则</li></ul><h5 id="更多查询示例"><a href="#更多查询示例" class="headerlink" title="更多查询示例"></a>更多查询示例</h5><ul><li>match_all 查询 bank 索引所有文档</li></ul><pre><code>GET /bank/_search{  &quot;query&quot;: {    &quot;match_all&quot;: {}  },  &quot;size&quot;: 2}</code></pre><ul><li>match 全文搜索，查询 address 字段值为 mill lane 的所有文档</li></ul><pre><code>GET /bank/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;address&quot;: &quot;mill lane&quot;    }  }}</code></pre><ul><li>match_phrase 短语匹配</li></ul><pre><code>GET /bank/_search{  &quot;query&quot;: {    &quot;match_phrase&quot;: {      &quot;address&quot;: &quot;mill lane&quot;    }  }}</code></pre><blockquote><p>note:<br>match 和 match_phrase 的区别：</p><ul><li>match 中会分词，将 mill lane 拆分为 mill 和 lane， 实际查询 address 中有 mill <strong>或者</strong> lane 的文档</li><li>match_phrase：将 mill lane 作为一个整体查询，实际查询 address 中有 mill lane 的文档</li></ul></blockquote><ul><li>布尔查询（多条件查询）</li></ul><pre><code>GET /bank/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: [        { &quot;match&quot;: { &quot;age&quot;: &quot;40&quot; } }      ],      &quot;must_not&quot;: [        { &quot;match&quot;: { &quot;state&quot;: &quot;ID&quot; } }      ]    }  }}</code></pre><ul><li>布尔查询-过滤<br>查询 bank 索引中 balance 值在 20000 到 30000 之间的文档</li></ul><pre><code>GET /bank/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: { &quot;match_all&quot;: {} },      &quot;filter&quot;: {        &quot;range&quot;: {          &quot;balance&quot;: {            &quot;gte&quot;: 20000,            &quot;lte&quot;: 30000          }        }      }    }  }}</code></pre><ul><li>聚合查询<br>对所有文档进行聚合，state 值相同的分到同一个桶里，分桶结果命名为 group_by_state ，再对每个桶里的文档的 balance 字段求平均值，结果命名为 average_balance，通过设置 size 的值为0，不返回任何文档内容</li></ul><pre><code>GET /bank/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;group_by_state&quot;: {      &quot;terms&quot;: {        &quot;field&quot;: &quot;state.keyword&quot;      },      &quot;aggs&quot;: {        &quot;average_balance&quot;: {          &quot;avg&quot;: {            &quot;field&quot;: &quot;balance&quot;          }        }      }    }  }}</code></pre><p>分别计算 age 值在 20~30 ，30~40，40~50 三个年龄段的男和女的平均存款balance</p><pre><code>GET /bank/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;group_by_age&quot;: {      &quot;range&quot;: {        &quot;field&quot;: &quot;age&quot;,        &quot;ranges&quot;: [          {            &quot;from&quot;: 20,            &quot;to&quot;: 30          },          {            &quot;from&quot;: 30,            &quot;to&quot;: 40          },          {            &quot;from&quot;: 40,            &quot;to&quot;: 50          }        ]      },      &quot;aggs&quot;: {        &quot;group_by_gender&quot;: {          &quot;terms&quot;: {            &quot;field&quot;: &quot;gender.keyword&quot;          },          &quot;aggs&quot;: {            &quot;average_balance&quot;: {              &quot;avg&quot;: {                &quot;field&quot;: &quot;balance&quot;              }            }          }        }      }    }  }}</code></pre><blockquote><p>参考文档：</p><ol><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started.html" target="_blank" rel="noopener">elasticsearch 官方文档 Getting Started</a></li><li>慕课网 <a href="https://coding.imooc.com/class/181.html" target="_blank" rel="noopener">Elastic Stack从入门到实践</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>使用hexo+github pages搭建博客</title>
      <link href="/2018/05/%E4%BD%BF%E7%94%A8hexo-github-pages%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/"/>
      <url>/2018/05/%E4%BD%BF%E7%94%A8hexo-github-pages%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</url>
      <content type="html"><![CDATA[<h2 id="为什么写博客"><a href="#为什么写博客" class="headerlink" title="为什么写博客"></a>为什么写博客</h2><p>就如我在博客主页上所说，主要有三点：</p><ol><li>记录与分享</li><li>锤炼技术，提高写作能力和表达能力</li><li>树立个人品牌，提高影响力</li></ol><p>而在此博客之前，我在CSDN上写过一些博客，截止于2018年5月23日，个人资料如下：</p><img title="小旋锋的csdn个人资料" alt="小旋锋的csdn个人资料" src="http://image.laijianfeng.org/static/images/201805/20180523_232554.png"><p>当我在CSDN上写博客的时候，几乎每天都会去看看阅读量增加了多少，排名增加了多少，又增加了几个粉丝或者新评论，每每都会带给我兴奋感，让我感到写博客其实是一件很有意义的事情，并且反过来推动我学习和记录，写更多的博客。</p><p>而为什么现在要重新整一个博客呢？主要是因为之前CSDN的博客更多的是转载和低质量的，而博主即将毕业，正走在程序员的职业道路上，需要树立个人品牌，写博客是目前对我比较合适且能做到的方式。</p><p>而独立博客自由度更高，第三方博客平台推广则更快，所以最终决定采用独立博客首发，第三方平台分发引流的模式。</p><p>我的第三方平台账户：</p><ul><li><a href="https://www.jianshu.com/u/ae269fd3620a" target="_blank" rel="noopener">小旋锋的简书</a></li><li><a href="https://blog.csdn.net/wwwdc1012" target="_blank" rel="noopener">小旋锋的csdn博客</a></li><li><a href="https://www.zhihu.com/people/whirlys/activities" target="_blank" rel="noopener">小旋锋的知乎</a></li><li><a href="http://image.laijianfeng.org/static/images/201805/20180523_230522.jpg" target="_blank" rel="noopener">小旋锋的微信公众号</a></li></ul><h2 id="Hexo主题选择"><a href="#Hexo主题选择" class="headerlink" title="Hexo主题选择"></a>Hexo主题选择</h2><p><a href="https://hexo.io/zh-cn/docs/index.html" target="_blank" rel="noopener">Hexo</a> 是一个快速、简洁且高效的博客框架，可托管于github pages，可免去维护服务器的麻烦，博主们可更专注于内容的创作，并且Hexo主题众多，总有一款适合你。</p><p>我对主题的要求主要有：</p><ol><li>不要太大众</li><li>大气美观</li><li>功能齐全</li></ol><p>经过了几天的搜索之后，筛选了几个比较满意的Hexo主题如下：</p><ol><li><a href="http://blog.zhangruipeng.me/hexo-theme-hueman/about/index.html" target="_blank" rel="noopener">Hueman</a></li><li><a href="http://jacman.wuchong.me/2014/11/20/how-to-use-jacman/" target="_blank" rel="noopener">jacman</a></li><li><a href="https://www.haomwei.com/" target="_blank" rel="noopener">大道至简</a></li><li><a href="http://threehao.com/" target="_blank" rel="noopener">Loo’s Blog</a></li><li><a href="http://yelog.org/2017/03/23/3-hexo-instruction/" target="_blank" rel="noopener">3-hexo</a></li></ol><p>最终选择了 <a href="http://yelog.org/2017/03/23/3-hexo-instruction/" target="_blank" rel="noopener">3-hexo</a> 这款主题，当然还有很多不错的主题。</p><h2 id="搭建步骤"><a href="#搭建步骤" class="headerlink" title="搭建步骤"></a>搭建步骤</h2><h3 id="1-根据-Hexo官网-步骤安装-git，node-js"><a href="#1-根据-Hexo官网-步骤安装-git，node-js" class="headerlink" title="1. 根据 Hexo官网 步骤安装 git，node.js"></a>1. 根据 <a href="https://hexo.io/zh-cn/docs/index.html" target="_blank" rel="noopener">Hexo官网</a> 步骤安装 git，node.js</h3><h3 id="2-安装Hexo"><a href="#2-安装Hexo" class="headerlink" title="2. 安装Hexo"></a>2. 安装Hexo</h3><pre><code class="javascript">npm install -g hexo-cli</code></pre><p>安装 Hexo 完成后，新建一个博客的主目录，然后执行以下命令：</p><pre><code class="shell">hexo init &lt;folder&gt;cd &lt;folder&gt;npm install</code></pre><p>新建完成之后该目录的目录结构如下:</p><p>.</p><p>├── _config.yml        # 网站的 配置 信息</p><p>├── package.json        # 应用程序的信息</p><p>├── scaffolds            # 模板文件夹</p><p>├── source            # 博文源文件目录</p><p>|   ├── _drafts        # 草稿文件夹</p><p>|   └── _posts            # 博文文件夹</p><p>└── themes            # 主题文件夹</p><p>再执行以下命令，访问 <a href="http://localhost:4000" target="_blank" rel="noopener">http://localhost:4000</a> 即可快速体验Hexo</p><pre><code class="shell">hexo ghexo s</code></pre><img src="http://image.laijianfeng.org/static/images/201805/20180524_003246.png"><h3 id="3-根据-Hexo文档-对网站做一些简单的配置，然后修改主题为-3-hexo"><a href="#3-根据-Hexo文档-对网站做一些简单的配置，然后修改主题为-3-hexo" class="headerlink" title="3. 根据 Hexo文档 对网站做一些简单的配置，然后修改主题为 3-hexo"></a>3. 根据 <a href="https://hexo.io/zh-cn/docs/configuration.html" target="_blank" rel="noopener">Hexo文档</a> 对网站做一些简单的配置，然后修改主题为 <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank" rel="noopener">3-hexo</a></h3><p>安装</p><pre><code class="shell">git clone https://github.com/yelog/hexo-theme-3-hexo.git themes/3-hexo</code></pre><p>修改hexo根目录的_config.yml中的theme参数</p><pre><code class="javascript">theme: 3-hexo</code></pre><p>然后执行 hexo clean &amp; hexo g &amp; hexo s 即可看到效果</p><p>更多的主题配置可见 <a href="http://yelog.org/2017/03/23/3-hexo-instruction/" target="_blank" rel="noopener">3-hexo使用说明</a></p><h3 id="4-配置-github-pages"><a href="#4-配置-github-pages" class="headerlink" title="4. 配置 github pages"></a>4. 配置 github pages</h3><p>到github上创建一个新的空仓库，名字格式为 账户名.github.io，譬如我的github账户名是 <a href="https://github.com/whirlys" target="_blank" rel="noopener">whirlys</a>，所以我的github pages 仓库的名字应为 whirlys.github.io</p><p>安装插件</p><pre><code class="shell">npm install hexo-deployer-git --save</code></pre><p>然后配置 Hexo根目录的 _config.yml，xxx为你的用户名，注意还需要加入你的 github 用户名和密码，不然后面推送失败（但是上传代码时注意防止密码泄露）</p><pre><code class="shell">deploy:  type: git  repo: https://[github用户名]:[github密码]@github.com/xxx/xxx.github.io.git  branch: master</code></pre><p>如果你是第一次配置 github 远程仓库，你还须将你电脑的ssh key 配置到 github 上，具体可参考 <a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001374385852170d9c7adf13c30429b9660d0eb689dd43a000" target="_blank" rel="noopener">git远程仓库</a></p><p>推送Hexo到github</p><pre><code class="shell">hexo deploy</code></pre><p>访问 xxx.github.io 即可看到你的 github pages 博客了</p><h3 id="5-绑定私有域名"><a href="#5-绑定私有域名" class="headerlink" title="5. 绑定私有域名"></a>5. 绑定私有域名</h3><p>我的域名为 laijianfeng.org，是一年前买 腾讯云1元学生主机 时送的，当然可以选择其他域名提供商</p><p>在 hexo source 目录下新建一个 CNAME 文件（没有后缀名），在文件里填入你的域名，然后 hexo d 推送到github</p><p>登录域名提供商网站，进入域名解析页面，分别添加两条记录</p><table><thead><tr><th>主机记录</th><th>记录类型</th><th>线路类型</th><th>记录值</th></tr></thead><tbody><tr><td>@</td><td>CNAME</td><td>默认</td><td>xxx.github.io</td></tr><tr><td>www</td><td>CNAME</td><td>默认</td><td><a href="http://www.xxx.github.io" target="_blank" rel="noopener">www.xxx.github.io</a></td></tr></tbody></table><p>等待十分钟之后，访问你的域名即可跳转到你的博客</p><h3 id="6-其他的配置"><a href="#6-其他的配置" class="headerlink" title="6. 其他的配置"></a>6. 其他的配置</h3><ul><li>接入评论，3-hexo主题中已经集成了多种评论，我选择了gitment，具体的配置参考 <a href="http://yelog.org/2017/06/26/gitment/" target="_blank" rel="noopener">完美替代多说-gitment</a>，如果gitment遇到问题，譬如报Error：validation failed异常，可参考 <a href="http://xichen.pub/2018/01/31/2018-01-31-gitment/" target="_blank" rel="noopener">添加Gitment评论系统踩过的坑</a> 以及 <a href="https://github.com/imsun/gitment/issues" target="_blank" rel="noopener">gitment issue</a>上的解决方法</li><li>使用七牛云图床，参考 <a href="http://skyhacks.org/2017/08/02/UseQiniudnToStorePic/" target="_blank" rel="noopener">使用七牛为Hexo存储图片</a> 和 <a href="https://github.com/gyk001/hexo-qiniu-sync" target="_blank" rel="noopener">Hexo七牛同步插件</a></li><li>代码高亮，字数统计，参考 <a href="http://yelog.org/2017/03/07/3-hexo/" target="_blank" rel="noopener">Hexo主题3-hexo</a></li></ul>]]></content>
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 博客 </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
